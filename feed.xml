<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Cizixs Write Here</title>
  
  <subtitle>Container, Microservice, Python, Go, Reading, Life, And Love.</subtitle>
  <link href="/feed.xml" rel="self"/>
  
  <link href="http://cizixs.com/"/>
  <updated>2018-11-21T07:18:02.000Z</updated>
  <id>http://cizixs.com/</id>
  
  <author>
    <name>Cizixs Wu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>什么是 istio</title>
    <link href="http://cizixs.com/2018/08/26/what-is-istio/"/>
    <id>http://cizixs.com/2018/08/26/what-is-istio/</id>
    <published>2018-08-25T16:00:00.000Z</published>
    <updated>2018-11-21T07:18:02.000Z</updated>
    
    <content type="html"><![CDATA[<p>如果你比较关注新兴技术的话，那么很可能在不同的地方听说过 istio，并且知道它和 service mesh 有着牵扯。这篇文章是我之前在公司内部做过的分享，可以作为了解 istio  的入门介绍，了解什么是 istio，istio 为什么最近这么火，以及 istio 能够我们带来什么好处。</p><h2 id="什么是-istio？"><a href="#什么是-istio？" class="headerlink" title="什么是 istio？"></a>什么是 istio？</h2><p>官方对 istio 的介绍浓缩成了一句话：</p><blockquote><p>An open platform to connect,  secure, control and observe services.</p></blockquote><p>翻译过来，就是”连接、安全加固、控制和观察服务的开放平台“。开放平台就是指它本身是开源的，服务对应的是微服务，也可以粗略地理解为单个应用。<br>中间的四个动词就是 istio 的主要功能，官方也各有一句话的说明。这里再阐释一下：</p><ul><li>连接（Connect）：智能控制服务之间的调用流量，能够实现灰度升级、AB 测试和红黑部署等功能</li><li>安全加固（Secure）：自动为服务之间的调用提供认证、授权和加密</li><li>控制（Control）：应用用户定义的 policy，保证资源在消费者中公平分配</li><li>观察（Observe）：查看服务运行期间的各种数据，比如日志、监控和 tracing，了解服务的运行情况</li></ul><p><img src="https://ws1.sinaimg.cn/large/006tNbRwgy1fumckfqh4ej31kw0sb4c7.jpg" alt="what is istio"></p><p>虽然听起来非常高级，功能非常强大，但是一股脑出现这么多名词，还都是非常虚的概念，说了跟没说一样。要想理解上面这几句话的含义，我们还是从头说起，先聊聊 service mesh。</p><p>NOTE：其实 istio 的源头是微服务，但这又是一个比较大的话题，目前可以参考网络上各种文章。如果有机会，我们再来聊聊微服务。</p><h2 id="什么是-service-mesh"><a href="#什么是-service-mesh" class="headerlink" title="什么是 service mesh"></a>什么是 service mesh</h2><p>一般介绍 service mesh 的文章都会从网络层的又一个抽象说起，把 service mesh 看做建立在 TCP 层之上的微服务层。我这次换个思路，从 service mesh 的技术根基——网络代理来分析。</p><p>说起网络代理，我们会想到翻墙，如果对软件架构比较熟悉的会想到 Nginx 等反向代理软件。其实网络代理的范围比较广，可以肯定的说，有网络访问的地方就会有代理的存在。</p><p>Wikipedia 对代理的定义如下：</p><blockquote><p>In computer networks, a proxy server is a server (a computer system or an application) that acts as an intermediary for requests from clients seeking resources from other servers.</p></blockquote><p><strong>NOTE</strong>：代理可以是嵌套的，也就是说通信双方 A、B 中间可以多多层代理，而这些代理的存在有可能对  A、B 是透明的。</p><p>简单来说，网络代理可以简单类比成现实生活中的中介，本来需要通信的双方因为各种原因在中间再加上一道关卡。本来双方就能完成的通信，为何非要多此一举呢？那是因为代理可以为整个通信带来更多的功能，比如：</p><ul><li>拦截：代理可以选择性拦截传输的网络流量，比如一些公司限制员工在上班的时候不能访问某些游戏或者电商网站，再比如把我们和世界隔离开来的 GFW，还有在数据中心中拒绝恶意访问的网关</li><li>统计：既然所有的流量都经过代理，那么代理也可以用来统计网络中的数据信息，比如了解哪些人在访问哪些网站，通信的应答延迟等</li><li>缓存：如果通信双方比较”远“，访问比较慢，那么代理可以把最近访问的数据缓存在本地，后面的访问不用访问后端来做到加速。CDN 就是这个功能的典型场景</li><li>分发：如果某个通信方有多个服务器后端，代理可以根据某些规则来选择如何把流量发送给多个服务器，也就是我们常说的负载均衡功能。比如著名的 Nginx 软件</li><li>跳板：如果 A、B 双方因为某些原因不能直接访问，而代理可以和双方通信，那么通过代理，双方可以绕过原来的限制进行通信。这应该广大中国网民比较熟悉的场景</li><li>注入：既然代理可以看到流量，那么它也可以修改网络流量，可以自动在收到的流量中添加一些数据，比如有些宽带提供商的弹窗广告</li><li>……</li></ul><p><img src="https://ws4.sinaimg.cn/large/006tNbRwgy1fume2oh274j30vg0glgmg.jpg" alt="what is proxy"></p><p>不是要讲 service mesh 吗？为什么扯了一堆代理的事情？因为 service mesh 可以看做是传统代理的升级版，用来解决现在微服务框架中出现的问题，可以把 service mesh 看做是<strong>分布式</strong>的<strong>微服务</strong>代理。</p><p>在传统模式下，代理一般是集中式的单独的服务器，所有的请求都要先通过代理，然后再流入转发到实际的后端。而在 service mesh 中，代理变成了分布式的，它常驻在了应用的身边（最常见的就是 kubernetes sidecar 模式，每一个应用的 pod 中都运行着一个代理，负责流量相关的事情）。这样的话，应用所有的流量都被代理接管，那么这个代理就能做到上面提到的所有可能的事情，从而带来无限的想象力。</p><p><img src="https://ws2.sinaimg.cn/large/006tNbRwgy1fumf6f3ighj30vu0gjt95.jpg" alt="side car proxy"></p><p>此外，原来的代理都是基于网络流量的，一般都是工作在 IP 或者 TCP 层，很少关心具体的应用逻辑。但是 service mesh 中，代理会知道整个集群的所有应用信息，并且额外添加了热更新、注入服务发现、降级熔断、认证授权、超时重试、日志监控等功能，让这些通用的功能不必每个应用都自己实现，放在代理中即可。换句话说，service mesh 中的代理对微服务中的应用做了定制化的改进！</p><p><img src="https://ws2.sinaimg.cn/large/006tNbRwgy1fumeg2zckgj30vc0gf761.jpg" alt="distributed micro-service proxy"></p><p>就这样，借着微服务和容器化的东风，传统的代理摇身一变，成了如今炙手可热的 service mesh。应用微服务之后，每个单独的微服务都会有很多副本，而且可能会有多个版本，这么多微服务之间的相互调用和管理非常复杂，但是有了 service mesh，我们可以把这块内容统一在代理层。</p><p><img src="https://ws3.sinaimg.cn/large/006tNbRwgy1fumdcd3gp1g31hc0teb2a.gif" alt="service mesh architecture"></p><p>有了看起来四通八达的分布式代理，我们还需要对这些代理进行统一的管理。手动更新每个代理的配置，对代理进行升级或者维护是个不可持续的事情，在前面的基础上，在加上一个控制中心，一个完整的 service mesh 就成了。管理员只需要根据控制中心的 API 来配置整个集群的应用流量、安全规则即可，代理会自动和控制中心打交道根据用户的期望改变自己的行为。</p><p><img src="https://ws2.sinaimg.cn/large/006tNbRwgy1fumf44jsmwj30w40i1djt.jpg" alt="service mesh with control plane"></p><p><strong>NOTE</strong>：所以你也可以理解 service mesh 中的代理会抢了 Nginx 的生意，这也是为了 Nginx 也要开始做 NginMesh 的原因。</p><h2 id="再来看-istio"><a href="#再来看-istio" class="headerlink" title="再来看 istio"></a>再来看 istio</h2><p>了解了 service mesh 的概念，我们再来看 istio ，也许就会清楚很多。首先来看 istio 官方给出的架构图：</p><p><img src="https://ws4.sinaimg.cn/large/006tNbRwgy1fumf8ajs4oj30s90g7did.jpg" alt="istio architecture"></p><p>可以看到，istio 就是我们上述提到的 service mesh 架构的一种实现，服务之间的通信（比如这里的 Service A 访问 Service B）会通过代理（默认是 envoy）来进行，而且中间的网络协议支持 HTTP/1.1，HTTP/2，gRPC 或者 TCP，可以说覆盖了主流的通信协议。控制中心做了进一步的系分，分成了 Pilot、Mixer、和 Citadel，它们的各自功能如下：</p><ul><li>Pilot：为  envoy 提供了服务发现，流量管理和智能路由（AB测试、金丝雀发布等），以及错误处理（超时、重试、熔断）功能。用户通过 pilot 的 API 管理网络相关的资源对象，pilot 会根据用户的配置和服务的信息把网络流量管理变成 envoy 能识别的格式分发到各个 sidecar 代理中。</li><li>Mixer：为整个集群执行访问控制（哪些用户可以访问哪些服务）和 policy 管理（rate limit，quota 等），并且收集代理观察到的服务之间的流量统计数据</li><li>Citadel：为服务之间提供认证和证书管理，可以让服务自动升级成 TLS 协议</li></ul><p>代理会和控制中心通信，一方面可以获取需要的服务之间的信息，另一方面也可以汇报服务调用的 metrics 数据。知道 istio 的核心架构，再来看看它的功能描述就非常容易理解了。</p><ul><li>连接：控制中心可以从集群中获取所有服务的信息，并分发给代理，这样代理就能根据用户的期望来完成服务之间的通信（自动地服务发现、负载均衡、流量控制等）</li><li>安全加固：因为所有的流量都是通过代理的，那么代理接收到不加密的网络流量之后，可以自动做一次封装，把它升级成安全的加密流量</li><li>控制：用户可以配置各种规则（比如 RBAC 授权、白名单、rate limit 或者 quota 等），当代理发现服务之间的访问不符合这些规则，就直接拒绝掉</li><li>观察：所有的流量都经过代理，因此代理对整个集群的访问情况知道得一清二楚，它把这些数据上报到控制中心，那么管理员就能观察到整个集群的流量情况了</li></ul><h2 id="istio-解决什么问题"><a href="#istio-解决什么问题" class="headerlink" title="istio 解决什么问题"></a>istio 解决什么问题</h2><p>虽然看起来非常炫酷，功能也很强大，但是一个架构和产品出来都是要解决具体的问题。所以这部分我们来看看微服务架构中的难题以及 istio 给出的答案。</p><p>首先，原来的单个应用拆分成了许多分散的微服务，它们之间相互调用才能完成一个任务，而一旦某个过程出错（组件越多，出错的概率也就越大），就非常难以排查。</p><p>用户请求出现问题无外乎两个问题：错误和响应慢。如果请求错误，那么我们需要知道那个步骤出错了，这么多的微服务之间的调用怎么确定哪个有调用成功？哪个没有调用成功呢？如果是请求响应太慢，我们就需要知道到底哪些地方比较慢？整个链路的调用各阶段耗时是多少？哪些调用是并发执行的，哪些是串行的？这些问题需要我们能非常清楚整个集群的调用以及流量情况。</p><p><img src="https://ws2.sinaimg.cn/large/006tNbRwgy1fundnum6cwj31510m375v.jpg" alt="微服务故障排查困难"></p><p>此外，微服务拆分成这么多组件，如果单个组件出错的概率不变，那么整体有地方出错的概率就会增大。服务调用的时候如果没有错误处理机制，那么会导致非常多的问题。比如如果应用没有配置超时参数，或者配置的超时参数不对，则会导致请求的调用链超时叠加，对于用户来说就是请求卡住了；如果没有重试机制，那么因为各种原因导致的偶发故障也会导致直接返回错误给用户，造成不好的用户体验；此外，如果某些节点异常（比如网络中断，或者负载很高），也会导致应用整体的响应时间变成，集群服务应该能自动避开这些节点上的应用；最后，应用也是会出现 bug 的，各种 bug 会导致某些应用不可访问。这些问题需要每个应用能及时发现问题，并做好对应的处理措施。</p><p><img src="https://ws3.sinaimg.cn/large/006tNbRwgy1fundt2q5alj31kw0sh7cx.jpg" alt="应用容错性"></p><p>应用数量的增多，对于日常的应用发布来说也是个难题。应用的发布需要非常谨慎，如果应用都是一次性升级的，出现错误会导致整个线上应用不可用，影响范围太大；而且，很多情况我们需要同时存在不同的版本，使用 AB 测试验证哪个版本更好；如果版本升级改动了 API，并且互相有依赖，那么我们还希望能自动地控制发布期间不同版本访问不同的地址。这些问题都需要智能的流量控制机制。</p><p><img src="https://ws4.sinaimg.cn/large/006tNbRwgy1fune76uq2wj31550jb0uc.jpg" alt="应用发布困难"></p><p>为了保证整个系统的安全性，每个应用都需要实现一套相似的认证、授权、HTTPS、限流等功能。一方面大多数的程序员对安全相关的功能并不擅长或者感兴趣，另外这些完全相似的内容每次都要实现一遍是非常冗余的。这个问题需要一个能自动管理安全相关内容的系统。</p><p><img src="https://ws2.sinaimg.cn/large/006tNbRwgy1funelzxf46j31kw0qu79g.jpg" alt="应用安全"></p><p>上面提到的这些问题是不是非常熟悉？它们就是 istio 尝试解决的问题，如果把上面的问题和 istio 提供的功能做个映射，你会发现它们是非常匹配，毕竟 istio 就是为了解决微服务的这些问题才出现的。</p><p><img src="https://ws2.sinaimg.cn/large/006tNbRwgy1funghiputng31hc0te7ip.gif" alt="istio solves microservice issues"></p><h2 id="用什么姿势接入-istio？"><a href="#用什么姿势接入-istio？" class="headerlink" title="用什么姿势接入 istio？"></a>用什么姿势接入 istio？</h2><p>虽然 istio 能解决那么多的问题，但是引入 istio 并不是没有代价的。最大的问题是 istio 的复杂性，强大的功能也意味着 istio 的概念和组件非常多，要想理解和掌握 istio ，并成功在生产环境中部署需要非常详细的规划。一般情况下，集群管理团队需要对 kubernetes 非常熟悉，了解常用的使用模式，然后采用逐步演进的方式把 istio 的功能分批掌控下来。</p><p>第一步，自然是在测试环境搭建一套 istio 的集群，理解所有的核心概念和组件。了解 istio 提供的接口和资源，知道它们的用处，思考如何应用到自己的场景中，然后是熟悉 istio 的源代码，跟进社区的 issues，了解目前还存在的 issues 和 bug，思考如何规避或者修复。这一步是基础，需要积累到 istio 安装部署、核心概念、功能和缺陷相关的知识，为后面做好准备。</p><p>第二步，可以考虑接入 istio 的观察性功能，包括 logging、tracing、metrics 数据。应用部署到集群中，选择性地（一般是流量比较小，影响范围不大的应用）为一些应用开启 istio 自动注入功能，接管应用的流量，并安装 prometheus 和 zipkin 等监控组件，收集系统所有的监控数据。这一步可以试探性地了解 istio 对应用的性能影响，同时建立服务的性能测试基准，发现服务的性能瓶颈，帮助快速定位应用可能出现的问题。此时，这些功能可以是对应用开发者透明的，只需要集群管理员感知，这样可以减少可能带来的风险。</p><p>第三步，为应用配置 timeout 超时参数、自动重试、熔断和降级等功能，增加服务的容错性。这样可以避免某些应用错误进行这些配置导致问题的出现，这一步完成后需要通知所有的应用开发者删除掉在应用代码中对应的处理逻辑。这一步需要开发者和集群管理员同时参与。</p><p>第四步，和 ingress、helm、应用上架等相关组件和流程对接，使用 istio 接管应用的升级发布流程。让开发者可以配置应用灰度发布升级的策略，支持应用的蓝绿发布、金丝雀发布以及 AB 测试。</p><p>第五步，接入安全功能。配置应用的 TLS 互信，添加 RBAC 授权，设置应用的流量限制，提升整个集群的安全性。因为安全的问题配置比较繁琐，而且优先级一般会比功能性相关的特性要低，所以这里放在了最后。</p><p>当然这个步骤只是一个参考，每个公司需要根据自己的情况、人力、时间和节奏来调整，找到适合自己的方案。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Istio 的架构在数据中心和集群管理中非常常见，每个 agent 分布在各个节点上（可以是服务器、虚拟机、pod、容器）负责接收指令并执行，以及汇报信息；控制中心负责汇聚整个集群的信息，并提供 API 让用户对集群进行管理。kubernetes 也是类似的架构，SDN（Software Defined Network） 也是如此。相信以后会有更多类似架构的出现，这是因为数据中心要管理的节点越来越多，我们需要把任务执行分布到各节点（agent 负责的功能），同时也需要对整个集群进行管理和控制（control plane 的功能），完全去中心化的架构是无法满足后面这个要求的。</p><p>Istio 的出现为负责的微服务架构减轻了很多的负担，开发者不用关心服务调用的超时、重试、rate limit 的实现，服务之间的安全、授权也自动得到了保证；集群管理员也能够很方便地发布应用（AB 测试和灰度发布），并且能清楚看到整个集群的运行情况。</p><p>但是这并不表明有了 istio 就可以高枕无忧了，istio 只是把原来分散在应用内部的复杂性统一抽象出来放到了统一的地方，并没有让原来的复杂消失不见。因此我们需要维护 istio 整个集群，而 istio 的架构比较复杂，尤其是它一般还需要架在 kubernetes 之上，这两个系统都比较复杂，而且它们的稳定性和性能会影响到整个集群。因此再采用 isito 之前，必须做好清楚的规划，权衡它带来的好处是否远大于额外维护它的花费，需要有相关的人才对整个网络、kubernetes 和 istio 都比较了解才行。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://istio.io/docs/concepts/what-is-istio/" target="_blank" rel="noopener">Istio / What is Istio?</a>：istio 官网上对 istio 进行介绍的文档</li><li><a href="http://philcalcado.com/2017/08/03/pattern_service_mesh.html" target="_blank" rel="noopener">Pattern: Service Mesh</a>：service mesh pattern 详解的文章</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;如果你比较关注新兴技术的话，那么很可能在不同的地方听说过 istio，并且知道它和 service mesh 有着牵扯。这篇文章是我之前在公司内部做过的分享，可以作为了解 istio  的入门介绍，了解什么是 istio，istio 为什么最近这么火，以及 istio
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="container" scheme="http://cizixs.com/tags/container/"/>
    
      <category term="istio" scheme="http://cizixs.com/tags/istio/"/>
    
      <category term="microservice" scheme="http://cizixs.com/tags/microservice/"/>
    
      <category term="servicemesh" scheme="http://cizixs.com/tags/servicemesh/"/>
    
  </entry>
  
  <entry>
    <title>serverless 平台 knative 简介</title>
    <link href="http://cizixs.com/2018/08/25/knative-serverless-platform/"/>
    <id>http://cizixs.com/2018/08/25/knative-serverless-platform/</id>
    <published>2018-08-24T16:00:00.000Z</published>
    <updated>2018-11-21T05:47:56.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是-Knative？"><a href="#什么是-Knative？" class="headerlink" title="什么是 Knative？"></a>什么是 Knative？</h2><p><a href="https://github.com/knative" target="_blank" rel="noopener">knative</a> 是谷歌开源的 serverless 架构方案，旨在提供一套简单易用的 serverless 方案，把 serverless 标准化。目前参与的公司主要是 Google、Pivotal、IBM、Red Hat，2018年7月24日才刚刚对外发布，当前还处于快速发展的阶段。</p><p>这是 Google Cloud Platform 宣布 knative 时给出的介绍：</p><blockquote><p>Developed in close partnership with Pivotal, IBM, Red Hat, and SAP, Knative pushes Kubernetes-based computing forward by providing the building blocks you need to build and deploy modern, container-based serverless applications.</p></blockquote><p>可以看出，knative 是为了解决容器为核心的 serverless 应用的构建、部署和运行的问题。</p><p>serverless 的概念已经出现蛮久了，为了理解 serverless, 可以从应用开发者的角度来看，使用 serverless 框架之后，应用开发者的整个操作流程就变成了：</p><pre class=" language-bash"><code class="language-bash">~ <span class="token comment" spellcheck="true"># 编写 code 和 configuration 文件</span>~ <span class="token comment" spellcheck="true"># faascli build</span>~ <span class="token comment" spellcheck="true"># faascli deploy</span>~ <span class="token comment" spellcheck="true"># curl http://myapp.com/hello</span>hello, world from Awesome FaaS App<span class="token operator">!</span></code></pre><p>可以看到用户只需要编写代码（或者函数），以及配置文件（如何 build、运行以及访问等声明式信息），然后运行 build 和 deploy 就能把应用自动部署到集群（可以是公有云，也可以是私有的集群）。</p><p>其他事情都是 serverless 平台（比如这里的 knative）自动处理的，这些事情包括：</p><ul><li>自动完成代码到容器的构建</li><li>把应用（或者函数）和特定的事件进行绑定：当事件发生时，自动触发应用（或者函数）</li><li>网络的路由和流量控制</li><li>应用的自动伸缩</li></ul><p>和标准化的 FaaS 不同（只运行特定标准的 Function 代码），knative 期望能够运行所有的 workload : traditional application、function、container。</p><p>knative 建立在 kubernetes 和 istio 平台之上，使用 kubernetes 提供的容器管理能力（deployment、replicaset、和 pods等），以及 istio 提供的网络管理功能（ingress、LB、dynamic route等）。</p><p><img src="https://i.loli.net/2018/08/25/5b811d40e22bb.png" alt="knative with istio and kubernetes"></p><h2 id="knative-核心概念和原理"><a href="#knative-核心概念和原理" class="headerlink" title="knative 核心概念和原理"></a>knative 核心概念和原理</h2><p>为了实现 serverless 应用的管理，knative 把整个系统分成了三个部分：</p><ul><li>Build：构建系统，把用户定义的函数和应用 build 成容器镜像</li><li>Serving：服务系统，用来配置应用的路由、升级策略、自动扩缩容等功能</li><li>Eventing：事件系统，用来自动完成事件的绑定和触发</li></ul><h3 id="Build-构建系统"><a href="#Build-构建系统" class="headerlink" title="Build 构建系统"></a>Build 构建系统</h3><p>build 的功能是把用户的代码自动化构建成容器镜像，初次听起来很奇怪，有了 docker 之后有一个 Dockerfile 不就能构建容器了吗？为什么还需要一个新的 Build 系统？</p><p>Knative 的特别之处在于两点：一是它的构建完全是在 kubernetes 中进行的，和整个 kubernetes 生态结合更紧密；另外，它旨在提供一个通用的标准化的构建组件，可以作为其他更大系统中的一部分。</p><p>正如官方文档中的说的那样，是为了定义标准化、可移植、可重用、性能高效的构建方法：</p><blockquote><p>The goal of a Knative build is to provide a standard, portable, reusable, and performance optimized method for defining and running on-cluster container image builds.</p></blockquote><p>Knative 提供了 <code>Build</code> CRD 对象，让用户可以通过 yaml 文件定义构建过程。一个典型的 <code>Build</code> 配置文件如下：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> build.knative.dev/v1alpha1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Build<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> example<span class="token punctuation">-</span>build<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">serviceAccountName</span><span class="token punctuation">:</span> build<span class="token punctuation">-</span>auth<span class="token punctuation">-</span>example  <span class="token key atrule">source</span><span class="token punctuation">:</span>    <span class="token key atrule">git</span><span class="token punctuation">:</span>      <span class="token key atrule">url</span><span class="token punctuation">:</span> https<span class="token punctuation">:</span>//github.com/example/build<span class="token punctuation">-</span>example.git      <span class="token key atrule">revision</span><span class="token punctuation">:</span> master  <span class="token key atrule">steps</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> ubuntu<span class="token punctuation">-</span>example    <span class="token key atrule">image</span><span class="token punctuation">:</span> ubuntu    <span class="token key atrule">args</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"ubuntu-build-example"</span><span class="token punctuation">,</span> <span class="token string">"SECRETS-example.md"</span><span class="token punctuation">]</span>  <span class="token key atrule">steps</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">image</span><span class="token punctuation">:</span> gcr.io/example<span class="token punctuation">-</span>builders/build<span class="token punctuation">-</span>example    <span class="token key atrule">args</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'echo'</span><span class="token punctuation">,</span> <span class="token string">'hello-example'</span><span class="token punctuation">,</span> <span class="token string">'build'</span><span class="token punctuation">]</span></code></pre><p>其中，<code>serviceAccountName</code> 是构建过程中需要用到的密码和认证信息（比如连接到 git repo 的 SSH keys、push 镜像到 registry 的用户名和密码等）；<br><code>source</code> 是代码信息，比如这里的 git 地址和分支；<code>steps</code> 是真正运行过程中的各个步骤。<br>这个示例中的步骤只是作为 demo，真正的构建过程一般是 pull 代码、 build 镜像和 push镜像到 registry 等逻辑。</p><p>因为大部分的构建过程都是一致的，因此 knative 还提供了 <code>Build template</code> 的概念，<br>Build template 封装了预先定义好的构建过程（就是封装了上面的 <code>steps</code> 过程），并提供了非常简单的配置参数来使用。</p><p>使用 build template 构建容器镜像就更简单了，只需要提供代码的地址和镜像名字即可，比如下面是使用 Google kaniko 模板构建 github 源码的 yaml 文件（需要在代码根目录存在 Dockerfile 文件）：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> build.knative.dev/v1alpha1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Build<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> kaniko<span class="token punctuation">-</span>build<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">serviceAccountName</span><span class="token punctuation">:</span> build<span class="token punctuation">-</span>bot  <span class="token key atrule">source</span><span class="token punctuation">:</span>    <span class="token key atrule">git</span><span class="token punctuation">:</span>      <span class="token key atrule">url</span><span class="token punctuation">:</span> https<span class="token punctuation">:</span>//github.com/my<span class="token punctuation">-</span>user/my<span class="token punctuation">-</span>repo      <span class="token key atrule">revision</span><span class="token punctuation">:</span> master  <span class="token key atrule">template</span><span class="token punctuation">:</span>    <span class="token key atrule">name</span><span class="token punctuation">:</span> kaniko    <span class="token key atrule">arguments</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> IMAGE      <span class="token key atrule">value</span><span class="token punctuation">:</span> us.gcr.io/my<span class="token punctuation">-</span>project/my<span class="token punctuation">-</span>app</code></pre><h3 id="Serving：服务系统"><a href="#Serving：服务系统" class="headerlink" title="Serving：服务系统"></a>Serving：服务系统</h3><p>serving 的核心功能是让应用运行起来提供服务。</p><p>虽然听起来很简单，但这里包括了很多的事情：</p><ul><li>自动化启动和销毁容器</li><li>根据名字生成网络访问相关的 service、ingress 等对象</li><li>监控应用的请求，并自动扩缩容</li><li>支持蓝绿发布、回滚功能，方便应用发布流程</li></ul><p>knative serving 功能是基于 kubernetes 和 istio 开发的，它使用 kubernetes 来管理容器（deployment、pod），istio 来管理网络路由（VirtualService、DestinationRule）。</p><p>因为 kubernetes 和 istio 本身的概念非常多，理解和管理起来比较困难，knative 在此之上提供了更高一层的抽象（这些对应是基于 kubernetes 的 CRD 实现的）。这些抽象出来的概念对应的关系如下图：</p><p><img src="https://i.loli.net/2018/08/25/5b81211da0309.png" alt="knative serving terminology"></p><ul><li>Configuration：应用的最新配置，也就是应用目前期望的状态，对应了 kubernetes 的容器管理（deployment）。每次应用升级都会更新 configuration，而 knative 也会保留历史版本的记录（图中的 revision），结合流量管理，knative 可以让多个不同的版本共同提供服务，方便蓝绿发布和滚动升级</li><li>Route：应用的路由规则，也就是进来的流量如何访问应用，对应了 istio 的流量管理（VirtualService）</li><li>Service：注意这里不是 kubernetes 中提供服务发现的那个 service，而是 knative 自定义的 CRD，它的全称目前是 <code>services.serving.knative.dev</code> 。单独控制 route 和 configuration 就能实现 serving 的所有功能，但knative 更推荐使用 Service 来管理，因为它会自动帮你管理 route 和 configuration</li></ul><p>一个 hello world 的 serving 配置如下所示：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> serving.knative.dev/v1alpha1<span class="token key atrule">kind</span><span class="token punctuation">:</span> Service<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> helloworld<span class="token punctuation">-</span>go  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> default<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">runLatest</span><span class="token punctuation">:</span>    <span class="token key atrule">configuration</span><span class="token punctuation">:</span>      <span class="token key atrule">revisionTemplate</span><span class="token punctuation">:</span>        <span class="token key atrule">spec</span><span class="token punctuation">:</span>          <span class="token key atrule">container</span><span class="token punctuation">:</span>            <span class="token key atrule">image</span><span class="token punctuation">:</span> docker.io/<span class="token punctuation">{</span>username<span class="token punctuation">}</span>/helloworld<span class="token punctuation">-</span>go            <span class="token key atrule">env</span><span class="token punctuation">:</span>            <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> TARGET              <span class="token key atrule">value</span><span class="token punctuation">:</span> <span class="token string">"Go Sample v1"</span></code></pre><p>看起来和 kubernetes 的 pod 定义非常类似，但是它会帮你管理 deployment、ingress、service discovery、auto scaling……从这个角度来看，可以认为 knative 提供了更高的抽象，自动帮你封装掉了 kubernetes 和 istio 的实现细节。</p><p>下面这张图介绍了 knative serving 各组件之间的关系：</p><p><img src="https://ws4.sinaimg.cn/large/006tNbRwgy1fum2swzqebj31j00to41f.jpg" alt="knative serving architecture"></p><ul><li>可以看到，每个 revision 对应了一组 deployment 管理的 pod</li><li>pod 会自动汇报 metrics 数据到 autoscaler，autoscaler 会根据请求量和资源使用情况修改 deployment 的 replicas 数量，从而实现自动扩缩容。serverless 一个重要的特定是它会 scale to 0 的，也就是当应用没有流量访问时，它会自动销毁所有的 pod</li><li>activator 比较有趣，它是为了处理 scale to 0 而出现的。当某个 revision 后面的 pod 缩容到 0 时，route 的流量会指向 activator，activator 接收到请求之后会自动拉起 pod，然后把流量转发过去</li><li>route 对象对应了 istio 的 DestinationRoute 和 VirtualService，决定了访问应用的流量如何路由</li></ul><h3 id="Eventing：事件系统"><a href="#Eventing：事件系统" class="headerlink" title="Eventing：事件系统"></a>Eventing：事件系统</h3><p>serving 系统实现的功能是让应用/函数能够运行起来，并且自动伸缩，那什么时候才会调用应用呢？除了我们熟悉的正常应用调用之外，serverless 最重要的是基于事件的触发机制，也就是说当某件事发生时，就触发某个特定的函数。</p><p>事件概念的出现，让函数和具体的调用方能够解耦。函数部署出来不用关心谁会调用它，而事件源触发也不用关心谁会处理它。</p><p>Note：目前 serverless 的产品和平台很多，每个地方支持的事件来源以及对事件的定义都是不同的（比如 AWS Lambda 支持很多自己产品的事件源）。Knative 自然也会定义自己的事件类型，除此之外，knative 还联合 CNCF 在做事件标准化的工作，目前的产出是 CloudEvents 这个项目。</p><p>为了让整个事件系统更有扩展性和通用性，knative 定义了很多事件相关的概念。我们先来介绍一下：</p><ul><li>EventSource：事件源，能够产生事件的外部系统</li><li>Feed：把某种类型的 EventType 和 EventSource 和对应的 Channel 绑定到一起</li><li>Channel：对消息实现的一层抽象，后端可以使用 kafka、RabbitMQ、Google PubSub 作为具体的实现。channel name 类似于消息集群中的 topic，可以用来解耦事件源和函数。事件发生后 sink 到某个 channel 中，然后 channel 中的数据会被后端的函数消费</li><li>Subscription：把 channel 和后端的函数绑定的一起，一个 channel 可以绑定到多个knative service</li></ul><p>它们之间的关系流程图如下：</p><p><img src="https://ws1.sinaimg.cn/large/006tNbRwgy1fum30a10ynj31jm0v2dkq.jpg" alt="knative eventing architecture"></p><p>Bus 是 knative 内部的事件存储层，用户可以选择自己感兴趣的实现，目前支持的方式有：Stub（在内存中实现的简单消息系统）、Kafka、Google PubSub。如果想要事件能够正常运行，必须在 knative 集群中安装其中一个 bus 实现方式。</p><p>有了 bus 之后，我们就可以监听外部的事件了。目前支持的事件源有三个：github（比如 merge 事件，push 事件等），kubernetes（events），Google PubSub（消息系统），后面还会不断接入更多的事件源。</p><p>如果要想监听对应的事件源，需要在 knative 中部署一个 source adaptor 的 pod，它负责从外部的系统中读取事件。</p><p>读取后的事件，会根据用户配置的 Feed 对象（里面包括了事件源和 channel 的对应关系），找到对应的 channel，然后把消息发送到这个 channel 中（channel 的消息最终是存储在后端的 bus 系统里的）。</p><p>然后，knative 会根据 subscription 的配置，不断从 channel 中读取事件，然后把事件作为参数调用对应的函数，从而完成了整个事件的流程。</p><h2 id="Knative-目前的状态"><a href="#Knative-目前的状态" class="headerlink" title="Knative 目前的状态"></a>Knative 目前的状态</h2><p>knative 是 2018 年 7月才刚刚对外开放，虽然内部已经开发一段时间，但是目前还处于非常早前的阶段（从支持的事件源和 bus就能看出来）。目前代码还不稳定，很多实现都是 hard-coded。</p><p>knative 也是脱产于 google 和 CNCF，因此整个社区运行方式和目标与之前的 kubernetes 以及 istio 非常相似。社区根据组件分成多个 Working Group，每个 Group 独立负责自己的功能，所有的开源活动（文档、视频、代码）都是开放的。另外，CloudEvents 作为 knative 依赖的标准，目标也是成为 CRI、CNI、CSI 这种类似的标准。</p><p>knative 社区目前非常活跃，以 <code>github.com/knative/serving</code> 项目为例，一个月已经有 600+ star，目前有 60+ contributor，900+ commits，而且入门的文档和教程都已经非常全面。</p><h2 id="Knative-应用场景和思考"><a href="#Knative-应用场景和思考" class="headerlink" title="Knative 应用场景和思考"></a>Knative 应用场景和思考</h2><p>knative 基于 kubernetes 和 istio 的 serverless 开源实现，目标是提供更高层次的抽象，让开发者无需关注基础设施（虚拟机或者容器，网络配置，容量规划），而专注于业务代码即可。更多关于 knative 的使用场景可以参考 AWS Lambda 或者其他相关的文档，这里不再赘述，主要讲讲 knative 目前的局限性或者问题：</p><h3 id="1-性能问题"><a href="#1-性能问题" class="headerlink" title="1. 性能问题"></a>1. 性能问题</h3><p>性能问题一直是 serverless 被人诟病的一点，也是目前它不能广泛用于应用服务上的决定性原因。互联网的应用大多数有高并发、高性能的要求，serverless 整个网络链路很长，容器启停需要额外的时间，还无法满足互联网应用的要求。</p><p>针对这一点，很多 serverless 框架也在不断地做改进，比如不断精简容器的启动时间、容器启动之后会做缓存等，比如 nuclio 就宣称自己的平台比 AWS Lambda 要快 10 倍以上。</p><p>相信随着 serverless 的不断演进，性能问题会不断优化，至于能不能达到互联网应用的要求，还要时间给我们答案。</p><h3 id="2-是否需要-istio-这一层？"><a href="#2-是否需要-istio-这一层？" class="headerlink" title="2. 是否需要 istio 这一层？"></a>2. 是否需要 istio 这一层？</h3><p>基于 kubernetes 的 serverless 组件非常多，比如 kubeless。但是基于 kubernetes 同时又基于 istio，目前 knative 还是第一个这么做的。</p><p>有些人的疑问在于，knative 真的有必要基于 istio 来做吗？对于这个问题，我个人的看法是必要的。</p><p>虽然 istio 才刚刚release 1.0 版本，但是它作为集群基础设施通用网络层的地位已经开始显露，相信在未来的发展中接受度会越来越大，并逐渐巩固自己的地位。虽然现阶段来说，很多人并不非常熟悉 istio 的情况，但是从长远角度来看，这一点将是 knative 的一个优势所在。</p><p>另外，基于 istio 构建自己的 serverless 服务，也符合目前软件行业不要重复造轮子的思路。istio 在集群的网络管理方面非常优秀（智能路由、负载均衡、蓝绿发布等），基于 istio 来做可以让 knative 不用重复工作就能直接使用 istio 提供的网络通用功能。</p><h3 id="3-系统复杂度"><a href="#3-系统复杂度" class="headerlink" title="3. 系统复杂度"></a>3. 系统复杂度</h3><p>这一点和上面类似，knative 下面已经有两个非常复杂的平台：kubernetes 和 istio。这两个平台的理解、构建、运维本身就很复杂，如今又加上 knative 整个平台，需要了解的概念都要几十个，更不要提落地过程中会遇到的各种问题。</p><p>对于公有云来说，kubernetes 和 istio 这些底层平台可以交给云供应商来维护（比如 google Function），但是对于内部构建来说，这无疑提高了整个技术门槛，对系统管理人员的要求更高。</p><p>如何安装部署整个集群？如何对集群做升级？出现问题怎么调试和追踪？怎么更好地和内部的系统对接？这些系统的最佳实践是什么？怎么做性能优化？所有这些问题都需要集群管理人员思考并落实。</p><h3 id="4-函数的可运维性？"><a href="#4-函数的可运维性？" class="headerlink" title="4. 函数的可运维性？"></a>4. 函数的可运维性？</h3><p>相对于编写微服务来说，单个函数的复杂度已经非常低，但是当非常多的函数需要共同工作的时候，如何管理这些函数就成了一个必须解决的问题。</p><ul><li>如何快速找到某个函数？</li><li>如何知道一个函数的功能是什么？接受的参数是什么？</li><li>怎么保证函数的升级不会破坏原有的功能？升级之后如何回滚？怎么记录函数的历史版本方面追溯？</li><li>当有多个函数需要同时工作的时候，怎么定义它们之间的关系？</li><li>函数出现问题的时候如何调试？</li></ul><p>对于函数的运维，一般的 serverless 平台（包括 knative）都提供了 logging、metrics、tracing 三个方面的功能。默认情况下，knative 使用 EFK（Elasticsearch、Fluent、Kibana）来收集、查找和分析日志；使用 prometheus + grafana 来收集和索引、展示 metrics 数据；使用 jaeger 来进行调用关系的 tracing。</p><p>针对 serverless 衍生出来的运维工具和平台还不够多，如何调试线上问题还没有看到非常好的解决方案。</p><h3 id="5-knative-成熟度"><a href="#5-knative-成熟度" class="headerlink" title="5. knative 成熟度"></a>5. knative 成熟度</h3><p>最后一点是关于 knative 成熟度的，前面已经提到，knative 目前刚出现不久。虽然整个框架和设计都已经搭好了，但是很多实现都比较初级。这里提几点来说：</p><ul><li>为了实现 autoscaling，knative 在每个 pod 中添加一个叫做 queue proxy 的代理，它会自动把请求的 metrics 发送给 autoscaler 组件作为参考。这样一来，整个网络链路上又多了一层，对整个性能势必会有影响，未来的打算是直接使用 envoy sidecar 来替换掉 queue proxy</li><li>支持的事件源和消息系统还很有限，外部事件只支持 github、kubernetes 和 Google PubSub。 这个问题可以慢慢扩展，knative 本身会实现很常用的事件类型，自定义的事件源用户可以自己实现</li><li>目前还没有函数的 pipeline 管理（类似 AWS Lambda Step Functions），多个函数如何协作并没有自己处理。虽然没有在官方文档中看到这方面的 roadmap，但是以后一定会有这方面的功能（不管是 knative 本身来做，还是社区作为工具补充来实现）</li></ul><p>这方面的问题都不是大事情，随着 knative 版本的迭代，在很快的时间都能够解决。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li>Google Cloud Platform 宣布 Knative 发布的博客文章： <a href="https://cloudplatform.googleblog.com/2018/07/bringing-the-best-of-serverless-to-you.html" target="_blank" rel="noopener">Google Cloud Platform Blog: Bringing the best of serverless to you</a></li><li>the Newstack 上非常好的科普文章： <a href="https://thenewstack.io/knative-enables-portable-serverless-platforms-on-kubernetes-for-any-cloud/" target="_blank" rel="noopener">Knative Enables Portable Serverless Platforms on Kubernetes, for Any Cloud - The New Stack</a></li><li>Serving 的设计理念：<a href="https://docs.google.com/presentation/d/1CbwVC7W2JaSxRyltU8CS1bIsrIXu1RrZqvnlMlDaaJE/edit#slide=id.g32c674a9d1_0_5" target="_blank" rel="noopener">https://docs.google.com/presentation/d/1CbwVC7W2JaSxRyltU8CS1bIsrIXu1RrZqvnlMlDaaJE/edit#slide=id.g32c674a9d1_0_5</a></li><li>knative 官方文档：<a href="https://github.com/knative/docs" target="_blank" rel="noopener">GitHub - knative/docs: Documentation for users of Knative components</a></li><li>Google Cloud Next 2018 大会上宣布 knative 的视频 presentation：  <a href="https://www.youtube.com/watch?v=LtELzpw1l1M&amp;t=1s&amp;list=PLBgogxgQVM9v0xG0QTFQ5PTbNrj8uGSS-&amp;index=105" target="_blank" rel="noopener">Kubernetes, Serverless, and You (Cloud Next ’18) - YouTube</a></li><li><a href="https://cloud.google.com/knative/" target="_blank" rel="noopener">Google Cloud Knative 产品页面，目前只有最简单的介绍和文档链接</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;什么是-Knative？&quot;&gt;&lt;a href=&quot;#什么是-Knative？&quot; class=&quot;headerlink&quot; title=&quot;什么是 Knative？&quot;&gt;&lt;/a&gt;什么是 Knative？&lt;/h2&gt;&lt;p&gt;&lt;a
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="kubernetes" scheme="http://cizixs.com/tags/kubernetes/"/>
    
      <category term="container" scheme="http://cizixs.com/tags/container/"/>
    
      <category term="serverless" scheme="http://cizixs.com/tags/serverless/"/>
    
      <category term="knative" scheme="http://cizixs.com/tags/knative/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes 资源管理概述</title>
    <link href="http://cizixs.com/2018/06/25/kubernetes-resource-management/"/>
    <id>http://cizixs.com/2018/06/25/kubernetes-resource-management/</id>
    <published>2018-06-24T16:00:00.000Z</published>
    <updated>2019-03-18T13:05:47.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="kubernetes-资源简介"><a href="#kubernetes-资源简介" class="headerlink" title="kubernetes 资源简介"></a>kubernetes 资源简介</h2><h3 id="什么是资源？"><a href="#什么是资源？" class="headerlink" title="什么是资源？"></a>什么是资源？</h3><p>在 kubernetes 中，有两个基础但是非常重要的概念：node 和 pod。node 翻译成节点，是对集群资源的抽象；pod 是对容器的封装，是应用运行的实体。node 提供资源，而 pod 使用资源，这里的资源分为计算（cpu、memory、gpu）、存储（disk、ssd）、网络（network bandwidth、ip、ports）。这些资源提供了应用运行的基础，正确理解这些资源以及集群调度如何使用这些资源，对于大规模的 kubernetes 集群来说至关重要，不仅能保证应用的稳定性，也可以提高资源的利用率。</p><p>在这篇文章，我们主要介绍 CPU 和内存这两个重要的资源，它们虽然都属于计算资源，但也有所差距。CPU 可分配的是使用时间，也就是操作系统管理的时间片，每个进程在一定的时间片里运行自己的任务（另外一种方式是绑核，也就是把 CPU 完全分配给某个 pod 使用，但这种方式不够灵活会造成严重的资源浪费，kubernetes 中并没有提供）；而对于内存，系统提供的是内存大小。</p><p>CPU 的使用时间是可压缩的，换句话说它本身无状态，申请资源很快，也能快速正常回收；而内存大小是不可压缩的，因为它是有状态的（内存里面保存的数据），申请资源很慢（需要计算和分配内存块的空间），并且回收可能失败（被占用的内存一般不可回收）。</p><p>把资源分成<strong>可压缩</strong>和<strong>不可压缩</strong>，是因为在资源不足的时候，它们的表现很不一样。对于不可压缩资源，如果资源不足，也就无法继续申请资源（内存用完就是用完了），并且会导致 pod 的运行产生无法预测的错误（应用申请内存失败会导致一系列问题）；而对于可压缩资源，比如 CPU 时间片，即使 pod 使用的 CPU 资源很多，CPU 使用也可以按照权重分配给所有 pod 使用，虽然每个人使用的时间片减少，但不会影响程序的逻辑。</p><p>在 kubernetes 集群管理中，有一个非常核心的功能：就是为 pod 选择一个主机运行。调度必须满足一定的条件，其中最基本的是主机上要有足够的资源给 pod 使用。</p><p><img src="https://cdn-images-1.medium.com/max/800/1*PfGIiTw68JLIUyo0FQY2dA.png" alt="kubernetes scheduler architecture"></p><p>资源除了和调度相关之外，还和很多事情紧密相连，这正是这篇文章要解释的。</p><h3 id="kubernetes-资源的表示"><a href="#kubernetes-资源的表示" class="headerlink" title="kubernetes 资源的表示"></a>kubernetes 资源的表示</h3><p>用户在 pod 中可以配置要使用的资源总量，kubernetes 根据配置的资源数进行调度和运行。目前主要可以配置的资源是 CPU 和 memory，对应的配置字段是 <code>spec.containers[].resource.limits/request.cpu/memory</code>。</p><p>需要注意的是，用户是对每个容器配置 request 值，所有容器的资源请求之和就是 pod 的资源请求总量，而我们一般会说 pod 的资源请求和 limits。</p><p><code>limits</code> 和 <code>requests</code> 的区别我们下面会提到，这里先说说比较容易理解的 cpu 和 memory。</p><p><code>CPU</code> 一般用核数来标识，一核CPU 相对于物理服务器的一个超线程核，也就是操作系统 <code>/proc/cpuinfo</code> 中列出来的核数。因为对资源进行了池化和虚拟化，因此 kubernetes 允许配置非整数个的核数，比如 <code>0.5</code> 是合法的，它标识应用可以使用半个 CPU 核的计算量。CPU 的请求有两种方式，一种是刚提到的 <code>0.5</code>，<code>1</code> 这种直接用数字标识 CPU 核心数；另外一种表示是 <code>500m</code>，它等价于 <code>0.5</code>，也就是说 <code>1 Core = 1000m</code>。</p><p>内存比较容易理解，是通过字节大小指定的。如果直接一个数字，后面没有任何单位，表示这么多字节的内存；数字后面还可以跟着单位， 支持的单位有 <code>E</code>、<code>P</code>、<code>T</code>、<code>G</code>、<code>M</code>、<code>K</code>，前者分别是后者的 <code>1000</code> 倍大小的关系，此外还支持  <code>Ei</code>、<code>Pi</code>、<code>Ti</code>、<code>Gi</code>、<code>Mi</code>、<code>Ki</code>，其对应的倍数关系是 <code>2^10 = 1024</code>。比如要使用 100M 内存的话，直接写成 <code>100Mi</code>即可。</p><h3 id="节点可用资源"><a href="#节点可用资源" class="headerlink" title="节点可用资源"></a>节点可用资源</h3><p>理想情况下，我们希望节点上所有的资源都可以分配给 pod 使用，但实际上节点上除了运行 pods 之外，还会运行其他的很多进程：系统相关的进程（比如 sshd、udev等），以及 kubernetes 集群的组件（kubelet、docker等）。我们在分配资源的时候，需要给这些进程预留一些资源，剩下的才能给 pod 使用。预留的资源可以通过下面的参数控制：</p><ul><li><code>--kube-reserved=[cpu=100m][,][memory=100Mi][,][ephemeral-storage=1Gi]</code>：控制预留给 kubernetes 集群组件的 CPU、memory 和存储资源</li><li><code>--system-reserved=[cpu=100mi][,][memory=100Mi][,][ephemeral-storage=1Gi]</code>：预留给系统的 CPU、memory 和存储资源</li></ul><p>这两块预留之后的资源才是 pod 真正能使用的，不过考虑到 eviction 机制（下面的章节会提到），kubelet 会保证节点上的资源使用率不会真正到 100%，因此 pod 的实际可使用资源会稍微再少一点。主机上的资源逻辑分配图如下所示：</p><p><img src="https://i.loli.net/2018/06/25/5b3106f947190.png" alt="kubernetes reserved resource"></p><p><strong>NOTE：</strong>需要注意的是，allocatable 不是指当前机器上可以分配的资源，而是指能分配给 pod 使用的资源总量，一旦 kubelet 启动这个值是不会变化的。</p><p>allocatable 的值可以在 node 对象的 <code>status</code> 字段中读取，比如下面这样：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">status</span><span class="token punctuation">:</span>  <span class="token key atrule">allocatable</span><span class="token punctuation">:</span>    <span class="token key atrule">cpu</span><span class="token punctuation">:</span> <span class="token string">"2"</span>    <span class="token key atrule">ephemeral-storage</span><span class="token punctuation">:</span> <span class="token string">"35730597829"</span>    <span class="token key atrule">hugepages-2Mi</span><span class="token punctuation">:</span> <span class="token string">"0"</span>    <span class="token key atrule">memory</span><span class="token punctuation">:</span> 3779348Ki    <span class="token key atrule">pods</span><span class="token punctuation">:</span> <span class="token string">"110"</span>  <span class="token key atrule">capacity</span><span class="token punctuation">:</span>    <span class="token key atrule">cpu</span><span class="token punctuation">:</span> <span class="token string">"2"</span>    <span class="token key atrule">ephemeral-storage</span><span class="token punctuation">:</span> 38770180Ki    <span class="token key atrule">hugepages-2Mi</span><span class="token punctuation">:</span> <span class="token string">"0"</span>    <span class="token key atrule">memory</span><span class="token punctuation">:</span> 3881748Ki    <span class="token key atrule">pods</span><span class="token punctuation">:</span> <span class="token string">"110"</span></code></pre><h2 id="kubernetes-资源对象"><a href="#kubernetes-资源对象" class="headerlink" title="kubernetes 资源对象"></a>kubernetes 资源对象</h2><p>在这部分，我们来介绍 kubernetes 中提供的让我们管理 pod 资源的原生对象。</p><h3 id="请求（requests）和上限（limits）"><a href="#请求（requests）和上限（limits）" class="headerlink" title="请求（requests）和上限（limits）"></a>请求（requests）和上限（limits）</h3><p>前面说过用户在创建 pod 的时候，可以指定每个容器的 Requests 和 Limits 两个字段，下面是一个实例：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">resources</span><span class="token punctuation">:</span>  <span class="token key atrule">requests</span><span class="token punctuation">:</span>    <span class="token key atrule">memory</span><span class="token punctuation">:</span> <span class="token string">"64Mi"</span>    <span class="token key atrule">cpu</span><span class="token punctuation">:</span> <span class="token string">"250m"</span>  <span class="token key atrule">limits</span><span class="token punctuation">:</span>    <span class="token key atrule">memory</span><span class="token punctuation">:</span> <span class="token string">"128Mi"</span>    <span class="token key atrule">cpu</span><span class="token punctuation">:</span> <span class="token string">"500m"</span></code></pre><p><code>Requests</code> 是容器请求要使用的资源，kubernetes 会保证 pod 能使用到这么多的资源。请求的资源是调度的依据，只有当节点上的可用资源大于 pod 请求的各种资源时，调度器才会把 pod 调度到该节点上（如果 CPU 资源足够，内存资源不足，调度器也不会选择该节点）。</p><p>需要注意的是，调度器只关心节点上可分配的资源，以及节点上所有 pods 请求的资源，而<strong>不关心</strong>节点资源的实际使用情况，换句话说，如果节点上的 pods 申请的资源已经把节点上的资源用满，即使它们的使用率非常低，比如说 CPU 和内存使用率都低于 10%，调度器也不会继续调度 pod 上去。</p><p> <code>Limits</code> 是 pod 能使用的资源上限，是实际配置到内核 cgroups 里面的配置数据。对于内存来说，会直接转换成 <code>docker run</code> 命令行的 <code>--memory</code> 大小，最终会配置到 cgroups 对应任务的 <code>/sys/fs/cgroup/memory/……/memory.limit_in_bytes</code> 文件中。</p><p> <strong>NOTE</strong>：如果 limit 没有配置，则表明没有资源的上限，只要节点上有对应的资源，pod 就可以使用。</p><p>使用 requests 和 limits 概念，我们能分配更多的 pod，提升整体的资源使用率。但是这个体系有个非常重要的问题需要考虑，那就是<strong>怎么去准确地评估 pod 的资源 requests</strong>？如果评估地过低，会导致应用不稳定；如果过高，则会导致使用率降低。这个问题需要开发者和系统管理员共同讨论和定义。</p><h3 id="limit-range（默认资源配置"><a href="#limit-range（默认资源配置" class="headerlink" title="limit range（默认资源配置)"></a>limit range（默认资源配置)</h3><p>为每个 pod 都手动配置这些参数是挺麻烦的事情，kubernetes 提供了 <code>LimitRange</code> 资源，可以让我们配置某个 namespace 默认的 request 和 limit 值，比如下面的实例：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> <span class="token string">"v1"</span><span class="token key atrule">kind</span><span class="token punctuation">:</span> <span class="token string">"LimitRange"</span><span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> you<span class="token punctuation">-</span>shall<span class="token punctuation">-</span>have<span class="token punctuation">-</span>limits<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">limits</span><span class="token punctuation">:</span>    <span class="token punctuation">-</span> <span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"Container"</span>      <span class="token key atrule">max</span><span class="token punctuation">:</span>        <span class="token key atrule">cpu</span><span class="token punctuation">:</span> <span class="token string">"2"</span>        <span class="token key atrule">memory</span><span class="token punctuation">:</span> <span class="token string">"1Gi"</span>      <span class="token key atrule">min</span><span class="token punctuation">:</span>        <span class="token key atrule">cpu</span><span class="token punctuation">:</span> <span class="token string">"100m"</span>        <span class="token key atrule">memory</span><span class="token punctuation">:</span> <span class="token string">"4Mi"</span>      <span class="token key atrule">default</span><span class="token punctuation">:</span>        <span class="token key atrule">cpu</span><span class="token punctuation">:</span> <span class="token string">"500m"</span>        <span class="token key atrule">memory</span><span class="token punctuation">:</span> <span class="token string">"200Mi"</span>      <span class="token key atrule">defaultRequest</span><span class="token punctuation">:</span>        <span class="token key atrule">cpu</span><span class="token punctuation">:</span> <span class="token string">"200m"</span>        <span class="token key atrule">memory</span><span class="token punctuation">:</span> <span class="token string">"100Mi"</span></code></pre><p>如果对应 namespace 创建的 pod 没有写资源的 requests 和 limits 字段，那么它会自动拥有下面的配置信息：</p><ul><li>内存请求是 100Mi，上限是 200Mi</li><li>CPU 请求是 200m，上限是 500m</li></ul><p>当然，如果 pod 自己配置了对应的参数，kubernetes 会使用 pod 中的配置。使用 LimitRange 能够让 namespace 中的 pod 资源规范化，便于统一的资源管理。</p><h3 id="资源配额（resource-quota）"><a href="#资源配额（resource-quota）" class="headerlink" title="资源配额（resource quota）"></a>资源配额（resource quota）</h3><p>前面讲到的资源管理和调度可以认为 kubernetes 把这个集群的资源整合起来，组成一个资源池，每个应用（pod）会自动从整个池中分配资源来使用。默认情况下只要集群还有可用的资源，应用就能使用，并没有限制。kubernetes 本身考虑到了多用户和多租户的场景，提出了 namespace 的概念来对集群做一个简单的隔离。</p><p>基于 namespace，kubernetes 还能够对资源进行隔离和限制，这就是 resource quota 的概念，翻译成资源配额，它限制了某个 namespace 可以使用的资源总额度。这里的资源包括 cpu、memory 的总量，也包括 kubernetes 自身对象（比如 pod、services 等）的数量。通过 resource quota，kubernetes 可以防止某个 namespace 下的用户不加限制地使用超过期望的资源，比如说不对资源进行评估就大量申请 16核 CPU 32G内存的 pod。</p><p>下面是一个资源配额的实例，它限制了 namespace 只能使用 20核 CPU 和 1G 内存，并且能创建 10 个 pod、20个 rc、5个 service，可能适用于某个测试场景。</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1<span class="token key atrule">kind</span><span class="token punctuation">:</span> ResourceQuota<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> quota<span class="token key atrule">spec</span><span class="token punctuation">:</span>  <span class="token key atrule">hard</span><span class="token punctuation">:</span>    <span class="token key atrule">cpu</span><span class="token punctuation">:</span> <span class="token string">"20"</span>    <span class="token key atrule">memory</span><span class="token punctuation">:</span> 1Gi    <span class="token key atrule">pods</span><span class="token punctuation">:</span> <span class="token string">"10"</span>    <span class="token key atrule">replicationcontrollers</span><span class="token punctuation">:</span> <span class="token string">"20"</span>    <span class="token key atrule">resourcequotas</span><span class="token punctuation">:</span> <span class="token string">"1"</span>    <span class="token key atrule">services</span><span class="token punctuation">:</span> <span class="token string">"5"</span></code></pre><p>resource quota 能够配置的选项还很多，比如 GPU、存储、configmaps、persistentvolumeclaims 等等，更多信息可以参考<a href="****">官方的文档</a>。</p><p>Resource quota 要解决的问题和使用都相对独立和简单，但是它也有一个限制：那就是它不能根据集群资源动态伸缩。一旦配置之后，resource quota 就不会改变，即使集群增加了节点，整体资源增多也没有用。kubernetes 现在没有解决这个问题，但是用户可以通过编写一个 controller 的方式来自己实现。</p><h2 id="应用优先级"><a href="#应用优先级" class="headerlink" title="应用优先级"></a>应用优先级</h2><h3 id="QoS（服务质量）"><a href="#QoS（服务质量）" class="headerlink" title="QoS（服务质量）"></a>QoS（服务质量）</h3><p>Requests 和 limits 的配置除了表明资源情况和限制资源使用之外，还有一个隐藏的作用：它决定了 pod 的 QoS 等级。</p><p>上一节我们提到了一个细节：如果 pod 没有配置 limits ，那么它可以使用节点上任意多的可用资源。这类 pod 能灵活使用资源，但这也导致它不稳定且危险，对于这类 pod 我们一定要在它占用过多资源导致节点资源紧张时处理掉。优先处理这类 pod，而不是资源使用处于自己请求范围内的 pod 是非常合理的想法，而这就是 pod QoS 的含义：根据 pod 的资源请求把 pod 分成不同的重要性等级。</p><p>kubernetes 把 pod 分成了三个 QoS 等级：</p><ul><li><strong>Guaranteed</strong>：优先级最高，可以考虑数据库应用或者一些重要的业务应用。除非 pods 使用超过了它们的 limits，或者节点的内存压力很大而且没有 QoS 更低的 pod，否则不会被杀死</li><li><strong>Burstable</strong>：这种类型的 pod 可以多于自己请求的资源（上限有 limit 指定，如果 limit 没有配置，则可以使用主机的任意可用资源），但是重要性认为比较低，可以是一般性的应用或者批处理任务</li><li><strong>Best Effort</strong>：优先级最低，集群不知道 pod 的资源请求情况，调度不考虑资源，可以运行到任意节点上（从资源角度来说），可以是一些临时性的不重要应用。pod 可以使用节点上任何可用资源，但在资源不足时也会被优先杀死</li></ul><p>Pod 的 requests 和 limits 是如何对应到这三个 QoS 等级上的，可以用下面一张表格概括：</p><p><img src="https://i.loli.net/2018/06/25/5b307f4bc7d42.png" alt="pod QuS mapping"></p><p>看到这里，你也许看出来一个问题了：<strong>如果不配置 requests 和 limits，pod 的 QoS 竟然是最低的</strong>。没错，所以推荐大家理解 QoS 的概念，并且按照需求<strong>一定要给 pod 配置 requests 和 limits 参数</strong>，不仅可以让调度更准确，也能让系统更加稳定。</p><p><strong>NOTE</strong>：按照现在的方法根据 pod 请求的资源进行配置不够灵活和直观，更理想的情况是用户可以直接配置 pod 的 QoS，而不用关心具体的资源申请和上限值。但 kubernetes 目前还没有这方面的打算。</p><p>Pod 的 QoS 还决定了容器的 OOM（out-of-memory）值，它们对应的关系如下：</p><p><img src="https://i.loli.net/2018/06/25/5b307a5b3557c.png" alt="pod QoS oom score"></p><p>可以看到，QoS 越高的 pod oom 值越低，也就越不容易被系统杀死。对于 Bustable pod，它的值是根据 request 和节点内存总量共同决定的:</p><pre class=" language-go"><code class="language-go">oomScoreAdjust <span class="token operator">:=</span> <span class="token number">1000</span> <span class="token operator">-</span> <span class="token punctuation">(</span><span class="token number">1000</span><span class="token operator">*</span>memoryRequest<span class="token punctuation">)</span><span class="token operator">/</span>memoryCapacity</code></pre><p>其中 <code>memoryRequest</code> 是 pod 申请的资源，<code>memoryCapacity</code> 是节点的内存总量。可以看到，申请的内存越多，oom 值越低，也就越不容易被杀死。</p><p>QoS 的作用会在后面介绍 eviction 的时候详细讲解。</p><h3 id="pod-优先级（priority）"><a href="#pod-优先级（priority）" class="headerlink" title="pod 优先级（priority）"></a>pod 优先级（priority）</h3><p>除了 QoS，kubernetes 还允许我们自定义 pod 的优先级，比如：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> scheduling.k8s.io/v1alpha1<span class="token key atrule">kind</span><span class="token punctuation">:</span> PriorityClass<span class="token key atrule">metadata</span><span class="token punctuation">:</span>  <span class="token key atrule">name</span><span class="token punctuation">:</span> high<span class="token punctuation">-</span>priority<span class="token key atrule">value</span><span class="token punctuation">:</span> <span class="token number">1000000</span><span class="token key atrule">globalDefault</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">description</span><span class="token punctuation">:</span> <span class="token string">"This priority class should be used for XYZ service pods only."</span></code></pre><p>优先级的使用也比较简单，只需要在 <code>pod.spec.PriorityClassName</code> 指定要使用的优先级名字，即可以设置当前 pod 的优先级为对应的值。</p><p>Pod 的优先级在调度的时候会使用到。首先，待调度的 pod 都在同一个队列中，启用了 pod priority 之后，调度器会根据优先级的大小，把优先级高的 pod 放在前面，提前调度。</p><p>另外，如果在调度的时候，发现某个 pod 因为资源不足无法找到合适的节点，调度器会尝试 preempt 的逻辑。<br>简单来说，调度器会试图找到这样一个节点：找到它上面优先级低于当前要调度 pod 的所有 pod，如果杀死它们，能腾足够的资源，调度器会执行删除操作，把 pod 调度到节点上。</p><p><a href="https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/" target="_blank" rel="noopener">Pod Priority and Preemption - Kubernetes</a></p><h2 id="驱逐（Eviction）"><a href="#驱逐（Eviction）" class="headerlink" title="驱逐（Eviction）"></a>驱逐（Eviction）</h2><p>至此，我们讲述的都是理想情况下 kubernetes 的工作状况，我们假设资源完全够用，而且应用也都是在使用规定范围内的资源。</p><p>但现实不会如此简单，在管理集群的时候我们常常会遇到资源不足的情况，在这种情况下我们要<strong>保证整个集群可用</strong>，并且尽可能<strong>减少应用的损失</strong>。保证集群可用比较容易理解，首先要保证系统层面的核心进程正常，其次要保证 kubernetes 本身组件进程不出问题；但是如果量化应用的损失呢？首先能想到的是如果要杀死 pod，要尽量减少总数。另外一个就和 pod 的优先级相关了，那就是尽量杀死不那么重要的应用，让重要的应用不受影响。</p><p>Pod 的驱逐是在 kubelet 中实现的，因为 kubelet 能动态地感知到节点上资源使用率实时的变化情况。其核心的逻辑是：kubelet 实时监控节点上各种资源的使用情况，一旦发现某个不可压缩资源出现要耗尽的情况，就会主动终止节点上的 pod，让节点能够正常运行。被终止的 pod 所有容器会停止，状态会被设置为 failed。</p><h3 id="驱逐触发条件"><a href="#驱逐触发条件" class="headerlink" title="驱逐触发条件"></a>驱逐触发条件</h3><p>那么哪些资源不足会导致 kubelet 执行驱逐程序呢？目前主要有三种情况：实际内存不足、节点文件系统的可用空间（文件系统剩余大小和 inode 数量）不足、以及镜像文件系统的可用空间（包括文件系统剩余大小和 inode 数量）不足。</p><p>下面这图是具体的触发条件：</p><p><img src="https://i.loli.net/2018/06/24/5b2f1a966a703.png" alt="eviction conddition"></p><p>有了数据的来源，另外一个问题是触发的时机，也就是到什么程度需要触发驱逐程序？kubernetes 运行用户自己配置，并且支持两种模式：按照百分比和按照绝对数量。比如对于一个 32G 内存的节点当可用内存少于 10% 时启动驱逐程序，可以配置 <code>memory.available&lt;10%</code>或者 <code>memory.available&lt;3.2Gi</code>。</p><p><strong>NOTE</strong>：默认情况下，kubelet 的驱逐规则是 <code>memory.available&lt;100Mi</code>，对于生产环境这个配置是不可接受的，所以一定要根据实际情况进行修改。</p><h3 id="软驱逐（soft-eviction）和硬驱逐（hard-eviction）"><a href="#软驱逐（soft-eviction）和硬驱逐（hard-eviction）" class="headerlink" title="软驱逐（soft eviction）和硬驱逐（hard eviction）"></a>软驱逐（soft eviction）和硬驱逐（hard eviction）</h3><p>因为驱逐 pod 是具有毁坏性的行为，因此必须要谨慎。有时候内存使用率增高只是暂时性的，有可能 20s 内就能恢复，这时候启动驱逐程序意义不大，而且可能会导致应用的不稳定，我们要考虑到这种情况应该如何处理；另外需要注意的是，如果内存使用率过高，比如高于 95%（或者 90%，取决于主机内存大小和应用对稳定性的要求），那么我们不应该再多做评估和考虑，而是赶紧启动驱逐程序，因为这种情况再花费时间去判断可能会导致内存继续增长，系统完全崩溃。</p><p>为了解决这个问题，kubernetes 引入了 soft eviction 和 hard eviction 的概念。</p><p><strong>软驱逐</strong>可以在资源紧缺情况并没有哪些严重的时候触发，比如内存使用率为 85%，软驱逐还需要配置一个时间指定软驱逐条件持续多久才触发，也就是说 kubelet 在发现资源使用率达到设定的阈值之后，并不会立即触发驱逐程序，而是继续观察一段时间，如果资源使用率高于阈值的情况持续一定时间，才开始驱逐。并且驱逐 pod 的时候，会遵循 grace period ，等待 pod 处理完清理逻辑。和软驱逐相关的启动参数是：</p><ul><li><code>--eviction-soft</code>：软驱逐触发条件，比如 <code>memory.available&lt;1Gi</code></li><li><code>--eviction-sfot-grace-period</code>：触发条件持续多久才开始驱逐，比如 <code>memory.available=2m30s</code></li><li><code>--eviction-max-pod-grace-period</code>：kill pod 时等待 grace period 的时间让 pod 做一些清理工作，如果到时间还没有结束就做 kill</li></ul><p>前面两个参数必须同时配置，软驱逐才能正常工作；后一个参数会和 pod 本身配置的 grace period 比较，选择较小的一个生效。</p><p><strong>硬驱逐</strong>更加直接干脆，kubelet 发现节点达到配置的硬驱逐阈值后，立即开始驱逐程序，并且不会遵循 grace period，也就是说立即强制杀死 pod。对应的配置参数只有一个 <code>--evictio-hard</code>，可以选择上面表格中的任意条件搭配。</p><p>设置这两种驱逐程序是为了平衡节点稳定性和对 pod 的影响，软驱逐照顾到了 pod 的优雅退出，减少驱逐对 pod 的影响；而硬驱逐则照顾到节点的稳定性，防止资源的快速消耗导致节点不可用。</p><p>软驱逐和硬驱逐可以单独配置，不过还是推荐两者都进行配置，一起使用。</p><h3 id="驱逐哪些-pods？"><a href="#驱逐哪些-pods？" class="headerlink" title="驱逐哪些 pods？"></a>驱逐哪些 pods？</h3><p>上面我们已经整体介绍了 kubelet 驱逐 pod 的逻辑和过程，那这里就牵涉到一个具体的问题：<strong>要驱逐哪些 pod</strong>？驱逐的重要原则是尽量减少对应用程序的影响。</p><p>如果是存储资源不足，kubelet 会根据情况清理状态为 Dead 的 pod 和它的所有容器，以及清理所有没有使用的镜像。如果上述清理并没有让节点回归正常，kubelet 就开始清理 pod。</p><p>一个节点上会运行多个 pod，驱逐所有的 pods 显然是不必要的，因此要做出一个抉择：在节点上运行的所有 pod 中选择一部分来驱逐。虽然这些 pod 乍看起来没有区别，但是它们的地位是不一样的，正如乔治·奥威尔在《动物庄园》的那句话：</p><blockquote><p>所有动物生而平等，但有些动物比其他动物更平等。</p></blockquote><p>Pod 也是不平等的，有些 pod 要比其他 pod 更重要。只管来说，系统组件的 pod 要比普通的 pod 更重要，另外运行数据库的 pod 自然要比运行一个无状态应用的 pod 更重要。kubernetes 又是怎么决定 pod 的优先级的呢？这个问题的答案就藏在我们之前已经介绍过的内容里：pod requests 和 limits、优先级（priority），以及 pod 实际的资源使用。</p><p>简单来说，kubelet 会根据以下内容对 pod 进行排序：pod 是否使用了超过请求的紧张资源、pod 的优先级、然后是使用的紧缺资源和请求的紧张资源之间的比例。具体来说，kubelet 会按照如下的顺序驱逐 pod：</p><ul><li>使用的紧张资源超过请求数量的 <code>BestEffort</code> 和 <code>Burstable</code> pod，这些 pod 内部又会按照优先级和使用比例进行排序</li><li>紧张资源使用量低于 requests 的 <code>Burstable</code> 和 <code>Guaranteed</code> 的 pod 后面才会驱逐，只有当系统组件（kubelet、docker、journald 等）内存不够，并且没有上面 QoS 比较低的 pod 时才会做。执行的时候还会根据 priority 排序，优先选择优先级低的 pod</li></ul><h3 id="防止波动"><a href="#防止波动" class="headerlink" title="防止波动"></a>防止波动</h3><p>这里的波动有两种情况，我们先说说第一种。驱逐条件出发后，如果 kubelet 驱逐一部分 pod，让资源使用率低于阈值就停止，那么很可能过一段时间资源使用率又会达到阈值，从而再次出发驱逐，如此循环往复……为了处理这种问题，我们可以使用 <code>--eviction-minimum-reclaim</code>解决，这个参数配置每次驱逐至少清理出来多少资源才会停止。</p><p>另外一个波动情况是这样的：Pod 被驱逐之后并不会从此消失不见，常见的情况是 kubernetes 会自动生成一个新的 pod 来取代，并经过调度选择一个节点继续运行。如果不做额外处理，有理由相信 pod 选择原来节点的可能性比较大（因为调度逻辑没变，而它上次调度选择的就是该节点），之所以说可能而不是绝对会再次选择该节点，是因为集群 pod 的运行和分布和上次调度时极有可能发生了变化。</p><p>无论如何，如果被驱逐的 pod 再次调度到原来的节点，很可能会再次触发驱逐程序，然后 pod 再次被调度到当前节点，循环往复…… 这种事情当然是我们不愿意看到的，虽然看似复杂，但这个问题解决起来非常简单：驱逐发生后，kubelet 更新节点状态，调度器感知到这一情况，暂时不往该节点调度 pod 即可。<code>--eviction-pressure-transition-period</code> 参数可以指定 kubelet 多久才上报节点的状态，因为默认的上报状态周期比较短，频繁更改节点状态会导致驱逐波动。</p><p>做一个总结，下面是一个使用了上面多种参数的驱逐配置实例（你应该能看懂它们是什么意思了）：</p><pre class=" language-bash"><code class="language-bash">–eviction-soft<span class="token operator">=</span>memory.available<span class="token operator">&lt;</span>80%,nodefs.available<span class="token operator">&lt;</span>2Gi \–eviction-soft-grace-period<span class="token operator">=</span>memory.available<span class="token operator">=</span>1m30s,nodefs.available<span class="token operator">=</span>1m30s \–eviction-max-pod-grace-period<span class="token operator">=</span>120 \–eviction-hard<span class="token operator">=</span>memory.available<span class="token operator">&lt;</span>500Mi,nodefs.available<span class="token operator">&lt;</span>1Gi \–eviction-pressure-transition-period<span class="token operator">=</span>30s \--eviction-minimum-reclaim<span class="token operator">=</span><span class="token string">"memory.available=0Mi,nodefs.available=500Mi,imagefs.available=2Gi"</span></code></pre><h2 id="碎片整理和重调度"><a href="#碎片整理和重调度" class="headerlink" title="碎片整理和重调度"></a>碎片整理和重调度</h2><p>Kubernetes 的调度器在为 pod 选择运行节点的时候，只会考虑到调度那个时间点集群的状态，经过一系列的算法选择一个<strong>当时最合适</strong>的节点。但是集群的状态是不断变化的，用户创建的 pod 也是动态的，随着时间变化，原来调度到某个节点上的 pod 现在看来可能有更好的节点可以选择。比如考虑到下面这些情况：</p><ul><li>调度 pod 的条件已经不再满足，比如节点的 taints 和 labels 发生了变化</li><li>新节点加入了集群。如果默认配置了把 pod 打散，那么应该有一些 pod 最好运行在新节点上</li><li>节点的使用率不均匀。调度后，有些节点的分配率和使用率比较高，另外一些比较低</li><li>节点上有资源碎片。有些节点调度之后还剩余部分资源，但是又低于任何 pod 的请求资源；或者 memory 资源已经用完，但是 CPU 还有挺多没有使用</li></ul><p>想要解决上述的这些问题，都需要把 pod 重新进行调度（把 pod 从当前节点移动到另外一个节点）。但是默认情况下，一旦 pod 被调度到节点上，除非给杀死否则不会移动到另外一个节点的。</p><p>为此 kubernetes 社区孵化了一个称为  <a href="https://github.com/kubernetes-incubator/descheduler" target="_blank" rel="noopener"><code>descheduler</code></a> 的项目，专门用来做重调度。重调度的逻辑很简单：找到上面几种情况中已经不是最优的 pod，把它们驱逐掉（eviction）。</p><p>目前，descheduler 不会决定驱逐的 pod 应该调度到哪台机器，而是<strong>假定默认的调度器会做出正确的调度抉择</strong>。也就是说，之所以 pod 目前不合适，不是因为调度器的算法有问题，而是因为集群的情况发生了变化。如果让调度器重新选择，调度器现在会把 pod 放到合适的节点上。这种做法让 descheduler 逻辑比较简单，而且避免了调度逻辑出现在两个组件中。</p><p>Descheduler 执行的逻辑是可以配置的，目前有几种场景：</p><ul><li><code>RemoveDuplicates</code>：RS、deployment 中的 pod 不能同时出现在一台机器上</li><li><code>LowNodeUtilization</code>：找到资源使用率比较低的 node，然后驱逐其他资源使用率比较高节点上的 pod，期望调度器能够重新调度让资源更均衡</li><li><code>RemovePodsViolatingInterPodAntiAffinity</code>：找到已经违反 Pod Anti Affinity 规则的 pods 进行驱逐，可能是因为反亲和是后面加上去的</li><li><code>RemovePodsViolatingNodeAffinity</code>：找到违反 Node Affinity 规则的 pods 进行驱逐，可能是因为 node 后面修改了 label</li></ul><p>当然，为了保证应用的稳定性，descheduler 并不会随意地驱逐 pod，还是会尊重 pod 运行的规则，包括 pod 的优先级（不会驱逐 Critical pod，并且按照优先级顺序进行驱逐）和 PDB（如果违反了 PDB，则不会进行驱逐），并且不会驱逐没有 deployment、rs、jobs 的 pod 不会驱逐，daemonset pod 不会驱逐，有 local storage 的 pod 也不会驱逐。</p><p>Descheduler 不是一个常驻的任务，每次执行完之后会退出，因此推荐使用 CronJob 来运行。</p><p>总的来说，descheduler 是对原生调度器的补充，用来解决原生调度器的调度决策随着时间会变得失效，或者不够优化的缺陷。</p><h2 id="资源动态调整"><a href="#资源动态调整" class="headerlink" title="资源动态调整"></a>资源动态调整</h2><p>动态调整的思路：应用的实际流量会不断变化，因此使用率也是不断变化的，为了应对应用流量的变化，我们应用能够自动调整应用的资源。比如在线商品应用在促销的时候访问量会增加，我们应该自动增加 pod 运算能力来应对；当促销结束后，有需要自动降低 pod 的运算能力防止浪费。</p><p>运算能力的增减有两种方式：改变单个 pod 的资源，已经增减 pod 的数量。这两种方式对应了 kubernetes 的 HPA 和 VPA。</p><h3 id="Horizontal-Pod-AutoScaling（横向-Pod-自动扩展）"><a href="#Horizontal-Pod-AutoScaling（横向-Pod-自动扩展）" class="headerlink" title="Horizontal Pod AutoScaling（横向 Pod 自动扩展）"></a>Horizontal Pod AutoScaling（横向 Pod 自动扩展）</h3><p><img src="https://478h5m1yrfsa3bbe262u7muv-wpengine.netdna-ssl.com/wp-content/uploads/2018/02/autoscaler_kubernetes.jpg" alt="kubernetes HPA"></p><p>横向 pod 自动扩展的思路是这样的：kubernetes 会运行一个 controller，周期性地监听 pod 的资源使用情况，当高于设定的阈值时，会自动增加 pod 的数量；当低于某个阈值时，会自动减少 pod 的数量。自然，这里的阈值以及 pod 的上限和下限的数量都是需要用户配置的。</p><p>上面这句话隐藏了一个重要的信息：HPA 只能和 RC、deployment、RS 这些可以动态修改 replicas 的对象一起使用，而无法用于单个 pod、daemonset（因为它控制的 pod 数量不能随便修改）等对象。</p><p>目前官方的监控数据来源是 metrics server 项目，可以配置的资源只有 CPU，但是用户可以使用自定义的监控数据（比如 prometheus），其他资源（比如 memory）的 HPA 支持也已经在路上了。</p><h3 id="Vertical-Pod-AutoScaling"><a href="#Vertical-Pod-AutoScaling" class="headerlink" title="Vertical Pod AutoScaling"></a>Vertical Pod AutoScaling</h3><p>和 HPA 的思路相似，只不过 VPA 调整的是单个 pod 的 request 值（包括 CPU 和 memory）。VPA 包括三个组件：</p><ul><li>Recommander：消费 metrics server 或者其他监控组件的数据，然后计算 pod 的资源推荐值</li><li>Updater：找到被 vpa 接管的 pod 中和计算出来的推荐值差距过大的，对其做 update 操作（目前是 evict，新建的 pod 在下面 admission controller 中会使用推荐的资源值作为 request）</li><li>Admission Controller：新建的 pod 会经过该 Admission  Controller，如果 pod 是被 vpa 接管的，会使用 recommander 计算出来的推荐值</li></ul><p>可以看到，这三个组件的功能是互相补充的，共同实现了动态修改 pod 请求资源的功能。相对于 HPA，目前 VPA 还处于 alpha，并且还没有合并到官方的 kubernetes release 中，后续的接口和功能很可能会发生变化。</p><h3 id="Cluster-Auto-Scaler"><a href="#Cluster-Auto-Scaler" class="headerlink" title="Cluster Auto Scaler"></a>Cluster Auto Scaler</h3><p>随着业务的发展，应用会逐渐增多，每个应用使用的资源也会增加，总会出现集群资源不足的情况。为了动态地应对这一状况，我们还需要 CLuster Auto Scaler，能够根据整个集群的资源使用情况来增减节点。</p><p>对于公有云来说，Cluster Auto Scaler 就是监控这个集群因为资源不足而 pending 的 pod，根据用户配置的阈值调用公有云的接口来申请创建机器或者销毁机器。对于私有云，则需要对接内部的管理平台。</p><p>目前 HPA 和 VPA 不兼容，只能选择一个使用，否则两者会相互干扰。而且 VPA 的调整需要重启 pod，这是因为 pod 资源的修改是比较大的变化，需要重新走一下 apiserver、调度的流程，保证整个系统没有问题。目前社区也有计划在做原地升级，也就是说不通过杀死 pod 再调度新 pod 的方式，而是直接修改原有 pod 来更新。</p><p>理论上 HPA 和 VPA 是可以共同工作的，HPA 负责瓶颈资源，VPA 负责其他资源。比如对于 CPU 密集型的应用，使用 HPA  监听 CPU 使用率来调整 pods 个数，然后用 VPA 监听其他资源（memory、IO）来动态扩展这些资源的 request 大小即可。当然这只是理想情况，</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>从前面介绍的各种 kubernetes 调度和资源管理方案可以看出来，提高应用的资源使用率、保证应用的正常运行、维护调度和集群的公平性是件非常复杂的事情，kubernetes 并没有<em>完美</em>的方法，而是对各种可能的问题不断提出一些针对性的方案。</p><p>集群的资源使用并不是静态的，而是随着时间不断变化的，目前 kubernetes 的调度决策都是基于调度时集群的一个静态资源切片进行的，动态地资源调整是通过 kubelet 的驱逐程序进行的，HPA 和 VPA 等方案也不断提出，相信后面会不断完善这方面的功能，让 kubernetes 更加智能。</p><p>资源管理和调度、应用优先级、监控、镜像中心等很多东西相关，是个非常复杂的领域。在具体的实施和操作的过程中，常常要考虑到企业内部的具体情况和需求，做出针对性的调整，并且需要开发者、系统管理员、SRE、监控团队等不同小组一起合作。但是这种付出从整体来看是值得的，提升资源的利用率能有效地节约企业的成本，也能让应用更好地发挥出作用。</p><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p>kubernetes 官方文档：</p><ul><li><a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/" target="_blank" rel="noopener">Managing Compute Resources for Containers</a>：如何为 pod 配置 cpu 和 memory 资源</li><li><a href="https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/" target="_blank" rel="noopener">Configure Quality of Service for Pods - Kubernetes</a>：pod QoS 的定义和配置规则</li><li><a href="https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/" target="_blank" rel="noopener">Configure Out Of Resource Handling - Kubernetes</a>：配置资源不足时 kubernetes 的 处理方式，也就是 eviction</li><li><a href="https://kubernetes.io/docs/concepts/policy/resource-quotas/" target="_blank" rel="noopener">kubernetes 官方文档：Resource Quota</a>：为 namespace 配置 quota</li><li><a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/resource-qos.md" target="_blank" rel="noopener">community/resource-qos.md at master · kubernetes/community · GitHub</a>：QoS 设计文档</li><li><a href="https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/" target="_blank" rel="noopener">Reserve Compute Resources for System Daemons</a>：如何在节点上预留资源</li><li><a href="https://github.com/kubernetes-incubator/descheduler" target="_blank" rel="noopener">GitHub - kubernetes-incubator/descheduler: Descheduler for Kubernetes</a>：descheduler 重调度官方 repo</li><li><a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/" target="_blank" rel="noopener">Horizontal Pod Autoscaler - Kubernetes</a>：kubernetes HPA 介绍文档</li><li><a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/autoscaling/vertical-pod-autoscaler.md" target="_blank" rel="noopener">community/vertical-pod-autoscaler.md at master · kubernetes/community · GitHub</a>: kubernetes VPA 设计文档</li></ul><p>其他文档：</p><ul><li><a href="https://speakerdeck.com/thockin/everything-you-ever-wanted-to-know-about-resource-scheduling-dot-dot-dot-almost" target="_blank" rel="noopener">Everything You Ever Wanted To Know About Resource Scheduling… Almost - Speaker Deck</a>: Tim Hockin 在 kubecon 上介绍的 kubernetes 资源管理理念，强烈推荐</li><li><a href="https://mp.weixin.qq.com/s/hyPNOcR3Nhy9bAiDhXUP7A" target="_blank" rel="noopener">聊聊Kubernetes计算资源模型（上）——资源抽象、计量与调度</a></li><li><a href="https://www.atatech.org/articles/99071" target="_blank" rel="noopener">【Sigma敏捷版系列文章】kubernetes应用驱逐分析</a></li><li><a href="https://www.atatech.org/articles/99071" target="_blank" rel="noopener">kubernetes 应用驱逐分析</a></li><li><a href="http://www.noqcks.io/notes/2018/02/03/understanding-kubernetes-resources/" target="_blank" rel="noopener">Understanding Kubernetes Resources | Benji Visser</a>：介绍了 kubernetes 的资源模型</li><li><a href="https://cloud.tencent.com/developer/article/1004976" target="_blank" rel="noopener">Kubernetes 资源分配之 Request 和 Limit 解析 - 云+社区 - 腾讯云</a>：用图表的方式解释了 requests 和 limits 的含义，以及在提高资源使用率方面的作用</li><li><a href="https://my.oschina.net/HardySimpson/blog/1359276" target="_blank" rel="noopener">kubernetes中容器资源控制的那些事儿</a>：这篇文章介绍了 kubernetes pod 中 cpu 和 memory 的 request 和 limits 是如何最终变成 cgroups 配置的</li><li><a href="https://medium.com/@Rancher_Labs/the-three-pillars-of-kubernetes-container-orchestration-247f42115a4a" target="_blank" rel="noopener">The Three Pillars of Kubernetes Container Orchestration</a>：kubernetes 调度、资源管理和服务介绍</li><li><a href="https://www.slideshare.net/AmazonWebServices/dem19-advanced-auto-scaling-and-deployment-tools-for-kubernetes-and-ecs" target="_blank" rel="noopener">DEM19 Advanced Auto Scaling and Deployment Tools for Kubernetes and E…</a></li><li><a href="https://my.oschina.net/jxcdwangtao/blog/837875" target="_blank" rel="noopener">Kubernetes Resource QoS机制解读</a></li><li><a href="https://www.jianshu.com/p/a5a7b3fb6806" target="_blank" rel="noopener">深入解析 kubernetes 资源管理，容器云牛人有话说 - 简书</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;kubernetes-资源简介&quot;&gt;&lt;a href=&quot;#kubernetes-资源简介&quot; class=&quot;headerlink&quot; title=&quot;kubernetes 资源简介&quot;&gt;&lt;/a&gt;kubernetes 资源简介&lt;/h2&gt;&lt;h3 id=&quot;什么是资源？&quot;&gt;&lt;a
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="docker" scheme="http://cizixs.com/tags/docker/"/>
    
      <category term="kubernetes" scheme="http://cizixs.com/tags/kubernetes/"/>
    
      <category term="container" scheme="http://cizixs.com/tags/container/"/>
    
      <category term="monitor" scheme="http://cizixs.com/tags/monitor/"/>
    
  </entry>
  
  <entry>
    <title>使用 promethues 和 grafana 监控自己的 linux 机器</title>
    <link href="http://cizixs.com/2018/01/24/use-prometheus-and-grafana-to-monitor-linux-machine/"/>
    <id>http://cizixs.com/2018/01/24/use-prometheus-and-grafana-to-monitor-linux-machine/</id>
    <published>2018-01-23T16:00:00.000Z</published>
    <updated>2018-10-01T07:36:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近在研究如何给应用添加合适的 metrics，用来分析应用的使用情况以及调试，整体思路是使用 promethues 收集数据，grafana 进行数据的展示。过程中发现了 node-exporter 项目，觉得可以直接拿来监控自己平时使用的 linux 机器，就有了这篇文章。</p><p>整个系统使用了三个组件：</p><ul><li>node-exporter：运行在主机上收集操作系统上各种数据的 agent，promethues 中称为 exporter</li><li>prometheus：开源的时序数据库，作为数据存储和分析的中心</li><li>grafana：数据展示分析界面，提供各种强大的 dashboard，可以从多个数据源读取数据，其中就包括 promethues</li></ul><p>NOTE：所有的服务都是通过 docker 启动的，需要安装 docker 和 docker-compose，并熟悉它们的使用。</p><h2 id="安装配置-promethues"><a href="#安装配置-promethues" class="headerlink" title="安装配置 promethues"></a>安装配置 promethues</h2><p>promethues 最早是 soundcloud 开发的一款时序数据库，用来作为 metrics 数据收集和存储，目前已经成为 CNCF 基金会下面的一个项目，也是 kubernets 官方推荐的 metrics 收集和监控工具。</p><p>首先，我们创建一个 <code>docker-compose.yml</code> 文件，里面只包含 promethues 一个服务：</p><pre><code>version: &#39;2&#39;services:  prometheus:    image: prom/prometheus:v2.0.0    volumes:      - ./prometheus.yml:/etc/prometheus/prometheus.yml    command:      - &#39;--config.file=/etc/prometheus/prometheus.yml&#39;    ports:      - &#39;9090:9090&#39;</code></pre><p>如果对 docker 和 docker-compose 熟悉的话，上面的内容容易理解：</p><ul><li>image 后面指定了使用的 promethues 容器镜像，该文件使用的是 v2.0.0 版本</li><li>volumes 把当前目录下面的 <code>prometheus.yml</code> 文件挂载到容器里，这样是因为后面会一直修改这个文件，利用 volume 挂载的方式比较灵活</li><li>command 指定了 promethues 运行的命令行参数，这里只指定配置文件的位置，更多参数可以使用 <code>--help</code> 来查看</li><li>ports 把 promethues 服务监听的端口映射到主机上，这样可以直接访问主机端口使用它</li></ul><p>其中比较重要的是 <code>prometheus.yml</code> 文件，它的内容如下：</p><pre><code>global:    scrape_interval: 5s    external_labels:        monitor: &#39;my-monitor&#39;scrape_configs:    - job_name: &#39;prometheus&#39;      static_configs:          - targets: [&#39;localhost:9090&#39;]</code></pre><p>这个配置文件一共分为两个部分：<code>global</code> 和 <code>scrape_configs</code>，前者是全局的配置，如果后面的任务没有对特定配置项进行覆盖，这里的选项会生效。这里有两个配置项，<code>scrape_interval</code> 表示 promethues server 抓取的周期，如果太频繁会导致 promethues 压力比较大，如果太久，可能会导致某些关键数据漏掉，推荐根据每个任务的重要性和集群规模分别进行配置。</p><p><code>scrape_configs</code> 配置了每个抓取任务，因此是一个列表，这里我们只有一个任务，那就是抓取 promethues 本身的 metrics。配置里面最重要的是 <code>static_configs.targets</code>，表示要抓取任务的 HTTP 地址，默认会在 <code>/metrics</code> url 出进行抓取，比如这里就是 <code>http://localhost:9090/</code>。 这是 prometheus 本身提供的监控数据，可以在浏览器中直接查看。</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fn9hdcuslmj30rd0l27b4.jpg" alt=""></p><p>每个数据都是有一个名字和一系列称为 label 的键值对组成的，prometheus 在抓取数据的时候还会自动添加上 <code>instance</code>（节点的 host:port 标识） 和 <code>job</code>（任务名称） 两个 label 作为任务之间的区分。</p><p>这些数据本身没有时间信息，当 promethues 抓取的时候会自动添加上当时的时间戳。此外这些数据在客户端会分成四种不同的类型：counter、gauge、histogram 和 summary。更多关于 promethues metrics 数据类型的说明请查阅官方文档。</p><p>运行 <code>docker-compose up -d</code> 启动服务，然后在浏览器中打开 <code>http://server-ip:9090/status</code> 查看 promethues 运行的状态信息：</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fn9h9plxmtj30rd0l2tb2.jpg" alt=""></p><p>整个 promethues 体系的工作原理如下所示：</p><p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fnacyud8n5j30ko0e5jso.jpg" alt=""></p><ul><li>promethues server 位于中心，负责时序数据的收集、存储和查询</li><li>左边是数据来源，promethues 统一采用拉取的模式（pull mode）从兼容的 HTTP 接口处获取数据，数据源可以分为三种<ol><li>本身就暴露 promethues 可读取 metrics 数据的或者专门为某个组件编写的 exporter，称为 Jobs 或者 Exporters，比如 node exporter，HAProxy、Nginx、MySQL 等服务的 exporter</li><li>通过 push gateway 可以把原来 push 类型的数据转换成 pull 类型 </li><li>其他 promethues server</li></ol></li><li>上面是目标自动发现机制。对于生产的很多情况，手动配置所有的 metrics 来源可能会非常繁琐，所以 promethues 支持 DNS、kubernetes、Consul 等服务发现机制来动态地获取目标源进行数据抓取</li><li>右下方是数据输出，一般是用来进行 UI 展示，可以使用 grafana 等开源方案，也可以直接读取 promethues 的接口进行自主开发</li><li>右上方是告警部分，用户需要配置告警规则，一旦 alertManager 发现监控数据匹配告警规则，就把告警信息通过邮件、社交账号发送出去</li></ul><h2 id="使用-node-exporter-收集监控数据"><a href="#使用-node-exporter-收集监控数据" class="headerlink" title="使用 node exporter 收集监控数据"></a>使用 node exporter 收集监控数据</h2><p>虽然监控 promethues 服务自身是件有趣而且有用的事情，但是我们的目标是监控 linux 主机。因为 promethues 只能从 HTTP 接口的某个地址来拉取监控数据，因此需要一个工具把 linux 提供的系统数据以 HTTP 服务的形式暴露出来。庆幸的是，promethues 官方社区有很多 exporter，它们负责把某个组件或者系统的 而监控数据以 promethues 能理解的方式暴露出来，其中 <a href="https://github.com/prometheus/node_exporter" target="_blank" rel="noopener">node exporter</a> 就是导出 unix/linux 系统监控数据的工具。</p><p>grafana 主要是从 <code>/proc</code> 中读取 linux 提供的各种数据，修改 docker-compose.yml 文件，添加上 node-exporter 相关的内容，node-exporter 默认会监听在 9100 端口：</p><pre><code>version: &#39;2&#39;services:  prometheus:    image: prom/prometheus:v2.0.0    volumes:      - ./prometheus.yml:/etc/prometheus/prometheus.yml    command:      - &#39;--config.file=/etc/prometheus/prometheus.yml&#39;    ports:      - &#39;9090:9090&#39;  node-exporter:    image: prom/node-exporter:v0.15.2    ports:      - &#39;9100:9100&#39;</code></pre><p>为了让 promethues 收集 node-exporter 的内容，我们需要在配置文件中加上一个单独的任务：</p><pre><code>global:    scrape_interval: 5s    external_labels:        monitor: &#39;my-monitor&#39;scrape_configs:    - job_name: &#39;prometheus&#39;      static_configs:          - targets: [&#39;localhost:9090&#39;]    - job_name: &#39;node resources&#39;      scrape_interval: 10s      static_configs:        - targets:          - &#39;node-exporter:9100&#39;</code></pre><p>因为 docker-compose 会自动做服务到 IP 地址的解析，因此这里可以直接使用 <code>node-exporter:9100</code> 作为地址。</p><p>再次运行，确认 promethues 中 targets 列表中有 node-exporter。</p><h2 id="安装配置-grafana"><a href="#安装配置-grafana" class="headerlink" title="安装配置 grafana"></a>安装配置 grafana</h2><p>prometheus 自带的 web 界面可以用来查询配置内容、监控节点是否运行正常，也可以用来查询某个 metric 的数值，以及提供简单的图形化功能。但是它的图形化功能比较单一， 当有很多数据要同时进行展示时，就需要借助更强大的 dashboard 工具，比如这里要介绍的 grafana。</p><p>grafana 是一款强大的 dashboard 工具，界面设计很好看，功能强大，可配置性非常灵活。</p><p>同样，在 docker-compose.yml 文件中加入 grafana 服务：</p><pre><code>version: &#39;2&#39;services:  prometheus:    image: prom/prometheus:v2.0.0    volumes:      - ./prometheus.yml:/etc/prometheus/prometheus.yml      - prometheus_data:/prometheus    command:      - &#39;--config.file=/etc/prometheus/prometheus.yml&#39;    ports:      - &#39;9090:9090&#39;  node-exporter:    image: prom/node-exporter:v0.15.2    ports:      - &#39;9100:9100&#39;  grafana:    image: grafana/grafana:4.6.2    volumes:        - grafana_data:/var/lib/grafana    environment:      - GF_SECURITY_ADMIN_PASSWORD=pass    depends_on:      - prometheus    ports:      - &#39;3000:3000&#39;volumes:  grafana_data: {}  prometheus_data: {}</code></pre><p>这里使用 docker 的 volumes 来保存 grafana 和 promethues 运行过程中产生的数据来保证持久化，而且使用 <code>GF_SECURITY_ADMIN_PASSWORD=pass</code> 环境变量设置 admin 的密码。</p><p>docker-compose 运行之后，grafana 会运行在 <code>http://host-ip:3000</code> 地址，使用浏览器打开会出现登陆页面，输入用户名和刚才配置的密码进入服务。</p><p>grafana 本身只是一个 dashboard，它可以从多个数据源（时序数据库）中获取数据进行展示，比如我们这里使用的 promethues。所以在正式配置界面之前，需要先添加数据源，点击 grafana 左上角按钮找到 <code>Data Sources</code> 页面或者直接输入 <code>http://host-ip:3000/datasources</code> 地址，会进入对应页面。按照下面的内容进行填写，主要是 Type 要选择 <code>prometheus</code>，URL 添加 grafana 服务能访问的 promethues 地址（因为它们都是通过 docker-compose 运行的，所以这里可以直接使用名字来标识）；Name 字段随便填写一个用来标记来源的名字即可。</p><p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fnhfgtpz5yj310j0s2adm.jpg" alt=""></p><p>然后创建一个 dashboard，并里面添加 graph（为了简单，我用了 test dashboard 这个名字），在 graph 中添加一个 panel，我们用这个 panel 展示系统的 load 数据。编辑 panel 数据，选择 data source 为之前添加的 promethues，然后填写 query，系统 node 比较简单，一共是 <code>node_load1</code>、<code>node_load5</code> 和 <code>node_load15</code>，分别是系统最近一分钟、五分钟和十五分钟的 load 数值。输入完成后点击输入框之外，grafana 会自动更新上面的图表：</p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fnhhktp3i4j313a0ut43t.jpg" alt=""></p><p>类似的，可以添加其他的 panel，展示系统方方面的监控数据，比如 CPU、memory、IO、网络等。grafana 更多配置可以参考<a href="http://docs.grafana.org/features/panels/graph/" target="_blank" rel="noopener">官方文档</a>，选择合适的图表来展示想要的结果。</p><p>手动通过界面对 grafana 可以很灵活地创建出很强大的图表，但是这无疑会耗费很多时间（想想，每次搭建 grafana 都要重新做一遍），而且 node exporter 这种监控数据是通用的，如果所有人都手动创建一遍无疑是很多重复工作。为此，grafana 支持导入和导出配置，并且提供<a href="https://grafana.com/dashboards" target="_blank" rel="noopener">官方社区</a>供大家分享 dashboard 配置。</p><p>每个 dashboard 都有一个编号，比如<a href="https://grafana.com/dashboards/22" target="_blank" rel="noopener">编号 22 的 dashboard</a> 就是专门为 node-exporter 设计的展示图表。在 grafana 中点击导入 dashboard，添加编号选择数据源，就能得到已经配置完整的图表：</p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fnii0bgqqzj313v0utdl9.jpg" alt=""></p><p>如果对 dashboard 有什么不满，可以直接在页面进行添加和编辑，然后可以导出 json 文件，以便重复使用。</p><h2 id="配置告警"><a href="#配置告警" class="headerlink" title="配置告警"></a>配置告警</h2><p>通过 grafana 图表我们可以知道系统各种指标随着时间的变化，方便轻松判断系统某个资源是否异常。但是我们不能一直盯着 dashboard，还需要系统发生异常的时候能立即通过邮件或者其他方式通知我们，这就是告警的功能。</p><p>promethues 提供用户可以自己配置的告警规则，在处理 metrics 数据的时候，如果发现某个规则被触发，就执行对应的告警动作，通过发邮件或者其他方式通知用户。</p><p>对于我们的单节点主机来说，可以定义两个简单的告警规则：当主机 download 掉，或者 CPU load 持续过高一段时间就发送告警。对此，需要新建一个 <code>alert.rules</code> 文件，用来保存告警规则，按照需求对应的内容如下：</p><pre><code>➜  monitor git:(master) ✗ cat alert.rulesgroups:- name: node-alert  rules:  - alert: service_down    expr: up == 0    for: 2m  - alert: high_load    expr: node_load1 &gt; 0.5    for: 5m</code></pre><p>在启动 promethues 服务的时候把告警规则文件 mount 到 pod 中，如下添加一个 volume：</p><pre><code>➜  monitor git:(master) ✗ cat docker-compose.ymlversion: &#39;2&#39;services:  prometheus:    image: prom/prometheus:v2.0.0    volumes:      - ./prometheus.yml:/etc/prometheus/prometheus.yml      - ./alert.rules:/etc/prometheus/alert.rules ......</code></pre><p>然后，告知 promethues 加载这些规则：</p><pre><code>➜  monitor git:(master) ✗ cat prometheus.yml......rule_files:  - &#39;alert.rules&#39;</code></pre><p>为了验证告警规则是否生效，可以把 <code>node-exporter</code> 服务停掉：</p><pre><code>docker-compose stop node-exporter</code></pre><p>在 promethues 的告警页面(alert) 查看告警：</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fniiqnn2oij310r0ma0uw.jpg" alt=""></p><p>类似地，可以运行一些消耗 CPU 资源的服务来触发系统 load 过高的告警规则，比如运行下面这个 docker 容器（一直 while 循环霸占 CPU 资源可以轻松把 CPU load 提到很高）：</p><pre><code>docker run --rm -it busybox sh -c &quot;while true; do :; done&quot;</code></pre><p>promethues 还提供了 alertmanager 可以自动化根据告警规则触发对应的动作，一般是各种方式通知用户和管理员，这里就不再介绍了。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文中使用的完整配置文件放到了 <a href="https://github.com/cizixs/node-prometheus-monitor" target="_blank" rel="noopener">github 上</a>，可以作为参考。</p><p>需要注意的是，这只是一个本地的 test 环境，不能直接在生产上使用。首先我们没有配置安全访问，所有的服务都是 HTTP；其次 docker-compose 运行的话，所有的服务都是在同一台机器上，无法做到分布式监控和高可用。</p><p>如果想在生产中使用 promethues 和 grafana，请参考官方文档。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://fritshoogland.wordpress.com/2017/07/31/installation-overview-of-node_exporter-prometheus-and-grafana/" target="_blank" rel="noopener">Installation overview of node_exporter, prometheus and grafana</a></li><li><a href="https://finestructure.co/blog/2016/5/16/monitoring-with-prometheus-grafana-docker-part-1" target="_blank" rel="noopener">Monitoring with Prometheus, Grafana &amp; Docker Part 1</a></li><li><a href="https://www.digitalocean.com/community/tutorials/how-to-add-a-prometheus-dashboard-to-grafana" target="_blank" rel="noopener"> How To Add a Prometheus Dashboard to Grafana</a></li><li><a href="https://resin.io/blog/monitoring-linux-stats-with-prometheus-io/" target="_blank" rel="noopener">Monitoring linux stats with Prometheus.io</a></li><li><a href="https://stefanprodan.com/2016/a-monitoring-solution-for-docker-hosts-containers-and-containerized-services/" target="_blank" rel="noopener">a monitoring solution for docker and containerized services</a></li><li><a href="https://www.digitalocean.com/community/tutorials/how-to-query-prometheus-on-ubuntu-14-04-part-1" target="_blank" rel="noopener">How To Query Prometheus on Ubuntu 14.04</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;最近在研究如何给应用添加合适的 metrics，用来分析应用的使用情况以及调试，整体思路是使用 promethues 收集数据，grafana 进行数据的展示。过程中发现了 node-exporter 项目，觉得可以直接拿来监控自己平时使用的 linux
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="linux" scheme="http://cizixs.com/tags/linux/"/>
    
      <category term="docker" scheme="http://cizixs.com/tags/docker/"/>
    
      <category term="prometheus" scheme="http://cizixs.com/tags/prometheus/"/>
    
      <category term="grafana" scheme="http://cizixs.com/tags/grafana/"/>
    
      <category term="monitor" scheme="http://cizixs.com/tags/monitor/"/>
    
  </entry>
  
  <entry>
    <title>linux 系统 UDP 丢包问题分析思路</title>
    <link href="http://cizixs.com/2018/01/13/linux-udp-packet-drop-debug/"/>
    <id>http://cizixs.com/2018/01/13/linux-udp-packet-drop-debug/</id>
    <published>2018-01-12T16:00:00.000Z</published>
    <updated>2019-03-18T13:05:04.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近工作中遇到某个服务器应用程序 UDP 丢包，在排查过程中查阅了很多资料，总结出来这篇文章，供更多人参考。</p><p>在开始之前，我们先用一张图解释 linux 系统接收网络报文的过程。</p><ol><li>首先网络报文通过物理网线发送到网卡</li><li>网络驱动程序会把网络中的报文读出来放到 ring buffer 中，这个过程使用 DMA（Direct Memory Access），不需要 CPU 参与</li><li>内核从 ring buffer 中读取报文进行处理，执行 IP 和 TCP/UDP 层的逻辑，最后把报文放到应用程序的 socket buffer 中</li><li>应用程序从 socket buffer 中读取报文进行处理</li></ol><p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fnf8b0c64xj31hc0u0goa.jpg" alt=""></p><p>在接收 UDP 报文的过程中，图中任何一个过程都可能会主动或者被动地把报文丢弃，因此丢包可能发生在网卡和驱动，也可能发生在系统和应用。</p><p>之所以没有分析发送数据流程，一是因为发送流程和接收类似，只是方向相反；另外发送流程报文丢失的概率比接收小，只有在应用程序发送的报文速率大于内核和网卡处理速率时才会发生。</p><p>本篇文章假定机器只有一个名字为 <code>eth0</code> 的 interface，如果有多个 interface 或者 interface 的名字不是 eth0，请按照实际情况进行分析。</p><p>NOTE：文中出现的 <code>RX</code>（receive） 表示接收报文，<code>TX</code>（transmit） 表示发送报文。</p><h2 id="确认有-UDP-丢包发生"><a href="#确认有-UDP-丢包发生" class="headerlink" title="确认有 UDP 丢包发生"></a>确认有 UDP 丢包发生</h2><p>要查看网卡是否有丢包，可以使用 <code>ethtool -S eth0</code> 查看，在输出中查找 <code>bad</code> 或者 <code>drop</code> 对应的字段是否有数据，在正常情况下，这些字段对应的数字应该都是 0。如果看到对应的数字在不断增长，就说明网卡有丢包。</p><p>另外一个查看网卡丢包数据的命令是 <code>ifconfig</code>，它的输出中会有 <code>RX</code>(receive 接收报文)和 <code>TX</code>（transmit 发送报文）的统计数据：</p><pre><code>~# ifconfig eth0...        RX packets 3553389376  bytes 2599862532475 (2.3 TiB)        RX errors 0  dropped 1353  overruns 0  frame 0        TX packets 3479495131  bytes 3205366800850 (2.9 TiB)        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0...</code></pre><p>此外，linux 系统也提供了各个网络协议的丢包信息，可以使用 <code>netstat -s</code> 命令查看，加上 <code>--udp</code> 可以只看 UDP 相关的报文数据：</p><pre><code>[root@holodesk02 GOD]# netstat -s -uIcmpMsg:    InType0: 3    InType3: 1719356    InType8: 13    InType11: 59    OutType0: 13    OutType3: 1737641    OutType8: 10    OutType11: 263Udp:    517488890 packets received    2487375 packets to unknown port received.    47533568 packet receive errors    147264581 packets sent    12851135 receive buffer errors    0 send buffer errorsUdpLite:IpExt:    OutMcastPkts: 696    InBcastPkts: 2373968    InOctets: 4954097451540    OutOctets: 5538322535160    OutMcastOctets: 79632    InBcastOctets: 934783053    InNoECTPkts: 5584838675</code></pre><p>对于上面的输出，关注下面的信息来查看 UDP 丢包的情况：</p><ul><li><code>packet receive errors</code> 不为空，并且在一直增长说明系统有 UDP 丢包</li><li><code>packets to unknown port received</code> 表示系统接收到的 UDP 报文所在的目标端口没有应用在监听，一般是服务没有启动导致的，并不会造成严重的问题</li><li><code>receive buffer errors</code> 表示因为 UDP 的接收缓存太小导致丢包的数量 </li></ul><p><strong>NOTE</strong>： 并不是丢包数量不为零就有问题，对于 UDP 来说，如果有少量的丢包很可能是预期的行为，比如丢包率（丢包数量/接收报文数量）在万分之一甚至更低。</p><h2 id="网卡或者驱动丢包"><a href="#网卡或者驱动丢包" class="headerlink" title="网卡或者驱动丢包"></a>网卡或者驱动丢包</h2><p>之前讲过，如果 <code>ethtool -S eth0</code> 中有 <code>rx_***_errors</code> 那么很可能是网卡有问题，导致系统丢包，需要联系服务器或者网卡供应商进行处理。</p><pre><code># ethtool -S eth0 | grep rx_ | grep errors     rx_crc_errors: 0     rx_missed_errors: 0     rx_long_length_errors: 0     rx_short_length_errors: 0     rx_align_errors: 0     rx_errors: 0     rx_length_errors: 0     rx_over_errors: 0     rx_frame_errors: 0     rx_fifo_errors: 0</code></pre><p><code>netstat -i</code> 也会提供每个网卡的接发报文以及丢包的情况，正常情况下输出中 error 或者 drop 应该为 0。</p><p>如果硬件或者驱动没有问题，一般网卡丢包是因为设置的缓存区（ring buffer）太小，可以使用 <code>ethtool</code> 命令查看和设置网卡的 ring buffer。</p><p><code>ethtool -g</code> 可以查看某个网卡的 ring buffer，比如下面的例子</p><pre><code># ethtool -g eth0Ring parameters for eth0:Pre-set maximums:RX:        4096RX Mini:    0RX Jumbo:    0TX:        4096Current hardware settings:RX:        256RX Mini:    0RX Jumbo:    0TX:        256</code></pre><p>Pre-set 表示网卡最大的 ring buffer 值，可以使用 <code>ethtool -G eth0 rx 8192</code> 设置它的值。</p><h2 id="Linux-系统丢包"><a href="#Linux-系统丢包" class="headerlink" title="Linux 系统丢包"></a>Linux 系统丢包</h2><p>linux 系统丢包的原因很多，常见的有：UDP 报文错误、防火墙、UDP buffer size 不足、系统负载过高等，这里对这些丢包原因进行分析。</p><h3 id="UDP-报文错误"><a href="#UDP-报文错误" class="headerlink" title="UDP 报文错误"></a>UDP 报文错误</h3><p>如果在传输过程中UDP 报文被修改，会导致 checksum 错误，或者长度错误，linux 在接收到 UDP 报文时会对此进行校验，一旦发明错误会把报文丢弃。</p><p>如果希望 UDP 报文 checksum 及时有错也要发送给应用程序，可以在通过 socket 参数禁用 UDP checksum 检查：</p><pre><code>int disable = 1;setsockopt(sock_fd, SOL_SOCKET, SO_NO_CHECK, (void*)&amp;disable, sizeof(disable)</code></pre><h3 id="防火墙"><a href="#防火墙" class="headerlink" title="防火墙"></a>防火墙</h3><p>如果系统防火墙丢包，表现的行为一般是所有的 UDP 报文都无法正常接收，当然不排除防火墙只 drop 一部分报文的可能性。</p><p>如果遇到丢包比率非常大的情况，请先检查防火墙规则，保证防火墙没有主动 drop UDP 报文。</p><h3 id="UDP-buffer-size-不足"><a href="#UDP-buffer-size-不足" class="headerlink" title="UDP buffer size 不足"></a>UDP buffer size 不足</h3><p>linux 系统在接收报文之后，会把报文保存到缓存区中。因为缓存区的大小是有限的，如果出现 UDP 报文过大（超过缓存区大小或者 MTU 大小）、接收到报文的速率太快，都可能导致 linux 因为缓存满而直接丢包的情况。</p><p>在系统层面，linux 设置了 receive buffer 可以配置的最大值，可以在下面的文件中查看，一般是 linux 在启动的时候会根据内存大小设置一个初始值。</p><ul><li>/proc/sys/net/core/rmem_max：允许设置的 receive buffer 最大值</li><li>/proc/sys/net/core/rmem_default：默认使用的 receive buffer 值</li><li>/proc/sys/net/core/wmem_max：允许设置的 send buffer 最大值</li><li>/proc/sys/net/core/wmem_dafault：默认使用的 send buffer 最大值</li></ul><p>但是这些初始值并不是为了应对大流量的 UDP 报文，如果应用程序接收和发送 UDP 报文非常多，需要讲这个值调大。可以使用 <code>sysctl</code> 命令让它立即生效：</p><pre><code>sysctl -w net.core.rmem_max=26214400 # 设置为 25M</code></pre><p>也可以修改 <code>/etc/sysctl.conf</code> 中对应的参数在下次启动时让参数保持生效。</p><p>如果报文报文过大，可以在发送方对数据进行分割，保证每个报文的大小在 MTU 内。</p><p>另外一个可以配置的参数是 <code>netdev_max_backlog</code>，它表示 linux 内核从网卡驱动中读取报文后可以缓存的报文数量，默认是 1000，可以调大这个值，比如设置成 2000：</p><pre><code>sudo sysctl -w net.core.netdev_max_backlog=2000</code></pre><h3 id="系统负载过高"><a href="#系统负载过高" class="headerlink" title="系统负载过高"></a>系统负载过高</h3><p>系统 CPU、memory、IO 负载过高都有可能导致网络丢包，比如 CPU 如果负载过高，系统没有时间进行报文的 checksum 计算、复制内存等操作，从而导致网卡或者 socket buffer 出丢包；memory 负载过高，会应用程序处理过慢，无法及时处理报文；IO 负载过高，CPU 都用来响应 IO wait，没有时间处理缓存中的 UDP 报文。</p><p>linux 系统本身就是相互关联的系统，任何一个组件出现问题都有可能影响到其他组件的正常运行。对于系统负载过高，要么是应用程序有问题，要么是系统不足。对于前者需要及时发现，debug 和修复；对于后者，也要及时发现并扩容。</p><h2 id="应用丢包"><a href="#应用丢包" class="headerlink" title="应用丢包"></a>应用丢包</h2><p>上面提到系统的 UDP buffer size，调节的 sysctl 参数只是系统允许的最大值，每个应用程序在创建 socket 时需要设置自己 socket buffer size 的值。</p><p>linux 系统会把接受到的报文放到 socket 的 buffer 中，应用程序从 buffer 中不断地读取报文。所以这里有两个和应用有关的因素会影响是否会丢包：socket buffer size 大小以及应用程序读取报文的速度。</p><p>对于第一个问题，可以在应用程序初始化 socket 的时候设置 socket receive buffer 的大小，比如下面的代码把 socket buffer 设置为 20MB：</p><pre><code>uint64_t receive_buf_size = 20*1024*1024;  //20 MBsetsockopt(socket_fd, SOL_SOCKET, SO_RCVBUF, &amp;receive_buf_size, sizeof(receive_buf_size));</code></pre><p>如果不是自己编写和维护的程序，修改应用代码是件不好甚至不太可能的事情。很多应用程序会提供配置参数来调节这个值，请参考对应的官方文档；如果没有可用的配置参数，只能给程序的开发者提 issue 了。</p><p>很明显，增加应用的 receive buffer 会减少丢包的可能性，但同时会导致应用使用更多的内存，所以需要谨慎使用。</p><p>另外一个因素是应用读取 buffer 中报文的速度，对于应用程序来说，处理报文应该采取异步的方式</p><h2 id="包丢在什么地方"><a href="#包丢在什么地方" class="headerlink" title="包丢在什么地方"></a>包丢在什么地方</h2><p>想要详细了解 linux 系统在执行哪个函数时丢包的话，可以使用 <code>dropwatch</code> 工具，它监听系统丢包信息，并打印出丢包发生的函数地址：</p><pre><code># dropwatch -l kasInitalizing kallsyms dbdropwatch&gt; startEnabling monitoring...Kernel monitoring activated.Issue Ctrl-C to stop monitoring1 drops at tcp_v4_do_rcv+cd (0xffffffff81799bad)10 drops at tcp_v4_rcv+80 (0xffffffff8179a620)1 drops at sk_stream_kill_queues+57 (0xffffffff81729ca7)4 drops at unix_release_sock+20e (0xffffffff817dc94e)1 drops at igmp_rcv+e1 (0xffffffff817b4c41)1 drops at igmp_rcv+e1 (0xffffffff817b4c41)</code></pre><p>通过这些信息，找到对应的内核代码处，就能知道内核在哪个步骤中把报文丢弃，以及大致的丢包原因。</p><p>此外，还可以使用 linux perf 工具监听 <code>kfree_skb</code>（把网络报文丢弃时会调用该函数） 事件的发生：</p><pre><code>sudo perf record -g -a -e skb:kfree_skbsudo perf script</code></pre><p>关于 perf 命令的使用和解读，网上有很多文章可以参考。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>UDP 本身就是无连接不可靠的协议，适用于报文偶尔丢失也不影响程序状态的场景，比如视频、音频、游戏、监控等。对报文可靠性要求比较高的应用不要使用 UDP，推荐直接使用 TCP。当然，也可以在应用层做重试、去重保证可靠性</li><li>如果发现服务器丢包，首先通过监控查看系统负载是否过高，先想办法把负载降低再看丢包问题是否消失</li><li>如果系统负载过高，UDP 丢包是没有有效解决方案的。如果是应用异常导致 CPU、memory、IO 过高，请及时定位异常应用并修复；如果是资源不够，监控应该能及时发现并快速扩容</li><li>对于系统大量接收或者发送 UDP 报文的，可以通过调节系统和程序的 socket buffer size 来降低丢包的概率</li><li>应用程序在处理 UDP 报文时，要采用异步方式，在两次接收报文之间不要有太多的处理逻辑</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://discuss.pivotal.io/hc/en-us/articles/218765528-Network-troubleshooting-guide" target="_blank" rel="noopener">Pivotal: Network troubleshooting guide</a></li><li><a href="https://support.hpe.com/hpsc/doc/public/display?docId=mmr_kc-0102153" target="_blank" rel="noopener">What are udp “packet receive errors” and “packets to unknown port received”</a></li><li><a href="https://ref.onixs.biz/lost-multicast-packets-troubleshooting.html" target="_blank" rel="noopener">Lost multicast packets troubleshooting guide</a></li><li><a href="https://answers.splunk.com/answers/7001/udp-drops-on-linux.html" target="_blank" rel="noopener">splunk Answers: UDP Drops on Linux</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;最近工作中遇到某个服务器应用程序 UDP 丢包，在排查过程中查阅了很多资料，总结出来这篇文章，供更多人参考。&lt;/p&gt;
&lt;p&gt;在开始之前，我们先用一张图解释 linux
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="linux" scheme="http://cizixs.com/tags/linux/"/>
    
      <category term="network" scheme="http://cizixs.com/tags/network/"/>
    
      <category term="performance" scheme="http://cizixs.com/tags/performance/"/>
    
      <category term="udp" scheme="http://cizixs.com/tags/udp/"/>
    
  </entry>
  
  <entry>
    <title>CNCF 云原生容器生态系统概要</title>
    <link href="http://cizixs.com/2017/12/30/cncf-cloud-native-landscape/"/>
    <id>http://cizixs.com/2017/12/30/cncf-cloud-native-landscape/</id>
    <published>2017-12-29T16:00:00.000Z</published>
    <updated>2019-03-18T13:19:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>CNCF（Cloud Native Compute Foundation） 是 Linux 基金会旗下的一个组织，旨在推动以容器为中心的云原生系统。从 2016 年 11 月，CNCF 开始维护了一个 <a href="https://github.com/cncf/landscape" target="_blank" rel="noopener">Cloud Native Landscape</a> 的 repo，汇总目前比较流行的云原生技术，并加以分类，希望能为企业构建云原生体系提供参考。</p><p>2017 年 12 月 06 日，landscape 的 v1.0 版本发布，本文就按照下面这种图介绍云原生系统的大致情况。</p><p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fmctola4a6j31kw0w0npf.jpg" alt=""></p><p>云原生以容器为核心技术，分为运行时（runtime）和 orchestration 两层，runtime 负责容器的计算、存储、网络；orchestration 负责容器集群的调度、服务发现和资源管理。</p><p>往下是基础设施和配置管理，作为容器底层的基石。容器可以运行在各种系统上，包括公有云、私有云、物理机等；容器还依赖自动化部署工具、容器镜像工具、安全工具等运维系统才能工作。</p><p>往上是容器平台上的应用层，类似于手机的 app store，图中分为数据库和数据分析、流处理、SCM 工具、CI/CD 和应用定义几类，每个公司根据业务需求会有不同的应用体系。</p><p>右边有两块：平台和观察分析。平台是指基于容器技术提供的平台级的服务，比如常见的 Paas 服务，和 Serverless 服务。观察分析是容器平台的运维，从日志和监控方面给出容器集群当前的运行情况，方便分析和 debug。</p><p><strong>NOTE</strong>：因为图中给出的软件很多，所以文中会挑选一些比较有名的以及本人比较熟悉的介绍，会略过一些信息；此外，也因为个人的水平有限，并没有对所有产品都一一使用过，因此有些内容未免有偏颇或者错误之处，如果读者发现，还望能不吝指出。</p><h2 id="1-Cloud（云）"><a href="#1-Cloud（云）" class="headerlink" title="1. Cloud（云）"></a>1. Cloud（云）</h2><p>容器需要运行在操作系统上，系统可以运行在虚拟机或者物理机上。从使用方式上来分，操作系统这层（Iaas） 可以分为公有云和私有云。</p><h3 id="公有云"><a href="#公有云" class="headerlink" title="公有云"></a>公有云</h3><p>公有云国外以亚马逊 AWS、微软 Azure、谷歌 GCP、DigitalOcean 为代表，国内有阿里云、腾讯云、华为云，此外IBM、oracle、Fujitsu 都有自己的云产品，Joyent 也是国外很有名的云计算公司；packet 是物理机云服务商，直接为用户提供物理机资源。</p><p>企业一般会选择其中一个平台来使用，也有不少企业同时选择两种或者多种云服务商，以提高可用性和避免厂商锁定。</p><h3 id="私有云"><a href="#私有云" class="headerlink" title="私有云"></a>私有云</h3><p>私有云是指用户在自己的数据中心搭建的云服务，除了自己研发之外，常见搭建私有云的方法有 Vmware（商业化的虚拟化软件） 和 openstack（python 编写的开源 Iaas 平台软件）；此外 Maas 提供物理机自动安装和管理服务，分为免费版和收费版；foreman 是虚拟机和物理机的系统配置工具。</p><p>建设私有云的成本很高，但是当公司成长到一定规模的时候，私有云建设也是必要的一件事。除了能缩减成本，也能提高技术实力，而且也有更多的灵活性满足内部的各种需求。</p><h2 id="2-Provisioning（部署）"><a href="#2-Provisioning（部署）" class="headerlink" title="2. Provisioning（部署）"></a>2. Provisioning（部署）</h2><p>有了物理机和虚拟机，在运行容器服务之前，我们还需要为容器准备标准化的基础环境，以及保证基础设施的自动化，拿盖房子来比较，Iaas 和这部分共同组成了容器平台的地基。</p><h3 id="Host-Management-Tooling"><a href="#Host-Management-Tooling" class="headerlink" title="Host Management / Tooling"></a>Host Management / Tooling</h3><p>自动化配置工具，保证容器运行的系统配置的一致性，并提供升级、补丁等功能，一般也可以用来 bootstrap 容器服务。</p><p>这里的几家软件功能大同小异：</p><ul><li><code>ansible</code> 比较简洁，用 ssh 来自动化部署，使用 python 编写</li><li><code>cfEngine</code> 是这个领域非常老的工具，可以说是配置管理的元老，用 C 编写，因此性能会更好，但是学习曲线也更曲折</li><li><code>chef</code> 用 ruby 编写，而且配置文件格式也是 ruby DSL，因此对于 ruby 程序员非常亲切友好</li><li><code>saltstack</code> 采用 zeroMQ 作为消息队列，实现 master-salve 模式，兼具性能和灵活性，但同时整个系统也更加复杂</li><li><code>puppet</code> 是这个领域的老大哥，以成熟稳定著称，社区文档也更丰富</li></ul><p><a href="https://www.intigua.com/blog/puppet-vs.-chef-vs.-ansible-vs.-saltstack" target="_blank" rel="noopener">这篇博客</a> 和<a href="https://www.upguard.com/articles/the-7-configuration-management-tools-you-need-to-know" target="_blank" rel="noopener">这篇文章</a>比较了 CFEngine vs Puppet vs Chef vs Ansible vs Salt 这几个工具的异同，如果纠结如何选型，推荐阅读。</p><p>其实，对于大多数需求，根据开发语言、配置文件风格等选择其中一种就行。</p><h3 id="Infrastructure-Automation"><a href="#Infrastructure-Automation" class="headerlink" title="Infrastructure Automation"></a>Infrastructure Automation</h3><p>Iaas 平台提供了基础设施服务，但是对于复杂的场景来说，直接使用这些服务提供的接口还是会很麻烦，所以有了基础设施自动化。这部分做的事情就是能够让基础设施的配置自动化，一次完成多个资源的部署，提高效率。</p><ul><li><code>Bosh</code>：CloudFoundry 旗下的产品</li><li><code>Cloudify</code>：云应用编排系统，能够让用户定义软件，然后部署到不同的云环境中</li><li><code>CloudFormation</code>：AWS 提供的基础配置服务，能够通过配置文件定义要创建的各种 AWS 服务，然后一键完成集群或者系统的搭建</li><li><code>Ubuntu Juju</code>：Ubuntu 提供的管理工具，能够自动化把几百种服务部署到不同的平台</li><li><code>Terraform</code>：HashiCorp 旗下的基础设施配置工具，通过定义一份配置文件，Terraform 能够在不同云提供商运行服务，是 Infrastructure as Code 的信奉者</li><li><code>Manage IQ</code>：统一管理云主机、容器、网络、存储的 IT 平台</li><li><code>kubicorn</code>：管理多个 kubernetes 集群的工具，集群可以在不同的云上</li><li><code>Helm</code>：kubernetes 软件包安装工具，能够安装多个 kubernetes 资源，类似于 ubuntu 的 apt 工具</li></ul><p>总的来说，这些工具就是在云平台或者 kubernetes 平台上再封装一层，让用户能够通过一次定义，在不同平台部署多个资源或者服务，并做到版本升级和跟踪。如果云平台提供相关服务（比如 AWS 的 CloudFormation）直接使用即可，如果是混合云，则需要选择 Juju、Terraform 这样的管理工具。</p><h3 id="Container-Registries"><a href="#Container-Registries" class="headerlink" title="Container Registries"></a>Container Registries</h3><p>容器的镜像 registry 是容器平台的基础需求，毕竟所有的容器应用就是通过镜像来定义的，镜像服务分为自建和公有服务两种。</p><p>很多公司提供了它们公开的容器 registr 服务，比如 docker 官方的 registry，亚马逊 ECR（Elastic Container Registry）、Azure 和 Google 云 registry、此外 Quay、project atomic、JFrog Artifactory 也是比较著名的容器镜像服务提供商。</p><p>Harbor 是开源的企业级容器镜像管理平台，Portus 专门为 Docker registry 提供授权服务。</p><p>国内一般企业会选择自建 registry，因为国外的 registry 访问速度都很慢，而国内并没有非常流行的 registry 服务（当然很多容器服务公司都会提供 registry 服务），另一方面自建 registry 的技术并不复杂。</p><h3 id="Secure-Images"><a href="#Secure-Images" class="headerlink" title="Secure Images"></a>Secure Images</h3><p>随着镜像和容器标准化的完善，镜像和容器的安全也越来越受到企业的关注。虽然在大多数情况下，安全往往是软件开发者最后才关心的事情，但是容器安全却是不容忽视的一个环节。</p><p><a href="https://github.com/theupdateframework/notary" target="_blank" rel="noopener">notary</a> 和 <a href="https://github.com/theupdateframework/tuf" target="_blank" rel="noopener">tuf</a>（the update framework） 是 CNCF 旗下的两个项目，tuf 是开源的安全和验证标准，notary 是它的一个实现，notary 可以用来验证镜像的安全性，也可以用来安全地发布软件包。</p><ul><li><a href="https://github.com/coreos/clair" target="_blank" rel="noopener">clair</a>：coreOS 开源的容器安全性分析工具</li><li>twistlock 是云原生系统的安全性平台</li><li>NeuVector 是网络安全分析工具</li><li>aqua 也是容器安全平台，提供镜像、容器、用户认证、网络流量限制等多种安全功能</li><li>anchore 提供了一系列容器环境安全分析、审查和扫描工具</li></ul><h3 id="Key-Management"><a href="#Key-Management" class="headerlink" title="Key Management"></a>Key Management</h3><p>和安全相关的另一个问题是机密信息，包括密码数据、密钥等。</p><p>Keywhiz、pinterest 开源的 knox、lyft 开源的密码存储工具 confidant 和 HashiCorp 开源的 <a href="https://www.vaultproject.io/" target="_blank" rel="noopener">vault</a> 想要解决机密信息的存储，它们通过加密的方式把内容保存到后端存储中，而且提供了 auditing 等额外功能。</p><p><a href="https://spiffe.io/" target="_blank" rel="noopener">spiffe</a> 和 <a href="https://spiffe.io/spire/" target="_blank" rel="noopener">spire</a> 是一对的，spiffe 定义了服务的认证标准和认证信息的标准，spire 是它的一个实现，但是目前还没有达到生产可用。</p><h2 id="3-Runtime（运行时）"><a href="#3-Runtime（运行时）" class="headerlink" title="3. Runtime（运行时）"></a>3. Runtime（运行时）</h2><p>容器运行时这块是容器核心的技术，关注的是主机容器的技术模块，分为计算、存储、网络三块。</p><h3 id="Container-Runtime（容器运行时）"><a href="#Container-Runtime（容器运行时）" class="headerlink" title="Container Runtime（容器运行时）"></a>Container Runtime（容器运行时）</h3><p>我们知道，整个容器技术就是因为 docker 的出现才变得炙手可热，可以说 docker 重新定义了容器，也成为了容器技术的代名词。但是随着容器的标准化，docker 把核心组件抽象出 containerd，作为容器运行时，而更多公司也推出自己的容器实现，<strong>容器</strong>一词的含义开始扩展，而且也逐渐标准化了。</p><p>随着容器运行时的稳定，普通用户对其关注会逐渐下降。如果把运行时比作内核，那么容器调度系统就是操作系统，开发者应该更关心操作系统的功能和性能，只有遇到特殊需求或者问题时才会关注内核。</p><p>OCI（Open Container Initiative）是一个促进容器标准化的组织，主要工作是容器 runtime 和镜像的标准化协议，这部分内容可以参考我<a href="http://cizixs.com/2017/11/05/oci-and-runc">之前的介绍文章</a>。</p><ul><li>containerd：docker 公司从原来的 docker 引擎中剥离出来的容器核心功能，具有镜像管理和容器隔离两大功能，底层使用 runc </li><li>rkt：CoreOS 公司提出的容器引擎技术，一直作为 docker 的直接竞争对手存在，对于促进容器标准化贡献很大</li><li><a href="https://github.com/lxc/lxd" target="_blank" rel="noopener">lxd</a>：基于 linux 老牌容器管理工具 lxc，旨在提供更好用的接口，最大的特色是使用容器技术提供类似虚拟机的服务</li><li><a href="https://github.com/hyperhq/runv" target="_blank" rel="noopener">runv</a>：以兼容 OCI 接口的方式管理虚拟机，支持 kvm、Xen、QEMU 等虚拟化技术。换句话说，可以直接把虚拟机作为 runtime 运行在容器集群管理平台上</li><li>Intel Clear Containers：Intel 公司推出的容器技术，因为爸爸的缘故最近也开始出现在容器圈各种文章里</li></ul><p>CRI-O 是 kubernetes 推出的东西，它是 kubelet 和 OCI runtime 之间的桥梁，它内部采用 OCI 标准，因此可以兼容各种 runtime（比如 runc、Clear Container等），对上它提供 CRI 接口供 kubelet 调用。这样的话，CRI-O 的存在能够让 kubelet 使用任何 OCI 兼容的 runtime，从而绕过 docker、rkt 这种完整容器管理工具。</p><h3 id="Cloud-Native-Storage（云原生存储）"><a href="#Cloud-Native-Storage（云原生存储）" class="headerlink" title="Cloud Native Storage（云原生存储）"></a>Cloud Native Storage（云原生存储）</h3><p>容器从一出现就非常契合微服务中无状态服务的设计理念，因此初期甚至给了一些人容器只适合无状态服务的印象，但是随着容器技术的成熟和用户理念的变化，容器目前已经全面进入有状态服务领域。因为容器存活时间很短的特点，容器的状态（存储的数据）必须独立于容器的生命周期，也因为此，容器的存储变得非常重要，<strong>云原生存储</strong>这块介绍了很多相关的技术。</p><p>作为 IT 领域的核心技术，存储早在容器火起来之前就已经有发展了很多年，从单机的各种文件系统、到网络存储，再到现在比较热门的分布式存储、以及云计算催生的块存储、文件存储、对象存储，不同需求不同分类的存储早就五花八门了：</p><ul><li>Ceph：分布式存储系统，同时支持块存储、文件存储和对象存储，发展时间很久，稳定性也得到了验证。之前在 openstack 社区被广泛使用，目前在容器社区也是很好的选项。</li><li>GlusterFS：RedHat 旗下的产品，部署简单，扩展性强，</li><li>Hadoop HDFS：Apache 基金会下的开源文件系统项目，在大数据领域广泛使用，基于 GFS 理念的开源版本。主节点保存元数据，并负责数据分布、复制、备份决策，工作节点存储数据，每个数据会有多个副本，保存在不同的工作节点</li><li>SheepDog：起源于日本的块存储开源项目，设计之初是为了用于虚拟化平台 QEMU</li><li>Swift：openstack 项目提供的对象存储工具</li><li>LeoFS：高可用、分布式的对象存储系统，海量数据支持比较好，提供 HTTP、S3、NFS 等接口访问</li><li>minio：开源的对象存储软件，提供和 AWS S3 兼容的接口，简单易用</li></ul><p>除了这些开源的存储技术之外，还有很多容器存储圈的技术公司：</p><ul><li>DELL EMC：商业存储的典范，提供企业级各种需求的存储解决方案，作为商业存储的大哥，自然也会在容器存储上发力</li><li>NetApp：致力于混合云的存储方案，是一家老牌的公司，在存储行业深耕多年</li><li>Datera：一家存储创业公司，主要产品是 EDF(Elastic Data Fabric)，提供 API 优先的企业级存储方案，有纯软件和一体机两种不同的版本</li><li>Diamanti：Diamanti 一家超融合基础设施初创公司，主要为企业数据中心提供基于容器的硬件及软件支持服务</li><li>Hedvig：为私有云和混合云提供统一的数据存储服务，为虚拟机和容器提供软件定义存储</li><li><a href="https://infinit.sh/" target="_blank" rel="noopener">Infinit</a>：开源的软件定义存储公司，之前是做文件跨平台传输的。产品也是统一的存储平台，为各种计算平台提供块存储、对象存储和文件存储等接口。已经被 docker 收购</li><li>Pure Storage：一家明星存储创业公司，最大的特定是对闪存的支持</li><li>StorageOS：为容器提供分布式存储的统一视图，对上层提供 API 实现存储的自动化管理，作为容器部署。产品也分为免费版和收费版</li><li>Quobyte：数据中心文件系统，被 kubernetes volume 插件直接支持</li></ul><p>因为不同用户对存储需求不同，采取的存储方案也不同，不管是开源方案、商业方案还是自研方案，或者是文件存储、对象存储还是块存储，怎么把这些技术用到容器平台，以及保证标准化和统一化的接口，是非常有挑战性的事情，目前也有很多努力：</p><ul><li><a href="https://github.com/container-storage-interface/spec" target="_blank" rel="noopener">CSI</a>（Container Storage Interface）：定义云应用调度平台和各种存储服务接口的项目，核心的目标就是存储 provider 只需要编写一个 driver，就能集成到任何的容器平台上</li><li>libStorage：EMC 旗下研发的一个存储开发框架，旨在开发与容器平台无关的存储框架，大致的思想是 libstorage 来处理和容器平台的交互，存储框架只需要接入到该框架就行</li><li>REX-Ray：基于 libStorage 实现的存储管理平台，支持大部分的存储提供商，也能运行在大多数操作系统上</li><li>openSDS：开放的软件定义存储标准，集合各大存储厂商，提供统一管理的存储标准，隶属于 Linux 基金会</li><li><a href="https://rook.io/" target="_blank" rel="noopener">rook</a>：基于 ceph 作为后台存储技术，深度集成到 kubernetes 容器平台的容器项目，因为选择了 ceph 和 kubernetes 这两个都很热门的技术，并且提供自动部署、管理、扩展、升级、迁移、灾备和监控等功能，所以很受关注</li><li>portworx：针对容器技术打造的，把每个节点的存储资源组成一个存储池，每个数据自动进行备份，并通过和容器平台调度深度集成保证数据高可用。分为免费版和商业版</li></ul><h3 id="Cloud-Native-Network"><a href="#Cloud-Native-Network" class="headerlink" title="Cloud Native Network"></a>Cloud Native Network</h3><p>网络最重要的功能是提供不同计算资源的连通，随着虚拟化和容器技术的发展，传统的网络方案已经无法满足云计算快速增长、不断变化的网络需求。不同用户对网络的要求也越来越高：</p><ul><li>安全性：保证私有和公有云网络的安全，网络流量能够加密，不被窃听和修改</li><li>多租户：云计算需要同时为多个租户提供网络服务，不同租户之间互相独立而且隔离</li><li>快速响应：容器的生命周期大大缩短，集群的网络在实时动态变化，网络方案需要感知网络的变化，并快速提供服务</li><li>网络迁移：虚拟机和容器会在集群上迁移和调度，网络方案需要支持计算资源跨主机迁移后的连通</li><li>监控和调试：云上的网络环境，让整个网络的流量变得更加复杂，我们需要新的工具让网络可视化，并做到自动化运维</li><li>……</li></ul><p>因此，在云计算和容器这块涌现出很多网络解决方案和厂商，试图解决这些问题：</p><ul><li>cni（Container Network Interface）：kubernetes 和 CoreOS 提出的容器网络接口标准，旨在为容器平台提供统一的网络访问模式，目前很多网络方案都已经集成进来</li><li>calico：基于 BGP 的纯三层网络方案，性能很高，并且提供强大的网络防火墙功能，以满足用户对安全性的需求</li><li>canal：基于 flannel 和 calico 提供 kubernetes pod 之间网络防火墙的项目</li><li>contiv：思科推出的网络方案，支持 vxlan 和 vlan 方案，提供了多租户和主机访问控制策略功能</li><li>cilium：利用 Linux 原生技术提供的网络方案，支持 L7 和 L3、L4 层的访问策略</li><li>flannel：CoreOS 主要的容器网络项目，主要用于 kubernetes 平台提供 pod 之间的连通性，提供多种连网方案，部署和管理简单</li><li>midokura：日本 SDN 网络公司，主要产品是开源的 MidoNet，之前广泛用于 openstack 中，目前有很多把它应用到容器领域的尝试</li><li>openContrail：Juniper 收购的开源网络虚拟化平台，目前已经加入 linux 基金会。OpenContrail 是一个可扩展的网络虚拟化控制层，提供了丰富的软件定义网络功能和安全性</li><li>Open vSwitch：linux 平台的虚拟交换机软件，除了提供和 Linux 虚拟网桥类似功能外，还支持 openflow 协议</li><li>weave net：Weaveworks 公司开源的 docker 跨主机网络方案，安装和使用都比较简单，内部也是通过 overlay 网络实现的</li><li>romana：Panic Networks 推出的网络开源方案，基于 L3 实现的网络连通，因此没有 overlay 网络带来的性能损耗，但是只能通过 IP 网段规划来实现租户划分，不够灵活</li><li>tigera：网络方案初创公司，主推的方案是把 flannel 和 calico 集成到一起的 canal，应用Calico的网络策略到 Flannel 中</li></ul><p>也有很多的商业公司为企业提供网络解决方案：</p><ul><li><a href="http://www.aviatrix.com/" target="_blank" rel="noopener">aviatrix</a>：混合云网络解决方案提供商，集成 AWS、Azure、Google 等公有云网络，在同一平台管理公司混合云网络</li><li>Big Switch：下一代数据中心网络公司，提供 SDN 可编程的网络方案，主要有 Big Cloud Fabric 和 Big Monitoring Fabric 两种产品方案</li><li>vmware NSX：虚拟化厂商 vmware 提供虚拟化网络方案</li><li>cumulus：主要产品是 cumulus 操作系统，继承了众多的网络软件，提供丰富的网络功能。能够解除数据中心网络设备硬件和软件锁定的局面，为网络硬件带来软件的灵活特性</li><li>nuagenetworks：致力于数据中心 SDN 网络的公司，提供解决方案</li></ul><h2 id="4-Orchestration-amp-Management（编排和管理）"><a href="#4-Orchestration-amp-Management（编排和管理）" class="headerlink" title="4. Orchestration &amp; Management（编排和管理）"></a>4. Orchestration &amp; Management（编排和管理）</h2><p>当在生产环境中使用容器时，单台主机上的容器已经不能满足需求，需要管理多主机容器集群，也就需要有个工具能够提供资源管理、容器调度和服务发现等功能，保证多主机容器能够正常工作。可以说，对于云原生系统，orchestration 才是最核心的东西。</p><h3 id="Scheduling-amp-Orchestration"><a href="#Scheduling-amp-Orchestration" class="headerlink" title="Scheduling &amp; Orchestration"></a>Scheduling &amp; Orchestration</h3><p>调度和集群管理一直是容器技术的热点领域，竞争也非常激烈。打个可能不那么恰当的比喻，如果把容器 runtime 比作引擎，那么容器集群管理工具就是汽车。用户购买的是汽车，尽管引擎非常重要，但是它终归只是个可以替换的零件。</p><p>集群管理竞争还在，并没有最终的唯一胜利者，但总的来说 google 公司的 kubernetes 处于绝对的领先状态，也是目前社区发展最快的平台，随着 docker 官方支持 kubernetes，以及 azure 和 aws 。目前社区三个主流的容器调度平台是：</p><ul><li>kubernetes：起源于 google 内部的 Borg 系统，率先提出 pod 的概念，提供自动化管理、服务发现、服务升级、有状态服务等等特性</li><li>docker swarm：docker 公司官方的容器管理平台，最大的特点是和 docker 兼容的 API 和操作命令</li><li>mesos：apache 旗下的任务调度平台，后来应用于容器调度</li></ul><p>对于公有云上的容器服务，各大云服务商也有对应的产品：</p><ul><li>Amazon ECS：亚马逊推出的容器服务，特点是虚拟机收费，容器免费</li><li>Azure Service Fabric：微软 Azure 的容器服务调度平台</li><li>Nomad：hashicorp 旗下的数据中心调度平台，同时支持服务和任务两种 Job，也已经支持 docker 容器</li></ul><h3 id="Coordination-amp-Service-Discovery"><a href="#Coordination-amp-Service-Discovery" class="headerlink" title="Coordination &amp; Service Discovery"></a>Coordination &amp; Service Discovery</h3><p>有了容器集群管理工具，容器的规模逐渐变多，另外一个需要解决的问题是服务之间怎么互相发现对方。因为集群的容器是不断变化的，IP 地址也是不稳定的。这个问题再往下思考，就是集群的状态应该怎么保存，才能让所有节点能当前集群自己想要的信息，而且保证不会发生冲突和错误。</p><p>目前，集群的状态都会保存在一个分布式的键值存储里，这个存储保证数据的一致性，目前三款常用的键值存储工具是：</p><ul><li>Zookeeper：Hadoop 的一个子项目，本来是作为 Hadoop 集群管理的数据存储，目前也被应用到容器领域，开发语言是 Java。一个缺点是使用和维护比较复杂</li><li>Consul：HashiCorp 开发的分布式服务发现和配置管理工具，docker swarm 集群之前默认使用的就是这个</li><li>Etcd：CoreOS 旗下的键值存储工具，是 kubernetes 默认的选择，因此使用范围很广</li></ul><p>有了分布式键值存储保证一致性，还需要工具把集群数据自动写入到里面，并且需要格式化地读取和解析数据。围绕这一话题，周边也有很多工具：</p><ul><li>Registrator：自动监控 docker 容器，把每个容器的信息（IP、端口等）写入到键值存储中，支持 etcd、Consul </li><li>SkyDNS：基于 etcd 中的数据，对外提供 DNS 数据查询，是对 etcd 的一层封装。因为使用 etcd，所以 DNS 查询是实时的，避免了缓存导致的问题</li><li>CoreDNS：SkyDNS 继承者，主要特点是插件系统能完成各种各样的功能</li><li>ContainerPilot：Joyent 开源的容器服务发现工具，作为容器的 init 系统运行，通过定义一个 json 文件，它会把容器相关的信息更新到 consul 中、进行健康检查、运行用户定义的代码等</li></ul><p>除外，还有两个公司开源的服务发现工具要提一下：</p><ul><li>SmartStack：Airbnb 开源的服务发现工具，由 nerve 和 synapse 组成，安装和运维相对复杂了些</li><li>netflix OSS Eureka：netflix 开源的用于 AWS 的服务发现工具</li></ul><p>总的来说，这些工具保证这个集群的动态信息能统一保存，并保证一致性，这样每个节点和容器就能正确地获取到集群当前的信息。</p><h3 id="Service-Management"><a href="#Service-Management" class="headerlink" title="Service Management"></a>Service Management</h3><p>伴随着容器技术而变得火热的一个话题是微服务，每个服务作为容器或者 pod 运行，不同服务之间通过服务发现知道对方的地址进行通信。随着集群规模的增大、服务数量的增多，用户的需求也不断增加，微服务架构也面临更多的问题：</p><ul><li>认证和安全：为了安全，调用方需要进行身份认证，而且不同的微服务只能运行不同的用户访问</li><li>统计：每个微服务需要知道它的使用情况，什么人在什么时候调用了什么接口，方便监控和排查错误</li><li>健康检查和自动恢复：系统能自动检测服务的可用性，一旦不可用就重启恢复或者从调用链中删除</li><li>自动重试：如果调用某个服务发生错误，可以自动按照特定算法重试</li><li>限速：服务应该限制它能接收请求的速率，以保证它不会被过量的请求压垮</li><li>服务可用性和雪崩：每个服务的可用性都不可能是 100% 的，简单的串联调用会降低整个集群的可用性。如何保证每个服务不可用不会导致调用方的僵死</li><li>负载均衡：怎么自动把请求分配到不同的后端进行处理，调度算法能否满足各种各样的需求</li><li>升级发布：每个微服务的升级怎么做到不影响其他服务，怎么进行灰色发布，出错怎么快速回滚</li><li>测试：单个服务可以独立测试，但是整个集群怎么进行功能和性能测试</li><li>……</li></ul><p>这些东西都是每个微服务平台必须要考虑的，如果放在每个服务代码中实现某些功能，不仅增加了每个服务的复杂性，也会导致重复的工作，所以，微服务需要更好的框架和平台统一提供这些功能。总的来说，微服务虽然降低了单个服务的复杂性，但是把复杂性下沉到微服务管理平台层面。</p><p>针对这些问题，有很多软件和方案。对于负载均衡来说，HAProxy、nginx 和 F5 都是常用的方案，Traefik 是后起之秀，专门为微服务设计；RPC 框架用来在微服务内部进行通信，因为比 HTTP API 效率高而被大量使用，常用的用 Google 开源的 GRPC 、apache 旗下的 thrift 框架、Netflix 开源的自带负载均衡的 ribbon 和 avra 数据序列化框架。</p><p>微服务 gateway 是统一化管理 API 注册接入、权限认证、限速、日志等功能，是微服务对外的接口。</p><ul><li>Kong：Mashape 开源的项目，基于 openrestry（Nginx + Lua） 的微服务网关，以插件为中心组织功能</li><li>Netflix Zuul：Netflix 微服务网关，使用 Java 开发，因此适用于 Java 应用，需要添加代码来使用 Zuul 提供的功能</li><li>Nginx：Nginx Plus 产品为企业提供负载均衡、代理、微服务网关的各种功能</li><li>3scale：红帽公司的 API 网关工具</li></ul><p>这个领域也有一些公司在提供产品，比如 datawire 就专门为 kubernetes 应用提供 API gateway 和自动化源码部署的工具。</p><p>微服务开发框架 Hystrix 是 Netflix 开源的项目，能够帮助程序处理微服务交互的超时处理和容错的问题，提供熔断、隔离、降级等功能，但是只能用于 Java 语言项目，需要在程序中修改代码。</p><p>特别要强调一下微服务领域最近比较热门的概念：<strong>Service Mesh</strong>，它的主要想法是把微服务通用的功能单独抽象为一层，部署在容器管理平台中，对应用透明，并且通过简单自动化的接口来控制整个微服务的连通、灰度访问、升级、降级等功能。</p><ul><li>linkerd：开源的网络代理服务，使用 scala 语言编写，最早提出了 service mesh 的概念</li><li>envoy：C++ 编写的网络代理工具，和 linkerd 的定位相同，turbine labs 公司专门提供 envoy 的部署和管理工作</li><li>Istio：Google、IBM 和 Lyft 联合发布的微服务管理、配置和监控框架，使用 envoy 或者 linkerd 作为内部 worker，控制层面负责配置和管理，深度集成到 kubernetes 平台</li></ul><p>service mesh 相较于之前微服务框架的最大优势是它对业务是透明的，不需要像 Netflix 提供的很多微服务工具那样对应用有侵入性，因此就不再和任何语言绑定，可以看做整个网络栈的另一个抽象层。</p><h2 id="5-Platform（平台）"><a href="#5-Platform（平台）" class="headerlink" title="5. Platform（平台）"></a>5. Platform（平台）</h2><p>平台这块主要是基于容器技术做的更上面一层的封装，有直接是接管公有云或者私有云的容器平台，也有 Faas 这一类服务。</p><h3 id="PaaS-Container-Service"><a href="#PaaS-Container-Service" class="headerlink" title="PaaS/Container Service"></a>PaaS/Container Service</h3><p>因为容器技术的隔离性，以及对应用非常友好，因此可以直接拿来做 Paas 服务，当然也有种叫法是 Caas（Container as a service）。很多初创公司的业务也就是这块，基于容器提供应用的发布、升级、运维等管理工作。大部分公司做的事情都大同小异，因为最终的需求是一样的：让应用的开发、部署、扩展、升级、运维更轻松，用户无需关心基础架构，只需要考虑如何去实现业务逻辑就行，主要的区别在于侧重点，有些侧重私有的数据中心部署和管理，有的侧重 docker 容器的管理，有的测试 kubernetes 等容器集群的维护，有的提供应用平台，有的和公有云平台深度集成……</p><p>heroku 是老牌的公有云类型的 PaaS 平台，界面友好，成熟稳定，所有操作提供命令行实现自动化，提供完整的监控和日志方案。</p><p>cloud foundry 和 openshift 是两款重要的开源 Paas 平台，其中 cloud foundry 是 Pivotal 开源，支持多种语言、框架、云平台，旨在让开发者能够忽略架构问题，快速部署和扩展应用；openshift 是 redhat 开源的，功能和 cloud foundry 差不多，网络上有很多两者的对比文章，这里不再赘述。目前两者都已经开始拥抱容器、docker、kubernetes 技术，希望能和容器深度集成。它们的特点是功能强大，可扩展性强，但是相应的，复杂程度也高。</p><p>随着 kubernetes 的快速发展，很多以 kubernetes 为容器管理平台和应用管理的公司也都出来了，datawire 基于 kubernetes，侧重于微服务的管理；containerShip 也是 kubernetes 的管理平台，可以在多个云平台自动化部署和统一管理；Giant Swarm 提供混合云和多租户的 kubernetes 管理；kubermatic 能够给用户提供一键 kubernetes 集群安装和多集群管理服务；<a href="https://gravitational.com/" target="_blank" rel="noopener">Gravitational</a> 提供多 region 的 kubernetes 集群管理。</p><p>atomist 和 cloud66 侧重于 devOps 流程；flynn 是基于 docker 容器技术的开源 PaaS 软件，相比 cloud foundry 算是轻量级的实现；hyper.sh 比较有趣，它们以容器接口来提供虚拟机服务。</p><p>其他一些平台提供的服务如下：</p><ul><li>Apcera: 一个企业级的容器管理平台，包括了运行容器所需编排、网络和安全功能。Apcera的一个特点是支持传统的应用，同时兼容传统应用和云原生应用，支持把前者迁移到云上</li><li>apprenda：PaaS 云平台软件公司，基于 kubernetes 打造的应用管理平台，目前的商业版本 ACP(Apprenda Cloud Platform)提供了 kerberos 身份认证、应用审计等额外功能</li><li>convox：基于 AWS 的应用部署、管理、监控的平台服务，提供了命令行实现任务的自动化</li><li>DC/OS：mesos 的企业级产品，是一套开源项目，基于 mesos 分布式系统和 marathon，提供了编排、应用商店、GUI 界面等功能</li><li>Diamanti 也是一家解决方案公司，基于 kubernetes 调度平台，同时支持 openshift PaaS 平台</li><li>docker：没有看错，这里的 docker 指的是 docker 公司，而不是容器技术。作为一家商业化的公司，docker 也提供了商业化的产品和解决方案，开源的部分称为 docker CE（community edition），商业化产品为 docker EE（Enterprise Edition）</li><li>mitantis cloud platform：原来有名的 openstack 公司，目前也逐渐接纳 kubernetes，一起构建云平台</li><li>moby project：docker 公司把开源组件命名成 moby，意在把多个开源技术组件按照需求组合成满足用户需求的产品，docker CE 就是其中的产出</li><li>platform9：同时支持 openstack 和 kubernetes 为核心的 Paas 服务</li><li>portainer.io：docker 的界面化管理工具</li><li>rancher：容器管理平台，之前同时支持 swarm、mesos 和 kubernetes，目前把重心逐渐迁移到 kubernetes 上</li><li>tectonic：coreOS 推出的 kubernetes 集群服务，集成了 quay 镜像服务、coreOS 系统、和 promethues 监控等</li><li>ubuntu：ubuntu 系统也内嵌了 LXD 容器技术，提供更多的容器技术</li></ul><p>这块内容主要是容器创业公司，提供的都是基于 docker、kubernetes 或者其他容器技术的方案，因此做的事情大同小异，就不再一一介绍了，感兴趣的可以根据图中列出的公司自行了解。</p><h3 id="Serverless-Event-based"><a href="#Serverless-Event-based" class="headerlink" title="Serverless/Event-based"></a>Serverless/Event-based</h3><p>容器技术把微服务的概念吵得火热，随后也让 serverless 这个词出现了大众的面前。既然容器能够屏蔽基础设施，让开发者只关心交付的应用（容器镜像），那么我们可不可以更进一步，让开发者也不要关心交付的镜像，只关注业务的核心逻辑呢？这就是 serverless 的想法，开发者定义好基于事件触发的业务逻辑，其他一切都交给平台，当用户发出请求或者其他事件发生时，平台会根据事先的配置自动运行响应的业务逻辑代码，从而实现真正的按需服务。如果说容器关心的是应用，那么 serverless 关心的则是函数。serverless 不是没有服务器，而是不用关心服务器和系统。</p><p>serverless 是一个很新颖的技术，虽然理念非常好，但现阶段还不适用于所有的应用，主要是因为它的性能问题，以及距离成熟使用还缺少很多工具和方案，另外开发流程要接纳这种理念还需要一段时间。</p><p>AWS Lambda 服务算是商业产品中比较成熟的，它的出现让 serverless 从概念化和实验化的东西变成了可行的方案。微软家的云平台也推出了 Azure functions；Google 家对应的产品叫做 cloud functions，从命名来看亚马逊略胜一筹。</p><p>openFaas、fission 和 kubeless 都是基于 docker 和 kubernetes 开源的 serverless 开发框架，如果要想打造自己的 serverless 平台可以参考。</p><ul><li>Apex：帮助构建、管理和运行 AWS Lambda 的工具</li><li>nstack 和 nuclio 都是专门用作数据分析的 Faas 软件工具</li><li>OpenWhisk：apache 旗下的 serverless 框架，目前还是孵化项目</li><li>Oracle application container cloud</li><li>pubnub blocks：PubNub 提供的 serverless 服务，用于集成到自家的服务推送中</li><li><a href="https://serverless.com/" target="_blank" rel="noopener">serverless</a> 是一个集成工具，它能帮助开发者在 serverless 应该部署到 AWS Lambda、Azure Functions、GCP Cloud Functions、kubeless 等平台，也就是说它封装了这些平台差异，提供了一致的接口，方便迁移和管理多 serverless 平台应用</li></ul><h2 id="6-Observability-amp-Analysis（观察和分析）"><a href="#6-Observability-amp-Analysis（观察和分析）" class="headerlink" title="6. Observability &amp; Analysis（观察和分析）"></a>6. Observability &amp; Analysis（观察和分析）</h2><p>基于云原生的平台建立起来之后，我们要保证整个平台能够正常工作，保证运行在其上的服务不会因为平台错误而导致不可用，而且还要知道应用整体的运行情况，提前对某些可能出错的地方进行报警，一旦出错能够提供合适的信息便于调试和修复……这些都是观察（observability）和分析（analysis）要做的工作，为了方便下面统一使用<strong>监控</strong>（monitoring）一词。</p><p><strong>NOTE</strong>：对于监控、观察、分析、日志等词语的使用并没有非常严格的定义，监控是 IT 行业比较传统的叫法，表示对应用和系统运行情况的数据统计和展示。目前有个叫法是观察，分为metrics/monitoring、logging 和 tracing 三个部分。为了容易理解，我们使用<strong>监控</strong>一词来代替，它广义地包含了以上所有内容。</p><p>监控对于系统来说非常重要，没有监控的平台就像没有仪表盘的飞机。监控的目标有几点：</p><ul><li>了解系统的使用情况，可以用于容量规划、性能调优</li><li>提前或者及时发现问题，因为硬件总是会有故障的软件总是有 bug 的，及时发现能够更快处理，不影响到应用的正常运行。这些问题包括网卡不能工作、硬盘老化、或者软件异常等</li><li>帮助排查错误：当发现软件bug或者硬件故障时，监控能够帮忙分析哪个组件在什么时候出现了问题，方便定位问题</li></ul><h3 id="Monitoring"><a href="#Monitoring" class="headerlink" title="Monitoring"></a>Monitoring</h3><p>简单来说，监控就是了解应用和系统运行情况。</p><p>我们最常见的监控是对主机的监控，了解 CPU、内存、磁盘 IO、网络等资源的使用数据，以此了解主机是否正常，是否需要加硬盘或者扩展集群，是否有内存泄露等等。另外一个监控是应用的监控，不管是数据库、缓存服务器、消息队列、代理和缓存服务器，还是自己编写的应用，我们需要知道它们的运行情况，这个监控依据每个应用而定，监控方法、监控的数据以及解读方法对不同的应用来说会千差万别。</p><p>而容器的出现，让监控出现了另外一个维度：容器和平台的监控。我们不仅要知道每个主机的运行数据，还需要知道每个容器的数据，这个容器使用的 CPU、内存、磁盘 IO 和网络等，这个新的需求也就催生了新的监控思想和工具。</p><p>zabbix 是老牌的监控工具，功能强大，最近界面也改进了不少；Nagios 和 graphite 是另外两个经典的监控工具。sensu 是一款较新的监控工具，Riemann 也能够进行分布式系统的集中式监控处理。</p><p>influxdb 和 openTSDB 都是时序数据库，后者是基于 HBase 的。</p><p>AWS CloudWatch 是AWS 自家的监控工具，当然是负责 AWS 云上的服务监控；Azure Log Analytics 是微软家日志监控工具。很多商业公司也提供各种各样的监控产品：AppNeta、Axibase、APPDynamics、datadog、dynatrace、NewRelic 和 splunk 都提供应用级别的监控和数据分析业务。</p><p>再介绍一下经常听到的监控工具：</p><ul><li>Prometheus：时序数据库，提供了工具能读取 HTTP 接口暴露的数据保存起来，提供了丰富的查询接口以及一个 web 界面</li><li>grafana：监控管理界面，能够从多个数据源导入数据，提供优美的界面和丰富的面板配置</li><li>coscale：专门为容器和微服务优化的监控平台</li><li>sentry：错误收集工具，能够集中式地查看应用的 crash report 和 traceback 信息</li><li>server density：专注于服务监控的 SaaS 服务平台</li><li>statsD：etsy 开源的数据统计信息，可以把数据继续发到后端的监控平台，比如 graphite</li><li>sysdig：容器和 kubernetes 监控工具，同时提供了付费的监控服务</li></ul><p>图中列出的监控公司和工具还有很多，这块的创业公司也很多，因为监控的数据不像业务数据那样机密，因此很多公司愿意使用 SaaS 监控服务。</p><h3 id="Logging"><a href="#Logging" class="headerlink" title="Logging"></a>Logging</h3><p>日志容易理解，就是程序运行输出的信息，它们是调试的利器，当程序出错的时候，有效的日志分析能够快速定位问题。同时日志也能承担一部分的监控功能，反应系统运行是否正常。</p><p>fluented 是一个开源的基于数据流（stream）的日志收集框架；graylog 是另外一个开源的选择，它们的思想都是把日志从系统各处收集起来进行统一分析、过滤和管理；elastic 提供 ELK（Elasticsearch、Logstash、Kibana） 技术栈负责日志收集，也提供在线的企业级 Saas 服务。</p><p>除了使用开源的组件自己搭建日志服务平台，还可以使用一些公司提供的在线日志服务，只要把日志数据导入到它们的平台，不用关心日志服务的维护工作。loggly 是一个在线的日志分析服务，需要付费使用；logz.io 提供管理的 ELK 在线服务，提供 ELK as a service，并且可以基于 AI 对数据进行分析；另外一家声称支持 AI 分析的日志服务公司是 loom systems；splunk 这家公司也提供日志分析服务；papertrail、sematext、sumologic 也都提供类似的日志分析服务。</p><h3 id="tracing"><a href="#tracing" class="headerlink" title="tracing"></a>tracing</h3><p>随着微服务的采用，用户的一个请求可以中间会经过多个不同的微服务才最终得到应答。传统的监控、日志都是针对单个组件的分析，用来了解当前组件的健康和运行状态，并不能给我们一个整体的动态的情况。</p><p>对于微服务来说，我们需要知道一个请求到底经过了哪些组件，每个组件耗费了多少时间，错误发生在中间的哪个步骤，每次调用的网络延迟是多少等等。对于使用不同语言、开发框架、数据库、和系统的微服务，我们需要有统一的跟踪标准，这就是 tracing 要做的事情。分布式的 tracing，一般都受到 google Daper 系统的设计影响。</p><p>opentracing是一个开放的 tracing 接口标准和文档，提供了各种语言客户端的实现，支持的 tracing 工具包括 Jaeger、appdash 和 Zipkin（twitter 开源）；Cloud Sleuth 是 spring cloud 全家桶中一员，主要负责 tracing 功能。</p><p>这些 tracing 工具都需要在应用中编写对应的代码，和 logging 和 metrics 类似，用户可以自定义要 tracing 代码块的范围和父子关系。此外，也有很多工具会自动化嵌入服务组件之间的 tracing 数据，比如之前讲过的 Istio。</p><p>tracing 可以和 metrics 结合一起使用，tracing 负责组件和微服务之间的数据分析，metrics 负责单个组件内的性能数据监控。</p><h2 id="7-Application（应用）"><a href="#7-Application（应用）" class="headerlink" title="7. Application（应用）"></a>7. Application（应用）</h2><p>容器平台最终还是要跑应用的，最主要的应用当然是各个公司的业务应用，除此之外还有一些比较通用的应用，这个表格里也有列举，可以根据需求提供类似应用市场的功能。</p><h3 id="Database-amp-Data-Analytics"><a href="#Database-amp-Data-Analytics" class="headerlink" title="Database &amp; Data Analytics"></a>Database &amp; Data Analytics</h3><p>数据库一直是软件领域的核心组件，所以包括了很多老牌的数据库软件，比如 MySQL、DB2、oracle DB、postgreSQL、MariaDB 等关系型数据库。基于这些传统的数据库也有很多周边的工具和软件，比如 vitess 这种数据库集群工具；阿里巴巴开源的 SQL 数据库连接池工具 druid，它还同时提供了监控功能。</p><p>NoSQL 的发展也让很多新型的数据库出现在了我们的视野：有 redis、couchbase 这一类的 KV 数据库；也有 MongoDB、rethinkDB、ravenDB 为代表的文档类数据库；Cassandra、Hbase、vertica（列式关系数据库）、scylla（kvm 之父的作品，旨在成为下一代的 Cassandra 数据库） 这样的 column 数据库。它们最重要的特点是能够轻松进行集群扩容，不支持 SQL 查询，因此接口上都以其他形式满足用户各种各样的数据需求。</p><p>后来 newSQL 的概念出现，旨在结合 SQL 和 NoSQL 的优势，还是以 SQL 方式使用，但同时支持快速横向扩容和分布式事务，google 内部的 F1/spanner 是这方面的先驱，发过论文但是没有把项目开源，cockroachDB 和 TiDB 是这类数据库的代表，都是开源项目。</p><p>其他相关的数据库产品包括：</p><ul><li>bigchainDB：区块链数据库</li><li>carbondata：面向大数据平台的列数据文件存储格式，由国内的华为公司贡献给 Apache 基金会</li><li>crate.io：基于 elasticsearch 的分布式 SQL 数据库，适用于需要快速搜索和聚合的查询场景</li><li>MEMSQL：从名字也能看出来，这是一款内存数据库，特点自然是性能高，</li><li>Noms：采用 git 思想的支持版本控制、fork和同步的数据库</li><li>pachyderm：旨在成为一个更现代的大数据处理平台，资源调度基于 docker 和 kubernetes，底层是自己的分布式存储系统</li><li>iguazio 和 Qubole：自动化数据分析公司</li><li>SQL data warehouse：Azure SQL 数据库产品</li></ul><p>数据库是整个软件技术的基础，现在有个很流行的观念是：数据是一家公司最重要的资产之一。我们对数据库的要求也是更快、更多、更好，所以会有很多数据库相关的产品来解决各种各样的数据存储和处理需求。</p><h3 id="Streaming"><a href="#Streaming" class="headerlink" title="Streaming"></a>Streaming</h3><p>流处理与批处理对应，要求对海量数据的实时采集、计算和查询，很多业务场景要求尽可能快得对数据进行分析，从而做出决策，比如传感器、流量监控、股市行情、游戏数据分析等，对此类需求也催生了很多实时处理工具。</p><p>Kinesis 是亚马逊官方的流数据处理平台，是其云计算产品的一部分；cloud dataflow 是 google 的流处理产品；开源方面，Apex 是 apache 旗下开源的新型实时数据处理平台；heron 是 twitter 开源的数据处理平台，是 apache storm 的继承者；spark 和 flink 支持流处理的同时也支持批处理操作，两者定位非常相似，但内部实现的差距挺大</p><p>kafka 和 rabbitMQ 这类消息队列可以做到数据的快速收集；nifi 是另一个 apache 项目，是一个数据整合和分发系统，专门为数据流设计。</p><p>和大数据一样，流处理这个领域也是 apache 占据了大半的江山。</p><h3 id="SCM（Source-Code-Management）"><a href="#SCM（Source-Code-Management）" class="headerlink" title="SCM（Source Code Management）"></a>SCM（Source Code Management）</h3><p>虽然容器让产品以镜像的作为产出，但是代码还是要维护的，最有名的社区源码管理平台自然是 github，gitlab 是开源自建 SCM 的推荐选择，bitbucket 和 github 定义类似，提供免费也提供商业版本的服务。</p><h3 id="Application-Definition"><a href="#Application-Definition" class="headerlink" title="Application Definition"></a>Application Definition</h3><p>应用定义并没有明确的定义，大概要做的事情是屏蔽底层基础设置、云平台以及容器运行时，封装一个标准化的应用定义，从而实现应用自动化运行在任何地方。</p><ul><li>apache brooklyn：应用管理平台，可以通过简单的操作把应用部署到常用的云平台</li><li>docker compose：定义多个容器的运行关系，docker compose 可以自动化管理这些容器的构建、生命周期、和网络连通等问题</li><li>habitat：应用自动化管理平台，可以定义应用，并且提供 Supervisor 来保证应用的正确运行</li><li>kubeVirt：用于 kubernetes 的虚拟机运行时标准接口</li><li>Packer：通过一个 yaml 文件，生成各种虚拟化平台的镜像</li><li>OPEN API：标准化的 API 接口，规范化应用和服务之间的调用</li></ul><h3 id="CI-CD"><a href="#CI-CD" class="headerlink" title="CI/CD"></a>CI/CD</h3><p>持续集成和持续部署主要用于自动化地处理所有的 ops 的工作，包括从代码提交一直到应用部署到线上的整个过程的自动化。CI 侧重于构建和测试，CD 侧重于部署。</p><ul><li>jenkins 算是这个领域的翘楚，非常经典的一款软件，功能强大稳定，拥有很丰富的插件，算是开源界使用比较广泛的工具</li><li>travis CI 为开源的 github 项目免费，对私有项目收费，因此很多 github 上项目能看到它的身影</li><li>circleCI、 codeship、shippable、semaphore 都是 PaaS 产品，提供在线的 CI、CD 服务，一般提供免费和企业收费两种版本</li><li>Bamboo 是 Atlassian 公司（开发了著名的 jira 和 confluence）旗下的产品，当然也是商业化的，需要付费才能使用</li><li>drone：原生支持 docker 的 CI 开源产品，使用 go 编写，整个工作流都是基于 docker 的，最终也会自动化构建 docker 镜像，push 到 registry 上</li><li>gitlab runner：gitlab 提供的 CI 工具，gitlab CI 和 gitlab runner 一起工作，前者做控制，后者实际执行任务</li><li>spinnaker：开源的 CI 软件，可以在多个云平台运行构建和部署过程</li></ul><p>网络也有很多文章对 CI/CD 的软件进行比较，比如<a href="https://blog.takipi.com/jenkins-vs-travis-ci-vs-circle-ci-vs-teamcity-vs-codeship-vs-gitlab-ci-vs-bamboo/" target="_blank" rel="noopener">这篇就比较了 jenkins vs travis vs teamcity vs codeship vs gitlab vs bamboo</a>，其他的工具就不一一介绍了，感兴趣可以自行搜索。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>如果做个总结的话，2017 年 CNCF 云原生生态目前有如下的趋势：</p><ul><li>容器的标准化工作正在逐步完善，不会有太多新的功能出现，但是这方面的东西作为整个体系的核心仍旧非常重要</li><li>容器调度和编排平台的核心作用日渐突出，目前看来 kubernetes 是领先者，未来和其他竞争产品差距会进一步拉大。个人看法，<strong>kubernetes 将会窃取 docker 的果实，成为整个系统最大的受益者</strong></li><li>网络和存储有大量的产品和技术存在，但是目前没有统一的标准和绝对的领先者。如何把这两块功能更好地和容器结合，需要新的突破</li><li>监控和日志是容器平台运维的重中之重，云原生建设降低了应用部署、升级、构建、测试的难度，但是把难度下沉到容器平台这块，原来的运维工具和思路需要变化以适应新的容器平台，了解集群中正在发生的事情、及时发现可能出现的问题，才能保证业务应用稳定高效地运行</li><li><strong>微服务</strong>怎么更好地和容器集群技术结合，是目前非常热门的一个话题，因此 Istio、convoy、linkerd 这些技术发展迅速，也被很多人看好，认为是下一代微服务</li><li><strong>serverless</strong> 作为容器更高一层的封装，将会逐步进入我们的视野，继容器（container）之后，应用（application）的概念将会发生新的变化和革命</li><li>应用仍旧是最终目的。保证应用快速稳定地测试、构建、部署、升级，支持；减少代码开发时间人力成本；快速响应业务需求；降低应用的运维和使用成本……这些目标多久都不会变化</li></ul><p>CNCF 列出的生态只是一个参考，很多软件和公司并没有出现在这里，在构建云原生应用时不必拘谨于此。构建云原生架构是一个过程，不同的阶段会选择不同的工具和平台，并没有完全”标准”的做法。</p><p>另外一个没有出现在这里，但是随平台规模增长变得越发重要的话题是<strong>性能分析和优化</strong>，因为这个话题并没有统一的标准和方案，只能具体问题具体分析，而且整个过程比较复杂，所以很少有提供一站式方案的软件和公司。</p><p>每个特定的问题都有多个工具和解决方案，这样的情况就要求我们必须做出选择，知道每个工具要解决什么问题，有哪些取舍，和其他组件是否容易集成，社区活跃度……然后根据自身的情况和需求，找到最适合自己当前发展的工具。切不可一心求新求全，不然会带来严重的后果：</p><ul><li>社区并不友好或者活跃，对用户需求响应很慢</li><li>选择没过一年就停止了开发，只能重新选择新的工具</li><li>工具因为开发过快或者组件复杂等原因不够稳定，在使用过程中遇到很多问题，维护成本很高</li><li>选择的工具栈过大，完全超过了自己现在的问题，导致需要额外的人员来维护这些多余的功能</li><li>……</li></ul><p>推荐的方式是循序渐进，以满足最核心需求为主去选择合适的技术，优先使用比较稳定、文档丰富和社区活跃的。充分了解选择版本哪些功能是非常稳定可以直接使用的；哪些功能不太稳定，但是可以在开发和测试环境中小规模使用的；哪些功能是不稳定，需要测试开发或者等待社区进度的。如果有应用需要从旧环境迁移，编写自动化工具，并提供回滚的功能，以灰度发布的方式逐步迁移到容器集群。对于新技术，可以花时间去跟进，在合适的时候及时引进。</p><p>切不可听到别的公司使用了某个技术，自己就一定要用。如果没有问题要解决，引入新工具只会带来新的问题而已。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://medium.com/memory-leak/cloud-native-landscape-celebrates-first-anniversary-69a4eb829505" target="_blank" rel="noopener">Cloud Native Landscape Celebrates First Anniversary</a></li><li><a href="https://medium.com/@copyconstruct/monitoring-in-the-time-of-cloud-native-c87c7a5bfa3e" target="_blank" rel="noopener">Monitoring in the time of cloud native</a></li><li><a href="https://medium.com/memory-leak/this-year-gartner-added-serverless-to-its-hype-cycle-of-emerging-technologies-reflecting-the-5dfe43d818f0" target="_blank" rel="noopener">Introducing Redpoint’s FaaS Landscape</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;CNCF（Cloud Native Compute Foundation） 是 Linux 基金会旗下的一个组织，旨在推动以容器为中心的云原生系统。从 2016 年 11 月，CNCF 开始维护了一个 &lt;a
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="container" scheme="http://cizixs.com/tags/container/"/>
    
      <category term="cncf" scheme="http://cizixs.com/tags/cncf/"/>
    
      <category term="ecosystem" scheme="http://cizixs.com/tags/ecosystem/"/>
    
      <category term="landscape" scheme="http://cizixs.com/tags/landscape/"/>
    
  </entry>
  
  <entry>
    <title>raft 一致性算法</title>
    <link href="http://cizixs.com/2017/12/04/raft-consensus-algorithm/"/>
    <id>http://cizixs.com/2017/12/04/raft-consensus-algorithm/</id>
    <published>2017-12-03T16:00:00.000Z</published>
    <updated>2018-10-01T07:37:25.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="分布式系统和一致性"><a href="#分布式系统和一致性" class="headerlink" title="分布式系统和一致性"></a>分布式系统和一致性</h2><p>分布式系统有一个很重要的问题要解决，当一台机器出现问题时，我们希望整个集群还是能够正常运行的，以达到高可用的要求。因为系统的数据是不断变化的，所以要保证集群的数据是同步的，不然会出现数据混论或者丢失的情况。这就是<strong>一致性问题。</strong></p><p>换个说法，一致性就是让多台机器对一组给定的操作最终得到的状态一样，也就是所有机器执行命令的顺序是一样的，对客户端来说，它们表现得就要像一个机器一样。</p><p>分布式一致性问题可以抽象成下面这张图(分布式状态机 Replicated State Machine)：</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fm3p3e0lnnj30sh09zwhg.jpg" alt=""></p><p>最终的目的是所有节点上保存的状态机器（文件内容）是一样的，这是通过各个节点上一致性模块之间的通信完成的，它们保证按顺序添加日志，然后把日志执行修改状态机的内容。如果机器初始状态相同，而且日志中记录顺序是一样的，那么最终的状态一定也是相同的。</p><p>一致性算法需要满足以下条件才能在实际系统中工作：</p><ul><li>安全（safety）：不会返回错误的结果，即使网络出现延迟、分割（partitions）、丢包、重复和乱序</li><li>可用（available）：只要有一半以上的机器正常工作（能够互相通信并且可以和客户端通信），整个集群就要能正常工作</li><li>不能通过时间来保证一致性，错误的时钟以及严重的消息延迟最多只能造成集群不可用</li><li>只要大部分机器完成命令的执行，这个命令就算完成，结果可以返回给客户端。而不用等到那些执行更慢的少数节点完成，它们的操作可以异步在后台运行</li></ul><p>分布式系统关于一致性最著名的算法是 paxos，它的发布者 Lamport 是图灵奖的获得者。但是 paxos 算法非常复杂，很多实现都是它的特殊版。尽管 Lamport 后来还发布过 Paxos Made Simple 的文章，试图用更简单的语言解释 paxos 算法，但是这个版本的解释还是过于复杂，这对于理解和实现都带来困难。</p><p>paxos 算法在分布式系统中地位很高，Chubby 作者有过这样一段话：</p><blockquote><p>There is only one consensus protocol, and that’s Paxos. All other approaches are just broken versions of Paxos.</p></blockquote><p>只有一种一致性算法，那就是 Paxos；而其他所有的一致性算法都是 Paxos 的特殊版本。</p><p>raft 算法是基于 paxos 算法提出来的，主要是为了更加易懂，提出 raft 算法的论文是 《In search of an Understandable Consensus Algorithm》，可以在网上很容易搜到原文。</p><h2 id="raft-算法"><a href="#raft-算法" class="headerlink" title="raft 算法"></a>raft 算法</h2><p>为了容易理解，raft 算法主要分成几个可以单独解释的问题：</p><ul><li>Leader election：主节点选举，从集群中所有节点中选择一个作为主节点</li><li>Log replication：日志复制，主节点全权负责和客户端的交互，以及日志复制到其他节点，保证日志的一致性</li><li>Safety：安全，如果一个节点往保存的状态添加一个日志记录，其他节点不会再同一个日志 index 时期添加一个不同的记录</li></ul><p>它的工作流程是这样的：集群选择出一个节点作为 leader，leader 节点负责接收客户端的请求（日志），并负责把请求复制给所有的从节点，保证节点之间数据的同步。如果 leader 节点出现问题挂掉，那么其他正常节点会重新选择 leader。</p><h3 id="选主-leader-election"><a href="#选主-leader-election" class="headerlink" title="选主 leader election"></a>选主 leader election</h3><p>每个节点在任意情况下，只能有三种状态可选：</p><ul><li>leader：领导节点，或者主节点，用来处理客户端发来的请求，并保证请求数据在整个集群的同步，需要用心跳和 follower 节点通信，通知它们自己的可用性</li><li>follower：负责处理 leader 和 candidate 请求的节点。如果客户端把请求发送给 follower 节点，它需要把请求转发给 leader，由 leader 统一负责管理</li><li>candidate：leader 的候选人，只是在选举过程中短暂出现的状态。如果通过选举，则会变成 leader；如果选举失败，还是会回到 follower 状态</li></ul><p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fm40vgcvazj30y20j6tap.jpg" alt=""></p><p>raft 算法还有一个任期（Term）的概念，任期是依次递增的编号，每次选举都是一个新的任期。<strong>在一个任期内最多只能有一个 leader</strong>，也就是说一个任期可以有一个 leader，表示正常工作；也可以没有 leader，表明选举失败。某个节点选举成功后，就成为当前任期的 leader，负责日志复制工作。</p><p>任期的主要目的是保证所有节点逻辑时间上的一致，而不会出现过期的请求导致逻辑混乱的情况。</p><p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fm40vu4bbij30ya0e9q3f.jpg" alt=""></p><p>每个节点都会保存一个当前任期的值，当节点通信时会交互当前任期的值，如果节点发现其他节点的当前任期比自己的大，就更新自己当前任期的值；如果 leader 节点发现有比自己大的任期值，则知道自己的任期过期了，集群中有更新的 leader 节点，它立即变成 follower 状态；如果节点接收到历史任期的请求，则直接无视（这很可能是因为网络延迟或者报文重复导致的）。</p><p>当节点刚启动的时候，默认是在 follower 状态。如果它能定时收到 leader 的心跳或者日志复制的请求，则会一直处于该状态；如果在设定的超时时间（election timeout）内没有收到 leader 的消息，则认为当前集群没有 leader，或者 leader 以及失效，立即会发起重新投票。</p><p>投票开始，节点会增加自己的当前任期值，转换成 candidate 状态，并向其他节点发送请求投票的消息（表示自己想成为下一个任期的 leader）。下面的状态分为三种情况：</p><ol><li>节点收到大多数节点的投票，成为新任期的 leader。每个节点在每个任期只能投票一次，采取先到先得的原则，投票给最先收到的选主节点。大多数原则保证一个任期最多只能有一个节点</li><li>节点发现已经有另一个节点成为 leader。在等待选举结果的时候，节点收到了心跳或者日志复制的消息（也就是有 leader 了），如果这个 leader 合法（任期比自己的当前任期高），则当前节点会自动变成 follower 状态；否则会继续等待</li><li>一段时间过去，并没有任何节点成为 leader。比如有多个节点要选举 leader，而且都投票结果比较分散，没有节点获得过半的票数</li></ol><p>如果不采取任何措施，那么第三种情况一直出现，会导致整个集群一直处于选举的状态，这当然是不可接受的。为此，raft 采取了随机时间的办法。</p><p>首先，选举超时时间（election timeout）是随机的，保证会有一个节点首先超时，率先选举，其他节点来不及和它竞选，它就会成为新的 leader，发送心跳和日志复制请求。</p><p>其次，在开始选举时，每个 candidate 节点重置它的超时计时器，等待计时器结束之后才会开始下一次选举，从而打乱下次选举的前后顺序，保证有一个节点先开始选举，并成为 leader。</p><p>事实证明，这两种方式能够保证选举在很短的时间里完成，而不会一直循环。</p><p><strong>NOTE:</strong></p><ol><li>选举过期时间（election timeout）一般设置为 150-300ms，这是大量实验得到的经验值</li></ol><h3 id="日志复制-Log-replication"><a href="#日志复制-Log-replication" class="headerlink" title="日志复制 Log replication"></a>日志复制 Log replication</h3><p>当一个节点成为 leader 之后，它就会负责接收客户端的请求。客户端的每个请求都是一个指令，replicate state machine（复制状态机） 会执行这个指令，修改自己的状态。</p><p>主节点收到请求之后，把它作为新纪录写入到自己的日志中，然后发送请求给所有的从节点，让它们进行日志复制，等到日志复制完成，leader 节点返回结果给客户端。如果有从节点失败或者比较慢，主节点会一直重试，直到所有的节点保存了所有的日志记录（达到统一的状态）。</p><p>每个日志记录都要保存一个状态机的指令，同时还保存主节点接受请求时候的任期值，此外还有一个 index 表示它在日志文件中的位置。</p><p>当日志记录被状态机执行后，就称它为已提交（commited）。当主节点知道日志记录已经复制到大多数节点时，会把当前记录提交到本地的状态机（因为日志已经更新到大多数节点，所有数据是安全的），也就是更改数据的值。</p><p>leader 节点会记录已经提交（commited）的最大日志 index，然后后续的心跳和日志复制请求会带上这个值，这样从节点就能知道哪些记录已经提交了，自己也会让状态机开始执行日志中的记录。从而达到所有状态机数据的一致性！</p><p>这样的日志机制保证了如果不同节点的日志文件某个记录的 index 和任期都相同，那么它们的内容也一定相同，而且之前的日志记录也一定是一样的。</p><p>当主节点发送日志复制的请求时，它会带上前一个日志记录的 index 和 term，如果从节点发现自己的日志中不存在这个记录，则会拒绝这个请求。</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fm40wfjblhj30ym0i5dif.jpg" alt=""></p><p>正常情况下，每次日志复制都能正常完成，而且节点都能保证日志记录都是完全一致的。但如果 leader 节点崩溃掉，可能会出现日志不一致的情况（奔溃的主节点还没有完全把自己日志文件中的记录复制到其他节点，因此有些节点的日志比另外一些节点内容更多）。</p><p>对于日志内容不一致的请求，raft 采取用主节点日志内容覆盖 follower 节点日志的做法，先找到从节点日志和自己日志记录第一个不一致的地方，然后一直覆盖到最后。</p><p>整个过程是这样的：当某个节点当选 leader 之后，会发送日志复制请求到从节点，并带着 nextIndex（主节点要发送的下一个日志记录的 index），如果从节点出现日志记录不一致的情况，会拒绝该请求，那么主节点知道发生了不一致，递减 nextIndex，然后重新发送请求，直到日志一致的地方，一切回复正常，然后继续发送日志复制请求，就会把从节点的日志覆盖为主节点的日志内容。</p><h3 id="安全-safety"><a href="#安全-safety" class="headerlink" title="安全 safety"></a>安全 safety</h3><p>前面提到的选主和日志复制是 raft 算法的核心，能够保证日志里面记录最终是一致的，但是还不能够保证所有节点的状态机能够按顺序执行命令。raft 对选主做出了限制，从而实现算法的正确性。</p><p>总的来说，这个限制只有一句话：<strong>只有保存了最新日志的节点才能选举成为 leader</strong>，选举的时候如果节点发现候选节点日志没有自己的新，则拒绝投票给它。因为保存了最新日志，因此新 leader 产生之后，follower 节点和它保持同步就不会出现数据冲突的问题。这样也能保证 leader 节点不会覆盖日志中的记录。</p><p>上面<strong>最新日志</strong>指的是保存了所有的已提交日志记录，因为已提交已经包含了集群中大多数节点都会有对应的日志记录，因此能保证没有最新记录的候选人选不上（因为大多数节点会拒绝投票给它），而且至少有一个节点符合条件（只要集群节点数超过 3）。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>除了上述最核心的内容之外，raft 算法还有节点增删时候保证数据一致性的解决方案，以及利用快照（snapshot）进行日志压缩（log compaction）的内容，而且还要求客户端发送请求时带有一个 id，raft 集群保证请求处理的幂等性。</p><p>总的来说，易懂性是 raft 强调的核心，在不损失功能和性能的情况下，保证算法和系统的容易理解非常重要，这也是为什么相比很早就就出现的 paxos 算法，2013 年刚出现的 raft 就成为了很多新的分布式系统核心算法（比如分布式键值数据库 etcd ）。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://ramcloud.stanford.edu/raft.pdf" target="_blank" rel="noopener">raft 算法论文</a></li><li><a href="https://raft.github.io/" target="_blank" rel="noopener">raft 算法图解</a></li><li><a href="https://www.cnblogs.com/mindwind/p/5231986.html" target="_blank" rel="noopener">Raft 为什么是更易理解的分布式一致性算法</a></li><li><a href="http://thesecretlivesofdata.com/raft/" target="_blank" rel="noopener">raft 算法动画解析</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;分布式系统和一致性&quot;&gt;&lt;a href=&quot;#分布式系统和一致性&quot; class=&quot;headerlink&quot;
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="raft" scheme="http://cizixs.com/tags/raft/"/>
    
      <category term="distributed-system" scheme="http://cizixs.com/tags/distributed-system/"/>
    
  </entry>
  
  <entry>
    <title>etcd go 语言 v2 客户端开发介绍</title>
    <link href="http://cizixs.com/2017/12/03/etcd-v2-go-client/"/>
    <id>http://cizixs.com/2017/12/03/etcd-v2-go-client/</id>
    <published>2017-12-02T16:00:00.000Z</published>
    <updated>2018-09-17T13:18:45.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="etcd-介绍"><a href="#etcd-介绍" class="headerlink" title="etcd 介绍"></a>etcd 介绍</h2><p>很久之前写过<a href="http://cizixs.com/2016/08/02/intro-to-etcd">一篇 etcd 的介绍文章</a>，主要是讲 etcd 的概念和使用方式，这篇文章介绍如何使用 go 语言进行 etcd 的开发工作。</p><p>etcd 目前最新版 API 是 v3 版本，之前被广泛使用的 API 为 v2 版本。这篇文章会介绍 v2 版本 go 语言客户端的使用，涉及了最常见的增删查改和监听操作。</p><h2 id="v2-版本使用"><a href="#v2-版本使用" class="headerlink" title="v2 版本使用"></a>v2 版本使用</h2><p><a href="http://cizixs.com/2016/08/02/intro-to-etcd">之前的文章</a> 已经对 etcd v2 版本的概念和 API 介绍得很详细了，这里再总结一下。</p><ul><li>作为分布式的键值存储，etcd v2 存储的 key 和 value 都是字符串类型。其中 key 以类 unix 文件系统的结构存储，分为目录和文件，目录下面可以嵌套目录和文件，文件只能对应某个值（value）。可以对 key 进行创建、删除和修改的工作</li><li>可以为 key（包括目录和文件）设置一个 TTL 值，也就是过期时间，等到时间过了，值自动被删除</li><li>提供了 CAS(compare And Set）和 CAD（Compare And Delete）两种原子操作，可以实现比较然后执行某个动作的逻辑</li><li>可以监听某个文件和目录，当里面的值发生变化时，监听者会立即收到通知</li></ul><p>概念讲完了，下面看看如何用 go 语言进行 etcd 的开发工作。etcd 官方就维护了一个 etcd go 语言客户端，在 <code>github.com/coreos/etcd/client</code>，我们可以用下面的语句把它导入到 go 程序中：</p><pre><code>import    (    ...    etcd &quot;github.com/coreos/etcd/client&quot;    &quot;github.com/coreos/etcd/pkg/transport&quot;)</code></pre><p>我们给它取了个别名 <code>etcd</code>，之后后面的程序中我们可以用 <code>etcd</code> 而不是 <code>client</code> 来使用它提供的功能（这样程序的可读性更好）。</p><h3 id="创建-client-客户端"><a href="#创建-client-客户端" class="headerlink" title="创建 client 客户端"></a>创建 client 客户端</h3><p>首先，我们要创建一个 etcd 的 Client，可以使用 <code>etcd.New()</code> 函数，它接受 <code>etcd.Config</code> 作为参数，后者主要的参数包括：</p><ul><li><code>Endpoints</code>：etcd server 集群的地址列表，是一个 string 列表，每个值为一个 etcd 的监听地址</li><li><code>Transport</code>：底层用于进行 HTTP 请求传输的结构体</li><li><code>Username</code> 和 <code>Password</code>：进行简单认证的用户名和密码</li></ul><p>其他还有一些参数这里就不说了，使用默认值就行。为了完整性，我们会处理 etcd server 开启了简单认证和 TLS 的情况，首先创建一个自定义的结构体保存所有需要的参数：</p><pre><code>type EtcdConfig struct {    Endpoints []string    KeyFile   string    CertFile  string    CAFile    string    Username  string    Password  string}</code></pre><p>注意这是我们自己定义的结构体，不是客户端程序提供的。</p><p>然后构建能进行 TLS 处理的 transport，<code>transport</code> 是 etcd 提供的库，它内部会处理证书的读取和验证工作：</p><pre><code>tlsInfo := transport.TLSInfo{    CertFile: c.CertFile,    KeyFile:  c.KeyFile,    CAFile:   c.CAFile,}t, err := transport.NewTransport(tlsInfo, time.Second)</code></pre><p>然后就能构建 client：</p><pre><code>client, err := etcd.New(etcd.Config{    Endpoints: c.Endpoints,    Transport: t,    Username:  c.Username,    Password:  c.Password,})</code></pre><p>这个 client 主要负责 HTTP API 交互的逻辑，同时也负责从多个 endpoints 中选择一个可用的来调用。但是和 keys 交互的逻辑并没有直接在这个 client 中，而是需要另外一个对象 <code>KeysAPI</code>：</p><pre><code>kapi := etcd.NewKeysAPI(client)</code></pre><p>所有键值对有关的操作都是这个 <code>kapi</code> 对象的方法提供的，它会实现接口的如下方法：</p><pre><code>type KeysAPI interface {    // Get 从 etcd 中获取 Node 的信息    Get(ctx context.Context, key string, opts *GetOptions) (*Response, error)    // Set 设置对应 key 的值为 value，这个方法也可以用来创建目录    Set(ctx context.Context, key, value string, opts *SetOptions) (*Response, error)    // Delete 删除节点，包括目录和文件节点    Delete(ctx context.Context, key string, opts *DeleteOptions) (*Response, error)    // Create 是 set 的一种特殊形式，只有之前节点不存在时才会创建成功    Create(ctx context.Context, key, value string) (*Response, error)    // CreateInOrder 在目录下面创建递增的键值对    CreateInOrder(ctx context.Context, dir, value string, opts *CreateInOrderOptions) (*Response, error)    // Update 也是 Set 的一种特殊形式，只有对应的节点存在时才会更新成功    Update(ctx context.Context, key, value string) (*Response, error)    // Watcher 返回一个 Watcher 对象，监听某个节点下面的变化    Watcher(key string, opts *WatcherOptions) Watcher}</code></pre><h3 id="创建值"><a href="#创建值" class="headerlink" title="创建值"></a>创建值</h3><p>先来看看设置一个 key value 的操作，第一个是 context 对象，后面两个分别是 key 和 value 值，最后是额外的参数，目前并不需要设置为 nil：</p><pre><code>resp, err := client.Set(context.Background(), &quot;/user/name&quot;, &quot;cizixs&quot;, nil)</code></pre><p>如果要为某个值设置超时时间，可以添加选项 <code>TTL</code>：</p><pre><code>resp, err := client.Set(context.Background(), &quot;/user/name&quot;, &quot;&quot;,    &amp;etcd.SetOptions{        TTL: time.Duration(ttl) * time.Second,        Refresh: true,    },)</code></pre><p><code>SetOptions</code> 可选的字段有：</p><ul><li><code>Dir</code>：布尔值，表示要创建的是一个目录</li><li><code>Refresh</code>：如果设置为 true，则表明只是更新某个 key 的 TTL 时间，不会重置它的值</li><li><code>PrevValue</code>：原子操作，只有节点的值和这个字段指定的值相同时才会执行更新操作</li><li><code>PrevIndex</code>：原子操作，只有节点的 ModifiedIndex 和这个字段指定的值相同时才会执行更新操作</li><li><code>PrevExist</code>：原子操作，只有节点存在或者不存在时才会执行更新操作，支持的值有 <code>PrevIgnore</code>、<code>PrevExist</code> 和 <code>PrevNoExist</code></li></ul><p>这里要先讲一下返回值 <code>Response</code> 的构成，它包含了返回中节点的信息以及 index 信息：</p><pre><code>type Response struct {    // Action 操作的动作名称，可以是 set、delete    Action string `json:&quot;action&quot;`    // Node 代表操作的节点    Node *Node `json:&quot;node&quot;`    // PrevNode 节点之前的值    PrevNode *Node `json:&quot;prevNode&quot;`    // Index：response 生成是 cluster index 的值    Index uint64 `json:&quot;-&quot;`}</code></pre><p>其中节点的定义如下：</p><pre><code>type Node struct {    //  节点的位置，目录名称，比如 `/foo/bar`    Key string `json:&quot;key&quot;`    //  节点是否为一个目录    Dir bool `json:&quot;dir,omitempty&quot;`    //  节点存储的对象值，如果是目录，则忽略这个字段    Value string `json:&quot;value&quot;`    // Nodes 子节点，如果是目录，则这个字段保存了目录下面的所有节点内容    Nodes Nodes `json:&quot;nodes&quot;`    //  节点创建时候的 etcd  index    CreatedIndex uint64 `json:&quot;createdIndex&quot;`    //  节点更新时候的 etcd index    ModifiedIndex uint64 `json:&quot;modifiedIndex&quot;`    // 节点的过期时间    Expiration *time.Time `json:&quot;expiration,omitempty&quot;`    // TTL 节点设置的 time to live，单位是秒    TTL int64 `json:&quot;ttl,omitempty&quot;`}</code></pre><h3 id="获取值"><a href="#获取值" class="headerlink" title="获取值"></a>获取值</h3><p>获取值是通过 <code>Get</code> 方法，和 <code>Set</code> 一样，它也支持选项。如果只是简单获取某个键的值，直接设置选项为空就行：</p><pre><code>resp, err := client.Get(context.Background(), key, nil)</code></pre><p>如果要递归地获取某个目录下面所有的内容，可以使用 <code>Recursive</code> 参数：</p><pre><code>resp, err := client.Get(context.Background(), key, &amp;etcd.GetOptions{    Recursive: true,   })</code></pre><p>然后通过 resp 就能遍历所有的子节点的值。</p><h3 id="删除值"><a href="#删除值" class="headerlink" title="删除值"></a>删除值</h3><p>删除操作通过 <code>Delete</code> 方法完成，简单删除一个文件节点，可以忽略参数：</p><pre><code>_, err := client.Delete(context.Background(), key, nil)</code></pre><p>如果要删除某个非空的目录，需要 <code>Recursive</code> 参数：</p><pre><code>_, err := client.Delete(context.Background(), key, &amp;etcd.DeleteOptions{    Dir: true,    Recursive: true,})</code></pre><p>其他字段包括：</p><ul><li><code>PrevValue</code>：只有节点值和给定的值相同时才执行删除操作</li><li><code>PrevIndex</code>：只有节点的 index 和给定的 index 相同时，才执行删除操作</li></ul><h3 id="监听值"><a href="#监听值" class="headerlink" title="监听值"></a>监听值</h3><p>etcd 另外一个重要的功能是监听目录或者文件的变化，<code>Watcher</code> 方法会返回一个对象，调用它的 <code>Next()</code> 方法会阻塞，一直到监听的对象有变化，它才会返回变化节点的情况：</p><pre><code>watcher := client.Watcher(key, &amp;etcd.WatcherOptions{    Recursive: true,})for {    resp, err := watcher.Next(context.Background())    if err != nil {        return err    }}</code></pre><p>其中 <code>WatcherOptions</code> 接受 <code>AfterIndex</code> 和 <code>Recursive</code> 两个参数，分别表示才某个 Index 之后开始监听，以及递归监听某个目录下面所有的节点。</p><p>完整的 demo 代码在<a href="https://github.com/cizixs/etcd-demo/tree/master/v2" target="_blank" rel="noopener"> github 上</a>，请前往阅读。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://godoc.org/github.com/coreos/etcd/client" target="_blank" rel="noopener">etcd client v2 godoc 文档</a></li><li><a href="https://github.com/coreos/etcd/tree/master/client" target="_blank" rel="noopener">etcd client 源码</a></li><li><a href="http://dockone.io/article/801" target="_blank" rel="noopener">谈谈CoreOS的etcd</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;etcd-介绍&quot;&gt;&lt;a href=&quot;#etcd-介绍&quot; class=&quot;headerlink&quot; title=&quot;etcd 介绍&quot;&gt;&lt;/a&gt;etcd 介绍&lt;/h2&gt;&lt;p&gt;很久之前写过&lt;a
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="etcd" scheme="http://cizixs.com/tags/etcd/"/>
    
      <category term="go" scheme="http://cizixs.com/tags/go/"/>
    
  </entry>
  
  <entry>
    <title>OCI 和 runc：容器标准化和 docker</title>
    <link href="http://cizixs.com/2017/11/05/oci-and-runc/"/>
    <id>http://cizixs.com/2017/11/05/oci-and-runc/</id>
    <published>2017-11-04T16:00:00.000Z</published>
    <updated>2018-12-04T03:43:59.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="OCI-和容器标准"><a href="#OCI-和容器标准" class="headerlink" title="OCI 和容器标准"></a>OCI 和容器标准</h2><p>容器技术随着 docker 的出现炙手可热，所有的技术公司都积极拥抱容器，促进了 docker 容器的繁荣发展。<strong>容器</strong>一词虽然口口相传，但却没有统一的定义，这不仅是个技术概念的问题，也给整个社区带来一个阴影：容器技术的标准到底是什么？由谁来决定？</p><p>很多人可能觉得 docker 已经成为了容器的事实标准，那我们以它作为标准问题就解决了。事情并没有那么简单，首先是否表示容器完全等同于 docker，不允许存在其他的容器运行时（比如 coreOS 推出的 rkt）；其次容器上层抽象（容器集群调度，比如 kubernetes、mesos 等）和 docker 紧密耦合，docker 接口的变化将会导致它们无法使用。</p><p>总的来说，如果容器以 docker 作为标准，那么 docker 接口的变化将导致社区中所有相关工具都要更新，不然就无法使用；如果没有标准，这将导致容器实现的碎片化，出现大量的冲突和冗余。这两种情况都是社区不愿意看到的事情，OCI（Open Container Initiative） 就是在这个背景下出现的，它的使命就是推动容器标准化，容器能运行在任何的硬件和系统上，相关的组件也不必绑定在任何的容器运行时上。</p><p>官网上对 OCI 的说明如下：</p><blockquote><p>An open governance structure for the express purpose of creating open industry standards around container formats and runtime.<br>– Open Containers Official Site</p></blockquote><p>OCI 由 docker、coreos 以及其他容器相关公司创建于 2015 年，目前主要有两个标准文档：<a href="https://github.com/opencontainers/runtime-spec" target="_blank" rel="noopener">容器运行时标准</a> （runtime spec）和 <a href="https://github.com/opencontainers/image-spec" target="_blank" rel="noopener">容器镜像标准</a>（image spec）。</p><p>这两个协议通过 OCI runtime filesytem bundle 的标准格式连接在一起，OCI 镜像可以通过工具转换成 bundle，然后 OCI 容器引擎能够识别这个 bundle 来运行容器。</p><p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fl7l7qihpmj30vi0lj756.jpg" alt=""></p><p>下面，我们来介绍这两个 OCI 标准。因为标准本身细节很多，而且还在不断维护和更新，如果不是容器的实现者，没有必须对每个细节都掌握。所以我以介绍概要为主，给大家有个主观的认知。</p><h3 id="image-spec"><a href="#image-spec" class="headerlink" title="image spec"></a>image spec</h3><p>OCI 容器镜像主要包括几块内容：</p><ul><li><a href="https://github.com/opencontainers/image-spec/blob/master/layer.md" target="_blank" rel="noopener">文件系统</a>：以 layer 保存的文件系统，每个 layer 保存了和上层之间变化的部分，layer 应该保存哪些文件，怎么表示增加、修改和删除的文件等</li><li><a href="https://github.com/opencontainers/image-spec/blob/master/config.md" target="_blank" rel="noopener">config 文件</a>：保存了文件系统的层级信息（每个层级的 hash 值，以及历史信息），以及容器运行时需要的一些信息（比如环境变量、工作目录、命令参数、mount 列表），指定了镜像在某个特定平台和系统的配置。比较接近我们使用  <code>docker inspect &lt;image_id&gt;</code> 看到的内容</li><li><a href="https://github.com/opencontainers/image-spec/blob/master/manifest.md" target="_blank" rel="noopener">manifest 文件</a>：镜像的 config 文件索引，有哪些 layer，额外的 annotation 信息，manifest 文件中保存了很多和当前平台有关的信息</li><li><a href="https://github.com/opencontainers/image-spec/blob/master/image-index.md" target="_blank" rel="noopener">index 文件</a>：可选的文件，指向不同平台的 manifest 文件，这个文件能保证一个镜像可以跨平台使用，每个平台拥有不同的 manifest 文件，使用 index 作为索引</li></ul><h3 id="runtime-spec"><a href="#runtime-spec" class="headerlink" title="runtime spec"></a>runtime spec</h3><p>OCI 对容器 runtime 的标准主要是指定容器的运行状态，和 runtime 需要提供的命令。下图可以是容器状态转换图：</p><p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fl7l8q0xl4j30uf0iaq4s.jpg" alt=""></p><ul><li>init 状态：这个是我自己添加的状态，并不在标准中，表示没有容器存在的初始状态</li><li>creating：使用 <code>create</code> 命令创建容器，这个过程称为创建中</li><li>created：容器创建出来，但是还没有运行，表示镜像和配置没有错误，容器能够运行在当前平台</li><li>running：容器的运行状态，里面的进程处于 up 状态，正在执行用户设定的任务</li><li>stopped：容器运行完成，或者运行出错，或者 <code>stop</code> 命令之后，容器处于暂停状态。这个状态，容器还有很多信息保存在平台中，并没有完全被删除</li></ul><h2 id="runc"><a href="#runc" class="headerlink" title="runc"></a>runc</h2><p>runc 是 docker 捐赠给 OCI 的一个符合标准的 runtime 实现，目前 docker 引擎内部也是基于 runc 构建的。这部分我们就分析 runc 这个项目，加深对 OCI 的理解。</p><h3 id="使用-runc-运行-busybox-容器"><a href="#使用-runc-运行-busybox-容器" class="headerlink" title="使用 runc 运行 busybox 容器"></a>使用 runc 运行 busybox 容器</h3><p>先来准备一个工作目录，下面所有的操作都是在这个目录下执行的，比如 <code>mycontainer</code>：</p><pre><code># mkdir mycontainer</code></pre><p>接下来，准备容器镜像的文件系统，我们选择从 docker 镜像中提取：</p><pre><code># mkdir rootfs# docker export $(docker create busybox) | tar -C rootfs -xvf -# ls rootfs bin  dev  etc  home  proc  root  sys  tmp  usr  var</code></pre><p>有了 rootfs 之后，我们还要按照 OCI 标准有一个配置文件 config.json 说明如何运行容器，包括要运行的命令、权限、环境变量等等内容，<code>runc</code> 提供了一个命令可以自动帮我们生成：</p><pre><code># runc spec# lsconfig.json  rootfs</code></pre><p>这样就构成了一个 <a href="https://github.com/opencontainers/runtime-spec/blob/master/bundle.md" target="_blank" rel="noopener">OCI runtime bundle</a> 的内容，这个 bundle 非常简单，就上面两个内容：config.json 文件和 rootfs 文件系统。<code>config.json</code> 里面的内容很长，这里就不贴出来了，我们也不会对其进行修改，直接使用这个默认生成的文件。有了这些信息，runc 就能知道怎么怎么运行容器了，我们先来看看简单的方法 <code>runc run</code>（这个命令需要 root 权限），这个命令类似于 <code>docker run</code>，它会创建并启动一个容器：</p><pre><code>➜  runc run simplebusybox/ # lsbin   dev   etc   home  proc  root  sys   tmp   usr   var/ # hostnamerunc/ # whoamiroot/ # pwd// # ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host        valid_lft forever preferred_lft forever/ # ps auxPID   USER     TIME   COMMAND    1 root       0:00 sh   11 root       0:00 ps aux</code></pre><p>最后一个参数是容器的名字，需要在主机上保证唯一性。运行之后直接进入到了容器的 <code>sh</code> 交互界面，和通过 <code>docker run</code> 看到的效果非常类似。但是这个容器并没有配置网络方面的内容，只是有一个默认的 <code>lo</code> 接口，因此无法和外部通信，但其他功能都正常。</p><p>此时，另开一个终端，可以查看运行的容器信息：</p><pre><code>➜ runc listID              PID         STATUS      BUNDLE                                    CREATED                          OWNERsimplebusybox   18073       running     /home/cizixs/Workspace/runc/mycontainer   2017-11-02T06:54:52.023379345Z   root</code></pre><p>目前，在我的机器上，runc 会把容器的运行信息保存在 <code>/run/runc</code> 目录下：</p><pre><code>➜ tree /run/runc/                     /run/runc/└── simplebusybox    └── state.json1 directory, 1 file</code></pre><p>除了 run 命令之外，我们也能通过create、start、stop、kill 等命令对容器状态进行更精准的控制。继续实验，因为接下来要在后台模式运行容器，所以需要对 <code>config.json</code> 进行修改。改动有两处，把 <code>terminal</code> 的值改成 <code>false</code>，修改 <code>args</code> 命令行参数为 <code>sleep 20</code>：</p><pre><code>&quot;process&quot;: {        &quot;terminal&quot;: false,        &quot;user&quot;: {            &quot;uid&quot;: 0,            &quot;gid&quot;: 0        },        &quot;args&quot;: [            &quot;sleep&quot;, &quot;20&quot;        ],        ...}</code></pre><p>接着，用 runc 子命令来控制容器的运行，实现各个容器状态的转换：</p><pre><code>// 使用 create 创建出容器，此时容器并没有运行，只是准备好了所有的运行环境// 通过 list 命令可以查看此时容器的状态为 `created`➜  runc create mycontainerid➜  runc listID              PID         STATUS      BUNDLE                                    CREATED                          OWNERmycontainerid   15871       created     /home/cizixs/Workspace/runc/mycontainer   2017-11-02T08:05:50.658423519Z   root// 运行容器，此时容器会在后台运行，状态变成了 `running`➜  runc start mycontainerid➜  runc listID              PID         STATUS      BUNDLE                                    CREATED                          OWNERmycontainerid   15871       running     /home/cizixs/Workspace/runc/mycontainer   2017-11-02T08:05:50.658423519Z   root// 等待一段时间（20s）容器退出后，可以看到容器状态变成了 `stopped`➜  runc listID              PID         STATUS      BUNDLE                                    CREATED                          OWNERmycontainerid   0           stopped     /home/cizixs/Workspace/runc/mycontainer   2017-11-02T08:05:50.658423519Z   root// 删除容器，容器的信息就不存在了➜  runc delete mycontainerid➜  runc listID          PID         STATUS      BUNDLE      CREATED     OWNER</code></pre><p>把以上命令分开来虽然让事情变得复杂了，但是也有很多好处。可以类比 unix 系统 fork-exec 模式，在两者动作之间，用户可以做很多工作。比如把 create 和 start 分开，在创建出来容器之后，可以使用插件为容器配置多主机网络，或者准备存储设置等。</p><h3 id="runc-代码实现"><a href="#runc-代码实现" class="headerlink" title="runc 代码实现"></a>runc 代码实现</h3><p>看完了 runc 命令演示，这部分来深入分析 runc 的代码实现。要想理解 runc 是怎么创建 linux 容器的，需要熟悉 <a href="http://cizixs.com/2017/08/29/linux-namespace">namespace</a> 和 <a href="http://cizixs.com/2017/08/25/linux-cgroup">cgroup</a>、 go 语言 、常见的系统调用。</p><p>分析的代码对应的 commit id 如下，这个代码是非常接近 v1.0.0 版本的：</p><pre><code>➜  runc git:(master) git rev-parse HEAD0232e38342a8d230c2745b67c17050b2be70c6bc</code></pre><p><code>runc</code> 的代码结构如下（略去了部分内容）：</p><pre><code>➜  runc git:(master) tree -L 1 -F --dirsfirst                  .├── contrib/├── libcontainer/├── man/├── script/├── tests/├── vendor/├── checkpoint.go├── create.go├── delete.go├── Dockerfile├── events.go├── exec.go├── init.go├── kill.go├── LICENSE├── list.go├── main.go├── Makefile├── notify_socket.go├── pause.go├── PRINCIPLES.md├── ps.go├── README.md├── restore.go├── rlimit_linux.go├── run.go├── signalmap.go├── signalmap_mipsx.go├── signals.go├── spec.go├── start.go├── state.go├── tty.go├── update.go├── utils.go└── utils_linux.go</code></pre><p><code>main.go</code> 是入口文件，根目录下很多 <code>.go</code> 文件是对应的命令（比如 <code>run.go</code> 对应 <code>runc run</code> 命令的实现），其他是一些功能性文件。</p><p>最核心的目录是 <code>libcontainer</code>，它是启动容器进程的最终执行者，<code>runc</code> 可以理解为对 <code>libcontainer</code> 的封装，以符合 OCI 的方式读取配置和文件，调用 libcontainer 完成真正的工作。如果熟悉 docker 的话，可能会知道 libcontainer 本来是 docker 引擎的核心代码，用以取代之前 lxc driver。</p><p>我们会追寻 <code>runc run</code> 命令的执行过程，看看代码的调用和实现。</p><p><code>main.go</code> 使用 <code>github.com/urfave/cli</code> 库进行命令行解析，主要的思路是先声明各种参数解析、命令执行函数，运行的时候 <code>cli</code> 会解析命令行传过来的参数，把它们变成定义好的变量，调用指定的命令来运行。</p><pre><code>func main() {    app := cli.NewApp()    app.Name = &quot;runc&quot;    ...    app.Commands = []cli.Command{        checkpointCommand,        createCommand,        deleteCommand,        eventsCommand,        execCommand,        initCommand,        killCommand,        listCommand,        pauseCommand,        psCommand,        restoreCommand,        resumeCommand,        runCommand,        specCommand,        startCommand,        stateCommand,        updateCommand,    }    ...    if err := app.Run(os.Args); err != nil {        fatal(err)    }}</code></pre><p>从上面可以看到命令函数列表，也就是 <code>runc</code> 支持的所有命令，命令行会实现命令的转发，我们关心的 <code>runCommand</code> 定义在 <code>run.go</code> 文件，它的执行逻辑是：</p><pre><code>Action: func(context *cli.Context) error {    if err := checkArgs(context, 1, exactArgs); err != nil {        return err    }    if err := revisePidFile(context); err != nil {        return err    }    spec, err := setupSpec(context)    status, err := startContainer(context, spec, CT_ACT_RUN, nil)    if err == nil {        os.Exit(status)    }    return err},</code></pre><p>可以看到整个过程分为了四步：</p><ol><li>检查参数个数是否符合要求</li><li>如果指定了 pid-file，把路径转换为绝对路径</li><li>根据配置读取 <code>config.json</code> 文件中的内容，转换成 spec 结构对象</li><li>然后根据配置启动容器</li></ol><p>其中 spec 的定义在 <code>github.com/opencontainers/runtime-spec/specs-go/config.go#Spec</code>，其实就是对应了 OCI bundle 中 <code>config.json</code> 的字段，最重要的内容在 <code>startContainer</code> 函数中：</p><p><code>utils_linux.go#startContainer</code></p><pre><code>func startContainer(context *cli.Context, spec *specs.Spec, action CtAct, criuOpts *libcontainer.CriuOpts) (int, error) {    id := context.Args().First()    if id == &quot;&quot; {        return -1, errEmptyID    }    ......    container, err := createContainer(context, id, spec)    if err != nil {        return -1, err    }    ......    r := &amp;runner{        enableSubreaper: !context.Bool(&quot;no-subreaper&quot;),        shouldDestroy:   true,        container:       container,        listenFDs:       listenFDs,        notifySocket:    notifySocket,        consoleSocket:   context.String(&quot;console-socket&quot;),        detach:          context.Bool(&quot;detach&quot;),        pidFile:         context.String(&quot;pid-file&quot;),        preserveFDs:     context.Int(&quot;preserve-fds&quot;),        action:          action,        criuOpts:        criuOpts,    }    return r.run(spec.Process)}</code></pre><p>这个函数的内容也不多，主要分成两部分：</p><ol><li>调用 <code>createContainer</code> 创建出来容器，这个容器只是一个逻辑上的概念，保存了 namespace、cgroups、mounts、capabilities 等所有 Linux 容器需要的配置</li><li>然后创建 <code>runner</code> 对象，调用 <code>r.run</code> 运行容器。这才是运行最终容器进程的地方，它会启动一个新进程，把进程放到配置的 namespaces 中，设置好 cgroups 参数以及其他内容</li></ol><p>我们先来看 <code>utils_linux.go#createContainer</code>：</p><pre><code>func createContainer(context *cli.Context, id string, spec *specs.Spec) (libcontainer.Container, error) {    config, err := specconv.CreateLibcontainerConfig(&amp;specconv.CreateOpts{        CgroupName:       id,        UseSystemdCgroup: context.GlobalBool(&quot;systemd-cgroup&quot;),        NoPivotRoot:      context.Bool(&quot;no-pivot&quot;),        NoNewKeyring:     context.Bool(&quot;no-new-keyring&quot;),        Spec:             spec,        Rootless:         isRootless(),    })    ....    factory, err := loadFactory(context)    ....    return factory.Create(id, config)}</code></pre><p>它最终会返回一个 <code>libcontainer.Container</code> 对象，上面提到，这并不是一个运行的容器，而是逻辑上的容器概念，包含了 linux 上运行一个容器需要的所有配置信息。</p><p>函数的内容分为两部分：</p><ol><li>创建 config 对象，这个配置对象的定义在 <code>libcontainer/configs/config.go#Config</code>，包含了容器运行需要的所有参数。<code>specconv.CreateLibcontainerConfig</code> 这一个函数就是把 spec 转换成 libcontainer 内部的 config 对象。这个 config 对象是平台无关的，从逻辑上定义了容器应该是什么样的配置</li><li>通过 libcontainer 提供的 factory，创建满足 <code>libcontainer.Container</code>  接口的对象</li></ol><p><code>libcontainer.Container</code> 是个接口，定义在 <code>libcontainer/container_linux.go</code> 文件中：</p><pre><code>type Container interface {    BaseContainer    // 下面这些接口是平台相关的，也就是 linux 平台提供的特殊功能    // 使用 criu 把容器状态保存到磁盘    Checkpoint(criuOpts *CriuOpts) error    // 利用 criu 从磁盘中重新 load 容器    Restore(process *Process, criuOpts *CriuOpts) error    // 暂停容器的执行    Pause() error    // 继续容器的执行    Resume() error    // 返回一个 channel，可以从里面读取容器的 OOM 事件    NotifyOOM() (&lt;-chan struct{}, error)    // 返回一个  channel，可以从里面读取容器内存压力事件    NotifyMemoryPressure(level PressureLevel) (&lt;-chan struct{}, error)}</code></pre><p>里面包含了 Linux 平台特有的功能，基础容器接口为 <code>BaseContainer</code>，定义在 <code>libcontainer/container.go</code> 文件中，它定义了容器通用的方法：</p><pre><code>type BaseContainer interface {    // 返回容器 ID    ID() string    // 返回容器运行状态    Status() (Status, error)    // 返回容器详细状态信息    State() (*State, error)    // 返回容器的配置    Config() configs.Config    // 返回运行在容器里所有进程的 PID    Processes() ([]int, error)    // 返回容器的统计信息，主要是网络接口信息和 cgroup 中能收集的统计数据    Stats() (*Stats, error)    // 设置容器的配置内容，可以动态调整容器    Set(config configs.Config) error    // 在容器中启动一个进程    Start(process *Process) (err error)    // 运行容器    Run(process *Process) (err error)    // 销毁容器，就是删除容器    Destroy() error    // 给容器的 init 进程发送信号    Signal(s os.Signal, all bool) error    // 告诉容器在 init 结束后执行用户进程    Exec() error}</code></pre><p>可以看到，上面是容器应该支持的命令，包含了查询状态和创建、销毁、运行等。</p><p>这里使用 factory 模式是为了支持不同平台的容器，每个平台实现自己的 factory ，根据运行平台调用不同的实现就行。不过 runc 目前只支持 linux 平台，所以我们看 <code>libcontainer/factory_linux.go</code> 中的实现：</p><pre><code>func New(root string, options ...func(*LinuxFactory) error) (Factory, error) {    if root != &quot;&quot; {        if err := os.MkdirAll(root, 0700); err != nil {            return nil, newGenericError(err, SystemError)        }    }    l := &amp;LinuxFactory{        Root:      root,        InitPath:  &quot;/proc/self/exe&quot;,        InitArgs:  []string{os.Args[0], &quot;init&quot;},        Validator: validate.New(),        CriuPath:  &quot;criu&quot;,    }    Cgroupfs(l)    for _, opt := range options {        if opt == nil {            continue        }        if err := opt(l); err != nil {            return nil, err        }    }    return l, nil}func (l *LinuxFactory) Create(id string, config *configs.Config) (Container, error) {    ......    containerRoot := filepath.Join(l.Root, id)    if err := os.MkdirAll(containerRoot, 0711); err != nil {        return nil, newGenericError(err, SystemError)    }    ......    c := &amp;linuxContainer{        id:            id,        root:          containerRoot,        config:        config,        initPath:      l.InitPath,        initArgs:      l.InitArgs,        criuPath:      l.CriuPath,        newuidmapPath: l.NewuidmapPath,        newgidmapPath: l.NewgidmapPath,        cgroupManager: l.NewCgroupsManager(config.Cgroups, nil),    }    ......    c.state = &amp;stoppedState{c: c}    return c, nil}</code></pre><p><code>New</code> 创建了一个 linux 平台的 factory，从 <code>LinuxFactory</code> 的 fields 可以看到，它里面保存了和 linux 平台相关的信息。</p><p><code>Create</code> 返回的是 <code>linuxContainer</code> 对象，它是 <code>libcontainer.Container</code> 接口的实现。有了 <code>libcontainer.Container</code> 对象之后，回到 <code>utils_linux.go#Runner</code> 中看它是如何运行容器的：</p><pre><code>func (r *runner) run(config *specs.Process) (int, error) {    // 根据 OCI specs.Process 生成 libcontainer.Process 对象    // 如果出错，运行 destroy 清理产生的中间文件    process, err := newProcess(*config)    if err != nil {        r.destroy()        return -1, err    }    ......    var (        detach = r.detach || (r.action == CT_ACT_CREATE)    )    handler := newSignalHandler(r.enableSubreaper, r.notifySocket)    // 根据是否进入到容器终端来配置 tty，标准输入、标准输出和标准错误输出    tty, err := setupIO(process, rootuid, rootgid, config.Terminal, detach, r.consoleSocket)    defer tty.Close()    switch r.action {    case CT_ACT_CREATE:        err = r.container.Start(process)    case CT_ACT_RESTORE:        err = r.container.Restore(process, r.criuOpts)    case CT_ACT_RUN:        err = r.container.Run(process)    default:        panic(&quot;Unknown action&quot;)    }    ......    status, err := handler.forward(process, tty, detach)    if detach {        return 0, nil    }    r.destroy()    return status, err}</code></pre><p><code>runner</code> 是一层封装，主要工作是配置容器的 IO，根据命令去调用响应的方法。<code>newProcess(*config)</code> 将 OCI spec 中的 process 对象转换成 libcontainer 中的 process，process 的定义在 <code>libcontainer/process.go#Process</code>，包括进程的命令、参数、环境变量、用户、标准输入输出等。</p><p>有了 <code>process</code>，下一步就是运行这个进程 <code>r.container.Run(process)</code>，<code>Run</code> 会调用内部的 <code>libcontainer/container_linux.go#start()</code> 方法：</p><pre><code>func (c *linuxContainer) start(process *Process, isInit bool) error {    parent, err := c.newParentProcess(process, isInit)    if err := parent.start(); err != nil {        return newSystemErrorWithCause(err, &quot;starting container process&quot;)    }    c.created = time.Now().UTC()    if isInit {        ......         for i, hook := range c.config.Hooks.Poststart {            if err := hook.Run(s); err != nil {                return newSystemErrorWithCausef(err, &quot;running poststart hook %d&quot;, i)            }        }    }     return nil}</code></pre><p>运行容器进程，在容器进程完全起来之前，需要利用父进程和容器进程进行通信，因此这里封装了一个 <code>paerentProcess</code> 的概念，</p><pre><code>func (c *linuxContainer) newParentProcess(p *Process, doInit bool) (parentProcess, error) {    parentPipe, childPipe, err := utils.NewSockPair(&quot;init&quot;)    cmd, err := c.commandTemplate(p, childPipe)    ......    return c.newInitProcess(p, cmd, parentPipe, childPipe)}</code></pre><p><code>parentPipe</code> 和 <code>childPipe</code> 就是父进程和创建出来的容器 init 进程通信的管道，这个管道用于在 init 容器进程启动之后做一些配置工作，非常重要，后面会看到它们的使用。</p><p>最终创建的 parentProcess 是 <code>libcontainer/process_linux.go#initProcess</code> 对象，</p><pre><code>type initProcess struct {    cmd             *exec.Cmd    parentPipe      *os.File    childPipe       *os.File    config          *initConfig    manager         cgroups.Manager    intelRdtManager intelrdt.Manager    container       *linuxContainer    fds             []string    process         *Process    bootstrapData   io.Reader    sharePidns      bool}</code></pre><ul><li><code>cmd</code> 是 init 程序，也就是说启动的容器子进程是 <code>runc init</code>，后面我们会说明它的作用</li><li><code>paerentPipe</code> 和 <code>childPipe</code> 是父子进程通信的管道</li><li><code>bootstrapDta</code> 中保存了容器 init 初始化需要的数据</li><li><code>process</code> 会保存容器 init 进程，用于父进程获取容器进程信息和与之交互</li></ul><p>有了 <code>parentProcess</code>，接下来它的 <code>start()</code> 方法会被调用：</p><pre><code>func (p *initProcess) start() error {    defer p.parentPipe.Close()    err := p.cmd.Start()    p.process.ops = p    p.childPipe.Close()    // 把容器 pid 加入到 cgroup 中    if err := p.manager.Apply(p.pid()); err != nil {        return newSystemErrorWithCause(err, &quot;applying cgroup configuration for process&quot;)    }    // 给容器进程发送初始化需要的数据    if _, err := io.Copy(p.parentPipe, p.bootstrapData); err != nil {        return newSystemErrorWithCause(err, &quot;copying bootstrap data to pipe&quot;)    }    // 等待容器进程完成 namespace 的配置    if err := p.execSetns(); err != nil {        return newSystemErrorWithCause(err, &quot;running exec setns process for init&quot;)    }    // 创建网络 interface    if err := p.createNetworkInterfaces(); err != nil {        return newSystemErrorWithCause(err, &quot;creating network interfaces&quot;)    }    // 给容器进程发送进程配置信息    if err := p.sendConfig(); err != nil {        return newSystemErrorWithCause(err, &quot;sending config to init process&quot;)    }    // 和容器进程进行同步    // 容器 init 进程已经准备好环境，准备运行容器中的用户进程    // 所以这里会运行 prestart 的钩子函数    ierr := parseSync(p.parentPipe, func(sync *syncT) error {        ......        return nil    })    // Must be done after Shutdown so the child will exit and we can wait for it.    if ierr != nil {        p.wait()        return ierr    }    return nil}</code></pre><p>这里可以看到管道的用处：父进程把 bootstrapData 发送给子进程，子进程根据这些数据配置 namespace、cgroups，apparmor 等参数；等待子进程完成配置，进行同步。</p><p>容器子进程会做哪些事情呢？用同样的方法，可以找到 runc init 程序运行的逻辑代码在 <code>libcontainer/standard_init_linux.go#Init()</code>，它做的事情包括：</p><ol><li>配置 namespace</li><li>配置网络和路由规则</li><li>准备 rootfs</li><li>配置 console</li><li>配置 hostname</li><li>配置 apparmor profile</li><li>配置 sysctl 参数</li><li>初始化 seccomp 配置</li><li>配置 user namespace</li></ol><p>上面这些就是 linux 容器的大部分配置，完成这些之后，它就调用 <code>Exec</code> 执行用户程序：</p><pre><code>if err := syscall.Exec(name, l.config.Args[0:], os.Environ()); err != nil {    return newSystemErrorWithCause(err, &quot;exec user process&quot;)}</code></pre><p> <strong>NOTE</strong>：其实，init 在执行自身的逻辑之前，会被 libcontainer/nsenter 劫持，nsenter 是 C 语言编写的代码，目的是为容器配置 namespace，它会从 init pipe 中读取 namespace 的信息，调用setns 把当前进程加入到指定的 namespace 中。</p><p>之后，它会调用 clone 创建一个新的进程，初始化完成之后，把子进程的进程号发送到管道中，nsenter 完成任务退出，子进程会返回，让 init 接管，对容器进行初始化。</p><p>至此，容器的所有内容都 ok，而且容器里的用户进程也启动了。</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fl7mqae7ylj31kw138tn7.jpg" alt=""></p><p>runc 的代码调用关系如上图所示，可以在新页面打开查看大图。主要逻辑分成三块：</p><ul><li>最上面的红色是命令行封装，这是根据 OCI 标准实现的接口，它能读取 OCI 标准的容器 bundle，并实现了 OCI 指定 run、start、create 等命令</li><li>中间的紫色部分就是 libcontainer，它是 runc 的核心内容，是对 linux namespace、cgroups 技术的封装</li><li>右下角的绿色部分是真正的创建容器子进程的部分</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.opencontainers.org/faq" target="_blank" rel="noopener">OCI FAQ page</a></li><li><a href="http://dockone.io/article/776" target="_blank" rel="noopener">OCI标准和runC原理解读</a></li><li><a href="http://www.infoq.com/cn/articles/docker-container-management-libcontainer-depth-analysis" target="_blank" rel="noopener">Docker背后的容器管理——Libcontainer深度解析</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;OCI-和容器标准&quot;&gt;&lt;a href=&quot;#OCI-和容器标准&quot; class=&quot;headerlink&quot; title=&quot;OCI 和容器标准&quot;&gt;&lt;/a&gt;OCI 和容器标准&lt;/h2&gt;&lt;p&gt;容器技术随着 docker 的出现炙手可热，所有的技术公司都积极拥抱容器，促进了
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="linux" scheme="http://cizixs.com/tags/linux/"/>
    
      <category term="docker" scheme="http://cizixs.com/tags/docker/"/>
    
      <category term="container" scheme="http://cizixs.com/tags/container/"/>
    
      <category term="runc" scheme="http://cizixs.com/tags/runc/"/>
    
      <category term="oci" scheme="http://cizixs.com/tags/oci/"/>
    
  </entry>
  
  <entry>
    <title>使用 tc netem 模拟网络异常</title>
    <link href="http://cizixs.com/2017/10/23/tc-netem-for-terrible-network/"/>
    <id>http://cizixs.com/2017/10/23/tc-netem-for-terrible-network/</id>
    <published>2017-10-22T16:00:00.000Z</published>
    <updated>2018-09-17T13:18:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>在某些情况下，我们需要模拟网络很差的状态来测试软件能够正常工作，比如网络延迟、丢包、乱序、重复等。linux 系统强大的流量控制工具 tc 能很轻松地完成，tc 命令行是 <code>iproute2</code> 软件包中的软件，可以根据系统版本自行安装。</p><p>流量控制是个系统而复杂的话题，tc 能做的事情很多，除了本文介绍的还有带宽控制、优先级控制等等，这些功能是通过类似的<strong>模块</strong>组件实现的，这篇文章介绍的功能主要是通过 <code>netem</code> 这个组件实现的。<code>netem</code> 是 <code>Network Emulator</code> 的缩写，关于更多功能以及参数的详细解释可以参阅 <code>tc-netem</code> 的 man page。</p><h2 id="网络状况模拟"><a href="#网络状况模拟" class="headerlink" title="网络状况模拟"></a>网络状况模拟</h2><p>网络状况欠佳从用户角度来说就是下载东西慢（网页一直加载、视频卡顿、图片加载很久等），从网络报文角度来看却有很多情况：延迟（某个机器发送报文很慢）、丢包（发送的报文在网络中丢失需要一直重传）、乱序（报文顺序错乱，需要大量计算时间来重新排序）、重复（报文有大量重复，导致网络拥堵）、错误（接收到的报文有误只能丢弃重传）等。</p><p>对于这些情况，都可以用 netem 来模拟。需要注意的是，netem 是直接添加到网卡上的，也就是说所有从网卡发送出去的包都会收到配置参数的影响，所以最好搭建临时的虚拟机进行测试。</p><p>在下面的例子中 <code>add</code> 表示为网卡添加 netem 配置，<code>change</code> 表示修改已经存在的 netem 配置到新的值，如果要删除网卡上的配置可以使用 <code>del</code>：</p><pre><code># tc qdisc del dev eth0 root</code></pre><h3 id="1-模拟延迟传输"><a href="#1-模拟延迟传输" class="headerlink" title="1. 模拟延迟传输"></a>1. 模拟延迟传输</h3><p>最简单的例子是所有的报文延迟 100ms 发送：</p><pre><code># tc qdisc add dev eth0 root netem delay 100ms</code></pre><p>如果你想在一个局域网里模拟远距离传输的延迟可以用这个方法，比如实际用户会访问外国网站，延迟为 120ms，而你测试环境网络交互只需要 10ms，那么只要添加 110 ms 额外延迟就行。</p><p>在我本地的虚拟机中实验结果：</p><pre><code>[root@node02 ~]# tc qdisc replace dev enp0s8 root netem delay 100ms[root@node02 ~]# ping 172.17.8.100PING 172.17.8.100 (172.17.8.100) 56(84) bytes of data.64 bytes from 172.17.8.100: icmp_seq=1 ttl=64 time=101 ms64 bytes from 172.17.8.100: icmp_seq=2 ttl=64 time=100 ms64 bytes from 172.17.8.100: icmp_seq=3 ttl=64 time=102 ms^C--- 172.17.8.100 ping statistics ---3 packets transmitted, 3 received, 0% packet loss, time 2003msrtt min/avg/max/mdev = 100.725/101.370/102.048/0.653 ms</code></pre><p>如果在网络中看到非常稳定的时延，很可能是某个地方加了定时器，因为网络线路很复杂，传输过程一定会有变化。因此实际情况网络延迟一定会有变化的，<code>netem</code> 也考虑到这一点，提供了额外的参数来控制延迟的时间分布，完整的参数列表为：</p><pre><code>DELAY := delay TIME [ JITTER [ CORRELATION ]]]    [ distribution { uniform | normal | pareto |  paretonormal } ]</code></pre><p>除了延迟时间 <code>TIME</code> 之外，还有三个可选参数：</p><ul><li><code>JITTER</code>：抖动，增加一个随机时间长度，让延迟时间出现在某个范围</li><li><code>CORRELATION</code>：相关，下一个报文延迟时间和上一个报文的相关系数</li><li><code>distribution</code>：分布，延迟的分布模式，可以选择的值有 <code>uniform</code>、<code>normal</code>、<code>pareto</code> 和 <code>paretonormal</code></li></ul><p>先说说 <code>JITTER</code>，如果设置为 <code>20ms</code>，那么报文延迟的时间在 100ms  ± 20ms 之间（90ms - 110ms），具体值随机选择：</p><pre><code>[root@node02 ~]# tc qdisc replace dev enp0s8 root netem delay 100ms 20ms[root@node02 ~]# ping 172.17.8.100PING 172.17.8.100 (172.17.8.100) 56(84) bytes of data.64 bytes from 172.17.8.100: icmp_seq=1 ttl=64 time=112 ms64 bytes from 172.17.8.100: icmp_seq=2 ttl=64 time=89.7 ms64 bytes from 172.17.8.100: icmp_seq=3 ttl=64 time=114 ms......</code></pre><p><code>CORRELATION</code> 指相关性，因为网络状况是平滑变化的，短时间里相邻报文的延迟应该是近似的而不是完全随机的。这个值是个百分比，如果为 <code>100%</code>，就退化到固定延迟的情况；如果是 <code>0%</code> 则退化到随机延迟的情况</p><pre><code>[root@node02 ~]# tc qdisc replace dev enp0s8 root netem delay 100ms 20ms 50%[root@node02 ~]# ping 172.17.8.100PING 172.17.8.100 (172.17.8.100) 56(84) bytes of data.64 bytes from 172.17.8.100: icmp_seq=1 ttl=64 time=116 ms64 bytes from 172.17.8.100: icmp_seq=2 ttl=64 time=89.7 ms64 bytes from 172.17.8.100: icmp_seq=3 ttl=64 time=90.8 ms64 bytes from 172.17.8.100: icmp_seq=4 ttl=64 time=96.4 ms64 bytes from 172.17.8.100: icmp_seq=5 ttl=64 time=90.5 ms</code></pre><p>报文的分布和很多现实事件一样都满足某种统计规律，比如最常用的正态分布。因此为了更逼近现实情况，可以使用 <code>distribution</code> 参数来限制它的延迟分布模型。比如让报文延迟时间满足正态分布：</p><pre><code># tc qdisc change dev eth0 root netem delay 100ms 20ms distribution normal[root@node02 ~]# tc qdisc replace dev enp0s8 root netem delay 100ms 20ms distribution normal[root@node02 ~]# ping 172.17.8.100PING 172.17.8.100 (172.17.8.100) 56(84) bytes of data.64 bytes from 172.17.8.100: icmp_seq=1 ttl=64 time=119 ms64 bytes from 172.17.8.100: icmp_seq=2 ttl=64 time=102 ms64 bytes from 172.17.8.100: icmp_seq=3 ttl=64 time=115 ms64 bytes from 172.17.8.100: icmp_seq=4 ttl=64 time=105 ms64 bytes from 172.17.8.100: icmp_seq=5 ttl=64 time=119 ms</code></pre><p>这样的话，大部分的延迟会在平均值的一定范围内，而很少接近出现最大值和最小值的延迟。</p><p>其他分布方法包括：<a href="https://en.wikipedia.org/wiki/Uniform_distribution_(continuous" target="_blank" rel="noopener">uniform</a>)、<a href="https://en.wikipedia.org/wiki/Pareto_distribution" target="_blank" rel="noopener">pareto</a> 和 <code>paretonormal</code>，这些分布我没有深入去看它们的意思，感兴趣的读者可以自行了解。</p><p>对于大多数情况，随机在某个时间范围里延迟就能满足需求的。</p><h3 id="2-模拟丢包率"><a href="#2-模拟丢包率" class="headerlink" title="2. 模拟丢包率"></a>2. 模拟丢包率</h3><p>另一个常见的网络异常是因为丢包，丢包会导致重传，从而增加网络链路的流量和延迟。netem 的 <code>loss</code> 参数可以模拟丢包率，比如发送的报文有 50% 的丢包率（为了容易用 ping 看出来，所以这个数字我选的很大，实际情况丢包率可能比这个小很多，比如 <code>0.5%</code>）：</p><pre><code>[root@node02 ~]# tc qdisc change dev enp0s8 root netem loss 50%[root@node02 ~]# ping 172.17.8.100PING 172.17.8.100 (172.17.8.100) 56(84) bytes of data.64 bytes from 172.17.8.100: icmp_seq=1 ttl=64 time=0.716 ms64 bytes from 172.17.8.100: icmp_seq=3 ttl=64 time=0.713 ms64 bytes from 172.17.8.100: icmp_seq=5 ttl=64 time=0.719 ms64 bytes from 172.17.8.100: icmp_seq=7 ttl=64 time=0.938 ms64 bytes from 172.17.8.100: icmp_seq=10 ttl=64 time=0.594 ms64 bytes from 172.17.8.100: icmp_seq=11 ttl=64 time=0.698 ms64 bytes from 172.17.8.100: icmp_seq=12 ttl=64 time=0.681 ms</code></pre><p>可以从 <code>icmp_seq</code> 序号看出来大约有一半的报文丢掉了，和延迟类似，丢包率也可以增加一个相关系数，表示后一个报文丢包概率和它前一个报文的相关性：</p><pre><code># tc qdisc change dev eth0 root netem loss 0.3% 25%</code></pre><p>这个命令表示，丢包率是 0.3%，并且当前报文丢弃的可能性和前一个报文 25% 相关。默认的丢包模型为随机，loss 也支持 <code>state</code>（4-state Markov 模型） 和 <code>gemodel</code>（Gilbert-Elliot 丢包模型） 两种模型的丢包，因为两者都相对负责，这里也不再介绍了。</p><p>需要注意的是，丢包信息会发送到上层协议，如果是 TCP 协议，那么 TCP 会进行重传，所以对应用来说看不到丢包。这时候要模拟丢包，需要把 loss 配置到王桥或者路由设备上。</p><h3 id="3-模拟包重复"><a href="#3-模拟包重复" class="headerlink" title="3. 模拟包重复"></a>3. 模拟包重复</h3><p>报文重复和丢包的参数类似，就是重复率和相关性两个参数，比如随机产生 50% 重复的包：</p><pre><code>[root@node02 ~]# tc qdisc change dev enp0s8 root netem duplicate 50%[root@node02 ~]# ping 172.17.8.100PING 172.17.8.100 (172.17.8.100) 56(84) bytes of data.64 bytes from 172.17.8.100: icmp_seq=1 ttl=64 time=0.705 ms64 bytes from 172.17.8.100: icmp_seq=1 ttl=64 time=1.03 ms (DUP!)64 bytes from 172.17.8.100: icmp_seq=2 ttl=64 time=0.710 ms......</code></pre><h3 id="4-模拟包损坏"><a href="#4-模拟包损坏" class="headerlink" title="4. 模拟包损坏"></a>4. 模拟包损坏</h3><p>报文损坏和报文重复的参数也类似，比如随机产生 2% 损坏的报文（在报文的随机位置造成一个比特的错误）：</p><pre><code># tc qdisc add dev eth0 root netem corrupt 2%</code></pre><h3 id="5-模拟包乱序"><a href="#5-模拟包乱序" class="headerlink" title="5. 模拟包乱序"></a>5. 模拟包乱序</h3><p>网络传输并不能保证顺序，传输层 TCP 会对报文进行重组保证顺序，所以报文乱序对应用的影响比上面的几种问题要下。</p><p>报文乱序可前面的参数不太一样，因为上面的报文问题都是独立的，针对单个报文做操作就行，而乱序则牵涉到多个报文的重组。模拟报乱序一定会用到延迟（因为模拟乱序的本质就是把一些包延迟发送），netem 有两种方法可以做。第一种是固定的每隔一定数量的报文就乱序一次：</p><p>每 5 个报文（第 5、10、15…报文）会正常发送，其他的报文延迟 100ms：</p><pre><code># tc qdisc change dev enp0s8 root netem reorder 50% gap 3 delay 100ms[root@node02 ~]# ping -i 0.05 172.17.8.100PING 172.17.8.100 (172.17.8.100) 56(84) bytes of data.64 bytes from 172.17.8.100: icmp_seq=1 ttl=64 time=0.634 ms64 bytes from 172.17.8.100: icmp_seq=4 ttl=64 time=0.765 ms64 bytes from 172.17.8.100: icmp_seq=2 ttl=64 time=102 ms64 bytes from 172.17.8.100: icmp_seq=3 ttl=64 time=100 ms64 bytes from 172.17.8.100: icmp_seq=5 ttl=64 time=100 ms64 bytes from 172.17.8.100: icmp_seq=7 ttl=64 time=50.3 ms64 bytes from 172.17.8.100: icmp_seq=6 ttl=64 time=100 ms64 bytes from 172.17.8.100: icmp_seq=8 ttl=64 time=100 ms......</code></pre><p>要想看到 ping 报文的乱序，我们要保证发送报文的间隔小于报文的延迟时间 <code>100ms</code>，这里用 <code>-i 0.05</code> 把发送间隔设置为 <code>50ms</code>。</p><p>第二种方法的乱序是相对随机的，使用概率来选择乱序的报文：</p><pre><code>[root@node02 ~]# tc qdisc change dev enp0s8 root netem reorder 50% 15% delay 300ms[root@node02 ~]# ping -i 0.05 172.17.8.100PING 172.17.8.100 (172.17.8.100) 56(84) bytes of data.64 bytes from 172.17.8.100: icmp_seq=1 ttl=64 time=0.545 ms64 bytes from 172.17.8.100: icmp_seq=5 ttl=64 time=120 ms64 bytes from 172.17.8.100: icmp_seq=2 ttl=64 time=300 ms64 bytes from 172.17.8.100: icmp_seq=8 ttl=64 time=19.8 ms64 bytes from 172.17.8.100: icmp_seq=3 ttl=64 time=301 ms64 bytes from 172.17.8.100: icmp_seq=9 ttl=64 time=28.3 ms64 bytes from 172.17.8.100: icmp_seq=4 ttl=64 time=300 ms64 bytes from 172.17.8.100: icmp_seq=11 ttl=64 time=35.5 ms......</code></pre><p>50% 的报文会正常发送，其他报文（1-50%）延迟 300ms 发送，这里选择的延迟很大是为了能够明显看出来乱序的结果。</p><h2 id="两个工具"><a href="#两个工具" class="headerlink" title="两个工具"></a>两个工具</h2><p>netem 在 tc 中算是比较简单的模块，如果要实现流量控制或者精细化的过滤需要更复杂的配置。这里推荐两个小工具，它们共同的特点是用法简单，能满足特定的需求，而不用自己去倒腾 tc 的命令。</p><h3 id="wondershaper"><a href="#wondershaper" class="headerlink" title="wondershaper"></a>wondershaper</h3><p>netem 只能模拟网络状况，不能控制带宽，<a href="https://www.hecticgeek.com/2012/02/simple-traffic-shaping-ubuntu-linux/" target="_blank" rel="noopener">wondershaper</a> 能完美解决这个问题。wondershaper 的使用非常简单，只有三个参数：网卡名、下行限速、上行限速。比如要设置网卡下载速度为 200kb/s，上传速度为 <code>150kb/s</code>：</p><pre><code>wondershaper enp0s8 200 150</code></pre><h3 id="comcast"><a href="#comcast" class="headerlink" title="comcast"></a>comcast</h3><p><a href="https://github.com/tylertreat/comcast" target="_blank" rel="noopener">comcast</a> 是一个跨平台的网络模拟工具，旨在其他平台（OSX、Windows、BSD）也提供类似网络模拟的功能。</p><p>它的使用也相对简单：</p><pre><code>$ comcast --device=eth0 --latency=250 \    --target-bw=1000 --default-bw=1000000 \    --packet-loss=10% \    --target-addr=8.8.8.8,10.0.0.0/24 \    --target-proto=tcp,udp,icmp \    --target-port=80,22,1000:2000</code></pre><ul><li><code>--device</code> 说明要控制的网卡为 <code>eth0</code></li><li><code>--latency</code> 指定 250ms 的延迟</li><li><code>--target-bw</code>指定目标带宽</li><li><code>--default-bw</code> 指定默认带宽</li><li><code>--packet-loss</code> 是丢包率</li><li><code>--target-addr</code>、<code>--target-proto</code>、<code>--target-port</code> 参数指定在满足这些条件的报文上实施上面的配置</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>可以看出，tc 的 netem 模块主要用来模拟各种网络的异常状况，本身并没有提供宽带限制的功能，而且一旦在网卡上配置了 netem，该网卡上所有的报文都会受影响，如果想精细地控制部分报文，需要用到 tc 的 <a href="http://lartc.org/howto/lartc.qdisc.filters.html" target="_blank" rel="noopener">filter</a> 功能。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://wiki.linuxfoundation.org/networking/netem" target="_blank" rel="noopener">the Linux Foundation wiki: netem</a></li><li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.172.7072&amp;rep=rep1&amp;type=pdf" target="_blank" rel="noopener">Definition of a general and intuitive loss model for packet networks and its implementation in the Netem module in the Linux kernel</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;在某些情况下，我们需要模拟网络很差的状态来测试软件能够正常工作，比如网络延迟、丢包、乱序、重复等。linux 系统强大的流量控制工具 tc 能很轻松地完成，tc 命令行是 &lt;code&gt;iproute2&lt;/code&gt;
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="linux" scheme="http://cizixs.com/tags/linux/"/>
    
      <category term="network" scheme="http://cizixs.com/tags/network/"/>
    
      <category term="tc" scheme="http://cizixs.com/tags/tc/"/>
    
  </entry>
  
  <entry>
    <title>docker 容器网络方案：calico 网络模型</title>
    <link href="http://cizixs.com/2017/10/19/docker-calico-network/"/>
    <id>http://cizixs.com/2017/10/19/docker-calico-network/</id>
    <published>2017-10-18T16:00:00.000Z</published>
    <updated>2018-09-17T13:18:45.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="calico-简介"><a href="#calico-简介" class="headerlink" title="calico 简介"></a>calico 简介</h2><p>calico 是容器网络的又一种解决方案，和其他虚拟网络最大的不同是，它没有采用 overlay 网络做报文的转发，提供了纯 3 层的网络模型。三层通信模型表示每个容器都通过 IP 直接通信，中间通过路由转发找到对方。在这个过程中，容器所在的节点类似于传统的路由器，提供了路由查找的功能。</p><p>要想路由工作能够正常，每个虚拟路由器（容器所在的主机节点）必须有某种方法知道整个集群的路由信息，calico 采用的是 <a href="https://en.wikipedia.org/wiki/Border_Gateway_Protocol" target="_blank" rel="noopener">BGP 路由协议</a>，全称是 <code>Border Gateway Protocol</code>。</p><p>除了能用于 docker 这样的容器外，它还能集成到容器集群平台 kubernetes、共有云平台 AWS、GCE 等， 而且也能很容易地集成到 openstack 等 Iaas 平台。</p><p>这篇文章就介绍 calico 是如何实现 docker 跨主机网络的。</p><h2 id="calico-集群安装和实验"><a href="#calico-集群安装和实验" class="headerlink" title="calico 集群安装和实验"></a>calico 集群安装和实验</h2><p>这部分我会在自己的 virtualbox 环境中运行多节点 docker，并使用 calico 实现跨主机的容器网络通信功能。实验环境一共启动了三台 centos7 虚拟机：</p><ul><li><code>node00</code>: 172.17.8.100</li><li><code>node01</code>: 172.17.8.101</li><li><code>node02</code>: 172.17.8.102</li></ul><p>这三台机器可以通过上面的 IP 地址进行通信，并且<strong>有不同的 hostname</strong>，推荐使用 vagrant 运行虚拟机集群。</p><p>这部分我们会手动安装 calico 集群，以加深理解，在生产环境中推荐使用自动化安装。</p><h3 id="1-安装-docker"><a href="#1-安装-docker" class="headerlink" title="1. 安装 docker"></a>1. 安装 docker</h3><p>既然要在 docker 集群中测试 calico 网络，当然要有一个能正常工作的 docker 环境。docker 的安装这里就不说了，请参考<a href="https://docs.docker.com/engine/installation/" target="_blank" rel="noopener">官网上的安装手册</a>选择适合自己的方式。</p><h3 id="2-安装-etcd"><a href="#2-安装-etcd" class="headerlink" title="2. 安装 etcd"></a>2. 安装 etcd</h3><p>calico 集群的信息需要保存在 etcd 中，因此我们首先要安装 etcd 服务，关于 etcd 的安装可以参考我<a href="http://cizixs.com/2016/08/02/intro-to-etcd">之前的文章</a>或者 etcd 官方网站。</p><p>因为是用来测试，所以我创建了一个单点的 etcd 集群。</p><h3 id="3-配置安装-docker-参数"><a href="#3-配置安装-docker-参数" class="headerlink" title="3. 配置安装 docker 参数"></a>3. 配置安装 docker 参数</h3><p>要想让 docker 支持多节点网络，需要添加 <code>cluster-store</code> 参数，修改 <code>/etc/docker/daemon.json</code> 文件（如果文件不存在需要创建），添加一行内容：</p><pre><code>{  &quot;cluster-store&quot;: &quot;etcd://172.17.8.100:2379&quot;}</code></pre><p>然后重启 docker 服务，比如 <code>systemctl restart docker</code>，保证 docker 正常运行。</p><h3 id="4-下载-calicoctl-命令行"><a href="#4-下载-calicoctl-命令行" class="headerlink" title="4. 下载 calicoctl 命令行"></a>4. 下载 calicoctl 命令行</h3><p>calico 提供的 <code>calicoctl</code> 命令行工具能简化安装的过程，所以我们需要先下载这个程序：</p><pre><code>[~]# wget -O /usr/local/bin/calicoctl https://github.com/projectcalico/calicoctl/releases/download/v1.6.1/calicoctl[~]# chmod +x /usr/local/bin/calicoctl</code></pre><p>上述命令下载的是 1.6.1 版本，如果需要其他版本请按照<a href="https://github.com/projectcalico/calicoctl/releases" target="_blank" rel="noopener">官方指导</a>下载。</p><h3 id="5-配置-calicoctl-文件"><a href="#5-配置-calicoctl-文件" class="headerlink" title="5. 配置 calicoctl 文件"></a>5. 配置 calicoctl 文件</h3><p>运行的 calico 需要和 etcd 进行交互，因此要事先配置 etcd 的地址以便 calicoctl 使用。calicoctl 有一个配置文件 <code>/etc/calico/calicoctl.cfg</code>，往里面写入如下内容，etcd 地址根据需求更改：</p><pre><code># cat /etc/calico/calicoctl.cfg apiVersion: v1kind: calicoApiConfigmetadata:spec:  datastoreType: &quot;etcdv2&quot;  etcdEndpoints: &quot;http://172.17.8.100:2379&quot;</code></pre><h3 id="6-运行-calico-节点容器"><a href="#6-运行-calico-节点容器" class="headerlink" title="6. 运行 calico 节点容器"></a>6. 运行 calico 节点容器</h3><p>calicoctl 会运行一个 docker 容器来运行 calico，容器镜像默认放在 <code>quay.io/calico/node:latest</code> 上面，在国内需要代理访问，也可以自行创建维护镜像或者事先下载好，这样的话就要把容器镜像指向自己维护的版本：</p><pre><code>[root@localhost ~]# calicoctl node run --ip=172.17.8.101 --name node01 --node-image 172.16.1.41:5000/calico/node:v2.6.0Running command to load modules: modprobe -a xt_set ip6_tablesEnabling IPv4 forwardingEnabling IPv6 forwardingIncreasing conntrack limitRemoving old calico-node container (if running).Running the following command to start calico-node:docker run --net=host --privileged --name=calico-node -d --restart=always -e CALICO_LIBNETWORK_ENABLED=true -e IP=172.17.8.101 -e ETCD_ENDPOINTS=http://172.17.8.100:2379 -e NODENAME=node01 -e CALICO_NETWORKING_BACKEND=bird -v /var/log/calico:/var/log/calico -v /var/run/calico:/var/run/calico -v /lib/modules:/lib/modules -v /run:/run -v /run/docker/plugins:/run/docker/plugins -v /var/run/docker.sock:/var/run/docker.sock 172.16.1.41:5000/calico/node:v2.6.0Image may take a short time to download if it is not available locally.Container started, checking progress logs.Skipping datastore connection testUsing IPv4 address from environment: IP=172.17.8.101IPv4 address 172.17.8.101 discovered on interface enp0s8No AS number configured on node resource, using global valueCreated default IPv4 pool (192.168.0.0/16) with NAT outgoing true. IPIP mode: offCreated default IPv6 pool (fd80:24e2:f998:72d6::/64) with NAT outgoing false. IPIP mode: offUsing node name: node01Starting libnetwork serviceCalico node started successfully</code></pre><p>运行的命令指定了三个参数：</p><ul><li><code>--ip</code>：集群内节点用来互相通信的 IP 地址，如果要多个网卡或者网卡有多个 ip 地址最好手动指定。calicoctl 默认会自动选择这个 IP 地址，要实现自动化可以参考它的 IP 选择配置</li><li><code>--name</code>：唯一标识该节点的字符串，如果没有提供会使用 hostname，因此<strong>务必要保证 hostname 的唯一性</strong></li><li><code>--node-image</code>：calico node 的镜像地址，默认会从 <code>quay.io</code> 下载最新版本，如果想使用特定版本或者其他地址的镜像，需要手动指定</li></ul><p>从命令的输出可以看到，calicoctl 在运行容器之前还做了很多初始化的工作，比如加载需要的模块、配置系统参数、删除已经运行的 calico 容器（如果存在的话）；然后还会打印出来要运行的容器命令，所以理论上也可以手动执行这个命令；最后是运行使用的参数说明。</p><h3 id="7-创建网络并测试连通性"><a href="#7-创建网络并测试连通性" class="headerlink" title="7. 创建网络并测试连通性"></a>7. 创建网络并测试连通性</h3><p>在每个节点运行都不部署 calico 容器之后，calico 网络集群就搭建好了。接下来我们会创建两个网络，并测试 calico 跨主机网络的连通性，最终的网络示意图如下：</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fkgfg04nwbj31hc0u0qb0.jpg" alt=""></p><p>图中只展示了两个节点，每个节点有两个容器，其中蓝色容器在同一个网络，红色容器在另外一个网络。</p><p>先创建两个网络：</p><pre><code># docker network create --driver calico --ipam-driver calico-ipam net1# docker network create --driver calico --ipam-driver calico-ipam net2</code></pre><p>docker 创建网络的时候，会调用 calico 的网络驱动，由驱动完成具体的工作。注意这个网络是跨主机的，因此无论在哪台机器创建，在其他机器上都能看到：</p><pre><code>[root@node01 ~]# docker network lsNETWORK ID          NAME                DRIVER              SCOPEea7007efb6d1        bridge              bridge              localf76e9fe0eacc        host                host                localc9bc43f8c601        net1                calico              globalecda22cb8142        net2                calico              global</code></pre><p>然后分别在网络中运行容器：</p><p>node00:</p><pre><code># docker run --net net1 --name containerA -tid busybox# docker run --net net2 --name containerB -tid busybox</code></pre><p>node01：</p><pre><code># docker run --net net1 --name containerC -tid busybox# docker run --net net2 --name containerD -tid busybox</code></pre><p>可以测试 containerA 和 containerC 能互相通信，containerB 和 containerD 能互相通信：</p><pre><code>[root@node00 ~]# docker exec -it containerA ping -c 3 containerCPING containerC (192.168.196.129): 56 data bytes64 bytes from 192.168.196.129: seq=0 ttl=62 time=50.587 ms64 bytes from 192.168.196.129: seq=1 ttl=62 time=50.921 ms64 bytes from 192.168.196.129: seq=2 ttl=62 time=51.688 ms--- containerC ping statistics ---3 packets transmitted, 3 packets received, 0% packet lossround-trip min/avg/max = 50.587/51.065/51.688 ms</code></pre><p>同一个网络 docker 会保存各自的名字和 IP 的对应关系，而不同网络的容器无法解析，而且不能相互通信：</p><pre><code>[root@node00 ~]# docker exec -it containerA ping -c 3 192.168.196.128PING 192.168.196.128 (192.168.196.128): 56 data bytes--- 192.168.196.128 ping statistics ---3 packets transmitted, 0 packets received, 100% packet loss</code></pre><h2 id="报文流程"><a href="#报文流程" class="headerlink" title="报文流程"></a>报文流程</h2><p>我们来分析同个网络不同节点的容器是怎么通信的，借此还原 calico 的实现原理。以 containerA ping containerC 为例，先进入 containerA 中查看它的网络配置和路由表：</p><pre><code>[root@node00 ~]# docker exec -it containerA sh/ # ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue     link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever5: cali0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue     link/ether ee:ee:ee:ee:ee:ee brd ff:ff:ff:ff:ff:ff    inet 192.168.18.64/32 scope global cali0       valid_lft forever preferred_lft forever</code></pre><p>可以看到 containerA 的 ip 地址为 <code>192.168.18.64/32</code>，需要注意的是它的 MAC 地址为 <code>ee:ee:ee:ee:ee:ee</code>，很明显是个固定的特殊地址（事实上所有 calico 生成的容器 MAC 地址都一样），这么做的是因为 calico 只关心三层的 IP 地址，根本不关心二层 MAC 地址。为什么这么说？等我们分析完，你就知道了。</p><p>要 ping 的目的地址为 <code>192.168.196.129/32</code>，两者不再同一个网络中，所以会查看路由获取下一跳的地址：</p><pre><code>/ # ip routedefault via 169.254.1.1 dev cali0 169.254.1.1 dev cali0 </code></pre><p>容器的路由表非常有趣，和一般服务器创建的规则不同，所有的报文都会经过 <code>cali0</code> 发送到下一跳 <code>169.254.1.1</code>（这是预留的本地 IP 网段），这是 calico 为了简化网络配置做的选择，容器里的路由规则都是一样的，不需要动态更新。知道下一跳之后，容器会查询下一跳 <code>168.254.1.1</code> 的 MAC 地址，这个 ARP 请求发到哪里了呢？要回答这个问题，就要知道 <code>cali0</code> 是 veth pair 的一端，其对端是主机上 <code>caliXXXX</code> 命名的 interface，可以通过 <code>ethtool -S cali0</code> 列出对端的 interface idnex。</p><pre><code># ethtool -S cali0NIC statistics:     peer_ifindex: 6</code></pre><p>而主机上 index 为 6 的 interface 为：</p><pre><code># ip addr6: calif24874aae57: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP     link/ether a2:ff:0a:99:57:d2 brd ff:ff:ff:ff:ff:ff    inet6 fe80::a0ff:aff:fe99:57d2/64 scope link        valid_lft forever preferred_lft forever</code></pre><p>报文会发送到这个 interface，这个 interface 有一个随机分配的 MAC 地址，但是没有<br>IP地址，接收到想要 <code>169.254.1.1</code> MAC 地址的 ARP 请求报文，它会怎么做呢？这个又不是它的 IP，而且它又没有和任何的 bridge 相连可以广播 ARP 报文。</p><p>只能抓包看看了，记住要先删除容器中 <code>169.254.1.1</code> 对应的 ARP 表项（使用 <code>ip neigh del</code> 命令），然后运行 ping 的时候在主机上抓包：</p><pre><code>[root@node00 ~]# tcpdump -nn -i calif24874aae57 -etcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on calif24874aae57, link-type EN10MB (Ethernet), capture size 262144 bytes13:54:28.280252 ee:ee:ee:ee:ee:ee &gt; ff:ff:ff:ff:ff:ff, ethertype ARP (0x0806), length 42: Request who-has 169.254.1.1 tell 192.168.18.64, length 2813:54:28.280274 a2:ff:0a:99:57:d2 &gt; ee:ee:ee:ee:ee:ee, ethertype ARP (0x0806), length 42: Reply 169.254.1.1 is-at a2:ff:0a:99:57:d2, length 2813:54:28.280280 ee:ee:ee:ee:ee:ee &gt; a2:ff:0a:99:57:d2, ethertype IPv4 (0x0800), length 98: 192.168.18.64 &gt; 192.168.196.129: ICMP echo request, id 25581, seq 1, length 6413:54:28.280669 a2:ff:0a:99:57:d2 &gt; ee:ee:ee:ee:ee:ee, ethertype IPv4 (0x0800), length 98: 192.168.196.129 &gt; 192.168.18.64: ICMP echo reply, id 25581, seq 1, length 64</code></pre><p>从前面两个报文可以看到，接收到 ARP 请求后，它直接进行了应答，应答报文中 MAC 地址是 <code>a2:ff:0a:99:57:d2</code>，这正是该 interface 自己的 MAC 地址。换句话说，它把自己的 MAC 地址作为应答返回给容器。容器的后续报文 IP 地址还是目的容器，但是 MAC 地址就变成了主机上该 interface 的地址，也就是说所有的报文都会发给主机，然后主机根据 IP 地址进行转发。</p><p>主机这个 interface 不管 ARP 请求的内容，直接用自己的 MAC 地址作为应答的行为被成为 <code>ARP proxy</code>，是 calico 开启的，可以通过下面的命令确认：</p><pre><code># cat /proc/sys/net/ipv4/conf/calif24874aae57/proxy_arp1</code></pre><p>总的来说，可以认为 calico 把主机作为容器的默认网关来使用，所有的报文发到主机，然后主机根据路由表进行转发。和经典的网络架构不同的是，calico 并没有给默认网络配置一个 IP 地址（这样每个网络都会额外消耗一个 IP 资源，而且主机上也会增加对应的 IP 地址和路由信息），而是通过 arp proxy 和修改容器路由表来实现。</p><p>主机的 interface 接收到报文之后，下面的事情就容易理解了，所有的报文会根据路由表来走：</p><pre><code>[root@node00 ~]# ip route169.254.0.0/16 dev enp0s3  scope link  metric 1002 169.254.0.0/16 dev enp0s8  scope link  metric 1003 192.168.18.64 dev calif24874aae57  scope link blackhole 192.168.18.64/26  proto bird 192.168.18.65 dev cali4e5ed993aed  scope link 192.168.196.128/26 via 172.17.8.101 dev enp0s8  proto bird </code></pre><p>而我们的 ping 报文目的地址是 <code>192.168.196.129</code>，匹配的是最后一个表项，把 <code>172.17.8.101</code> 作为下一跳地址，并通过 <code>enp0s8</code> 发出去。这个路由规则匹配的是一个网段，也就是说该网段所有的容器 IP 都在目的主机上，可以推测 calico 为每个主机默认分配了一段子网。</p><p><strong>NOTE</strong>：在发送到另一台主机之前，报文还会经过 iptables，calico 设置的 ACL 规则还会过滤报文。这个步骤暂时先跳过，我们先认为报文能够被继续转发。</p><p>报文到达容器所在的主机 <code>172.17.8.101</code>，下一步怎么走呢？当然是看路由器（这里还是跳过 iptables 的检查步骤）：</p><pre><code>[root@node01 ~]# ip route169.254.0.0/16 dev enp0s3  scope link  metric 1002 169.254.0.0/16 dev enp0s8  scope link  metric 1003 192.168.18.64/26 via 172.17.8.100 dev enp0s8  proto bird 192.168.196.128 dev cali4907e793262  scope link blackhole 192.168.196.128/26  proto bird 192.168.196.129 dev cali69b2b8c106c  scope link </code></pre><p>同样的，这个报文会匹配最后一个路由规则，这个规则匹配的是一个 IP 地址，而不是网段，也就是说主机上每个容器都会有一个对应的路由表项。报文发送到 <code>cali69b2b8c106c</code> 这个 veth pair，然后从另一端发送给容器，容器接收到报文之后，发送目的地址是自己，就做出 ping 应答，应答报文的返回路径和之前类似。</p><p>总体的报文路径就是按照下图中的数字顺序，回来的报文按照原路返回：</p><p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fkgfhzbl9kj31hc0u047e.jpg" alt="calico-packet-flow"></p><h2 id="组件和架构"><a href="#组件和架构" class="headerlink" title="组件和架构"></a>组件和架构</h2><p>看完 calico 的报文流程，大致也能分析出 calico 做的事情：</p><ul><li>分配和管理 IP</li><li>配置上容器的 veth pair 和容器内默认路由</li><li>根据集群网络情况实时更新节点上路由表</li></ul><p>从部署过程可以知道，除了 etcd 保存了数据之外，节点上也就只运行了一个 calico-node 的容器，所以推测是这个容器实现了上面所有的功能。calico/node 这个容器运行了多个组件：</p><pre><code>[root@node00 ~]# docker exec -it calico-node sh/ # ps auxPID   USER     TIME   COMMAND    1 root       0:01 /sbin/runsvdir -P /etc/service/enabled   75 root       0:00 runsv felix   76 root       0:00 runsv bird   77 root       0:00 runsv bird6   78 root       0:00 runsv confd   79 root       0:00 runsv libnetwork   80 root       0:02 svlogd /var/log/calico/felix   81 root      30:49 calico-felix   82 root       0:00 svlogd /var/log/calico/confd   83 root       0:05 confd -confdir=/etc/calico/confd -interval=5 -watch --log-level=debug -node=http://172.17.8.100:2379 -client-key= -client-cert= -client-ca-keys=   84 root       0:00 svlogd -tt /var/log/calico/bird   85 root       0:20 bird -R -s /var/run/calico/bird.ctl -d -c /etc/calico/confd/config/bird.cfg   86 root       0:00 svlogd -tt /var/log/calico/bird6   87 root       0:18 bird6 -R -s /var/run/calico/bird6.ctl -d -c /etc/calico/confd/config/bird6.cfg   94 root       0:00 svlogd /var/log/calico/libnetwork   95 root       0:04 libnetwork-plugin</code></pre><p><a href="http://smarden.org/runit/runsv.8.html" target="_blank" rel="noopener">runsv</a> 是一个 minimal 的 init 系统提供的命令，用来管理多个进程，可以看到它运行的进程包括：<code>felix</code>、<code>bird</code>、<code>bird6</code>、<code>confd</code> 和 <code>libnetwork</code>，这部分就介绍各个进程的功能。</p><h3 id="libnetwork-plugin"><a href="#libnetwork-plugin" class="headerlink" title="libnetwork plugin"></a>libnetwork plugin</h3><p><a href="https://github.com/projectcalico/libnetwork-plugin" target="_blank" rel="noopener">libnetwork-plugin</a> 是 calico 提供的 docker 网络插件，主要提供的是 IP 管理和网络管理的功能。</p><p>默认情况下，当网络中出现第一个容器时，calico 会为容器所在的节点分配一段子网（子网掩码为 <code>/26</code>，比如<code>192.168.196.128/26</code>），后续出现在该节点上的容器都从这个子网中分配 IP 地址。这样做的好处是能够缩减节点上的路由表的规模，按照这种方式节点上 <code>2^6 = 64</code> 个 IP 地址只需要一个路由表项就行，而不是为每个 IP 单独创建一个路由表项。节点上创建的子网段可以在etcd 中 <code>/calico/ipam/v2/host/&lt;node_name&gt;/ipv4/block/</code> 看到。</p><p>calico 还允许创建容器的时候指定 IP 地址，如果用户指定的 IP 地址不在节点分配的子网段中，calico 会专门为该地址添加一个 <code>/32</code> 的网段。</p><h3 id="BIRD"><a href="#BIRD" class="headerlink" title="BIRD"></a>BIRD</h3><p><a href="http://bird.network.cz/" target="_blank" rel="noopener">BIRD</a>（BIRD Internet Routing Daemon） 是一个常用的网络路由软件，支持很多路由协议（BGP、RIP、OSPF等），calico 用它在节点之间共享路由信息。</p><p>关于 BIRD 如何配置 BGP 协议，可以参考<a href="http://bird.network.cz/?get_doc&amp;f=bird-6.html#ss6.3" target="_blank" rel="noopener">官方文档</a>，对应的配置文件在 <code>/etc/calico/confd/config/</code> 目录。</p><p><strong>NOTE</strong>：至于为什么选择 BGP 协议而不是其他的路由协议，官网上也有介绍: <a href="https://www.projectcalico.org/why-bgp/" target="_blank" rel="noopener">Why BGP?</a></p><p>默认所有的节点使用相同的 AS number 64512，因为 AS number 是一个32 比特的字段，所以有效取值范围是 <code>[0-4294967295]</code>，可以通过 <code>calicoctl config get asNumber</code> 命令查看当前节点使用的 AS number。</p><p>默认情况下，每个 calico 节点会和集群中其他所有节点建立 BGP peer 连接，也就是说这是一个 O(n^2) 的增长趋势。在集群规模比较小的情况下，这种模式是可以接受的，但是当集群规模扩展到百个节点、甚至更多的时候，这样的连接数无疑会带来很大的负担。为了解决集群规模较大情况下 BGP client 连接数膨胀的问题，calico 引入了 RR（Router Reflector） 的功能。</p><p>RR 的基本思想是选择一部分节点（一个或者多个）作为 Global BGP Peer，它们和所有的其他节点互联来交换路由信息，其他的节点只需要和 Global BGP Peer 相连就行，不需要之间再两两连接。更多的组网模式也是支持的，不管怎么组网，最核心的思想就是所有的节点能获取到整个集群的路由信息。</p><p>calico 对 BGP 的使用还是相对简单的，BGP 协议的原理不是一两句话能解释清楚的，以后有机会单独写篇文章来说吧。</p><h3 id="confd"><a href="#confd" class="headerlink" title="confd"></a>confd</h3><p>因为 bird 的配置文件会根据用户设置的变化而变化，因此需要一种动态的机制来实时维护配置文件并通知 bird 使用最新的配置，这就是 confd 的工作。<code>confd</code> 监听 etcd 的数据，用来更新 bird 的配置文件，并重新启动 bird 进程让它加载最新的配置文件。<code>confd</code> 的工作目录是  <code>/etc/calico/confd</code>，里面有三个目录：</p><ul><li><code>conf.d</code>：<code>confd</code> 需要读取的配置文件，每个配置文件告诉 confd 模板文件在什么，最终生成的文件应该放在什么地方，更新时要执行哪些操作等</li><li><code>config</code>：生成的配置文件最终放的目录</li><li><code>templates</code>：模板文件，里面包括了很多变量占位符，最终会替换成 etcd 中具体的数据</li></ul><p>具体的配置文件很多，我们只看一个例子：</p><pre><code>/ # cat /etc/calico/confd/conf.d/bird.toml[template]src = &quot;bird.cfg.mesh.template&quot;dest = &quot;/etc/calico/confd/config/bird.cfg&quot;prefix = &quot;/calico/bgp/v1&quot;keys = [    &quot;/host&quot;,    &quot;/global&quot;]check_cmd = &quot;bird -p -c {{.src}}&quot;reload_cmd = &quot;pkill -HUP bird || true&quot;</code></pre><p>它会监听 etcd 的 <code>/calico/bgp/v1</code> 路径，一旦发现更新，就用其中的内容更新模板文件 <code>bird.cfg.mesh.template</code>，把新生成的文件放在 <code>/etc/calico/confd/config/bird.cfg</code>，文件改变之后还会运行 <code>reload_cmd</code> 指定的命令重启 bird 程序。</p><p><strong>NOTE</strong>：关于 confd 的使用和工作原理请参考<a href="https://github.com/kelseyhightower/confd" target="_blank" rel="noopener">它的官方 repo</a>。</p><h3 id="felix"><a href="#felix" class="headerlink" title="felix"></a>felix</h3><p>felix 负责最终网络相关的配置，也就是容器网络在 linux 上的配置工作，比如：</p><ul><li>更新节点上的路由表项</li><li>更新节点上的 iptables 表项</li></ul><p>它的主要工作是从 etcd 中读取网络的配置，然后根据配置更新节点的路由和 iptables，felix 的代码在 <a href="https://github.com/projectcalico/felix" target="_blank" rel="noopener">github projectcalico/felix</a>。</p><h3 id="etcd"><a href="#etcd" class="headerlink" title="etcd"></a>etcd</h3><p>etcd 已经在前面多次提到过，它是一个分布式的键值存储数据库，保存了 calico 网络元数据，用来协调 calico 网络多个节点。可以使用 etcdctl 命令行来读取 calico 在 etcd 中保存的数据：</p><pre><code># etcdctl -C 172.17.8.100:2379 ls /calico/calico/ipam/calico/v1/calico/bgp</code></pre><p>每个目录保存的数据大致功能如下：</p><ul><li><code>/calico/ipam</code>：IP 地址分配管理，保存了节点上分配的各个子网段以及网段中 IP 地址的分配情况</li><li><code>/calico/v1</code>：profile 和 policy 的配置信息，节点上运行的容器 endpoint 信息（IP 地址、veth pair interface 的名字等），</li><li><code>/calico/bgp</code>：和 BGP 相关的信息，包括 mesh 是否开启，每个节点作为 gateway 通信的 IP 地址，AS number 等</li></ul><h2 id="强大的防火墙功能"><a href="#强大的防火墙功能" class="headerlink" title="强大的防火墙功能"></a>强大的防火墙功能</h2><p>从前面的实验我们不仅知道了 calico 容器网络的报文流程是怎样的，还发现了一个事实：<strong>默认情况下，同一个网络的容器能通信（不管容器是不是在同一个主机上），不同网络的容器是无法通信的。</strong></p><p>这个行为是 calico 强大的防火墙实现的，默认情况下 calico 为每个网络创建一个 profile：</p><pre><code>[root@node01 ~]# calicoctl get profile net2 -o yaml- apiVersion: v1  kind: profile  metadata:    name: net2    tags:    - net2  spec:    egress:    - action: allow      destination: {}      source: {}    ingress:    - action: allow      destination: {}      source:        tag: net2</code></pre><ul><li>profile 是和网络对应的，比如上面 <code>metadata.name</code> 的值是 <code>net2</code>，代表它匹配 <code>net2</code> 网络，并应用到所有的 <code>net2</code> 网络容器中</li><li>calico 使用 label 来增加防火墙规则的灵活性，源地址和目的地址都可以通过 label 匹配</li><li>profile 中 <code>metadata.tags</code> 会应用到网络中所有的容器上</li><li>如果有定义，profile中的 <code>metadata.labels</code> 也会应用到网络中所有的容器上</li><li>spec 指定 profile 默认的网络规则，egress 没有限制，ingress 表示只运行 tag 为 net2 容器（也就是同一个网络的容器）的访问</li></ul><p>每一个加入到网络的容器都会加上这个 profile，以此来实现网络之间的隔离。可以通过查看 endpoints 的详情得到它上面绑定的 <code>profiles</code>：</p><pre><code>[root@node01 ~]# calicoctl get workloadEndpoint 4e5ed993aed9e7c89bd5514fa67a2a8346295238801974d77eac8b444ae2afb0 -o yaml- apiVersion: v1  kind: workloadEndpoint  metadata:    name: 4e5ed993aed9e7c89bd5514fa67a2a8346295238801974d77eac8b444ae2afb0    node: node00    orchestrator: libnetwork    workload: libnetwork  spec:    interfaceName: cali4e5ed993aed    ipNetworks:    - 192.168.18.65/32    mac: ee:ee:ee:ee:ee:ee    profiles:    - net2</code></pre><p>用户也可以根据需求修改 profile 和 policy，可以参考<a href="https://docs.projectcalico.org/v2.6/getting-started/docker/tutorials/security-using-calico-profiles-and-policy" target="_blank" rel="noopener">官方教程</a>。</p><p>不过上面的防火墙都是针对网络的（网络中的容器的规则都是相同的），不能精细化到容器，也就是说只能做到网络之间的隔离和连通。不过 calico 也提供了对容器级别防火墙的支持，它主要是借助 docker 容器上的 label，通过匹配这些键值对来精细化控制防火墙。启动 docker label 支持需要在 <code>calicoctl node run</code> 命令运行时加上 <code>--use-docker-networking-container-labels</code> 参数，而且一旦启用后原来的 profile 就被废弃不能用了（可以用纯 policy 实现原来的 profile 功能）。容器启动的时候需要添加上 label 用来作为 policy 的标识，比如 <code>--label org.projectcalico.label.role=frontend</code>，具体的使用案例请参考<a href="https://docs.projectcalico.org/v2.6/getting-started/docker/tutorials/security-using-docker-labels-and-calico-policy" target="_blank" rel="noopener">这个教程</a>。</p><p>如果只要提供网络之间的隔离，可以使用 profile 和 policy；如果要实现精细化的容器之间的隔离，就需要启用容器的 label 功能了。在底层，calico 的 flelix 组件会实时跟踪 profile 和 policy 的内容，并更新各个节点的 iptables。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>calico 的核心是通过维护路由规则实现容器的通信，路由信息的传播是 BIRD 软件通过 BGP 协议完成的，而节点上路由和防火墙规则是 felix 维护的。</p><p>从 calico 本身的特性来说，它没有办法实现 VPC 网络，并且需要维护大量的路由表项和 iptables 表项，如果要部署在规模很大的生产环境中，需要预先规划系统的 iptables 和路由表项的上限。</p><p>在我看来，calico 最大的优点有两个：直接三层互联的网络，不需要报文封装，因此性能更好而且能和原来的网络设施直接融合；强大的防火墙规则，利用 label 机制灵活地匹配容器，几乎可以设置任何需求的防火墙。</p><p>但 calico 并非没有缺点，首先是它引入了 BGP 协议，虽然 bird 的配置很简单，但是运维这个系统需要熟悉 BGP 协议，这无疑会增加了人力、时间和金钱方面的投入；其次，calico 能支持的网络规模也有上限，虽然可以通过 Router Reflector 来缓解，但这么做又大大增加了网络规划、使用和排查的复杂度；最后 calico 无法用来实现 VPC 网络，IP 地址空间是所有租户共享的，租户之间是通过防火墙隔离的。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://www.lijiaocn.com/%E9%A1%B9%E7%9B%AE/2017/04/11/calico-usage.html" target="_blank" rel="noopener">Calico网络的原理、组网方式与使用</a></li><li><a href="http://leebriggs.co.uk/blog/2017/02/18/kubernetes-networking-calico.html" target="_blank" rel="noopener">Kubernetes Networking: Part 2 - Calico</a></li><li><a href="https://docs.projectcalico.org/v2.6/usage/troubleshooting/faq" target="_blank" rel="noopener">calico: Frequently Asked Questions</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;calico-简介&quot;&gt;&lt;a href=&quot;#calico-简介&quot; class=&quot;headerlink&quot; title=&quot;calico 简介&quot;&gt;&lt;/a&gt;calico 简介&lt;/h2&gt;&lt;p&gt;calico 是容器网络的又一种解决方案，和其他虚拟网络最大的不同是，它没有采用
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="linux" scheme="http://cizixs.com/tags/linux/"/>
    
      <category term="docker" scheme="http://cizixs.com/tags/docker/"/>
    
      <category term="network" scheme="http://cizixs.com/tags/network/"/>
    
      <category term="calico" scheme="http://cizixs.com/tags/calico/"/>
    
      <category term="bgp" scheme="http://cizixs.com/tags/bgp/"/>
    
  </entry>
  
  <entry>
    <title>linux 上实现 vxlan 网络</title>
    <link href="http://cizixs.com/2017/09/28/linux-vxlan/"/>
    <id>http://cizixs.com/2017/09/28/linux-vxlan/</id>
    <published>2017-09-27T16:00:00.000Z</published>
    <updated>2018-10-01T07:40:10.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="linux-上-vxlan-简介"><a href="#linux-上-vxlan-简介" class="headerlink" title="linux 上 vxlan 简介"></a>linux 上 vxlan 简介</h2><p><a href="http://cizixs.com/2017/09/25/vxlan-protocol-introduction">vxlan 协议的介绍文章</a>主要介绍了 vxlan 协议的理论知识，从产生的背景到报文的格式等等，和所有的计算机知识一样，理论必须结合实践理解才能更深刻，这篇文章我们就讲讲在 linux 机器上怎么手动搭建 vxlan overlay 网络。</p><p>Linux 对 vxlan 协议的支持时间并不久，2012 年 Stephen Hemminger 才把相关的工作合并到 kernel 中，并最终出现在 kernel 3.7.0 版本。为了稳定性和很多的功能，你可以会看到某些软件推荐在 3.9.0 或者 3.10.0 以后版本的 kernel 上使用 vxlan。</p><p><strong>NOTE</strong>：如果可以，尽量使用比较新版本的 kernel，以免出现因为内核版本太低导致功能或者性能上的问题。</p><p>本文的实验环境：</p><ul><li>MacBook Pro: 2.6 GHz Intel Core i5</li><li>virtualbox 5.1.8</li><li>vagrant 2.0.0</li><li>OS: ubuntu 16.04 </li><li>Linux Kernel: 4.4.0-83-generic</li></ul><p>我用 vagrant 启动了三台虚拟机，它们之间通信的 IP 地址（也就是 underlay 网络）为：</p><ul><li><code>192.168.8.100</code></li><li><code>192.168.8.101</code></li><li><code>192.168.8.102</code></li></ul><p>而要创建的 overlay 网络网段为 <code>10.20.1.0/24</code>，实验目的就是 vxlan 能够通过 overlay IP 互相连通。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="点对点的-vxlan"><a href="#点对点的-vxlan" class="headerlink" title="点对点的 vxlan"></a>点对点的 vxlan</h3><p>我们先来搭建一个最简单的 vxlan 网络，两台机器构成一个 vxlan 网络，每台机器上有一个 vtep，vtep 通过它们的 IP 互相通信。这次实验完成后的网络结构如下图所示：</p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fjy54027bgj31hc0u0tde.jpg" alt=""></p><p>首先使用 <code>ip</code> 命令创建我们的 vxlan interface：</p><pre><code>$ ip link add vxlan0 type vxlan \    id 42 \    dstport 4789 \    remote 192.168.8.101 \    local 192.168.8.100 \    dev enp0s8 </code></pre><p>上面这条命令创建一个名字为 <code>vxlan0</code>，类型为 <code>vxlan</code> 的网络 interface，后面是 vxlan interface 需要的参数：</p><ul><li><code>id 42</code>：指定 VNI 的值，这个值可以在 1 到 2^24 之间</li><li><code>dstport</code>：vtep 通信的端口，linux 默认使用 8472（为了保持兼容，默认值一直没有更改），而 IANA 分配的端口是 4789，所以我们这里显式指定了它的值</li><li><code>remote 192.168.8.101</code>：对方 vtep 的地址，类似于点对点协议</li><li><code>local 192.168.8.100</code>：当前节点 vtep 要使用的 IP 地址</li><li><code>dev enp0s8</code>：当节点用于 vtep 通信的网卡设备，用来读取 IP 地址。注意这个参数和 <code>local</code> 参数含义是相同的，在这里写出来是为了告诉大家有两个参数存在</li></ul><p>执行完之后，系统就会创建一个名字为 <code>vxlan0</code> 的 interface，可以用 <code>ip -d link</code> 查看它的详细信息：</p><pre><code>root@node1:~# ip -d link show dev vxlan04: vxlan0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000    link/ether ba:d4:0a:f8:41:7c brd ff:ff:ff:ff:ff:ff promiscuity 0    vxlan id 42 remote 192.168.8.101 dev enp0s8 srcport 0 0 dstport 4789 ageing 300 addrgenmode eui64</code></pre><p><strong>NOTE</strong>：<code>ip</code> 命令来自于 <code>iproute2</code> 软件包，它主要用来做网络相关的操作。</p><p>接下来，为刚创建的 interface 配置 IP 地址并启用它：</p><pre><code>$ ip addr add 10.20.1.2/24 dev vxlan0$ ip link set vxlan0 up</code></pre><p>执行结束之后，会发现路由表项多了下面的内容，所有 <code>10.20.1.0/24</code> 网段的 IP 地址要通过 vxlan0 来转发：</p><pre><code>root@node0:~# ip route10.20.1.0/24 dev vxlan0  proto kernel  scope link  src 10.20.1.2</code></pre><p>同时，vxlan0 fdb 表项中的内容如下：</p><pre><code>root@node1:~# bridge fdb00:00:00:00:00:00 dev vxlan0 dst 192.168.8.101 via enp0s8 self permanent</code></pre><p>这个表项的意思是说，默认的而 vtep 对端地址为 <code>192.168.8.101</code>，换句话说，如果接收到的报文添加上 vxlan 头部之后都会发到 <code>192.168.8.101</code>。</p><p>在另外一台虚拟机（<code>192.168.8.101</code>）上也进行相同的配置，要保证 VNI 也是 42，dstport 也是 4789，并修改 vtep 的地址和 remote IP 地址到相应的值。测试两台 vtep 的连通性：</p><pre><code>root@node0:~# ping -c 3 10.20.1.3PING 10.20.1.3 (10.20.1.3) 56(84) bytes of data.64 bytes from 10.20.1.3: icmp_seq=1 ttl=64 time=1.84 ms64 bytes from 10.20.1.3: icmp_seq=2 ttl=64 time=0.462 ms64 bytes from 10.20.1.3: icmp_seq=3 ttl=64 time=0.427 ms--- 10.20.1.3 ping statistics ---3 packets transmitted, 3 received, 0% packet loss, time 2003msrtt min/avg/max/mdev = 0.427/0.911/1.844/0.659 ms</code></pre><p>这种点对点的 vxlan 网络只能两两通信，实际用处不大。下面我们介绍多节点怎么组成 vxlan 网络进行通信。</p><h3 id="多播模式的-vxlan"><a href="#多播模式的-vxlan" class="headerlink" title="多播模式的 vxlan"></a>多播模式的 vxlan</h3><p>如果 vxlan 要使用多播模式，那么底层的网络结构需要支持多播的功能，幸运的是，virtualbox 本身就支持多播，不需要额外设置。</p><p>要组成同一个 vxlan 网络，vtep 必须能感知到彼此的存在。多播组本来的功能就是把网络中的某些节点组成一个虚拟的组，所以 vxlan 最初想到用多播来实现是很自然的事情。</p><p>这个实验和前面一个非常相似，只不过主机之间不是点对点的连接，而是通过多播组成一个虚拟的整体。最终的网络架构也很相似（为了简单图中只有两个主机，但这个模型可以容纳多个主机组成 vxlan 网络）：</p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fjy54jqv9xj31hc0u0n2d.jpg" alt=""></p><p>可能听起来要加入同一个多播组挺复杂的，但实际上非常简单，先上命令：</p><pre><code>$ ip link add vxlan0 type vxlan \    id 42 \    dstport 4789 \    group 239.1.1.1 \    dev enp0s8 $ ip addr add 10.20.1.2/24 dev vxlan0$ ip link set vxlan0 up</code></pre><p>这里最重要的参数是 <code>group 239.1.1.1</code> 表示把 vtep 加入到这个多播组。关于多播的原理和使用不是这篇文章的重点，这里选择的多播 IP 地址也没有特殊的含义，关于多播的内容可以自行了解。</p><p>运行上面的命令之后，一样添加了对应的路由，不同是的 fdb 表项：</p><pre><code>root@node0:~# bridge fdb00:00:00:00:00:00 dev vxlan0 dst 239.1.1.1 via enp0s8 self permanent</code></pre><p>这里默认表项的 dst 字段的值变成了多播地址 <code>239.1.1.1</code>，而不是之前对方的 vtep 地址。同理给所有需要通信的节点进行上述配置，可以验证他们能通过 10.20.1.0/24 网络互相访问。</p><p>我们来分析这个模式下 vxlan 通信的过程：</p><p>在配置完成之后，vtep 通过 IGMP 加入同一个多播网络 <code>239.1.1.1</code>。</p><ol><li>发送 ping 报文到 10.20.1.3，查看路由表，报文会从 vxlan0 发出去</li><li>内核发现 vxlan0 的 IP 是 10.20.1.2/24，和目的 IP 在同一个网段，所以在同一个局域网，需要知道对方的 MAC 地址，因此会发送 ARP 报文查询</li><li>ARP 报文源 MAC 地址为 vxlan0 的 MAC 地址，目的 MAC 地址为全 1 的广播地址</li><li>vxlan 根据配置（VNI 42）添加上头部</li><li>因为不知道对方 vtep 在哪台主机上，根据配置，vtep 会往多播地址 239.1.1.1 发送多播报文</li><li>多播组中所有的主机都会受到这个报文，内核发现是 vxlan 报文，会根据 VNI 发送给对应的 vtep</li><li>vtep 去掉 vxlan 头部，取出真正的 ARP 请求报文。同时 vtep 会记录 <code>&lt;源 MAC 地址 - vtep 所在主机 IP 地址&gt;</code> 信息到 fdb 表中</li><li>如果发现 ARP 不是发送给自己的，直接丢弃；如果是发送给自己的，则生成 ARP 应答报文</li><li>应答报文目的 MAC 地址是发送方 vtep 的 MAC 地址，而且 vtep 已经通过源报文学习到了 vtep 所在的主机，因此会直接单播发送给目的 vtep。因此 vtep 不需要多播，就能填充所有的头部信息</li><li>应答报文通过 underlay 网络直接返回给发送方主机，发送方主机根据 VNI 把报文转发给 vtep，vtep 解包取出 ARP 应答报文，添加 arp 缓存到内核。并根据报文学习到目的 vtep 所在的主机地址，添加到 fdb 表中</li><li>vtep 已经知道了通信需要的所有信息，后续 ICMP 的 ping 报文都是单播进行的</li></ol><p>在这个过程中，在主机上抓包更容易看到通信的具体情况，下面是 ARP 请求报文的详情：</p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fjyb6b5ybdj30x20lq11q.jpg" alt=""></p><p>可以看到 vxlan 报文可以分为三块：</p><ul><li>里层（图中最下面）是 overlay 网络中实体看到的报文（比如这里的 ARP 请求），它们和经典网络的通信报文没有任何区别，除了因为 MTU 导致有些报文比较小</li><li>然后是 vxlan 头部，我们最关心的字段 VNI 确实是 42</li><li>最外层（图中最上面）是 vtep 所在主机的通信报文头部。可以看到这里 IP 地址为多播 <code>239.1.1.1</code>，目的 MAC 地址也是多播对应的地址</li></ul><p>而 ARP 应答报文不是多播而是单播的事实也能看出来：</p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fjybddu0boj31kw11ekaq.jpg" alt=""></p><p>从上面的通信过程，可以看出不少信息：</p><ul><li>多播其实就相当于 vtep 之间的广播，报文会发给所有的 vtep，但是只有一个会做出应答</li><li>vtep 会通过接收到的报文学习 <code>MAC - VNI - Vtep IP</code> 的信息，减少后续不必要的多播报文</li><li>对于 overlay 网络中的通信实体来说，整个通信过程对它们的透明的，它们认为自己的通信过程和经典网络没有区别</li></ul><p>通信结束之后，可以在主机上看到保存的 ARP 缓存：</p><pre><code>root@node0:~# ip neigh10.20.1.3 dev vxlan0 lladdr d6:d9:cd:0a:a4:28 STALE</code></pre><p>以及 vtep 需要的 fdb 缓存：</p><pre><code>root@node0:~# bridge fdb00:00:00:00:00:00 dev vxlan0 dst 239.1.1.1 via enp0s8 self permanentd6:d9:cd:0a:a4:28 dev vxlan0 dst 192.168.8.101 self</code></pre><h3 id="利用-bridge-来接入容器"><a href="#利用-bridge-来接入容器" class="headerlink" title="利用 bridge 来接入容器"></a>利用 bridge 来接入容器</h3><p>尽管上面的方法能够通过多播实现自动化的 overlay 网络构建，但是通信的双方只有 vtep，在实际的生产中，每台主机上都有几十台甚至上百台的虚拟机或者容器需要通信，因此我们需要找到一种方法能够把这些通信实体组织起来。</p><p>在 linux 中把同一个网段的 interface 组织起来正是网桥（bridge，或者 switch，这两个名称等价）的功能，因此这部分我们介绍如何用网桥把多个虚拟机或者容器放到同一个 vxlan overlay 网络中。最终实现的网络架构如下图所示：</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fjy5517ktoj31hc0u0n39.jpg" alt=""></p><p>因为创建虚拟机或者容器比较麻烦，我们用 network namespace 来模拟，从理论上它们是一样的。关于 network namespace 和 veth pair 的基础知识，请参考我<a href="http://cizixs.com/2017/02/10/network-virtualization-network-namespace">之前的介绍文章</a>。</p><p>对于每个容器/虚拟机，我们创建一个 network namespace，并通过一对 veth pair 把容器中的 eth0 网络连接到网桥上。同时 vtep 也会放到网桥上，以便能够对报文进行 vxlan 相关的处理。</p><p>首先我们创建 vtep interface，使用的是多播模式：</p><p>创建 vtep interface：</p><pre><code>$ ip link add vxlan0 type vxlan \    id 42 \    dstport 4789 \    group 239.1.1.1 \    local 192.168.8.100 \    dev enp0s8 </code></pre><p>然后创建网桥 <code>br0</code>，把 vtep interface 绑定到上面：</p><pre><code>$ ip link add br0 type bridge$ ip link set vxlan100 master bridge$ ip link set vxlan100 up$ ip link set br0 up</code></pre><p>下面模拟把容器加入到网桥的操作，创建一个 network namespace，和一对 veth pair：</p><pre><code>ip netns add container1# 创建 veth pair，并把一端加到网桥上ip link add veth0 type veth peer name veth1ip link set dev veth0 master br0ip link set dev veth0 up# 配置容器内部的网络和 IPip link set dev veth1 netns container1ip netns exec container1 ip link set lo upip netns exec container1 ip link set veth1 name eth0ip netns exec container1 ip addr add 10.20.1.2/24 dev eth0ip netns exec container1 ip link set eth0 up</code></pre><p>为了方便操作，我把上面的过程写成了一个<a href="https://gist.github.com/cizixs/cfee4e8885df40c92f04b18807d1fb9d" target="_blank" rel="noopener">脚本</a>。</p><script src="https://gist.github.com/cizixs/cfee4e8885df40c92f04b18807d1fb9d.js"></script><p>使用这个脚本，下面的命令就能方便地创建另外一个容器：</p><pre><code>$ ./set_container br0 container4 10.20.1.4/24 </code></pre><p>用同样的方法在另外一台主机上配置 vxlan 网络，添加 IP 为 10.20.1.3/24 的容器，并测试它们的连通性。</p><p>容器通信过程和前面的实验类似，只不过这里容器发出的 ARP 报文会被网桥转发给 <code>vxlan0</code>，然后 <code>vxlan0</code> 添加 vxlan 头部通过多播来找到对方的 MAC 地址。</p><p>从逻辑上可以认为，在 <code>vxlan1</code> 的帮助下同一个 vxlan overlay 网络中的容器是连接到同一个网桥上的，示意图如下：</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fjy55dn4shj31hc0u0ag5.jpg" alt=""></p><p>多播实现很简单，不需要中心化的控制。但是不是所有的网络都支持多播，而且需要事先规划多播组和 VNI 的对应关系，在 overlay 网络数量比较多时也会很麻烦，多播也会导致大量的无用报文在网络中出现。现在很多云计算的网络都会通过自动化的方式来发现 vtep 和 MAC 信息，也就是自动构建 vxlan 网络。下面的几个部分，我们来解开自动化 vxlan 网络的秘密。</p><h3 id="手动维护-vtep-组"><a href="#手动维护-vtep-组" class="headerlink" title="手动维护 vtep 组"></a>手动维护 vtep 组</h3><p>经过上面几个实验，我们来思考一下为什么要使用多播。因为对 overlay 网络来说，它的网段范围是分布在多个主机上的，因此传统 ARP 报文的广播无法直接使用。要想做到 overlay 网络的广播，必须把报文发送到所有 vtep 在的节点，这才引入了多播。</p><p>如果有一种方法能够不通过多播，能把 overlay 的广播报文发送给所有的 vtep 主机的话，也能达到相同的功能。当然在维护 vtep 网络组之前，必须提前知道哪些 vtep 要组成一个网络，以及这些 vtep 在哪些主机上。</p><p>Linux 的 vxlan 模块也提供了这个功能，而且实现起来并不复杂。创建 vtep interface 的时候不使用 <code>remote</code> 或者 <code>group</code> 参数就行：</p><pre><code>$ ip link add vxlan0 type vxlan \    id 42 \    dstport 4789 \    dev enp0s8 </code></pre><p>这个 vtep interface 创建的时候没有指定多播地址，当第一个 ARP 请求报文发送时它也不知道要发送给谁。但是我们可以手动添加默认的 FDB 表项，比如：</p><pre><code>$ bridge fdb append 00:00:00:00:00:00 dev vxlan0 dst 192.168.8.101$ bridge fdb append 00:00:00:00:00:00 dev vxlan0 dst 192.168.8.102</code></pre><p>这样的话，如果不知道对方 VTEP 的地址，就会往选择默认的表项，发到 <code>192.168.8.101</code> 和 <code>192.168.8.102</code>，相当于手动维护了一个 vtep 的多播组。</p><p>在所有的节点的 vtep 上更新对应的 fdb 表项，就能实现 overlay 网络的连通。整个通信流程和多播模式相同，唯一的区别是，vtep 第一次会给所有的组内成员发送单播报文，当然也只有一个 vtep 会做出应答。</p><p>使用一些自动化工具，定时更新 FDB 表项，就能动态地维护 VTEP 的拓扑结构。</p><p>这个方案解决了在某些 underlay 网络中不能使用多播的问题，但是并没有解决多播的另外一个问题：每次要查找 MAC 地址要发送大量的无用报文，如果 vtep 组节点数量很大，那么每次查询都发送 N 个报文，其中只有一个报文真正有用。</p><h3 id="手动维护-fdb-表"><a href="#手动维护-fdb-表" class="headerlink" title="手动维护 fdb 表"></a>手动维护 fdb 表</h3><p>如果提前知道目的容器 MAC 地址和它所在主机的 IP 地址，也可以通过更新 fdb 表项来减少广播的报文数量。</p><p>创建 vtep 的命令：</p><pre><code>$ ip link add vxlan0 type vxlan \    id 42 \    dstport 4789 \    dev enp0s8 \    nolearning</code></pre><p>这次我们添加了 <code>nolearning</code> 参数，这个参数告诉 vtep 不要通过收到的报文来学习 fdb 表项的内容，因为我们会自动维护这个列表。</p><p>然后可以添加 fdb 表项告诉 vtep 容器 MAC 对应的主机 IP 地址：</p><pre><code>$ bridge fdb append 00:00:00:00:00:00 dev vxlan0 dst 192.168.8.101$ bridge fdb append 00:00:00:00:00:00 dev vxlan0 dst 192.168.8.102$ bridge fdb append 52:5e:55:58:9a:ab dev vxlan0 dst 192.168.8.101$ bridge fdb append d6:d9:cd:0a:a4:28 dev vxlan0 dst 192.168.8.102</code></pre><p>如果知道了对方的 MAC 地址，vtep 搜索 fdb 表项就知道应该发送到哪个对应的 vtep 了。需要注意是的，这个情况还是需要默认的表项（那些全零的表项），在不知道容器 IP 和 MAC 对应关系的时候通过默认方式发送 ARP 报文去查询对方的 MAC 地址。</p><p>需要注意的是，和上一个方法相比，这个方法并没有任何效率上的改进，只是把自动学习 fdb 表项换成了手动维护（当然实际情况一般是自动化程序来维护），第一次发送 ARP 请求还是会往 vtep 组发送大量单播报文。</p><p>当时这个方法给了我们很重要的提示：如果实现知道 vxlan 网络的信息，<strong>vtep 需要的信息都是可以自动维护的，而不需要学习</strong>。</p><h3 id="手动维护-ARP-表"><a href="#手动维护-ARP-表" class="headerlink" title="手动维护 ARP 表"></a>手动维护 ARP 表</h3><p>除了维护 fdb 表，arp 表也是可以维护的。如果能通过某个方式知道容器的 IP 和 MAC 地址对应关系，只要更新到每个节点，就能实现网络的连通。</p><p>但是这里有个问题，我们需要维护的是每个容器里面的 ARP 表项，因为最终通信的双方是容器。到每个容器里面（所有的 network namespace）去更新对应的 ARP 表，是件工作量很大的事情，而且容器的创建和删除还是动态的，。linux 提供了一个解决方案，vtep 可以作为 arp 代理，回复 arp 请求，也就是说只要 vtep interface 知道对应的 <code>IP - MAC</code> 关系，在接收到容器发来的 ARP 请求时可以直接作出应答。这样的话，我们只需要更新 vtep interface 上 ARP 表项就行了。 </p><p>创建 vtep interface 需要加上 <code>proxy</code> 参数：</p><pre><code>$ ip link add vxlan0 type vxlan \    id 42 \    dstport 4789 \    dev enp0s8 \    nolearning \    proxy</code></pre><p>这条命令和上部分相比多了 <code>proxy</code> 参数，这个参数告诉 vtep 承担 ARP 代理的功能。如果收到 ARP 请求，并且自己知道结果就直接作出应答。</p><p>当然我们还是要手动更新 fdb 表项来构建 vtep 组，</p><pre><code>$ bridge fdb append 00:00:00:00:00:00 dev vxlan0 dst 192.168.8.101$ bridge fdb append 00:00:00:00:00:00 dev vxlan0 dst 192.168.8.102$ bridge fdb append 52:5e:55:58:9a:ab dev vxlan0 dst 192.168.8.101$ bridge fdb append d6:d9:cd:0a:a4:28 dev vxlan0 dst 192.168.8.102</code></pre><p>然后，还需要为 vtep 添加 arp 表项，所有要通信容器的 <code>IP - MAC</code>二元组都要加进去。</p><pre><code>$ ip neigh add 10.20.1.3 lladdr d6:d9:cd:0a:a4:28 dev vxlan0$ ip neigh add 10.20.1.4 lladdr 52:5e:55:58:9a:ab dev vxlan0</code></pre><p>在要通信的所有节点配置完之后，容器就能互相 ping 通。当容器要访问彼此，并且第一次发送 ARP 请求时，这个请求并不会发给所有的 vtep，而是当前由当前 vtep 做出应答，大大减少了网络上的报文。</p><p>借助自动化的工具做到实时的表项（fdb 和 arp）更新，这种方法就能很高效地实现 overlay 网络的通信。</p><h3 id="动态更新-arp-和-fdb-表项"><a href="#动态更新-arp-和-fdb-表项" class="headerlink" title="动态更新 arp 和 fdb 表项"></a>动态更新 arp 和 fdb 表项</h3><p>尽管前一种方法通过动态更新 fdb 和 arp 表避免多余的网络报文，但是还有一个的问题：为了能够让所有的容器正常工作，所有可能会通信的容器都必须提前添加到 ARP 和 fdb 表项中。但并不是网络上所有的容器都会互相通信，所以<strong>添加的有些表项（尤其是 ARP 表项）是用不到的</strong>。</p><p>Linux 提供了另外一种方法，内核能够动态地通知节点要和哪个容器通信，应用程序可以订阅这些事件，如果内核发现需要的 ARP 或者 fdb 表项不存在，会发送事件给订阅的应用程序，这样应用程序从中心化的控制拿到这些信息来更新表项，做到更精确的控制。</p><p>要收到 L2（fdb）miss，必须要满足几个条件：</p><ul><li>目的 MAC 地址未知，也就是没有对应的 fdb 表项</li><li>fdb 中没有全零的表项，也就是说默认规则</li><li>目的 MAC 地址不是多播或者广播地址</li></ul><p>要实现这种功能，创建 vtep 的时候需要加上额外的参数：</p><pre><code>$ ip link add vxlan0 type vxlan \    id 42 \    dstport 4789 \    dev enp0s8 \    nolearning \    proxy \    l2miss \    l3miss</code></pre><p>这次多了两个参数 <code>l2miss</code> 和 <code>l3miss</code>：</p><ul><li><code>l2miss</code>：如果设备找不到 MAC 地址需要的 vtep 地址，就发送通知事件</li><li><code>l3miss</code>：如果设备找不到需要 IP 对应的 MAC 地址，就发送通知事件</li></ul><p><code>ip monitor</code> 命令能做到这点，监听某个 interface 的事件，具体用法请参考 man 手册。</p><pre><code>root@node0:~# ip monitor all dev vxlan0</code></pre><p>如果从本节点容器 ping 另外一个节点的容器，就先发生 l3 miss，这是 l3miss 的通知事件，：</p><pre><code>root@node0:~# ip monitor all dev vxlan0[nsid current]miss 10.20.1.3  STALE</code></pre><p><code>l3miss</code> 是说这个 IP 地址，vtep 不知道它对应的 MAC 地址，因此要手动添加 arp 记录：</p><pre><code>$ ip neigh replace 10.20.1.3 \    lladdr b2:ee:aa:42:8b:0b \    dev vxlan0 \    nud reachable</code></pre><p>上面这条命令设置的 <code>nud reachable</code> 参数意思是，这条记录有一个超时时间，系统发现它无效一段时间会自动删除。这样的好处是，不需要手动去删除它，删除后需要通信内核会再次发送通知事件。 <code>nud</code> 是 <code>Neighbour Unreachability Detection</code> 的缩写， 当然根据需要这个参数也可以设置成其他值，比如 <code>permanent</code>，表示这个记录永远不会过时，系统不会检查它是否正确，也不会删除它，只有管理员也能对它进行修改。</p><p>这时候还是不能正常通信，接着会出现 l2miss 的通知事件：</p><pre><code>root@node0:~# ip monitor all dev vxlan0[nsid current]miss lladdr b2:ee:aa:42:8b:0b STALE</code></pre><p>类似的，这个事件是说不知道这个容器的 MAC 地址在哪个节点上，所以要手动添加 fdb 记录：</p><pre><code>root@node0:~# bridge fdb add b2:ee:aa:42:8b:0b dst 192.168.8.101 dev vxlan0</code></pre><p>在通信的另一台机器上执行响应的操作，就会发现两者能 ping 通了。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>上面提出的所有方案中，其中手动的部分都可以使用程序来自动完成，需要的信息一般都是从集中式的控制中心获取的，这也是大多数基于 vxlan 的 SDN 网络的大致架构。当然具体的实现不一定和某种方法相同，可能是上述方法的变形或者组合，但是设计思想都是一样的。</p><p>虽然上述的实验中，为了简化图中只有两台主机，而且只有一个 vxlan 网络，但是利用相同的操作很容易创建另外一个 vxlan 网络（必须要保证 vtep 的 VNI 值不同，如果使用多播，也要保证多播 IP 不同），如下图所示：</p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fjy55xwqxuj31hc0u0gqo.jpg" alt=""></p><p>主机会根据 VNI 来区别不同的 vxlan 网络，不同的 vxlan 网络之间不会相互影响。如果再加上 network namespace，就能实现更复杂的网络结构。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://vincent.bernat.im/en/blog/2017-vxlan-linux" target="_blank" rel="noopener">Vincent Bernat -VXLAN &amp; Linux</a></li><li><a href="https://www.kernel.org/doc/Documentation/networking/vxlan.txt" target="_blank" rel="noopener">Linux Kernel Documentation: vxlan</a></li><li><a href="http://events.linuxfoundation.org/sites/events/files/slides/2013-linuxcon.pdf" target="_blank" rel="noopener">Software Defined network using VXLAN</a></li><li><a href="https://www.singlestoneconsulting.com/-/media/files/docker-multi-host-networking-overlays-to-the-rescue.pdf?la=en" target="_blank" rel="noopener">Docker Multi Host Networking: Overlay to the Rescue</a></li><li><a href="http://techblog.d2-si.eu/2017/08/20/deep-dive-into-docker-overlay-networks-part-3.html" target="_blank" rel="noopener">Deep Dive into Docker Overlay Network Part 3</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;linux-上-vxlan-简介&quot;&gt;&lt;a href=&quot;#linux-上-vxlan-简介&quot; class=&quot;headerlink&quot; title=&quot;linux 上 vxlan 简介&quot;&gt;&lt;/a&gt;linux 上 vxlan 简介&lt;/h2&gt;&lt;p&gt;&lt;a
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="linux" scheme="http://cizixs.com/tags/linux/"/>
    
      <category term="network" scheme="http://cizixs.com/tags/network/"/>
    
      <category term="vxlan" scheme="http://cizixs.com/tags/vxlan/"/>
    
      <category term="sdn" scheme="http://cizixs.com/tags/sdn/"/>
    
  </entry>
  
  <entry>
    <title>vxlan 协议原理简介</title>
    <link href="http://cizixs.com/2017/09/25/vxlan-protocol-introduction/"/>
    <id>http://cizixs.com/2017/09/25/vxlan-protocol-introduction/</id>
    <published>2017-09-24T16:00:00.000Z</published>
    <updated>2018-09-17T13:18:45.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-vxlan-简介"><a href="#1-vxlan-简介" class="headerlink" title="1. vxlan 简介"></a>1. vxlan 简介</h2><p>VXLAN 全称是 <code>Virtual eXtensible Local Area Network</code>，虚拟可扩展的局域网。它是一种 overlay 技术，通过三层的网络来搭建虚拟的二层网络。rfc7348 (参考资料1) 上的介绍是这样的：</p><blockquote><p>A framework for overlaying virtualized layer 2 networks over lay 3 networks.</p></blockquote><p>每一个技术出来都有它要解决的问题，VXLAN 也不例外，那么我们先看看 VXLAN 到底要解决哪些问题。</p><ul><li>虚拟化（虚拟机和容器）的兴起使得一个数据中心会有成千上万的机器需要通信，而传统的 VLAN 技术只能支持 4096 个网络上限，已经满足不了不断扩展的数据中心规模</li><li>越来越多的数据中心（尤其是公有云服务）需要提供多租户的功能，不同用户之间需要独立地分配 ip 和 MAC 地址，如何保证这个功能的扩展性和正确性也是一个待解决的问题</li><li>云计算业务对业务灵活性要求很高，虚拟机可能会大规模迁移，并保证网络一直可用，也就是大二层的概念。解决这个问题同时保证二层的广播域不会过分扩大，也是云计算网络的要求</li></ul><p>传统二层+三层的网络在应对这些要求时变得力不从心，虽然很多改进型的技术比如堆叠、SVF、TRILL 等能够增加二层的范围，努力改进经典网络，但是要做到对网络改动小同时保证灵活性高却非常困难。</p><p>为了解决这些问题，有很多方案被提出来，vxlan 就是其中之一。vxlan 是 VMware、Cisco 等一众大型企业共同推出的，目前标准文档在 <a href="https://tools.ietf.org/html/rfc7348" target="_blank" rel="noopener">RFC7348</a>。</p><h2 id="2-VXLAN-模型"><a href="#2-VXLAN-模型" class="headerlink" title="2. VXLAN 模型"></a>2. VXLAN 模型</h2><p>vxlan 这类隧道网络的一个特点是对原有的网络架构影响小，原来的网络不需要做任何改动，在原来网络基础上架设一层新的网络。</p><p>vxlan 自然会引入一些新的概念，这部分就讲讲它们。下面这张图 是 vxlan 的工作模型，它创建在原来的 IP 网络（三层）上，只要是三层可达（能够通过 IP 互相通信）的网络就能部署 vxlan。在每个端点上都有一个 vtep 负责 vxlan 协议报文的封包和解包，也就是在虚拟报文上封装 vtep 通信的报文头部。物理网络上可以创建多个 vxlan 网络，这些 vxlan 网络可以认为是一个隧道，不同节点的虚拟机能够通过隧道直连。每个 vxlan 网络由唯一的 VNI 标识，不同的 vxlan 可以不相互影响。</p><p><img src="http://support.huawei.com/huaweiconnect/enterprise/data/attachment/forum/dm/ecommunity/uploads/2015/1123/16/5652c940898f4.png" alt=""></p><ul><li>VTEP（VXLAN Tunnel Endpoints）：vxlan 网络的边缘设备，用来进行 vxlan 报文的处理（封包和解包）。vtep 可以是网络设备（比如交换机），也可以是一台机器（比如虚拟化集群中的宿主机）</li><li>VNI（VXLAN Network Identifier）：VNI 是每个 vxlan 的标识，是个 24 位整数，一共有 2^24 = 16,777,216（一千多万），一般每个 VNI 对应一个租户，也就是说使用 vxlan 搭建的公有云可以理论上可以支撑千万级别的租户</li><li>Tunnel：隧道是一个逻辑上的概念，在 vxlan 模型中并没有具体的物理实体想对应。隧道可以看做是一种虚拟通道，vxlan 通信双方（图中的虚拟机）认为自己是在直接通信，并不知道底层网络的存在。从整体来说，每个 vxlan 网络像是为通信的虚拟机搭建了一个单独的通信通道，也就是隧道</li></ul><p>现在来说，这些概念还是非常晦涩难理解的，我们会在下面具体讲解 vxlan 网络的报文和通信流程，希望文章结束之后再回来看这些概念能明白它们的意思。</p><h2 id="3-VXLAN-报文解析"><a href="#3-VXLAN-报文解析" class="headerlink" title="3. VXLAN 报文解析"></a>3. VXLAN 报文解析</h2><p>前面说过，vxlan 在三层网络上构建一个虚拟的二层网络出来，这一点能够在 vxlan 的报文上很明显地体现出来。</p><p>下图是 vxlan 协议的报文，白色的部分是虚拟机发送报文（二层帧，包含了 MAC 头部、IP 头部和传输层头部的报文），前面加了 vxlan 头部用来专门保存 vxlan 相关的内容，在前面是标准的 UDP 协议头部（UDP 头部、IP 头部和 MAC 头部）用来在底层网路上传输报文。</p><p><img src="https://ying-zhang.github.io/img/vnet-vxlan.png" alt=""></p><p>从这个报文中可以看到三个部分：</p><ol><li>最外层的 UDP 协议报文用来在底层网络上传输，也就是 vtep<br>之间互相通信的基础</li><li>中间是 VXLAN 头部，vtep 接受到报文之后，去除前面的 UDP 协议部分，根据这部分来处理 vxlan 的逻辑，主要是根据 VNI 发送到最终的虚拟机</li><li>最里面是原始的报文，也就是虚拟机看到的报文内容</li></ol><p>报文各个部分的意义如下：</p><ul><li>VXLAN header：vxlan 协议相关的部分，一共 8 个字节<ul><li>VXLAN flags：标志位 </li><li>Reserved：保留位</li><li>VNID：24 位的 VNI 字段，这也是 vxlan 能支持千万租户的地方</li><li>Reserved：保留字段</li></ul></li><li>UDP 头部，8 个字节<ul><li>UDP 应用通信双方是 vtep 应用，其中目的端口就是接收方 vtep 使用的端口，IANA 分配的端口是 4789</li></ul></li><li>IP 头部：20 字节<ul><li>主机之间通信的地址，可能是主机的网卡 IP 地址，也可能是多播 IP 地址</li></ul></li><li>MAC 头部：14 字节<ul><li>主机之间通信的 MAC 地址，源 MAC 地址为主机 MAC 地址，目的 MAC 地址为下一跳设备的 MAC 地址</li></ul></li></ul><p>可以看出 vxlan 协议比原始报文多 50 字节的内容，这会降低网络链路传输有效数据的比例。vxlan 头部最重要的是 VNID 字段，其他的保留字段主要是为了未来的扩展，目前留给不同的厂商用这些字段添加自己的功能。</p><h2 id="4-vxlan-网络通信过程"><a href="#4-vxlan-网络通信过程" class="headerlink" title="4. vxlan 网络通信过程"></a>4. vxlan 网络通信过程</h2><p>通过上节的内容，我们大致了解 vxlan 报文的发送过程。虚拟机的报文通过 vtep 添加上 vxlan 以及外部的报文层，然后发送出去，对方 vtep 收到之后拆除 vxlan 头部然后根据 VNI 把原始报文发送到目的虚拟机。</p><p>上面的过程是双方已经知道所有通信信息的过程，但是在第一次通信之前还有很多问题有解决：</p><ul><li>哪些 vtep 需要加到一个相同的 VNI 组？</li><li>发送方虚拟机怎么知道对方的 MAC 地址？</li><li>vtep 怎么知道目的虚拟机在哪一台宿主机上？</li></ul><p>这三个问题可以归结为同一个问题：vxlan 网络怎么感知彼此的存在并选择正确的路径传输报文？</p><p>而且第一个问题也是不用回答的，因为 vtep 形成的组是虚构的概念，只有某些 vtep 能够正确地传递报文，它们就是在同一个组内。也就是说，我们只要回答后面两个问题就行。</p><p>要回答这两个问题，我们还是回到 vxlan 协议报文上，看看一个完整的 vxlan 报文需要哪些信息。</p><ul><li>内层报文：通信的虚拟机双方要么直接使用 IP 地址，要么通过 DNS 等方式已经获取了对方的 IP 地址，因此网络层地址已经知道。同一个网络的虚拟机需要通信，还需要知道<strong>对方虚拟机的 MAC 地址</strong>，vxlan 需要一个机制来实现传统网络 ARP 的功能</li><li>vxlan 头部：只需要知道 VNI，这一般是直接配置在 vtep 上的，要么是提前规划写死的，要么是根据内部报文自动生成的，也不需要担心</li><li>UDP 头部：最重要的是源地址和目的地址的端口，源地址端口是系统生成并管理的，目的端口也是写死的，比如 IANA 规定的 4789 端口，这部分也不需要担心</li><li>IP 头部：IP 头部关心的是 vtep 双方的 IP 地址，源地址可以很简单确定，目的地址是<strong>虚拟机所在地址宿主机 vtep 的 IP 地址</strong>，这个也需要由某种方式来确定</li><li>MAC 头部：如果 vtep 的 IP 地址确定了，MAC 地址可以通过经典的 ARP 方式来获取，毕竟 vtep 网络在同一个三层，经典网络架构那一套就能直接用了</li></ul><p>总结一下，一个 vxlan 报文需要确定两个地址信息：目的虚拟机的 MAC 地址和目的 vtep 的 IP 地址，如果 VNI 也是动态感知的，那么 vtep 就需要一个三元组：</p><blockquote><p>内部 MAC <--> VNI <--> VTEP IP</--></--></p></blockquote><p>根据实现的不同，一般分为两种方式：多播和控制中心。多播的概念是同个 vxlan 网络的 vtep 加入到同一个多播网络，如果需要知道以上信息，就在组内发送多播来查询；控制中心的概念是在某个集中式的地方保存了所有虚拟机的上述信息，自动化告知 vtep 它需要的信息。</p><p>针对这两种方式，我们下面就分别分析。</p><h3 id="多播"><a href="#多播" class="headerlink" title="多播"></a>多播</h3><p>多播的概念和工作原理不是这里的重点，所以就不介绍了。简单来说，每个多播组对应一个多播 IP 地址，往这个多播 IP 地址发送的报文会发给多播组的所有主机。</p><p>为什么要使用多播？因为 vxlan 的底层网络是三层的，广播地址无法穿越三层网络，要给 vxlan 网络所有 vtep 发送报文只能通过多播。</p><p>下图是在多播模式下，vxlan 的报文工作流程，位于左下方的 机器 A 要通过 vxlan 网络发送报文给右下方的机器 B。</p><p><img src="http://img.blog.csdn.net/20160113005124711?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center" alt=""></p><p>vtep 建立的时候会通过配置加入到多播组（具体做法取决于实现），图中的多播组 IP 地址是 <code>239.1.1.1</code>。</p><ol><li>机器 A 只知道对方的 IP 地址，不知道 MAC 地址，因此会发送 ARP 报文进行查询，内部的 ARP 报文很普通，目标地址为全 1 的广播地址</li><li>vtep 收到 ARP 报文，发现虚拟机目的 MAC 为广播地址，封装上 vxlan 协议头部之后（外层 IP 为多播组 IP，MAC 地址为多播组的 MAC 地址），发送给多播组 <code>239.1.1.1</code>，支持多播的底层网络设备（交换机和路由器）会把报文发送给组内所有的成员</li><li>vtep 接收到 vxlan 封装的 ARP 请求，去掉 vxlan 头部，并通过报文学习到发送方 &lt;虚拟机 MAC - VNI - Vtep IP&gt; 三元组保存起来，把原来的 ARP 报文广播给主机</li><li>主机接收到 ARP 请求报文，如果 ARP 报文请求的是自己的 MAC 地址，就返回 ARP 应答</li><li>vtep-2 此时已经知道发送放的虚拟机和 vtep 信息，把 ARP 应答添加上 vxlan 头部（外部 IP 地址为 vtep-1 的 IP 地址，VNI 是原来报文的 VNI）之后通过单播发送出去</li><li>vtep-1 接收到报文，并学习到报文中的三元组，记录下来。然后 vtep 进行解包，知道内部的 IP 和 MAC 地址，并转发给目的虚拟机</li><li>虚拟机拿到 ARP 应答报文，就知道了到目的虚拟机的 MAC 地址</li></ol><p>在这个过程中，只有一次多播，因为 vtep 有自动学习的能力，后续的报文都是通过单播直接发送的。可以看到，多播报文非常浪费，每次的多播其实只有一个报文是有效的，如果某个多播组的 vtep 数量很多，这个浪费是非常大的。但是多播组也有它的实现起来比较简单，不需要中心化的控制，只有底层网络支持多播，只有配置好多播组就能自动发现了。</p><p>单播报文的发送过程就是上述应答报文的逻辑，应该也非常容易理解了。还有一种通信方式，那就是不同 VNI 网络之间的通信，这个需要用到 vxlan 网关（可以是物理网络设备，也可以是软件），它接收到一个 vxlan 网络报文之后解压，根据特定的逻辑添加上另外一个 vxlan 头部转发出去。</p><p>因为并不是所有的网络设备都支持多播，再加上多播方式带来的报文浪费，在实际生产中这种方式很少用到。</p><h3 id="分布式控制中心"><a href="#分布式控制中心" class="headerlink" title="分布式控制中心"></a>分布式控制中心</h3><p>从多播的流程可以看出来，其实 vtep 发送报文最关键的就是知道对方虚拟机的 MAC 地址和虚拟机所在主机的 vtep IP 地址。如果能够事先知道这两个信息，直接告诉 vtep，那么就不需要多播了。</p><p>在虚拟机和容器的场景中，当虚拟机或者容器启动还没有进行网络通讯时，我们就可以知道它的 IP 和 MAC（可能是用某种方式获取，也有可能是事先控制这两个地址），分布式控制中心保存了这些信息。除此之外，控制中心还保存了每个 vxlan 网络有哪些 vtep，这些 vtep 的地址是多少。有了这些信息，vtep 就能发送报文时直接查询并添加头部，不需要多播去满网络地问了。</p><p>一般情况下，在每个 vtep 所在的节点都会有一个 agent，它会和控制中心通信，获取 vtep 需要的信息以某种方式告诉 vtep。具体的做法取决于具体的实现，每种实现可能会更新不同的信息给 vtep，比如 HER（Head End Replication）只是把多播组替换成多个单播报文，也就是把多播组所有的 VTEP IP 地址告诉 vtep，这样查询的时候不是发送多播，而是给组内每个 vtep 发送一个单播报文；有些实现只是告诉 vtep 目的虚拟机的 MAC 地址信息；有些实现告诉 MAC 地址对应的 vtep IP 地址。</p><p>此外，什么时候告诉 vtep 这些信息也是有区别的。一般有两种方式：常见的是一旦知道了虚拟机的三元组信息就告诉 vtep（即使某个 vtep 用不到这个信息，因为它管理的虚拟机不会和这个地址通信），一般这时候第一次通信还没有发生；另外一种方式是在第一次通信时，当 vtep 需要这些信息的时候以某种方式通知 agent，然后 agent 这时候才告诉 vtep 信息。</p><p>分布式控制的 vxlan 是一种典型的 SDN 架构，也是目前使用最广泛的方式。因为它的实现多样，而且每种实现都有些许差距，这里不便来具体的例子来说明，只要明白了上面的原理，不管是什么样的实现，都能很快上手。</p><h2 id="5-vxlan-网络带来新的问题"><a href="#5-vxlan-网络带来新的问题" class="headerlink" title="5. vxlan 网络带来新的问题"></a>5. vxlan 网络带来新的问题</h2><p>vxlan 协议给虚拟网络带来了灵活性和扩展性，让云计算网络能够像计算、存储资源那样按需扩展，并灵活分布。和计算机领域所有技术一样，这也是一种 tradeoff，相对于经典网络来说，vxlan 主要的问题是它的复杂性和额外的开销。</p><h3 id="额外的报文和计算"><a href="#额外的报文和计算" class="headerlink" title="额外的报文和计算"></a>额外的报文和计算</h3><p>这一点可容易看出来，每个 vxlan 报文都有额外的 50 字节开销，如果加上 vlan 字段，开销要到 54 字节。这对于小报文的传输是非常昂贵的操作，试想如果某个报文应用数据才几个字节，原来的网络头部加上 vxlan 报文头部都能有 100 字节的控制信息。</p><p>额外的报文也带来了额外的计算量，每个 vxlan 报文的封包和解包操作都是必须的，如果用软件来实现这些步骤，额外的计算量也是不可以忽略的影响。</p><h3 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h3><p>vxlan 另外一个缺点是复杂度，虽然经典网络在应对云计算时捉紧见拙，但是经典网络模型已经发展了很久，所有的部署、监控、运维都比较成熟。如果使用 vxlan 网络，那么所有的这些都要重新学习，时间和人力成本必然会大大提高。</p><h2 id="6-参考资料"><a href="#6-参考资料" class="headerlink" title="6. 参考资料"></a>6. 参考资料</h2><ul><li><a href="https://tools.ietf.org/html/rfc7348" target="_blank" rel="noopener">VXLAN 协议文档: rfc7348</a></li><li><a href="http://support.huawei.com/huaweiconnect/enterprise/thread-334207.html" target="_blank" rel="noopener">【华为悦读汇】技术发烧友：认识VXLAN</a></li><li><a href="http://support.huawei.com/huaweiconnect/enterprise/forum.php?mod=viewthread&amp;tid=284371&amp;page=1#pid1553281" target="_blank" rel="noopener">Vxlan基础理解-新的三层overlay技术的浅析</a></li><li><a href="http://blog.csdn.net/sinat_31828101/article/details/50504656" target="_blank" rel="noopener">vxlan 技术探究</a></li><li><a href="https://blogs.vmware.com/vsphere/2013/05/vxlan-series-how-vtep-learns-and-creates-forwarding-table-part-5.html" target="_blank" rel="noopener">VMware vxlan series</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;1-vxlan-简介&quot;&gt;&lt;a href=&quot;#1-vxlan-简介&quot; class=&quot;headerlink&quot; title=&quot;1. vxlan 简介&quot;&gt;&lt;/a&gt;1. vxlan 简介&lt;/h2&gt;&lt;p&gt;VXLAN 全称是 &lt;code&gt;Virtual eXtensible
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="network" scheme="http://cizixs.com/tags/network/"/>
    
      <category term="vxlan" scheme="http://cizixs.com/tags/vxlan/"/>
    
      <category term="sdn" scheme="http://cizixs.com/tags/sdn/"/>
    
  </entry>
  
  <entry>
    <title>aufs 简介以及在 docker 中的使用</title>
    <link href="http://cizixs.com/2017/09/13/docker-aufs-storage-driver/"/>
    <id>http://cizixs.com/2017/09/13/docker-aufs-storage-driver/</id>
    <published>2017-09-12T16:00:00.000Z</published>
    <updated>2018-09-17T13:18:45.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="AUFS-简介"><a href="#AUFS-简介" class="headerlink" title="AUFS 简介"></a>AUFS 简介</h2><p>AUFS 的全称是 Advanced Multi-layered unification filesytem，它的主要功能是：把多个目录结合成一个目录，对外使用。</p><p>把多个目录 mount 成一个，那么读写操作是怎样的呢？</p><ul><li>默认情况下，最上层的目录为读写层，只能有一个；下面可以有一个或者多个只读层</li><li>读文件，打开文件的时候使用了 <code>O_RDONLY</code> 选项：从最上面一个开始往下逐层去找，打开第一个找到的文件，读取其中的内容</li><li>写文件，打开文件时用了 <code>O_WRONLY</code> 或者 <code>O_RDWR</code> 选项<ul><li>如果在最上层找到了该文件，直接打开</li><li>否则，从上往下开始查找，找到文件后，把文件复制到最上层，然后再打开这个 copy（所以，如果要读写的文件很大，这个过程耗时会很久）</li></ul></li><li>删除文件：在最上层创建一个 whiteout 文件，<code>.wh.&lt;origin_file_name&gt;</code>，就是在原来的文件名字前面加上 <code>.wh.</code> </li></ul><h2 id="aufs-简单实验"><a href="#aufs-简单实验" class="headerlink" title="aufs 简单实验"></a>aufs 简单实验</h2><p>Ubuntu 系统默认已经安装了 aufs，对应的安装包是 <code>aufs-tools</code>。下面我们就做一个简单的试验，看看 aufs 具体的样子。</p><p>工作目录可以随便选择，后面的操作都是在这个目录进行的。首先创建三个子目录: </p><ul><li><code>base</code> 作为底层的目录</li><li><code>top</code> 作为上层的目录</li><li><code>mnt</code>： aufs 使用的挂载点，会把上面两个目录挂载到这里</li></ul><p>然后创建几个文件，如下：</p><pre><code>➜  tree                     .├── base│   ├── common.txt│   └── hello.txt├── mnt└── top    ├── common.txt    └── foo.txt</code></pre><p>接下来使用 aufs，把 <code>base</code> 和 <code>top</code> 一起 mount 到 <code>./mnt</code> 目录：</p><pre><code>➜  sudo mount -t aufs -o br=./top:./base none ./mnt</code></pre><p>在 aufs 中，<code>base/</code> 和 <code>top/</code> 被称为 branch，它们就是源目录。</p><p>这个 mount 命令的参数意义是这样的：</p><ul><li><code>-t aufs</code>：mount 的文件类型，使用的是 aufs</li><li><code>-o</code>：传递个 aufs 的选项，每个文件类型的选项不同</li><li><code>br</code>：表示 branch，也就是 aufs 需要的的各个目录</li><li><code>none</code>：这个本来是设备的名字，但是我们并没有用到任何设备，只会用到文件夹，因此这里为 none</li><li><code>./mnt</code>：挂载点，也就是内容最终出现的目录</li></ul><p>默认情况下，<code>-o</code> 后面的第一个目录是以可读写模式挂载的，剩下的目录都是只读模式（和 docker 容器模型非常一致）。</p><p>查看挂载好之后的组织形式，发现 <code>./mnt</code> 中出现了原来两个文件夹的综合内容，其中 <code>common.txt</code> 文件选择的是 <code>top/</code> 文件夹的。</p><pre><code>➜  tree.├── base│   ├── common.txt│   └── hello.txt├── mnt│   ├── common.txt│   ├── foo.txt│   └── hello.txt└── top    ├── common.txt    └── foo.txt➜  cat mnt/common.txt top</code></pre><p>如果要修改 <code>common.txt</code> 文件，会发现只有 <code>top</code> 目录对应的内容发生了变化，<code>base</code> 下面的内容会保持不动：</p><pre><code>➜  echo changed &gt; ./mnt/common.txt➜  cat top/common.txt changed➜  cat base/common.txt base</code></pre><p>这是因为 aufs 会逐层去查找文件，发现最上层存在文件 <code>common.txt</code> 并且是可写的，就会直接操作这个文件。类似的，如果是修改 <code>foo.txt</code> 也会直接反应在 <code>top/</code> 目录里面。</p><p>但是如果我们想要修改 <code>hello.txt</code> 文件，和预期不一样的是，<code>base/hello.txt</code> 并没有变化，而是新建了一个 <code>top/hello.txt</code> 文件，所有的操作都是在这个文件进行的。实验结果如下：</p><pre><code>➜  echo hello, world &gt; mnt/hello.txt ➜  tree.├── base│   ├── common.txt│   └── hello.txt├── mnt│   ├── common.txt│   ├── foo.txt│   └── hello.txt└── top    ├── common.txt    ├── foo.txt    └── hello.txt</code></pre><p>这是因为，aufs 从上往下查找文件，虽然在 <code>base/</code> 中发现了 <code>hello.txt</code> 文件，但是这个 branch 是以只读的方式挂载的，所以 aufs 并不能直接修改它，而是把它拷贝一份到上层，并对这个拷贝进行修改。</p><p>当然我们可以在 mount 的指定每个 branch 的读写模式，比如把两个 branch 都以可写的方式挂载：</p><pre><code>➜  sudo mount -t aufs -o br=./top=rw:./base=rw none ./mnt</code></pre><p>那么修改文件的规则会发生一些变化，文件查找还是从前到后，但是一旦发现文件，就能直接修改这个 branch 的文件内容，而不需要进行拷贝了。具体的实验就不做了，操作也非常简单，读者可以自行完成。</p><p>可以指定的权限一共有三种：</p><ul><li><code>rw</code>：可读可写，用户能直接修改这个 branch 的文件内容</li><li><code>ro</code>：只读，用户不能通过 aufs 的接口对文件进行写操作，只能读取里面的内容</li><li><code>rr</code>：real read only，底层的文件本来就是只读的（这种情况比较少见），这种情况下，aufs 就不用担心文件不通过它的接口被修改的情况</li></ul><p>除了读写模式之外，还有一个重要的属性——<code>whiteout</code>。</p><p>通过 aufs 指定的读写模式，只有用户通过最终的挂载点访问才有效，如果用户绕过挂载点，直接修改原来的文件，aufs 应该怎么处理呢？这个行为是由一个参数控制的，<code>udba</code>（全称是 User Direct Branch Access），这个参数有三个可选值：</p><ul><li><code>udba=none</code>：aufs 不会进行任何数据同步的检查，因此性能会高一点，但是可能会出现数据不一致的情况。如果用户能保证文件不会直接被修改，或者对文件内容一致性要求不高，可以使用</li><li><code>udba=reval</code>：aufs 会检查底层的文件有没有改动，如果有的话，把改动的内容更新到挂载点。这个性能会导致 aufs 产生额外的性能损耗</li><li><code>udba=notify</code>：通过 inotify 监听底层的文件变化，基于事件驱动，能够减少第二种方式的性能损耗</li></ul><p>说了这么多，可以看出来其实 aufs 最核心的功能还是那句话：<strong>把多个目录合并成一个目录，让用户决定在操作统一的文件系统</strong>。虽然看起来很有趣，那么 aufs 有哪些实际的用处呢？当然它被我们提起是因为 docker 可以用它来保存镜像和容器，但是 aufs 出现的时间要比 docker 长很多，它常见的用法包括：</p><ul><li>Linux 光盘演示和教程，录制了 Linux 的光盘可以用来让用户体验，但是光盘的内容是只读的，可以通过 aufs 把光盘和 U 盘或者磁盘 mount 到一起，用户对文件的修改保存到后面的存储上</li><li>如果系统上因为各种原因，不同用户的 home 目录保存在不同的路径和磁盘上，可以通过 aufs 把它们 mount 到一起，统一进行操作</li></ul><p>当然，下面我们就要讲讲 aufs 在 docker 中的用法。</p><h2 id="docker-使用-aufs-作为-storage-driver"><a href="#docker-使用-aufs-作为-storage-driver" class="headerlink" title="docker 使用 aufs 作为 storage driver"></a>docker 使用 aufs 作为 storage driver</h2><p>在 ubuntu 系统中，安装了 docker 之后，docker 运行默认选择的 storage driver 就是 aufs，通过 <code>docker info</code> 命令可以查看，我自己的机器上显示的信息如下：</p><pre><code>➜  docker infoServer Version: 17.03.0-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 228 Dirperm1 Supported: true</code></pre><p>所有 aufs 的内容都在 <code>/var/lib/docker/aufs</code> 目录中，这个目录下面有三个子目录：</p><pre><code>➜ tree -L 1 /var/lib/docker/aufs/var/lib/docker/aufs├── diff├── layers└── mnt</code></pre><ul><li><code>diff</code>：镜像每一层的内容，每个文件夹代表一个层</li><li><code>layers</code>：镜像各层是怎么组织的 metadata，每个文件代表一个层，这个文件中保存着它下面所有层的 ID（按照顺序）</li><li><code>mnt</code>: 镜像或者容器的 mountpoints，也就是容器最终看到的文件系统的样子</li></ul><p>通过这三个子目录，docker 就能实现镜像的分层存储、容器的 Copy-On-Write 启动。</p><h2 id="docker-容器的文件存储解析"><a href="#docker-容器的文件存储解析" class="headerlink" title="docker 容器的文件存储解析"></a>docker 容器的文件存储解析</h2><p>先来看看镜像，docker 的镜像是分层的，而且这些层之间有父子关系，它们共同组成了我们看到的一个个镜像。在本地，这些层是保存在 <code>/var/lib/docker/aufs/diff</code> 目录下的，我们可以用 <code>docker inspect ubuntu:16.04</code> 查看 <code>ubuntu:16.04</code> 有哪些层：</p><pre><code>&quot;RootFS&quot;: {            &quot;Type&quot;: &quot;layers&quot;,            &quot;Layers&quot;: [                &quot;sha256:90edd0ba21c8da7e530c3fdb0af496a07a33c285c7e51f30de80c50c624a5905&quot;,                &quot;sha256:267964ef478ec7e5969fc9c6efa41026195bc9bc4c6d6a06aa319adbd4378b5c&quot;,                &quot;sha256:bec30309c6f4462637b06947692a17fd3e3ba6a0233f74c7c9292b4930421541&quot;,                &quot;sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef&quot;,                &quot;sha256:4a3596d391da67de46a4f50b07f69277e4c81d65debdf68b99aa726959602e39&quot;,                &quot;sha256:72a672688aec3c93f4a1c6af75494c163347ad5319a582fe01c435bc84b08295&quot;,                &quot;sha256:11d4787bae4222ff2790dc6d9678d8c205286b86c33cad3ec80762602799384c&quot;,                &quot;sha256:0e593a4c1af6701dd33b58fead3fdb276cd2b87f020085297e8f690316e61b85&quot;,                &quot;sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef&quot;,                &quot;sha256:5f70bf18a086007016e948b04aed3b82103a36bea41755b6cddfaf10ace3c6ef&quot;            ]        }</code></pre><p>可以看到，<code>ubuntu:16.04</code> 一共有 10 层，每一层都对应了 <code>aufs/diff</code> 下面的一个目录，但是每个目录名和上面的 <code>sha256</code> ID 并不相同。</p><p>接下来，我们运行容器：</p><pre><code>$ docker run -d ubuntu:16.04 sh -c &quot;while true; do sleep 1; echo 1; done&quot;</code></pre><p>这个容器会在 <code>aufs/mnt</code> 目录下创建一个目录：<code>/var/lib/docker/aufs/mnt/223993596e6e22217d86604b374e24d973ebe48254f34a92a5e960d4e3860caa</code>，这也是容器中最终看到的文件系统的内容。</p><p>怎么中找到每个容器的层级关系呢？可以先通过通过 <code>cat /proc/mounts</code> 看到 aufs 的内部 ID(si)，比如下面的 <code>bca8de84a45d534b</code>：</p><pre><code>➜  cat /proc/mounts| grep aufsnone /var/lib/docker/aufs/mnt/223993596e6e22217d86604b374e24d973ebe48254f34a92a5e960d4e3860caa aufs rw,relatime,si=bca8de84a45d534b,dio,dirperm1 0 0</code></pre><p>然后就能根据这个 id，查看它保存的各个 branch 的信息（对应了 docker 的每个层）：</p><pre><code>➜  cat /sys/fs/aufs/si_bca8de84a45d534b/br[0-9]*/var/lib/docker/aufs/diff/223993596e6e22217d86604b374e24d973ebe48254f34a92a5e960d4e3860caa=rw/var/lib/docker/aufs/diff/223993596e6e22217d86604b374e24d973ebe48254f34a92a5e960d4e3860caa-init=ro+wh/var/lib/docker/aufs/diff/0809f5e8e6753bce10504289fceed0c377c6cc99e2a8d66505c56f01b85217a3=ro+wh/var/lib/docker/aufs/diff/5febf4aecb9a60edb6d789da279490e3677f40b2e5af3bdfeec51bd2d1bef230=ro+wh/var/lib/docker/aufs/diff/ec53b179c0bf8a9f9d729e19ca9ecbc7230d4c5daa7bf88bc2ef049a6c939800=ro+wh/var/lib/docker/aufs/diff/2d1b95d7488f268999bfe058ca114c2efdbc0772f57ee7f6c96bbeb05577f2db=ro+wh/var/lib/docker/aufs/diff/55d5a8091dc476bf0f4e39a119408acb4b8b690e3ace7022e7aaeea30b404d20=ro+wh/var/lib/docker/aufs/diff/893023d4e2be28ba1660dd035bd0b3892478c50c83d2c8d6477fa9170068d2e4=ro+wh/var/lib/docker/aufs/diff/f876a0ffdfa44a939b8b851f6b2cce086836acff6d55701739b2ad8d786ae346=ro+wh/var/lib/docker/aufs/diff/e1863e30cbc5198d0c84f6611c0f5b2a6750abcefdb29aa57c4c4cd0becadd54=ro+wh/var/lib/docker/aufs/diff/dcc613560b91ab550919a7f5b89025b1144ee63fa6dcdab929dec237ef3e8280=ro+wh/var/lib/docker/aufs/diff/b671e25db34edc80d115c50338c9546faad8abf704c1d5c1450a9d9a7d84e8b6=ro+wh</code></pre><p>可以看到，除了第一个是 <code>rw</code> 之外，其他都是 <code>ro+wh</code>（<code>ro</code> 表示 readonly 只读，<code>wh</code> 表示 whiteout，目录中可以包含 whiteout 文件），你可以查看各个目录的内容，它们对应了每个层的修改。</p><p><img src="https://docs.docker.com/engine/userguide/storagedriver/images/aufs_layers.jpg" alt=""></p><p>最终看到的文件是这样的：</p><pre><code>$ ls aufs/mnt/223993596e6e22217d86604b374e24d973ebe48254f34a92a5e960d4e3860caa     bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var</code></pre><p>因为我运行的容器并没有修改任何文件，因此最上面的层最开始为空。在容器中创建一个 <code>/root/hello.txt</code> 文件，这个目录就能看到新创建的文件：</p><pre><code>➜  ls aufs/diff/223993596e6e22217d86604b374e24d973ebe48254f34a92a5e960d4e3860caa➜  tree aufs/diff/223993596e6e22217d86604b374e24d973ebe48254f34a92a5e960d4e3860caa/aufs/diff/223993596e6e22217d86604b374e24d973ebe48254f34a92a5e960d4e3860caa/└── root    └── hello.txt1 directory, 1 file</code></pre><p>同理，直接在这个目录中新建文件也能在容器里看到。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>aufs 是 docker 最早选择的存储驱动，因为 docker 公司最开始支持的操作系统为 Debian。aufs 概念很简单，非常容易理解和使用，但是 aufs 也有它的问题。</p><p>最大的问题是它不没有进入到 Linux 内核，因此不能保证可移植性，虽然像 ubuntu 这种发行版默认支持 aufs，但并不是所有系统都如此，比如 centos 就默认没有提供 aufs 支持。之所以没有合并到内核，据说是因为 aufs 的实现代码很冗杂，Linus 认为代码质量太差，虽然开发者多次精简，最终还是没有进入到内核，而且在短时间内也不会有什么变化。</p><p>另外的问题是 aufs 对性能有比较大的影响，通过上面的知识，我们至少能看到两个性能问题：第一次修改一个大文件会非常耗时；另外层级过多也会影响整体的读写性能。此外，<a href="https://sthbrx.github.io/blog/2015/10/30/docker-just-stop-using-aufs/" target="_blank" rel="noopener">这里有篇文章</a>提出，aufs 在频繁打开文件的时候性能损耗很大，虽然只是一个例子，而且没有给出 root cause，但能从另外一个侧面反应出 aufs 性能确实有待商榷。</p><p>如果在生产环境适用，上面两点因素会使很多人不会选择 aufs。但是 aufs 非常适合在开发环境，或者对性能要求较低的情况，因为 ubuntu 默认的驱动就是 aufs，而且它确实足够简单，维护的压力会小很多。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://coolshell.cn/articles/17061.html" target="_blank" rel="noopener">DOCKER基础技术：AUFS</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;AUFS-简介&quot;&gt;&lt;a href=&quot;#AUFS-简介&quot; class=&quot;headerlink&quot; title=&quot;AUFS 简介&quot;&gt;&lt;/a&gt;AUFS 简介&lt;/h2&gt;&lt;p&gt;AUFS 的全称是 Advanced Multi-layered unification
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="linux" scheme="http://cizixs.com/tags/linux/"/>
    
      <category term="docker" scheme="http://cizixs.com/tags/docker/"/>
    
      <category term="container" scheme="http://cizixs.com/tags/container/"/>
    
      <category term="aufs" scheme="http://cizixs.com/tags/aufs/"/>
    
      <category term="storage" scheme="http://cizixs.com/tags/storage/"/>
    
      <category term="filesystem" scheme="http://cizixs.com/tags/filesystem/"/>
    
  </entry>
  
  <entry>
    <title>使用 pprof 和火焰图调试 golang 应用</title>
    <link href="http://cizixs.com/2017/09/11/profiling-golang-program/"/>
    <id>http://cizixs.com/2017/09/11/profiling-golang-program/</id>
    <published>2017-09-10T16:00:00.000Z</published>
    <updated>2019-03-18T13:14:39.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是-Profiling"><a href="#什么是-Profiling" class="headerlink" title="什么是 Profiling?"></a>什么是 Profiling?</h2><p>Profiling 这个词比较难翻译，一般译成<code>画像</code>。比如在案件侦破的时候会对嫌疑人做画像，从犯罪现场的种种证据，找到嫌疑人的各种特征，方便对嫌疑人进行排查；还有就是互联网公司会对用户信息做画像，通过了解用户各个属性（年龄、性别、消费能力等），方便为用户推荐内容或者广告。</p><p>在计算机性能调试领域里，profiling 就是对应用的画像，这里画像就是应用使用 CPU 和内存的情况。也就是说应用使用了多少 CPU 资源？都是哪些部分在使用？每个函数使用的比例是多少？有哪些函数在等待 CPU 资源？知道了这些，我们就能对应用进行规划，也能快速定位性能瓶颈。</p><p>golang 是一个对性能特别看重的语言，因此语言中自带了 profiling 的库，这篇文章就要讲解怎么在 golang 中做 profiling。</p><p>在 go 语言中，主要关注的应用运行情况主要包括以下几种：</p><ul><li>CPU profile：报告程序的 CPU 使用情况，按照一定频率去采集应用程序在 CPU 和寄存器上面的数据</li><li>Memory Profile（Heap Profile）：报告程序的内存使用情况</li><li>Block Profiling：报告 goroutines 不在运行状态的情况，可以用来分析和查找死锁等性能瓶颈</li><li>Goroutine Profiling：报告 goroutines 的使用情况，有哪些 goroutine，它们的调用关系是怎样的</li></ul><h2 id="两种收集方式"><a href="#两种收集方式" class="headerlink" title="两种收集方式"></a>两种收集方式</h2><p>做 Profiling 第一步就是怎么获取应用程序的运行情况数据。go 语言提供了 <code>runtime/pprof</code> 和 <code>net/http/pprof</code> 两个库，这部分我们讲讲它们的用法以及使用场景。</p><h3 id="工具型应用"><a href="#工具型应用" class="headerlink" title="工具型应用"></a>工具型应用</h3><p>如果你的应用是一次性的，运行一段时间就结束。那么最好的办法，就是在应用退出的时候把 profiling 的报告保存到文件中，进行分析。对于这种情况，可以使用 <a href="https://golang.org/pkg/runtime/pprof/" target="_blank" rel="noopener"><code>runtime/pprof</code> 库</a>。</p><p><code>pprof</code> 封装了很好的接口供我们使用，比如要想进行 CPU Profiling，可以调用 <code>pprof.StartCPUProfile()</code> 方法，它会对当前应用程序进行 CPU profiling，并写入到提供的参数中（<code>w io.Writer</code>），要停止调用 <code>StopCPUProfile()</code> 即可。</p><p>去除错误处理只需要三行内容，一般把部分内容写在 <code>main.go</code> 文件中，应用程序启动之后就开始执行：</p><pre><code>f, err := os.Create(*cpuprofile)...pprof.StartCPUProfile(f)defer pprof.StopCPUProfile()</code></pre><p>应用执行结束后，就会生成一个文件，保存了我们的 CPU profiling 数据。</p><p>想要获得内存的数据，直接使用 <code>WriteHeapProfile</code> 就行，不用 <code>start</code> 和 <code>stop</code> 这两个步骤了：</p><pre><code>f, err := os.Create(*memprofile)pprof.WriteHeapProfile(f)f.Close()</code></pre><h3 id="服务型应用"><a href="#服务型应用" class="headerlink" title="服务型应用"></a>服务型应用</h3><p>如果你的应用是一直运行的，比如 web 应用，那么可以使用 <code>net/http/pprof</code> 库，它能够在提供 HTTP 服务进行分析。</p><p>如果使用了默认的 <code>http.DefaultServeMux</code>（通常是代码直接使用 <code>http.ListenAndServe(&quot;0.0.0.0:8000&quot;, nil)</code>），只需要添加一行：</p><pre><code>import _ &quot;net/http/pprof&quot;</code></pre><p>如果你使用自定义的 <code>Mux</code>，则需要手动注册一些路由规则：</p><pre><code>r.HandleFunc(&quot;/debug/pprof/&quot;, pprof.Index)r.HandleFunc(&quot;/debug/pprof/cmdline&quot;, pprof.Cmdline)r.HandleFunc(&quot;/debug/pprof/profile&quot;, pprof.Profile)r.HandleFunc(&quot;/debug/pprof/symbol&quot;, pprof.Symbol)r.HandleFunc(&quot;/debug/pprof/trace&quot;, pprof.Trace)</code></pre><p>不管哪种方式，你的 HTTP 服务都会多出 <code>/debug/pprof</code> endpoint，访问它会得到类似下面的内容：</p><pre><code>/debug/pprof/profiles:0    block62    goroutine444    heap30    threadcreatefull goroutine stack dump</code></pre><p>这个路径下还有几个子页面：</p><ul><li><code>/debug/pprof/profile</code>：访问这个链接会自动进行 CPU profiling，持续 30s，并生成一个文件供下载</li><li><code>/debug/pprof/heap</code>： Memory Profiling 的路径，访问这个链接会得到一个内存 Profiling 结果的文件</li><li><code>/debug/pprof/block</code>：block Profiling 的路径</li><li><code>/debug/pprof/goroutines</code>：运行的 goroutines 列表，以及调用关系</li></ul><h2 id="go-tool-pprof-命令：获取和分析-Profiling-数据"><a href="#go-tool-pprof-命令：获取和分析-Profiling-数据" class="headerlink" title="go tool pprof 命令：获取和分析 Profiling 数据"></a>go tool pprof 命令：获取和分析 Profiling 数据</h2><p>能通过对应的库获取想要的 Profiling 数据之后（不管是文件还是 http），下一步就是要对这些数据进行保存和分析，我们可以使用 <code>go tool pprof</code> 命令行工具。</p><p>在后面我们会生成调用关系图和火焰图，需要安装 <code>graphviz</code> 软件包，在 ubuntu 系统可以使用下面的命令：</p><pre><code>$ sudo apt-get install -y graphviz</code></pre><p><strong>NOTE</strong>：获取的 Profiling 数据是动态的，要想获得有效的数据，请保证应用处于较大的负载（比如正在生成中运行的服务，或者通过其他工具模拟访问压力）。否则如果应用处于空闲状态，得到的结果可能没有任何意义。</p><h3 id="CPU-Profiling"><a href="#CPU-Profiling" class="headerlink" title="CPU Profiling"></a>CPU Profiling</h3><p><code>go tool pprof</code> 最简单的使用方式为 <code>go tool pprof [binary] [source]</code>，<code>binary</code> 是应用的二进制文件，用来解析各种符号；<code>source</code> 表示 profile 数据的来源，可以是本地的文件，也可以是 http 地址。比如：</p><pre><code>➜  go tool pprof ./hyperkube http://172.16.3.232:10251/debug/pprof/profileFetching profile from http://172.16.3.232:10251/debug/pprof/profilePlease wait... (30s)Saved profile in /home/cizixs/pprof/pprof.hyperkube.172.16.3.232:10251.samples.cpu.002.pb.gzEntering interactive mode (type &quot;help&quot; for commands)(pprof) </code></pre><p>这个命令会进行 CPU profiling 分析，等待一段时间（默认是 30s，如果在 url 最后加上 <code>?seconds=60</code> 参数可以调整采集数据的时间为 60s）之后，我们就进入了一个交互式命令行，可以对解析的结果进行查看和导出。可以通过 <code>help</code> 来查看支持的自命令有哪些。</p><p>一个有用的命令是 <code>topN</code>，它列出最耗时间的地方：</p><pre><code>(pprof) top10130ms of 360ms total (36.11%)Showing top 10 nodes out of 180 (cum &gt;= 10ms)      flat  flat%   sum%        cum   cum%      20ms  5.56%  5.56%      100ms 27.78%  encoding/json.(*decodeState).object      20ms  5.56% 11.11%       20ms  5.56%  runtime.(*mspan).refillAllocCache      20ms  5.56% 16.67%       20ms  5.56%  runtime.futex      10ms  2.78% 19.44%       10ms  2.78%  encoding/json.(*decodeState).literalStore      10ms  2.78% 22.22%       10ms  2.78%  encoding/json.(*decodeState).scanWhile      10ms  2.78% 25.00%       40ms 11.11%  encoding/json.checkValid      10ms  2.78% 27.78%       10ms  2.78%  encoding/json.simpleLetterEqualFold      10ms  2.78% 30.56%       10ms  2.78%  encoding/json.stateBeginValue      10ms  2.78% 33.33%       10ms  2.78%  encoding/json.stateEndValue      10ms  2.78% 36.11%       10ms  2.78%  encoding/json.stateInString</code></pre><p>每一行表示一个函数的信息。前两列表示函数在 CPU 上运行的时间以及百分比；第三列是当前所有函数累加使用 CPU 的比例；第四列和第五列代表这个函数以及子函数运行所占用的时间和比例（也被称为<code>累加值 cumulative</code>），应该大于等于前两列的值；最后一列就是函数的名字。如果应用程序有性能问题，上面这些信息应该能告诉我们时间都花费在哪些函数的执行上了。</p><p>pprof 不仅能打印出最耗时的地方(<code>top</code>)，还能列出函数代码以及对应的取样数据(<code>list</code>)、汇编代码以及对应的取样数据(<code>disasm</code>)，而且能以各种样式进行输出，比如 svg、gv、callgrind、png、gif等等。</p><p>其中一个非常便利的是 <code>web</code> 命令，在交互模式下输入 <code>web</code>，就能自动生成一个 <code>svg</code> 文件，并跳转到浏览器打开，生成了一个函数调用图：</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fjfq8wjqunj31fa0q3afd.jpg" alt=""></p><p>这个调用图包含了更多的信息，而且可视化的图像能让我们更清楚地理解整个应用程序的全貌。图中每个方框对应一个函数，方框越大代表执行的时间越久（包括它调用的子函数执行时间，但并不是正比的关系）；方框之间的箭头代表着调用关系，箭头上的数字代表被调用函数的执行时间。</p><p>因为原图比较大，这里只截取了其中一部分，但是能明显看到 <code>encoding/json.(*decodeState).object</code> 是这里耗时比较多的地方，而且能看到它调用了哪些函数，分别函数多少。这些更详细的信息对于定位和调优性能是非常有帮助的！</p><p>要想更细致分析，就要精确到代码级别了，看看每行代码的耗时，直接定位到出现性能问题的那行代码。<code>pprof</code> 也能做到，<code>list</code> 命令后面跟着一个正则表达式，就能查看匹配函数的代码以及每行代码的耗时：</p><pre><code>(pprof) list podFitsOnNodeTotal: 120msROUTINE ======================== k8s.io/kubernetes/plugin/pkg/scheduler.podFitsOnNode in /home/cizixs/go/src/k8s.io/kubernetes/_output/local/go/src/k8s.io/kubernetes/plugin/pkg/scheduler/generic_scheduler.go         0       20ms (flat, cum) 16.67% of Total         .          .    230:         .          .    231:// Checks whether node with a given name and NodeInfo satisfies all predicateFuncs.         .          .    232:func podFitsOnNode(pod *api.Pod, meta interface{}, info *schedulercache.NodeInfo, predicateFuncs map[string]algorithm.FitPredicate) (bool, []algorithm.PredicateFailureReason, error) {         .          .    233:    var failedPredicates []algorithm.PredicateFailureReason         .          .    234:    for _, predicate := range predicateFuncs {         .       20ms    235:        fit, reasons, err := predicate(pod, meta, info)         .          .    236:        if err != nil {         .          .    237:            err := fmt.Errorf(&quot;SchedulerPredicates failed due to %v, which is unexpected.&quot;, err)         .          .    238:            return false, []algorithm.PredicateFailureReason{}, err         .          .    239:        }         .          .    240:        if !fit {</code></pre><p>如果想要了解对应的汇编代码，可以使用 <code>disadm &lt;regex&gt;</code> 命令。这两个命令虽然强大，但是在命令行中查看代码并不是很方面，所以你可以使用 <code>weblist</code> 命令，用法和两者一样，但它会在浏览器打开一个页面，能够同时显示源代码和汇编代码。 </p><p><strong>NOTE</strong>：更详细的 pprof 使用方法可以参考 <code>pprof --help</code> 或者 <a href="https://github.com/google/pprof/blob/master/doc/pprof.md" target="_blank" rel="noopener">pprof 文档</a>。</p><h3 id="Memory-Profiling"><a href="#Memory-Profiling" class="headerlink" title="Memory Profiling"></a>Memory Profiling</h3><p>要想获得内存使用 Profiling 信息，只需要把数据源修改一下就行（对于 http 方式来说就是修改 url 的地址，从 <code>/debug/pprof/profile</code> 改成 <code>/debug/pprof/heap</code>）：</p><pre><code>➜  go tool pprof ./hyperkube http://172.16.3.232:10251/debug/pprof/heap        Fetching profile from http://172.16.3.232:10251/debug/pprof/heapSaved profile in /home/cizixs/pprof/pprof.hyperkube.172.16.3.232:10251.inuse_objects.inuse_space.002.pb.gzEntering interactive mode (type &quot;help&quot; for commands)(pprof)</code></pre><p>和 CPU Profiling 使用一样，使用 <code>top N</code> 可以打印出使用内存最多的函数列表：</p><pre><code>(pprof) top11712.11kB of 14785.10kB total (79.22%)Dropped 580 nodes (cum &lt;= 73.92kB)Showing top 10 nodes out of 146 (cum &gt;= 512.31kB)      flat  flat%   sum%        cum   cum% 2072.09kB 14.01% 14.01%  2072.09kB 14.01%  k8s.io/kubernetes/vendor/github.com/beorn7/perks/quantile.NewTargeted 2049.25kB 13.86% 27.87%  2049.25kB 13.86%  k8s.io/kubernetes/pkg/api/v1.(*ResourceRequirements).Unmarshal 1572.28kB 10.63% 38.51%  1572.28kB 10.63%  k8s.io/kubernetes/vendor/github.com/beorn7/perks/quantile.(*stream).merge 1571.34kB 10.63% 49.14%  1571.34kB 10.63%  regexp.(*bitState).reset 1184.27kB  8.01% 57.15%  1184.27kB  8.01%  bytes.makeSlice 1024.16kB  6.93% 64.07%  1024.16kB  6.93%  k8s.io/kubernetes/pkg/api/v1.(*ObjectMeta).Unmarshal  613.99kB  4.15% 68.23%  2150.63kB 14.55%  k8s.io/kubernetes/pkg/api/v1.(*PersistentVolumeClaimList).Unmarshal  591.75kB  4.00% 72.23%  1103.79kB  7.47%  reflect.Value.call  520.67kB  3.52% 75.75%   520.67kB  3.52%  k8s.io/kubernetes/vendor/github.com/gogo/protobuf/proto.RegisterType  512.31kB  3.47% 79.22%   512.31kB  3.47%  k8s.io/kubernetes/pkg/api/v1.(*PersistentVolumeClaimStatus).Unmarshal</code></pre><p>每一列的含义也是类似的，只不过从 CPU 使用时间变成了内存使用大小，就不多解释了。</p><p>类似的，<code>web</code> 命令也能生成 <code>svg</code> 图片在浏览器中打开，从中可以看到函数调用关系，以及每个函数的内存使用多少。</p><p>需要注意的是，默认情况下，统计的是内存使用大小，如果执行命令的时候加上 <code>--inuse_objects</code> 可以查看每个函数分配的对象数；<code>--alloc-space</code> 查看分配的内存空间大小。</p><p>这里还要提两个比较有用的方法，如果应用比较复杂，生成的调用图特别大，看起来很乱，有两个办法可以优化：</p><ul><li>使用 <code>web funcName</code> 的方式，只打印和某个函数相关的内容</li><li>运行 <code>go tool pprof</code> 命令时加上 <code>--nodefration=0.05</code> 参数，表示如果调用的子函数使用的 CPU、memory 不超过 5%，就忽略它，不要显示在图片中</li></ul><p>pprof 已经支持动态的 web 浏览方式：<a href="https://github.com/google/pprof/commit/f83a3d89c18c445178f794d525bf3013ef7b3330" target="_blank" rel="noopener">https://github.com/google/pprof/commit/f83a3d89c18c445178f794d525bf3013ef7b3330</a></p><h2 id="go-torch-和火焰图"><a href="#go-torch-和火焰图" class="headerlink" title="go-torch 和火焰图"></a>go-torch 和火焰图</h2><p>火焰图（Flame Graph）是 Bredan Gregg 创建的一种性能分析图表，因为它的样子近似 🔥而得名。上面的 profiling 结果也转换成火焰图，如果对火焰图比较了解可以手动来操作，不过这里我们要介绍一个工具：<a href="https://github.com/uber/go-torch" target="_blank" rel="noopener">go-torch</a>。这是 uber 开源的一个工具，可以直接读取 golang profiling 数据，并生成一个火焰图的 svg 文件。</p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fjc5nh6x52j30xc0litck.jpg" alt=""></p><p>火焰图 svg 文件可以通过浏览器打开，它对于调用图的最优点是它是动态的：可以通过点击每个方块来 zoom in 分析它上面的内容。</p><p>火焰图的调用顺序从下到上，每个方块代表一个函数，它上面一层表示这个函数会调用哪些函数，方块的大小代表了占用 CPU 使用的长短。火焰图的配色并没有特殊的意义，默认的红、黄配色是为了更像火焰而已。</p><p>go-torch 工具的使用非常简单，没有任何参数的话，它会尝试从 <code>http://localhost:8080/debug/pprof/profile</code> 获取 profiling 数据。它有三个常用的参数可以调整：</p><ul><li><code>-u --url</code>：要访问的 URL，这里只是主机和端口部分</li><li><code>-s --suffix</code>：pprof profile 的路径，默认为 <code>/debug/pprof/profile</code></li><li><code>--seconds</code>：要执行 profiling 的时间长度，默认为 30s</li></ul><p>要生成火焰图，需要事先安装 <a href="https://github.com/brendangregg/FlameGraph" target="_blank" rel="noopener">FlameGraph</a>工具，这个工具的安装很简单，只要把对应的可执行文件放到 <code>$PATH</code> 目录下就行。</p><h2 id="和测试工具的集成"><a href="#和测试工具的集成" class="headerlink" title="和测试工具的集成"></a>和测试工具的集成</h2><p>go test 命令有两个参数和 pprof 相关，它们分别指定生成的 CPU 和 Memory profiling 保存的文件：</p><ul><li><code>-cpuprofile</code>：cpu profiling 数据要保存的文件地址</li><li><code>-memprofile</code>：memory profiling 数据要报文的文件地址</li></ul><p>比如下面执行测试的同时，也会执行 CPU profiling，并把结果保存在 <code>cpu.prof</code> 文件中：</p><pre><code>$ go test -bench . -cpuprofile=cpu.prof</code></pre><p>执行结束之后，就会生成 <code>main.test</code> 和 <code>cpu.prof</code>  文件。要想使用 <code>go tool pprof</code>，需要指定的二进制文件就是 <code>main.test</code>。</p><p>需要注意的是，Profiling 一般和性能测试一起使用，这个原因在前文也提到过，只有应用在负载高的情况下 Profiling 才有意义。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://blog.golang.org/profiling-go-programs" target="_blank" rel="noopener">The Go Blog: Profiling Go Programs</a></li><li><a href="https://github.com/hyper0x/go_command_tutorial/blob/master/0.12.md" target="_blank" rel="noopener">go command tutorial: go tool pprof   </a></li><li><a href="http://artem.krylysov.com/blog/2017/03/13/profiling-and-optimizing-go-web-applications/" target="_blank" rel="noopener">Profiling and optimizing Go web applications</a></li><li><a href="https://software.intel.com/en-us/blogs/2014/05/10/debugging-performance-issues-in-go-programs" target="_blank" rel="noopener">Debugging performance issues in Go programs</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;什么是-Profiling&quot;&gt;&lt;a href=&quot;#什么是-Profiling&quot; class=&quot;headerlink&quot; title=&quot;什么是 Profiling?&quot;&gt;&lt;/a&gt;什么是 Profiling?&lt;/h2&gt;&lt;p&gt;Profiling
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="golang" scheme="http://cizixs.com/tags/golang/"/>
    
      <category term="pprof" scheme="http://cizixs.com/tags/pprof/"/>
    
      <category term="flamegraph" scheme="http://cizixs.com/tags/flamegraph/"/>
    
  </entry>
  
  <entry>
    <title>docker 容器基础技术：linux namespace 简介</title>
    <link href="http://cizixs.com/2017/08/29/linux-namespace/"/>
    <id>http://cizixs.com/2017/08/29/linux-namespace/</id>
    <published>2017-08-28T16:00:00.000Z</published>
    <updated>2018-09-17T13:18:45.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Linux-namespace-简介"><a href="#1-Linux-namespace-简介" class="headerlink" title="1. Linux namespace 简介"></a>1. Linux namespace 简介</h2><p>Linux namespace 是一种内核级别的资源隔离机制，用来让运行在同一个操作系统上的进程互相不会干扰。</p><p><strong>namespace 目的就是隔离</strong>，要做到的效果是：如果某个 namespace 中有进程在里面运行，它们只能看到该 namespace 的信息，无法看到 namespace 以外的东西。我们来想一下：一个进程在运行的时候，它会知道哪些信息？</p><ul><li>看到系统的 hostname</li><li>可用的网络资源（bridge、interface、网络端口的时候情况……）</li><li>进程的关系（有哪些进程，进程之间的父子关系等）、</li><li>系统的用户信息（有哪些用户、组，它们的权限是怎么样的）</li><li>文件系统（有哪些可用的文件系统，使用情况）</li><li>IPC（怎么实现进程间通信）</li><li>……</li></ul><p>也就是说，如果要实现隔离，必须保证不同 namespace 中进程看到的上面这些东西是不同的。</p><p>如果让我来做，首先的想法是每个 namespace 都实现一整套上述资源的隔离，但是实际上 linux 的实现中，上述的所有资源都是可以单独隔离的。这遵循了 <code>KISS</code> 原则，增加了使用的灵活性（针对不同的情况使用不同的隔离自组合）。</p><p><strong>NOTE</strong>：在这系列文章中，经常会遇到某些名词后面跟着带有数字的括号。这是 linux 的规范，对应的数字代表了命令所在的不同 section，可能的数字有：</p><ol><li>Executable programs or shell commands</li><li>System calls (functions provided by the kernel)</li><li>Library calls (functions within program libraries)</li><li>Special files (usually found in /dev)</li><li>File formats and conventions eg /etc/passwd</li><li>Games</li><li>Miscellaneous (including macro packages and conventions), e.g. man(7), groff(7)</li><li>System administration commands (usually only for root)</li><li>Kernel routines [Non standard]</li></ol><h2 id="2-不同的-namespace"><a href="#2-不同的-namespace" class="headerlink" title="2. 不同的 namespace"></a>2. 不同的 namespace</h2><p>目前 linux 内核主要实现了一下几种不同的资源 namespace：</p><table><thead><tr><th>名称</th><th>宏定义</th><th>隔离的内容</th></tr></thead><tbody><tr><td>IPC</td><td>CLONE_NEWIPC</td><td>System V IPC, POSIX message queues (since Linux 2.6.19)</td></tr><tr><td>Network</td><td>CLONE_NEWNET</td><td>network device interfaces, IPv4 and IPv6 protocol stacks, IP routing  tables,  firewall rules, the /proc/net and /sys/class/net directory trees, sockets, etc (since Linux 2.6.24)</td></tr><tr><td>Mount</td><td>CLONE_NEWNS</td><td>Mount points (since Linux 2.4.19)</td></tr><tr><td>PID</td><td>CLONE_NEWPID</td><td>Process IDs (since Linux 2.6.24)</td></tr><tr><td>User</td><td>CLONE_NEWUSER</td><td>User and group IDs (started in Linux 2.6.23 and completed in Linux 3.8)</td></tr><tr><td>UTS</td><td>CLONE_NEWUTS</td><td>Hostname and NIS domain name (since Linux 2.6.19)</td></tr><tr><td>Cgroup</td><td>CLONE_NEWCGROUP</td><td>Cgroup root directory (since Linux 4.6)</td></tr></tbody></table><p>这些 namespace 基本上覆盖了一个程序运行所需的环境，保证运行在的隔离的 namespace 中的，会让程序不会受到其他收到 namespace 程序的干扰。但不是所有的系统资源都能隔离，时间就是个例外，没有对应的 namespace，因此同一台 Linux 启动的容器时间都是相同的。</p><p>我们会用接下来的内容解释每个 namespace 的含义和用法。</p><p><strong>NOTE:</strong> Cgroup namespace 比较新，还没有大量使用，比如 docker(v1.13.0) 目前就没有用到。</p><h2 id="3-proc-目录"><a href="#3-proc-目录" class="headerlink" title="3. /proc 目录"></a>3. /proc 目录</h2><p>每个进程都有一个 <code>/proc/[pid]/ns</code> 的目录，里面保存了该进程所在对应 namespace 的链接：</p><pre><code>➜  namespace git:(uts-demo) ✗ ls -l /proc/$$/ns/total 0lrwxrwxrwx 1 cizixs cizixs 0 12月 21 15:36 cgroup -&gt; cgroup:[4026531835]lrwxrwxrwx 1 cizixs cizixs 0 12月 21 15:36 ipc -&gt; ipc:[4026531839]lrwxrwxrwx 1 cizixs cizixs 0 12月 21 15:36 mnt -&gt; mnt:[4026531840]lrwxrwxrwx 1 cizixs cizixs 0 12月 21 15:36 net -&gt; net:[4026531969]lrwxrwxrwx 1 cizixs cizixs 0 12月 21 15:36 pid -&gt; pid:[4026531836]lrwxrwxrwx 1 cizixs cizixs 0 12月 21 15:36 user -&gt; user:[4026531837]lrwxrwxrwx 1 cizixs cizixs 0 12月 21 15:36 uts -&gt; uts:[4026531838]</code></pre><p>每个文件都是对应 namespace 的文件描述符，方括号里面的值是 namespace 的 inode，如果两个进程所在的 namespace 一样，那么它们列出来的 inode 是一样的；反之亦然。如果某个 namespace 中没有进程了，它会被自动删除，不需要手动删除。但是有个例外，如果 namespace 对应的文件某个应用程序打开，那么该 namespace 是不会被删除的，这个特性可以让我们保持住某个 namespace，以便后面往里面添加进程。</p><p>需要注意的是，上面列出来是我正常运行的 <code>bash</code> 程序的 namespace，并没有运行任何的容器，也没有执行任何和 namespace 有关的操作。也就是说，所有的程序都会有 namespace，可以简单理解成 namespace 其实就是进程的属性，然后操作系统把这个属性相同的进程组织到一起，起到资源隔离的作用。</p><p>正应了 David Wheeler 那句名言：</p><blockquote><p>All problems in computer science can be solved by another level of indirection.</p></blockquote><h2 id="4-三个系统调用"><a href="#4-三个系统调用" class="headerlink" title="4. 三个系统调用"></a>4. 三个系统调用</h2><p>我们知道，linux 内核提供的功能都会提供系统调用接口供应用程序使用，namespace 也不例外。和 namespace 相关的系统调用主要有三个，这部分内容就分别介绍它们的定义和使用。</p><p><strong>NOTE：</strong>这些系统调用都是 linux 内核实现的，不能直接适用于其他操作系统。</p><h3 id="clone：创建新进程并设置它的namespace"><a href="#clone：创建新进程并设置它的namespace" class="headerlink" title="clone：创建新进程并设置它的namespace"></a>clone：创建新进程并设置它的namespace</h3><p><a href="http://man7.org/linux/man-pages/man2/clone.2.html" target="_blank" rel="noopener">clone</a> 类似于 fork 系统调用，可以创建一个新的进程，不同的是你可以指定要子进程要执行的函数以及通过参数控制子进程的运行环境（比如这篇文章主要介绍的 namespace）。下面是 <code>clone(2)</code> 的定义：</p><pre><code>#include &lt;sched.h&gt;int clone(int (*fn)(void *), void *child_stack,         int flags, void *arg, ...         /* pid_t *ptid, struct user_desc *tls, pid_t *ctid */ );</code></pre><p>它有四个重要的参数：</p><ul><li><code>fn</code> 参数是一个函数指针，子进程启动的时候会调用这个函数来执行</li><li><code>arg</code> 作为参数传给该函数。当这个函数返回，子进程的运行也就结束，函数的返回结果就是 exit code。</li><li><code>child_stack</code> 参数指定了子进程 stack 开始的内存地址，因为 stack 都会从高位到地位增长，所以这个指针需要指向分配 stack 的最高位地址。</li><li><code>flags</code> 是子进程启动的一些配置信息，包括信号（子进程结束的时候发送给父进程的信号 SIGCHLD）、子进程要运行的 namespace 信息（上面已经看到的 <code>CLONE_NEWIPC</code>，<code>CLONE_NEWNET</code>、<code>CLONE_NEWIPC</code>等）、其他配置信息（可以参考 <code>clone(2)</code> man page）。</li></ul><h3 id="setns：让进程加入已经存在-namespace"><a href="#setns：让进程加入已经存在-namespace" class="headerlink" title="setns：让进程加入已经存在 namespace"></a>setns：让进程加入已经存在 namespace</h3><p><code>setns</code> 能够把某个进程加入到给定的 namespace，它的定义是这样的：</p><pre><code>int setns(int fd, int nstype);</code></pre><p><code>fd</code> 参数是一个文件描述符，指向 <code>/proc/[pid]/ns/</code> 目录下的某个 namespace，调用这个函数的进程就会被加入到 <code>fd</code> 指向文件所代表的 namespace，<code>fd</code> 可以通过打开 namespace 对应的文件获取。</p><p><code>nstype</code> 限定进程可以加入的 namespaces，可能的取值是：</p><ul><li>0: 可以加入任意的 namespaces</li><li><code>CLONE_NEWIPC</code>：fd 必须指向 ipc namespace</li><li><code>CLONE_NEWNET</code>：fd 必须指向 network namespace</li><li><code>CLONE_NEWNS</code>：fd 必须指向 mount namespace</li><li><code>CLONE_NEWPID</code>：fd 必须指向 PID namespace</li><li><code>CLONE_NEWUSER</code>： fd 必须指向 user namespace</li><li><code>CLONE_NEWUTS</code>： fd 必须指向 UTS namespace</li></ul><p>如果不知道 <code>fd</code> 指向的 namespace 类型（比如 fd 是其他进程打开的，然后通过参数传递过来），然后在应用中希望明确指定特种类型的 <code>namespace</code>，<code>nstype</code>  就非常有用。</p><p>更详细地说，setns 能够让进程离开现在所在的某个特性的 namespace，加入到另外一个同类型的已经存在的 namespace。</p><p>需要注意的是：<code>CLONE_NEWPID</code> 和其他 namespace 不同，把进程加入到<br>PID namespace 并不会修改该进程的 PID namespace，而只修改它所有子进程的 PID namespace。</p><h3 id="unshare：让进程加入新的-namespace"><a href="#unshare：让进程加入新的-namespace" class="headerlink" title="unshare：让进程加入新的 namespace"></a>unshare：让进程加入新的 namespace</h3><pre><code>int unshare(int flags);</code></pre><p><code>unshare</code> 比较简单，只有一个参数 <code>flags</code>，它的含义和 <code>clone</code> 的 <code>flags</code> 相同。<code>unshare</code> 和 <code>setns</code> 的区别是，<code>setns</code> 只能让进程加入到已经存在的 namespace 中，而 <code>unshare</code> 则让进程离开当前的 namespace，加入到新建的 namespace 中。</p><p><code>unshare</code> 和 <code>clone</code> 的区别在于：<code>unshare</code> 是把当前进程进入到新的 namespace；<code>clone</code> 是创建新的进程，然后让新创建的进程（子进程）加入到新的 namespace。</p><h2 id="5-实践"><a href="#5-实践" class="headerlink" title="5. 实践"></a>5. 实践</h2><p>这部分所有的代码都被放到了 <a href="https://github.com/cizixs/namespace" target="_blank" rel="noopener">github 这个 repo</a>，不同版本放在不同的 tag 下面，可以供读者很方便地运行。</p><p>所有的代码都在 ubuntu16.04 运行通过，操作系统信息如下：</p><pre><code>➜  namespace git:(master) ✗ uname -aLinux ubuntu-xenial 4.4.0-47-generic #68-Ubuntu SMP Wed Oct 26 19:39:52 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux➜  namespace git:(master) ✗ lsb_release -aNo LSB modules are available.Distributor ID:    UbuntuDescription:    Ubuntu 16.04.1 LTSRelease:    16.04Codename:    xenial</code></pre><p><strong>NOTE:</strong> 所有的代码都需要 root 权限执行！</p><h3 id="clone-系统调用"><a href="#clone-系统调用" class="headerlink" title="clone 系统调用"></a>clone 系统调用</h3><p>我们先来看看 <code>clone</code> 一个简单的使用例子：创建一个新的进程，并执行 <code>/bin/bash</code>，这样就可以接受命令，方便我们查看新进程的信息。后面所有的代码都是在这个框架下进行扩展的，它在 repo 中的 tag 是 <code>v0.1</code>。具体代码如下，关键部分都已经进行了注释：</p><pre><code>#define _GNU_SOURCE#include &lt;sched.h&gt;#include &lt;sys/wait.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;// 设置子进程要使用的栈空间#define STACK_SIZE (1024*1024)static char container_stack[STACK_SIZE];#define errExit(code, msg); {if(code == -1){perror(msg); exit(-1);} }char* const container_args[] = {    &quot;/bin/bash&quot;,    NULL};static int container_func(void *arg){    pid_t pid = getpid();    printf(&quot;Container[%d] - inside the container!\n&quot;, pid);    // 用一个新的bash来替换掉当前子进程，    // 这样我们就能通过 bash 查看当前子进程的情况.    // bash退出后，子进程执行完毕    execv(container_args[0], container_args);    // 从这里开始的代码将不会被执行到，因为当前子进程已经被上面的bash替换掉了;    // 所以如果执行到这里，一定是出错了    printf(&quot;Container[%d] - oops!\n&quot;, pid);    return 1;}int main(int argc, char *argv[]){    pid_t pid = getpid();    printf(&quot;Parent[%d] - create a container!\n&quot;, pid);    // 创建并启动子进程，调用该函数后，父进程将继续往后执行，也就是执行后面的waitpid    pid_t child_pid = clone(container_func,  // 子进程将执行container_func这个函数                    container_stack + sizeof(container_stack),                    // 这里SIGCHLD是子进程退出后返回给父进程的信号，跟namespace无关                    SIGCHLD,                    NULL);  // 传给child_func的参数    errExit(child_pid, &quot;clone&quot;);    waitpid(child_pid, NULL, 0); // 等待子进程结束    printf(&quot;Parent[%d] - container exited!\n&quot;, pid);    return 0;}</code></pre><p><strong>NOTE：不要忘记开头的 <code>#define _GNU_SOURCE</code></strong>！因为 clone 不是符合 POSIX 标准的系统调用。</p><p>这段代码不长，但是做了很多事情：</p><ul><li>通过 <code>clone</code> 创建出一个子进程，并设置启动时的参数</li><li>在子进程中调用 <code>execv</code> 来执行 <code>/bin/bash</code>，等待用户进行交互</li><li>子进程退出之后，父进程也跟着退出</li></ul><p>为了方便区分不同的进行，我们还在不同的部分打印出了父进程和子进程的 pid 以及简单的信息。来看一下具体的执行效果：</p><pre><code># 先编译代码➜  namespace git:(master) gcc container.c -o container# 运行程序，可以看到父进程和子进程的 pid 分别是 10666 和 10667。# 分别在子进程和父进程中查看 /proc/$$/ns 的内容，发现两者完全一样，也就是说它们属于同一个 namespace# 因为我们没有在 clone 的时候修改子进程的 namespace➜  namespace git:(master) ✗ ./containerParent[10666] - create a container!Container[10667] - inside the container!vagrant@ubuntu-xenial:/home/vagrant/Code/namespace$ ls -l /proc/$$/nstotal 0lrwxrwxrwx 1 vagrant vagrant 0 Dec 21 15:53 cgroup -&gt; cgroup:[4026531835]lrwxrwxrwx 1 vagrant vagrant 0 Dec 21 15:53 ipc -&gt; ipc:[4026531839]lrwxrwxrwx 1 vagrant vagrant 0 Dec 21 15:53 mnt -&gt; mnt:[4026531840]lrwxrwxrwx 1 vagrant vagrant 0 Dec 21 15:53 net -&gt; net:[4026531957]lrwxrwxrwx 1 vagrant vagrant 0 Dec 21 15:53 pid -&gt; pid:[4026531836]lrwxrwxrwx 1 vagrant vagrant 0 Dec 21 15:53 user -&gt; user:[4026531837]lrwxrwxrwx 1 vagrant vagrant 0 Dec 21 15:53 uts -&gt; uts:[4026531838]vagrant@ubuntu-xenial:/home/vagrant/Code/namespace$ exitexitParent[10666] - container exited!➜  namespace git:(master) ✗ ls -l /proc/$$/nstotal 0lrwxrwxrwx 1 vagrant vagrant 0 Dec 21 15:54 cgroup -&gt; cgroup:[4026531835]lrwxrwxrwx 1 vagrant vagrant 0 Dec 21 15:54 ipc -&gt; ipc:[4026531839]lrwxrwxrwx 1 vagrant vagrant 0 Dec 21 15:54 mnt -&gt; mnt:[4026531840]lrwxrwxrwx 1 vagrant vagrant 0 Dec 21 15:54 net -&gt; net:[4026531957]lrwxrwxrwx 1 vagrant vagrant 0 Dec 21 15:54 pid -&gt; pid:[4026531836]lrwxrwxrwx 1 vagrant vagrant 0 Dec 21 15:54 user -&gt; user:[4026531837]lrwxrwxrwx 1 vagrant vagrant 0 Dec 21 15:54 uts -&gt; uts:[4026531838]# 运行 bash 的时候，可以从提示符看到子进程的 hostname 是 `ubuntu-xenial`➜  namespace git:(master) ✗ hostnameubuntu-xenial</code></pre><h3 id="UTS-namespace"><a href="#UTS-namespace" class="headerlink" title="UTS namespace"></a>UTS namespace</h3><p>UTS namespace 功能最简单，它只隔离了 hostname 和 NIS domain name 两个资源。同一个 namespace 里面的进程看到的 hostname 和 domain name 是相同的，这两个值可以通过 <code>sethostname(2)</code> 和 <code>setdomainname(2)</code> 来进行设置，也可以通过 <code>uname(2)</code>、<code>gethostname(2)</code> 和 <code>getdomainname(2)</code> 来读取。</p><p><strong>NOTE</strong>： UTS 的名字来自于 <code>uname</code> 函数用到的结构体 <code>struct utsname</code>，这个结构体的名字源自于 <code>UNIX Time-sharing System</code>。</p><p>代码主要修改两个地方：<code>clone</code> 的参数加上了 <code>CLONE_NEWUTS</code>，子进程函数中使用 <code>sethostname</code> 来设置 hostname。</p><pre><code>static int container_func(void *hostname){    pid_t pid = getpid();    printf(&quot;Container[%d] - inside the container!\n&quot;, pid);    // 使用 sethostname 设置子进程的 hostname 信息    struct utsname uts;    if (sethostname(hostname, strlen(hostname)) == -1) {        errExit(-1, &quot;sethostname&quot;)    };    // 使用 uname 获取子进程的机器信息，并打印 hostname 出来    if (uname(&amp;uts) == -1){        errExit(-1, &quot;uname&quot;)    }    printf(&quot;Container[%d] - container uts.nodename: [%s]!\n&quot;, pid, uts.nodename);    ……}int main(int argc, char *argv[]){    // 把第一个参数作为子进程的 hostname，默认是 `container`    char *hostname;    if (argc &lt; 2) {        hostname = &quot;container&quot;;    } else {        hostname = argv[1];    }    ……    pid_t child_pid = clone(container_func,                        container_stack + sizeof(container_stack),                        // CLONE_NEWUTS表示创建新的UTS namespace，                        CLONE_NEWUTS | SIGCHLD,                        hostname);     ……}</code></pre><p>完整的代码在 repo 中的 tag 为 <code>v0.2</code>，感兴趣可以前往查看。下面就运行代码看看效果：</p><pre><code># 先查看父进程的 uts 信息➜  namespace git:(master) ✗ ls -l /proc/$$/ns/utslrwxrwxrwx 1 cizixs cizixs 0 12月 22 11:20 /proc/21472/ns/uts -&gt; uts:[4026531838]# 运行 container，并把 hostname 设置为 container007# 可以看到 container 内部 hostname 已经变了，而且对应的 uts namespace inode 也发生了改变，说明# container 内部 uts 和父进程不一样➜  namespace git:(master) ✗ sudo ./container container007Parent[27312] - parent uts.nodename: [cizixs-ThinkPad-T450]!Parent[27312] - create a container!Container[27313] - inside the container!Container[27313] - container uts.nodename: [container007]!root@container007:~/Programs/namespace# hostnamecontainer007root@container007:~/Programs/namespace# ls -l /proc/$$/ns/utslrwxrwxrwx 1 root root 0 12月 22 11:18 /proc/27313/ns/uts -&gt; uts:[4026533424]</code></pre><p>此外，这个版本还新加了一个 <code>join_uts</code> 的代码，用来把进程加入到已有的 namespace。 保持上面的 container 不要退出，在另外 terminal 中运行 <code>join_ns</code> 的程序：</p><pre><code># 运行 join_ns 进入到上面 container 新建的 uts namespace# 进程的 pid 和上面都不一样，说明是新建的进程。# 但是 hostname 为 container007，进程的 uts inode 和上面 container 也一样# 说明这个进程和 container 在同一个 uts namespace➜  namespace git:(master) ✗ sudo ./join_ns /proc/27313/ns/utsroot@container007:~/Programs/namespace# hostnamecontainer007root@container007:~/Programs/namespace# ls -l /proc/$$/ns/utslrwxrwxrwx 1 root root 0 12月 22 11:23 /proc/28096/ns/uts -&gt; uts:[4026533424]root@container007:~/Programs/namespace# echo $$28096</code></pre><h3 id="PID-namespace"><a href="#PID-namespace" class="headerlink" title="PID namespace"></a>PID namespace</h3><p>PID namespace 隔离的是进程的 pid 属性，也就是说不同的 namespace 中的进程可以有相同的 pid。PID namespace 和我们常见的系统规则一样，都是从 <code>pid 1</code> 开始，每次 <code>fork</code>、<code>vfork</code>、<code>clone</code> 调用都会分配新的 pid。</p><p>PID namespace 第一个运行的进程的 pid 编号为 1，也被成为 init 进程。所有的孤儿进程（父进程被杀死）都会被 reparent 到 init 进程，<strong>如果 init 进程挂掉了，系统会发送 SIGKILL 信号给该 namespace 中的所有进程来杀死它们</strong>。由此可见，init 进程对于 PID namespace 至关重要，因此在容器中你可能听说过关于哪个程序最适合做 init 进程的争论。</p><p>PID namespace 另外一个特殊的特性是，通过 unshare 和 setns 系统调用都不会都不会把当前进程加入到新的 namespace，而是把该进程的子进程进入到里面。之所以这样设计，是因为 pid 是进程非常重要的信息，很多应用程序都会假定这个值不会变化，如果 unshare 或者 setns 把当前进程加入到新的 namespace 中，那么进程的 PID 将会发生变化，原来的 PID 也会被其他进程使用，会导致很多程序出现问题。</p><p>PID namespace 是可以嵌套的。除了 root PID namespace 之外，所有的 PID namespace 都有一个父亲 PID namespace，这个父亲 PID namespace 就是执行 <code>clone</code> 或者 <code>unshare</code> 创建该 namespace 进程所在的 PID namespace。这样的话，所有的 PID namespace 就组成了一棵树形结构。每个 PID namespace 中进程对该 PID namespace 以及所有直系祖先 PID namespace 中的进程都是可见的，而对于其他 PID namespace 都是不可见的。</p><p>既然 PID namespace 是树形组织的，那么一个进程在它可见的 PID namespace 都会有一个 pid，所有和某个进程有关的系统调用使用的 pid 都是属于调用方被创建的 PID namespace 。如果某个进程的父进程属于另外一个 PID namespace，那么调用 <code>getppid</code> 将返回 0。</p><p><img src="https://uploads.toptal.io/blog/image/674/toptal-blog-image-1416487554032.png" alt=""></p><p>之前讲过，可以通过 <code>setns</code> 来修改进程所在的 namespace。对于 PID namespace 来说，进程只能移动到子 PID namespace，而不能移动到祖先 PID namespace。</p><p>对应的代码版本是 v0.3，这个版本的改动很小，只是在 <code>clone</code> 函数中添加了 <code>CLONE_NEWPID</code>。运行一下代码，测试 PID namespace 是否运行成功：</p><pre><code># 查看原来 shell 的 PID namespace➜  namespace git:(master) ✗ ls -l /proc/$$/ns/pidlrwxrwxrwx 1 root root 0 Aug 28 16:08 /proc/2270/ns/pid -&gt; pid:[4026531836]# 运行程序，进入容器内部，把容器的 hostname 改成 cizixs007➜  namespace git:(master) ✗ ./container cizixs007Parent[5957] - parent uts.nodename: [vagrant]!Parent[5957] - create a container!Container[1] - inside the container!Container[1] - container uts.nodename: [cizixs007]!# 查看容器内部 PID namespace root@cizixs007:~/code/namespace# ls -l /proc/$$/ns/pidlrwxrwxrwx 1 root root 0 Aug 28 16:08 /proc/1/ns/pid -&gt; pid:[4026531836]</code></pre><p>可以发现，容器内部 PID namespace 文件的 inode 不同，说明进入了不同的 PID namespace。另外容器内部第一个进程的 pid 是 1，而父进程的 pid 是 <code>5957</code>，说明 PID namespace 中进程号是独立的，重新从 1 开始分配。</p><p><strong>NOTE：</strong>如果在容器中运行 <code>ps aux</code> 命令，还是能看到主机上所有的进程信息，那是不是 PID namespace 隔离程度不够呢？并不是！<code>ps aux</code> 是从 <code>/proc</code> 文件中读取并展示进程信息的，这个特殊的目录并不属于 PID namespace 隔离的一部分，而是属于下面要讲到的 Mount namespace。默认情况下，容器会集成父进程的 namespace，所以 <code>/proc</code> 中还是父进程的信息，接下来我们会讲到解决方案。</p><h3 id="Mount-namespace"><a href="#Mount-namespace" class="headerlink" title="Mount namespace"></a>Mount namespace</h3><p>Mount namespace 隔离的是 mount points（挂载点），也就是说不同 namespace 下面的进程看到的文件系统结构是不同的，namespace 内的 mount points 可以通过 <code>mount(2)</code> 和 <code>umount(2)</code> 来修改，因此Mount namespace 可以用来实现容器文件系统的隔离。</p><p><img src="https://uploads.toptal.io/blog/image/677/toptal-blog-image-1416545619045.png" alt=""></p><ul><li><code>/proc/[pid]/mounts</code> 文件保存了进程所在 namespace 所有已经 mount  的文件系统。</li><li><code>/proc/[pid]/mountstats</code> 文件保存了进程所在 namespace mount point 的统计信息</li><li><code>/proc/[pid]/mountinfo</code> </li></ul><p>因为 Mount namespace 是最早加入到 linux 的，当时并没有预计到其他 namespace 的可能性，所以它被取名为 <code>CLONE_NEWNS</code>，而不是 <code>CLONE_NEWMOUNT</code> 之类的名字。为了保持兼容性，这个名字就一直延续到现在。</p><p>通过 <code>clone</code> 和 <code>unshare</code> 创建的 Mount namespace 会默认继承父 namespace 的内容，也就是说两者看到的文件系统内容是一样的。但是之后，新 Mount namespace 的所有操作都是独立的，不会影响到其他 namespace，因此可以用来创建完全属于自己的文件系统，也可以解决之间 PID namespace 中 <code>/proc</code> 目录的问题。</p><p>Mount namespace 实现了隔离当然是好事，但是它和 PID namespace 不同，完全的隔离却带来了不便之处。因为很多时候，我们希望某个设备能自动 Mount 到所有的 namespace 中，比如系统中插入了新磁盘，虽然每个 namespace 都重新 mount 一次也能达到效果，但是未免太多复杂。</p><p>因此 Mount 引入了 shared subtree 特性，每个挂载点都有一个 <code>propagation type</code> 的属性字段，决定了 Mount 事件怎样在 Peer Group 之间传播（关于什么是 Peer Group，我们下面会解释）。这个字段有四个可选值：</p><ul><li><code>MS_SHARED</code>：挂载事件（mount 和 umount）会自动传播。一个挂载点下面添加或者删除挂载点的话，同一个 peer group 的其他挂载点下面会自动执行同样的操作</li><li><code>MS_PRIVATE</code>：挂载信息是私有的，不共享，所有的挂载操作不属于任何 peer group，也不会影响其他任何目录</li><li><code>MS_SLAVE</code>：介于 <code>MS_SHARED</code> 和 <code>MS_PRIVATE</code> 之间，peer group 有 master-slave 之分，master 的挂载事件会传播到 slave；而 slave 的挂载事件不会传播到 master</li><li><code>MS_UNBINDABLE</code>：和 <code>MS_SLAVE</code> 类似，区别是不能作为 bind mount 的源，以防止递归嵌套。</li></ul><p>现在来说说 peer group，它就是一个或者多个挂载点的集合，之间可以共享挂载信息。有两种情况会导致挂载点属于同一个 peer group（前提是挂载点的 propagation type 必须是 shared）：</p><ul><li><code>mount --bind</code> 命令，会把源挂载点和目的挂载点放在同一个 peer group</li><li>创建新的 Mount namespace 时，子 namespace 和 父 namespace 也属于同一个 peer group</li></ul><p>还有两点需要额外说明一下：</p><ul><li>挂载点的父子关系是它们所在目录的父子关系决定的</li><li>默认情况下，子挂载点只有两种类型，如果父挂载点是 <code>MS_SHARED</code>，那么子挂载点也是 <code>MS_SHARED</code>；否则，子挂载点就是 <code>MS_PRIVATE</code> 的</li></ul><p>来看一下代码的测试效果，对应的 tag 是 <code>v0.4</code>：</p><pre><code># 查看原来的 mount namespace inode 信息➜  namespace git:(master) ✗ ls -lh /proc/$$/ns/mntlrwxrwxrwx 1 root root 0 Aug 29 09:17 /proc/2270/ns/mnt -&gt; mnt:[4026531840]# 运行容器应用➜  namespace git:(master) ✗ ./container cizixs007Parent[7436] - parent uts.nodename: [vagrant]!Container[1] - inside the container!Container[1] - container uts.nodename: [cizixs007]!root@cizixs007:~/code/namespace# ls -lh /proc/$$/ns/mntlrwxrwxrwx 1 root root 0 Aug 29 09:17 /proc/1/ns/mnt -&gt; mnt:[4026532183]# ps aux 也只能看到自己 namespace 的应用root@cizixs007:~/code/namespace# ps auxUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMANDroot         1  0.0  0.3  21228  3772 pts/2    S    09:17   0:00 /bin/bashroot        12  0.0  0.3  37364  3264 pts/2    R+   09:17   0:00 ps aux</code></pre><p>如果回到默认 namespace 执行 <code>ps aux</code> 出现下面错误的话，是因为 <code>/proc</code> 挂载点是共享的，子 namespace 对 <code>/proc</code> 目录的重新挂载影响到了父 namespace，需要重新挂载。</p><pre><code>Error, do this: mount -t proc proc /proc</code></pre><p>临时的解决方案可以把 <code>/proc</code> 设置为 private，然后再运行容器程序就不会出错了：</p><pre><code>$ sudo mount --make-private /proc</code></pre><h3 id="Net-namespace"><a href="#Net-namespace" class="headerlink" title="Net namespace"></a>Net namespace</h3><p>Net namespace 隔离的是和网络相关的资源，包括网络设备、路由表、防火墙(iptables)、socket（ss、netstat）、 <code>/proc/net</code> 目录、<code>/sys/class/net</code> 目录、网络端口(network interfaces)等等。</p><p>一个物理网络设备只能出现在最多一个网络 namespace 中，不同网络 namespace 之间可以通过创建 veth pair 提供类似管道的通信。</p><p>要想配置一个可用的网络有需要工作要做，可以参考我之前的 <a href="http://cizixs.com/2017/02/10/network-virtualization-network-namespace">network namespace</a> 这篇文章。这里就不再赘述了，我们的脚本里没有隔离网络，是为了方便，容器能够直接使用主机的网络通信。</p><p>如果添加了网络隔离，但是没有做额外的配置，那么容器中就无法和外部通信，这往往是某些应用期望的场景。比如在线代码运行平台，为了防止用户有恶意代码从网络下载脚本，或者扫描集群的网络等，使用无任何配置的隔离网络就再合适不过了。</p><h3 id="User-namespace"><a href="#User-namespace" class="headerlink" title="User namespace"></a>User namespace</h3><p>User namespace 隔离的是用户和组信息，在不同的 namespace 中用户可以有相同的 UID 和 GID，它们之间互相不影响。另外，还有父子 namespace 之间用户和组映射的功能。父 namespace 中非 root 用户也能成为子 namespace 中的 root，这样就能增加安全性（如果所有 namespace 的 root 用户都是一样的，会带来子 namespace 操作父 namespace 内容的危险）。</p><p>要想实现容器内部和外部用户/组的 mapping，要把对应关系写入到 <code>/proc/PID/uid_map</code> 和 <code>/proc/PID/gid_map</code> 文件中，<code>PID</code> 表示容器内进程在父 namespace 中的 PID（如果没有 PID 隔离，也就是容器内部的 PID）。</p><p>文件内容的格式为：</p><pre><code>ID-inside-ns   ID-outside-ns   length</code></pre><ul><li>ID-inside-ns 表示 user namespace 里面用户或者组的起始 id</li><li>ID-outside-ns 表示 user namespace 外部（也就是父 user namespace）用户或者组的起始 id</li><li>length 表示要 mapping 的个数，如果 为 1，则表示一一映射；如果大于 1，则表示连续 mapping 多个</li></ul><p>比如下面的内容表示将容器内 1-100 ID 映射到外部的 1000-1100：</p><pre><code>1 1000 100</code></pre><p>为了简单，我们的脚本也没有添加 user namespace，使用方法可以参考 LWN 网站上的文章。</p><h3 id="IPC-namespace"><a href="#IPC-namespace" class="headerlink" title="IPC namespace"></a>IPC namespace</h3><p>IPC 可能是大家都比较少关系的一块内容，也是了解最少的只是。IPC 是进程间通信的意思，作用是每个 namespace 都有自己的 IPC，防止不同 namespace 进程能互相通信（这样存在安全隐患）。</p><p>IPC namespace 隔离的是 IPC（Inter-Process Communication） 资源，也就是进程间通信的方式，包括 System V IPC 和 POSIX message queues。每个 IPC namespace 都有自己的 System V IPC 和 POSIX message queues，并且对其他 namespace 不可见，这样的话，只有同一个 namespace 下的进程之间才能够通信。</p><p>下面这些 <code>/proc</code> 中内容对于每个 namespace 都是不同的：</p><ul><li><code>/proc/sys/fs/mqueue</code> 下的 POSIX message queues</li><li><code>/proc/sys/kernel</code> 下的 System V IPC，包括 msgmax, msgmnb, msgmni, sem, shmall, shmmax, shmmni, and shm_rmid_forced</li><li><code>/proc/sysvipc/</code>：保存了该 namespace 下的 system V ipc 信息</li></ul><p>在 linux 下和 ipc 打交道，需要用到以下两个命令：</p><ul><li><code>ipcs</code>：查看IPC(共享内存、消息队列和信号量)的信息</li><li><code>ipcmk</code>：创建IPC(共享内存、消息队列和信号量)的信息</li></ul><p>下面开始我们的实验，这部分对应的代码在repo 中的 tag 为 <code>v0.5</code>，读者可以跟着一起做：</p><pre><code># 先看一下全局 ipc namespace，readlink 会读取 link 的值➜  namespace git:(master) ✗ readlink /proc/$$/ns/ipcipc:[4026531839]# 先看一下系统的 hostname，以此和容器内进行区分➜  namespace git:(master) ✗ hostnameubuntu-xenial# 查看系统消息队列 ipc，发现为空。然后用 `ipcmk` 创建出来一个 message queue ➜  namespace git:(master) ✗ ipcs -q------ Message Queues --------key        msqid      owner      perms      used-bytes   messages➜  namespace git:(master) ✗ ipcmk -QMessage queue id: 0➜  namespace git:(master) ✗ ipcs -q------ Message Queues --------key        msqid      owner      perms      used-bytes   messages0xeabd3aac 0          vagrant    644        0            0# 运行我们的程序，自动创建新的 uts 和 ipc namespace➜  namespace git:(master) ✗ sudo ./container container001Parent[17325] - create a container!Container[17326] - inside the container!# 我们来看一下 ipc namespace 对应的文件，发现和之前全局 ipc namespace 不同root@container001:/home/vagrant/Code/namespace# readlink /proc/$$/ns/ipcipc:[4026532134]# 列出容器中的 message queue，发现为空，也就是说和全局 ipc 是隔离的（因为我们已经创建了全局 ipc ）root@container001:/home/vagrant/Code/namespace# ipcs -q------ Message Queues --------key        msqid      owner      perms      used-bytes   messages# 然后使用 `ipcmk` 创建一个 message queue，注意这里的 key 和之前创建出来的也是不同的root@container001:/home/vagrant/Code/namespace# ipcmk -QMessage queue id: 0root@container001:/home/vagrant/Code/namespace# ipcs -q------ Message Queues --------key        msqid      owner      perms      used-bytes   messages0x0eb75307 0          root       644        0            0# 保持上面的程序不退出，在另外一个终端运行 join_ns 程序，加入到 ipc namespace，发现可以通过 `ipcs` 看到这个 namespace 中已经创建的 message queue。证明我们使用的 ipc namespace 和上面的容器是一样的。➜  namespace git:(master) ✗ sudo ./join_ns /proc/17326/ns/ipcroot@ubuntu-xenial:/home/vagrant/Code/namespace# ipcs -q------ Message Queues --------key        msqid      owner      perms      used-bytes   messages0x0eb75307 0          root       644        0            0</code></pre><h2 id="6-内核中的实现"><a href="#6-内核中的实现" class="headerlink" title="6. 内核中的实现"></a>6. 内核中的实现</h2><p>每个进程都对应一个 <code>task_struct</code> 结构体，其中包含了 <a href="https://github.com/torvalds/linux/blob/master/include/linux/sched.h#L1713" target="_blank" rel="noopener">nsproxy 变量</a>:</p><pre><code>struct task_struct {    ……    volatile long state;    /* -1 unrunnable, 0 runnable, &gt;0 stopped */    void *stack;    ……    /* namespaces */    struct nsproxy *nsproxy;}</code></pre><p>而 nsproxy 中保存的就是指向该进程所有 namespace 的指针， <code>clone</code> 和 <code>unshare</code> 每次系统调用都会导致 nsproxy 被复制。</p><pre><code>/* * A structure to contain pointers to all per-process * namespaces - fs (mount), uts, network, sysvipc, etc. * * The pid namespace is an exception -- it&#39;s accessed using * task_active_pid_ns.  The pid namespace here is the * namespace that children will use. * * &#39;count&#39; is the number of tasks holding a reference. * The count for each namespace, then, will be the number * of nsproxies pointing to it, not the number of tasks. * * The nsproxy is shared by tasks which share all namespaces. * As soon as a single namespace is cloned or unshared, the * nsproxy is copied. */struct nsproxy {    atomic_t count;    struct uts_namespace *uts_ns;    struct ipc_namespace *ipc_ns;    struct mnt_namespace *mnt_ns;    struct pid_namespace *pid_ns_for_children;    struct net          *net_ns;    struct cgroup_namespace *cgroup_ns;};</code></pre><p>因为每个进程使用的 namespace 不同，因此访问得到的资源信息也不相同，从而达到资源隔离的效果。</p><h2 id="7-实用的命令：nsenter，unshare"><a href="#7-实用的命令：nsenter，unshare" class="headerlink" title="7. 实用的命令：nsenter，unshare"></a>7. 实用的命令：nsenter，unshare</h2><p><code>nsenter</code> 用来进入到某些指定的 namespace 中执行命令，可以方便地进行容器的调试。</p><p>ubuntu 中可以通过安装 <code>util-linux</code> 软件包获得 <code>nsenter</code>，在 ubuntu 14.04 之前，nsenter 并不存在，你可以<a href="http://askubuntu.com/questions/439056/why-there-is-no-nsenter-in-util-linux" target="_blank" rel="noopener">通过源码自己编译安装</a>，或者使用 <a href="https://github.com/jpetazzo/nsenter" target="_blank" rel="noopener">docker 版本的 nsenter</a>。</p><p><code>nsenter</code> 常用的一个场景是进入到另外一个进程的 namespace 中进行调试，可以用下面的命令：</p><pre><code>$ nseneter -t 23456 --net --pid bash</code></pre><p><code>-t 23456</code> 表示进程的 pid，<code>--net</code> 表示进入到进程的 net namespace，<code>--pid</code> 表示进入到进程的 PID namespace，<code>bash</code> 是执行的命令。这样我们就得到一个 shell，它所有的命令都是在进程的网络和 PId namespace 中执行的。更多的命令可以查看 <code>man nsenter</code>。</p><p><code>unshare</code> 和 <code>nsenter</code> 参数有些相似，功能却不同，它是离开父进程的某些 namespace 去执行命令。</p><h2 id="8-参考资料"><a href="#8-参考资料" class="headerlink" title="8. 参考资料"></a>8. 参考资料</h2><ul><li><a href="https://lwn.net/Articles/531114/" target="_blank" rel="noopener">Namespaces in operation, part 1: namespaces overview</a></li><li><a href="https://blog.yadutaf.fr/2013/12/22/introduction-to-linux-namespaces-part-1-uts/" target="_blank" rel="noopener">Introduction to Linux namespaces - Part 1: UTS</a></li><li><a href="https://www.toptal.com/linux/separation-anxiety-isolating-your-system-with-linux-namespaces" target="_blank" rel="noopener">Separation Anxiety: A Tutorial for Isolating Your System with Linux Namespaces</a></li><li>namespaces(7) man page</li><li><a href="https://www.slideshare.net/jpetazzo/anatomy-of-a-container-namespaces-cgroups-some-filesystem-magic-linuxcon" target="_blank" rel="noopener">Container’s Anatomy</a></li><li><a href="http://www.haifux.org/lectures/299/netLec7.pdf" target="_blank" rel="noopener">Resource Management: Linux kernel Namespaces and cgroups</a></li><li><a href="https://blog.phusion.nl/2015/01/20/docker-and-the-pid-1-zombie-reaping-problem/" target="_blank" rel="noopener">Docker and the PID 1 zombie reaping problem</a></li><li><a href="https://coolshell.cn/articles/17010.html" target="_blank" rel="noopener">DOCKER基础技术：LINUX NAMESPACE（上）</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;1-Linux-namespace-简介&quot;&gt;&lt;a href=&quot;#1-Linux-namespace-简介&quot; class=&quot;headerlink&quot; title=&quot;1. Linux namespace 简介&quot;&gt;&lt;/a&gt;1. Linux namespace
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="linux" scheme="http://cizixs.com/tags/linux/"/>
    
      <category term="docker" scheme="http://cizixs.com/tags/docker/"/>
    
      <category term="container" scheme="http://cizixs.com/tags/container/"/>
    
      <category term="kernel" scheme="http://cizixs.com/tags/kernel/"/>
    
      <category term="namespace" scheme="http://cizixs.com/tags/namespace/"/>
    
  </entry>
  
  <entry>
    <title>docker 容器基础技术：linux cgroup 简介</title>
    <link href="http://cizixs.com/2017/08/25/linux-cgroup/"/>
    <id>http://cizixs.com/2017/08/25/linux-cgroup/</id>
    <published>2017-08-24T16:00:00.000Z</published>
    <updated>2018-09-17T13:18:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>Linux cgroups 的全称是 Linux Control Groups，它是 Linux 内核的特性，主要作用是<strong>限制、记录和隔离进程组（process groups）使用的物理资源（cpu、memory、IO 等）</strong>。</p><p>2006 的时候，Google 的一些工程师（主要是 Paul Menage 和 Rohit Seth）启动了这个项目，最初的名字叫 <strong>process containers</strong>。因为 <strong>container</strong> 在内核中名字有歧义，2007 的时候改名为 <strong>control groups</strong>，并合并到 2008 年发布的 2.6.24 内核版本。</p><p>最初 cgroups 的版本被称为 v1，这个版本的 cgroups 设计并不友好，理解起来非常困难。后续的开发工作由 Tejun Heo 接管，他重新设计并重写了 cgroups，新版本被称为 v2，并首次出现在 kernel 4.5 版本。</p><p>cgroups 从设计之初使命就很明确，为进程提供资源控制，它主要的功能包括：</p><ul><li><strong>资源限制</strong>：限制进程使用的资源上限，比如最大内存、文件系统缓存使用限制</li><li><strong>优先级控制</strong>：不同的组可以有不同的优先级，比如 CPU 使用和磁盘 IO 吞吐</li><li><strong>审计</strong>：计算 group 的资源使用情况，可以用来计费</li><li><strong>控制</strong>：挂起一组进程，或者重启一组进程</li></ul><p>目前 cgroups 已经成为很多技术的基础，比如 LXC、docker、systemd等。</p><p><strong>NOTE：</strong>资源限制是这篇文章的重点，也是 docker 等容器技术的基础。其他特性可以参考内核 cgroups 文档。</p><h2 id="cgroups-核心概念"><a href="#cgroups-核心概念" class="headerlink" title="cgroups 核心概念"></a>cgroups 核心概念</h2><p>前面说过，cgroups 是用来对进程进行资源管理的，因此 cgroup 需要考虑如何抽象这两种概念：进程和资源，同时如何组织自己的结构。cgroups 中有几个非常重要的概念：</p><ul><li><strong>task</strong>：任务，对应于系统中运行的一个实体，一般是指进程</li><li><strong>subsystem</strong>：子系统，具体的资源控制器（resource class 或者 resource controller），控制某个特定的资源使用。比如 CPU 子系统可以控制 CPU 时间，memory 子系统可以控制内存使用量</li><li><strong>cgroup</strong>：控制组，一组任务和子系统的关联关系，表示对这些任务进行怎样的资源管理策略</li><li><strong>hierarchy</strong>：层级树，一系列 cgroup 组成的树形结构。每个节点都是一个 cgroup，cgroup 可以有多个子节点，子节点默认会继承父节点的属性。系统中可以有多个 hierarchy</li></ul><p>虽然 cgroups 支持 hierarchy，允许不同的子资源挂到不同的目录，但是多个树之间有各种限制，增加了理解和维护的复杂性。在实际使用中，所有的子资源都会统一放到某个路径下（比如 ubuntu16.04 的 <code>/sys/fs/cgroup/</code>），因此本文并不详细介绍多个树的情况，感兴趣的可以参考 <a href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Resource_Management_Guide/sec-Relationships_Between_Subsystems_Hierarchies_Control_Groups_and_Tasks.html" target="_blank" rel="noopener">RedHat 的这篇文档。</a></p><h3 id="子资源系统（Resource-Classes-or-SubSystem）"><a href="#子资源系统（Resource-Classes-or-SubSystem）" class="headerlink" title="子资源系统（Resource Classes or SubSystem）"></a>子资源系统（Resource Classes or SubSystem）</h3><p>目前有下面这些资源子系统：</p><ul><li>Block IO（<code>blkio</code>)：限制块设备（磁盘、SSD、USB 等）的 IO 速率</li><li>CPU Set(<code>cpuset</code>)：限制任务能运行在哪些 CPU 核上</li><li>CPU Accounting(<code>cpuacct</code>)：生成 cgroup 中任务使用 CPU 的报告</li><li>CPU (<code>CPU</code>)：限制调度器分配的 CPU 时间</li><li>Devices (<code>devices</code>)：允许或者拒绝 cgroup 中任务对设备的访问</li><li>Freezer (<code>freezer</code>)：挂起或者重启 cgroup 中的任务</li><li>Memory (<code>memory</code>)：限制 cgroup 中任务使用内存的量，并生成任务当前内存的使用情况报告</li><li>Network Classifier(<code>net_cls</code>)：为 cgroup 中的报文设置上特定的 classid 标志，这样 tc 等工具就能根据标记对网络进行配置</li><li>Network Priority (<code>net_prio</code>)：对每个网络接口设置报文的优先级</li><li><code>perf_event</code>：识别任务的 cgroup 成员，可以用来做性能分析</li></ul><h3 id="Hierarchy"><a href="#Hierarchy" class="headerlink" title="Hierarchy"></a>Hierarchy</h3><p>Linux 进程之间组成一棵树的结构，每个进程（除了 <code>init</code> 根进程之外）都有一个父进程，子进程创建之后会继承父进程的一些属性（比如环境变量，打开的文件描述符等）。</p><p>和进程模型类似，只不过 cgroups 是一个森林结构。</p><h2 id="使用-cgroups"><a href="#使用-cgroups" class="headerlink" title="使用 cgroups"></a>使用 cgroups</h2><p>cgroup 内核功能比较有趣的地方是它没有提供任何的系统调用接口，而是对 linux vfs 的一个实现，因此可以用类似文件系统的方式进行操作。</p><p>使用 cgroups 的方式有几种：</p><ul><li>使用 cgroups 提供的虚拟文件系统，直接通过创建、读写和删除目录、文件来控制 cgroups</li><li>使用命令行工具，比如 libcgroup 包提供的 cgcreate、cgexec、cgclassify 命令</li><li>使用 <code>rules engine daemon</code> 提供的配置文件</li><li>当然，systemd、lxc、docker 这些封装了 cgroups 的软件也能让你通过它们定义的接口控制 cgroups 的内容</li></ul><h3 id="直接操作-cgroup-文件系统"><a href="#直接操作-cgroup-文件系统" class="headerlink" title="直接操作 cgroup 文件系统"></a>直接操作 cgroup 文件系统</h3><h4 id="查看-cgroups-挂载信息"><a href="#查看-cgroups-挂载信息" class="headerlink" title="查看 cgroups 挂载信息"></a>查看 cgroups 挂载信息</h4><p>在 ubuntu 16.04 的机器上，cgroups 已经挂载到文件系统上了，可以通过  <code>mount</code> 命令查看：</p><pre><code>➜  ~ mount -t cgroupcgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/lib/systemd/systemd-cgroups-agent,name=systemd)cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_cls,net_prio)cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpu,cpuacct)cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb,release_agent=/run/cgmanager/agents/cgm-release-agent.hugetlb)cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset,clone_children)cgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer)cgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event,release_agent=/run/cgmanager/agents/cgm-release-agent.perf_event)cgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids,release_agent=/run/cgmanager/agents/cgm-release-agent.pids)cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)cgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)cgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)</code></pre><p>如果没有的话，也可以通过以下命令来把想要的 subsystem mount 到系统中：</p><pre><code>$ mount -t cgroup -o cpu,cpuset,memory cpu_and_mem /cgroup/cpu_and_mem</code></pre><p>上述命令表示把 cpu、cpuset、memory 三个子资源 mount 到 <code>/cgroup/cpu_and_mem</code> 目录下。</p><p>每个 cgroup 目录下面都会有描述该 cgroup 的文件，除了每个 cgroup 独特的资源控制文件，还有一些通用的文件：</p><ul><li><code>tasks</code>：当前 cgroup 包含的任务（task）pid 列表，把某个进程的 pid 添加到这个文件中就等于把进程移到该 cgroup</li><li><code>cgroup.procs</code>：当前 cgroup 中包含的 thread group 列表，使用逻辑和 <code>tasks</code> 相同</li><li><code>notify_on_release</code>：0 或者 1，是否在 cgroup 销毁的时候执行 notify。如果为 1，那么当这个 cgroup 最后一个任务离开时（退出或者迁移到其他 cgroup），并且最后一个子 cgroup 被删除时，系统会执行 <code>release_agent</code> 中指定的命令</li><li><code>release_agent</code>：需要执行的命令</li></ul><h4 id="创建-cgroup"><a href="#创建-cgroup" class="headerlink" title="创建 cgroup"></a>创建 cgroup</h4><p>创建 cgroup，可以直接用 <code>mkdir</code> 在对应的子资源中创建一个目录：</p><pre><code>➜  ~ mkdir /sys/fs/cgroup/cpu/mycgroup➜  ~ ls /sys/fs/cgroup/cpu/mycgroupcgroup.clone_children  cpuacct.stat   cpuacct.usage_percpu  cpu.cfs_quota_us  cpu.stat           taskscgroup.procs           cpuacct.usage  cpu.cfs_period_us     cpu.shares        notify_on_release</code></pre><p>上面命令在 cpu 子资源中创建了 <code>mycgroup</code>，创建 cgroup 之后，目录中会自动创建需要的文件。我们后面会详细讲解这些文件的含义，目前只需要知道它们能够控制对应子资源就行。</p><h4 id="删除-cgroup"><a href="#删除-cgroup" class="headerlink" title="删除 cgroup"></a>删除 cgroup</h4><p>删除子资源，就是删除对应的目录：</p><pre><code>$ rmdir /sys/fs/cgroup/cpu/mycgroup/</code></pre><p>删除之后，如果 tasks 文件中有进程，它们会自动迁移到父 cgroup 中。</p><h4 id="设置-cgroup-参数"><a href="#设置-cgroup-参数" class="headerlink" title="设置 cgroup 参数"></a>设置 cgroup 参数</h4><p>设置 group 的参数就是直接往特定的文件中写入特定格式的内容，比如要限制 cgroup 能够使用的 CPU 核数：</p><pre><code>$ echo 0-1 &gt; /sys/fs/cgroup/cpuset/mycgroup/cpuset.cpus</code></pre><h4 id="把进程加入到-cgroup"><a href="#把进程加入到-cgroup" class="headerlink" title="把进程加入到 cgroup"></a>把进程加入到 cgroup</h4><p>要把某个已经运行的进程加入到 cgroup，可以直接往需要的 cgroup tasks 文件中写入进程的 PID：</p><pre><code>$ echo 2358 &gt; /sys/fs/cgroup/memory/mycgroup/tasks</code></pre><h4 id="在-cgroup-中运行进程"><a href="#在-cgroup-中运行进程" class="headerlink" title="在 cgroup 中运行进程"></a>在 cgroup 中运行进程</h4><p>如果想直接把进程运行在某个 cgroup，但是运行前还不知道进程的 Pid 应该怎么办呢？</p><p>我们可以利用 cgroup 的继承方式来实现，因为子进程会继承父进程的  cgroup，因此我们可以把当前 shell 加入到要想的 cgroup：</p><pre><code>echo $$ &gt; /sys/fs/cgroup/cpu/mycgroup/tasks</code></pre><p>上面的方案有个缺陷，运行完之后原来的 shell 还在 cgroup 中。如果希望进程运行完不影响当前使用的 shell，可以另起一个临时的 shell：</p><pre><code>sh -c &quot;echo \$$ &gt; /sys/fs/cgroup/memory/mycgroup/tasks &amp; &amp; stress -m 1&quot;</code></pre><h4 id="把进程移动到-cgroup"><a href="#把进程移动到-cgroup" class="headerlink" title="把进程移动到 cgroup"></a>把进程移动到 cgroup</h4><p>如果想要把进程移动到另外一个 cgroup，只要使用 <code>echo</code> 把进程 PID 写入到 cgroup tasks 文件中即可，原来 cgroup tasks 文件会自动删除该进程。</p><h3 id="cgroup-tools"><a href="#cgroup-tools" class="headerlink" title="cgroup-tools"></a>cgroup-tools</h3><p><code>cgroup-tools</code> 软件包提供了一系列命令可以操作和管理 cgroup，ubuntu 系统中可以通过下面的命令安装：</p><pre class=" language-bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> -y cgroup-tools</code></pre><h4 id="列出-cgroup-mount-信息"><a href="#列出-cgroup-mount-信息" class="headerlink" title="列出 cgroup mount 信息"></a>列出 cgroup mount 信息</h4><p>最简单的，<code>lssubsys</code> 可以查看系统中存在的 subsystems：</p><pre><code>➜  ~ lssubsys -amcpuset /sys/fs/cgroup/cpusetcpu,cpuacct /sys/fs/cgroup/cpu,cpuacctblkio /sys/fs/cgroup/blkiomemory /sys/fs/cgroup/memorydevices /sys/fs/cgroup/devicesfreezer /sys/fs/cgroup/freezernet_cls,net_prio /sys/fs/cgroup/net_cls,net_prioperf_event /sys/fs/cgroup/perf_eventhugetlb /sys/fs/cgroup/hugetlbpids /sys/fs/cgroup/pids</code></pre><h4 id="创建-cgroup-1"><a href="#创建-cgroup-1" class="headerlink" title="创建 cgroup"></a>创建 cgroup</h4><p><code>cgcreate</code> 可以用来为用户创建指定的 cgroups：</p><pre><code>➜  sudo cgcreate -a cizixs -t cizixs -g cpu,memory:test1 ➜  ls cpu/test1 cgroup.clone_children  cpuacct.stat   cpuacct.usage_all     cpuacct.usage_percpu_sys   cpuacct.usage_sys   cpu.cfs_period_us  cpu.shares  notify_on_releasecgroup.procs           cpuacct.usage  cpuacct.usage_percpu  cpuacct.usage_percpu_user  cpuacct.usage_user  cpu.cfs_quota_us   cpu.stat    tasks</code></pre><p>上面的命令表示在 <code>/sys/fs/cgroup/cpu</code> 和 <code>/sys/fs/cgroup/memory</code> 目录下面分别创建 <code>test1</code> 目录，也就是为 cpu 和 memory 子资源创建对应的 cgroup。</p><ul><li>选项 <code>-t</code> 指定 <code>tasks</code> 文件的用户和组，也就是指定哪些人可以把任务添加到 cgroup 中，默认是从父 cgroup 继承</li><li><code>-a</code> 指定除了 <code>tasks</code> 之外所有文件（资源控制文件）的用户和组，也就是哪些人可以管理资源参数</li><li><code>-g</code> 指定要添加的 cgroup，冒号前是逗号分割的子资源类型，冒号后面是 cgroup 的路径（这个路径会添加到对应资源 mount 到的目录后面）。也就是说在特定目录下面添加指定的子资源</li></ul><h4 id="删除-cgroup-1"><a href="#删除-cgroup-1" class="headerlink" title="删除 cgroup"></a>删除 cgroup</h4><p>知道怎么创建，也要知道怎么删除。不然系统中保留着太多用不到的 cgroup 浪费系统资源，也会让管理很麻烦。</p><p><code>cgdelete</code> 可以删除对应的 cgroups，它和 <code>cgcreate</code> 命令类似，可以用 <code>-g</code> 指定要删除的 cgroup：</p><pre><code>➜  cgroup sudo cgdelete -g cpu,memory:test1</code></pre><p><code>cgdelete</code> 也提供了 <code>-r</code> 参数可以递归地删除某个 cgroup 以及它所有的子 cgroup。</p><p>如果被删除的 cgroup 中有任务，这些任务会自动移到父 cgroup 中。</p><h4 id="设置-cgroup-的参数"><a href="#设置-cgroup-的参数" class="headerlink" title="设置 cgroup 的参数"></a>设置 cgroup 的参数</h4><p><code>cgset</code> 命令可以设置某个子资源的参数，比如如果要限制某个 cgroup 中任务能使用的 CPU 核数：</p><pre><code>$ cgset -r cpuset.cpus=0-1 /mycgroup</code></pre><p><code>-r</code> 后面跟着参数的键值对，每个子资源能够配置的键值对都有自己的规定，我们会在后面详细解释。</p><p><code>cgset</code> 还能够把一个 cgroup 的参数拷贝到另外一个 cgroup 中：</p><pre><code>$ cgset --copy-from group1/ group2/</code></pre><p><strong>NOTE</strong>: cgset 如果设置没有成功也不会报错，请一定要注意。</p><h4 id="在某个-cgroup-中运行进程"><a href="#在某个-cgroup-中运行进程" class="headerlink" title="在某个 cgroup 中运行进程"></a>在某个 cgroup 中运行进程</h4><p><code>cgexec</code> 执行某个程序，并把程序添加到对应的 cgroups 中：</p><pre><code>➜  cgroup cgexec -g memory,cpu:cizixs bash</code></pre><p>cgroups 是可以有层级结构的，因此可以直接创建具有层级关系的 cgroup，然后运行在该 cgroup 中：</p><pre><code>$ cgcreate -g memory,cpu:groupname/foo$ cgexec -g memory,cpu:groupname/foo bash</code></pre><h4 id="把已经运行的进程移动到某个-cgroup"><a href="#把已经运行的进程移动到某个-cgroup" class="headerlink" title="把已经运行的进程移动到某个 cgroup"></a>把已经运行的进程移动到某个 cgroup</h4><p>要把某个已经存在的程序（能够知道它的 pid）移到某个 cgroup，可以使用 <code>cgclassify</code> 命令:</p><p>比如把当前 bash shell 移入到特定的 cgroup 中</p><pre><code>$ cgclassify -g memory,cpu:/mycgroup $$</code></pre><p><code>$$</code> 表示当前进程的 pid 号，上面命令可以方便地测试一些耗费内存或者 CPU 的进程，如果 /mycgroup 对 CPU 和 memory 做了限制。</p><p>这个命令也可以同时移动多个进程，它们 pid 之间用空格隔开：</p><pre><code>$ cgclassify -g cpu,memory:group1 1701 1138</code></pre><h2 id="cgroup-子资源参数详解"><a href="#cgroup-子资源参数详解" class="headerlink" title="cgroup 子资源参数详解"></a>cgroup 子资源参数详解</h2><p>每个 subssytem 负责系统的一部分资源管理，又分别提供多个参数可以控制，每个参数对应一个文件，往文件中写入特定格式的内容就能控制该资源。</p><h3 id="blkio：限制设备-IO-访问"><a href="#blkio：限制设备-IO-访问" class="headerlink" title="blkio：限制设备 IO 访问"></a>blkio：限制设备 IO 访问</h3><p>限制磁盘 IO 有两种方式：权重（weight）和上限（limit）。权重是给不同的应用（或者 cgroup）一个权重值，各个应用按照百分比来使用 IO 资源；上限是直接写死应用读写速率的最大值。</p><p><strong>设置 cgroup 访问设备的权重</strong>：</p><p>设置的权重并不能保证什么，当只有某个应用在读写磁盘时，不管它权重多少，都能使用磁盘。只有当多个应用同时读写磁盘时，才会根据权重为应用分配读写的速率。</p><ul><li><code>blkio.weight</code>：设置 cgroup 读写设备的权重，取值范围在 100-1000</li><li><code>blkio.weight_device</code>：设置 cgroup 使用某个设备的权重。当访问该设备时，它会使用当前值，覆盖 <code>blkio.weight</code> 的值。内容的格式为 <code>major:minor weight</code>，前面是设备的 major 和 minor 编号，用来唯一表示一个设备，后面是 100-1000 之间的整数值。设备号的分配可以参考：<a href="https://www.kernel.org/doc/html/v4.11/admin-guide/devices.html" target="_blank" rel="noopener">https://www.kernel.org/doc/html/v4.11/admin-guide/devices.html</a></li></ul><p><strong>设置 cgroup 访问设备的限制</strong>：</p><p>除了设置权重之外，还能设置 cgroup 磁盘的使用上限，保证 cgroup 中的进程读写磁盘的速率不会超过某个值。</p><ul><li><code>blkio.throttle.read_bps_device</code>：最多每秒钟从设备读取多少字节</li><li><code>blkio.throttle.read_iops_device</code>：最多每秒钟从设备中执行多少次读操作</li><li><code>blkio.throttle.write_bps_device</code>：最多每秒钟可以往设备写入多少字节</li><li><code>blkio.throttle.write_iops_device</code>：最多每秒钟可以往设备执行多少次写操作</li></ul><p>读写字节数的限制格式一样 <code>major:minor bytes_per_second</code>，前面两个数字代表某个设备，后面跟着一个整数，代表每秒读写的字节数，单位为比特，如果需要其他单位（KB、MB等）需要自行转换。比如要限制 <code>/dev/sda</code> 读速率上线为 10 Mbps，可以运行：</p><pre><code>$ echo &quot;8:0 10485760&quot; &gt;/sys/fs/cgroup/blkio/mygroup/blkio.throttle.read_bps_device</code></pre><p><code>iops</code> 代表 IO per second，是每秒钟执行读写的次数，格式为 <code>major:minor operations_per_second</code>。比如，要限制每秒只能写 10 次，可以运行：</p><pre><code>$ echo &quot;8:0 10&quot; &gt;/sys/fs/cgroup/blkio/mygroup/blkio.throttle.write_iops_device</code></pre><p>除了限制磁盘使用之外，blkio 还提供了 throttle 规则下磁盘使用的统计数据。</p><ul><li><code>blkio.throttle.io_serviced</code>：cgroup 中进程读写磁盘的次数，文件中内容格式为 <code>major:minor operation number</code>，表示对磁盘进行某种操作（read、write、sync、async、total）的次数</li><li><code>blkio.throttle.io_service_bytes</code>：和上面类似，不过这里保存的是操作传输的字节数</li><li><code>blkio.reset_stats</code>：重置统计数据，往该文件中写入一个整数值即可</li><li><code>blkio.time</code>：统计 cgroup 对各个设备的访问时间，格式为 <code>major:minor milliseconds</code></li><li><code>blkio.io_serviced</code>：CFQ 调度器下，cgroup 对设备的各种操作次数，和 <code>blkio.throttle.io_serviced</code> 刚好相反，所有不是 throttle 下的请求</li><li><code>blkio.io_services_bytes</code>：CFQ 调度器下，cgroup 对各种设备的操作字节数</li><li><code>blkio.sectors</code>：cgroup 中传输的扇区次数，格式为 <code>major:minor sector_count</code></li><li><code>blkio.queued</code>：cgroup IO 请求进队列的次数，格式为 <code>number operation</code></li><li><code>blkio.dequeue</code>：cgroup 的 IO 请求被设备出队列的次数，格式为 <code>major:minor number</code></li><li><code>blkio.avg_queue_size</code>：</li><li><code>blkio.merged</code>：cgroup 把 BIOS 请求合并到 IO 操作请求的次数，格式为 <code>number operation</code></li><li><code>blkio.io_wait_time</code>：cgroup 等待队列服务的时间</li><li><code>blkio.io_service_time</code>：CFQ 调度器下，cgroup 处理请求的时间（从请求开始调度，到 IO 操作完成）</li></ul><h3 id="cpu：限制进程组-CPU-使用"><a href="#cpu：限制进程组-CPU-使用" class="headerlink" title="cpu：限制进程组 CPU 使用"></a>cpu：限制进程组 CPU 使用</h3><p>CPU 子资源可以管理 cgroup 中任务使用 CPU 的行为，任务使用 CPU 资源有两种调度方式：完全公平调度（CFS，Completely Fair Scheduler）和 实时调度（RT，Real-Time Scheduler）。前者可以根据权重为任务分配响应的 CPU 时间片，后者能够限制使用 CPU 的核数。</p><p><strong>CFS 调优参数：</strong></p><p>CFS 调度下，每个 cgroup 都会分配一个权重，但是这个权重并不能保证任务使用 CPU 的具体数据。如果只有一个进程在运行（理论上，现实中机器上不太可能只有一个进程），不管它所在 cgroup 对应的 CPU 权重是多少，都能使用所有的 CPU 资源；在 CPU 资源紧张的情况，内核会根据 cgroup 的权重按照比例分配个给任务各自使用 CPU 的时间片。</p><p>CFS 调度模式下，也可以给 cgroup 分配一个使用上限，限制任务能使用 CPU 的核数。</p><p>设置 CPU 数字的单位都是微秒（microsecond），用 us 表示。</p><ul><li><code>cpu.cfs_quota_us</code>：每个周期 cgroup 中所有任务能使用的 CPU 时间，默认为 <code>-1</code>，表示不限制 CPU 使用。需要配合 <code>cpu.cfs_period_us</code> 一起使用，一般设置为 <code>100000</code>（docker 中设置的值）</li><li><code>cpu.cfs_period_us</code>：每个周期中 cgroup 任务可以使用的时间周期，如果想要限制 cgroup 任务每秒钟使用 0.5 秒 CPU，可以在 <code>cpu.cfs_quota_us</code> 为 <code>100000</code> 的情况下把它设置为 <code>50000</code>。如果它的值比 <code>cfs_quota_us</code> 大，表明进程可以使用多个核 CPU，比如 <code>200000</code> 表示进程能够使用 <code>2.0</code> 核</li><li><code>cpu.stat</code>：CPU 使用的统计数据，<code>nr_periods</code> 表示已经过去的时间周期；<code>nr_throttled</code> 表示 cgroup 中任务被限制使用 CPU 的次数（因为超过了规定的上限）；<code>throttled_time</code> 表示被限制的总时间</li><li><code>cpu.shares</code>：cgroup 使用 CPU 时间的权重值。如果两个 cgroup 的权重都设置为 100，那么它们里面的任务同时运行时，使用 CPU 的时间应该是一样的；如果把其中一个权重改为 200，那么它能使用的 CPU 时间将是对方的两倍。</li></ul><p><strong>RT 调度模式下的参数：</strong></p><p>RT 调度模式下和 CFS 中上限设置类似，区别是它只是限制实时任务的 CPU。</p><ul><li><code>cpu.rt_period_us</code>：设置一个周期时间，表示多久 cgroup 能够重新分配 CPU 资源</li><li><code>cpu.rt_runtime_us</code>：设置运行时间，表示在周期时间内 cgroup 中任务能访问 CPU 的时间。这个限制是针对单个 CPU 核数的，如果是多核，需要乘以对应的核数</li></ul><h3 id="cpuacct：-任务使用-CPU-情况统计"><a href="#cpuacct：-任务使用-CPU-情况统计" class="headerlink" title="cpuacct： 任务使用 CPU 情况统计"></a>cpuacct： 任务使用 CPU 情况统计</h3><p>cpuacct 不做任何资源限制，它的功能是资源统计，自动地统计 cgroup 中任务对 CPU 资源的使用情况，统计数据也包括子 cgroup 中的任务。</p><ul><li><code>cpuacct.usage</code>：该 cgroup 中所有任务（包括子 cgroup 中的任务，下同）总共使用 CPU 的时间，单位是纳秒（ns）。往文件中写入 <code>0</code> 可以重置统计数据</li><li><code>cpuacct.stat</code>：该 cgroup 中所有任务使用 CPU 的user 和 system 时间，也就是用户态 CPU 时间和内核态 CPU 时间</li><li><code>cpuacct.usage_percpu</code>：该 cgroup 中所有任务使用各个 CPU 核数的时间，单位为纳秒（ns）</li></ul><h3 id="cpuset-cpu-绑定"><a href="#cpuset-cpu-绑定" class="headerlink" title="cpuset: cpu 绑定"></a>cpuset: cpu 绑定</h3><p>除了限制 CPU 的使用量，cgroup 还能把任务绑定到特定的 CPU，让它们只运行在这些 CPU 上，这就是 <code>cpuset</code> 子资源的功能。除了 CPU 之外，还能绑定内存节点（memory node）。</p><p><strong>NOTE：</strong>在把任务加入到 cpuset 的 task 文件之前，用户必须设置 <code>cpuset.cpus</code> 和 <code>cpuset.mems</code> 参数。</p><ul><li><code>cpuset.cpus</code>：设置 cgroup 中任务能使用的 CPU，格式为逗号（<code>,</code>）隔开的列表，减号（<code>-</code>）可以表示范围。比如，<code>0-2,7</code> 表示 CPU 第 0，1，2，和 7 核。</li><li><code>cpuset.mems</code>：设置 cgroup 中任务能使用的内存节点，和 <code>cpuset.cpus</code> 格式一样</li></ul><p>上面两个是最常用的参数，<code>cpuset</code> 中有很多其他参数，需要对 CPU 调度机制有深入的了解，很少用到，而且我也不懂，所以就不写了，具体可以参考参考文档中 RedHat 网站。</p><h3 id="memory：限制内存使用"><a href="#memory：限制内存使用" class="headerlink" title="memory：限制内存使用"></a>memory：限制内存使用</h3><p>memory 子资源系统能限制 cgroup 中任务对内存的使用，也能生成它们使用数据的报告。</p><p><strong>控制内存使用：</strong></p><ul><li><code>memory.limit_in_bytes</code>：cgroup 能使用的内存上限值，默认为字节；也可以添加 <code>k/K</code>、<code>m/M</code> 和 <code>g/G</code> 单位后缀。往文件中写入 <code>-1</code> 来移除设置的上限，表示不对内存做限制</li><li><code>memory.memsw.limit_in_bytes</code>：cgroup 能使用的内存加 swap 上限，用法和上面一样。写入 <code>-1</code> 来移除上限</li><li><code>memory.failcnt</code>：任务使用内存量达到 <code>limit_in_bytes</code> 上限的次数</li><li><code>memory.memsw.failcnt</code>：任务使用内存加 swap 量达到 <code>memsw.limit_in_bytes</code> 上限的次数</li><li><code>memory.soft_limit_in_bytes</code>：设置内存软上限。如果内存充足， cgroup 中的任务可以用到 <code>memory.limit_in_bytes</code> 设定的内存上限；当时当内存资源不足时，内核会让任务使用的内存不超过 <code>soft_limit_in_bytes</code> 中的值。文件内容的格式和 <code>limit_in_bytes</code> 一样</li><li><code>memory.swappiness</code>：设置内核 swap out 进程内存（而不是从 page cache 中回收页） 的倾向。默认值为 60，低于 60 表示降低倾向，高于 60 表示增加倾向；如果值高于 100，表示允许内核 swap out 进程地址空间的页。如果值为 0 表示倾向很低，而不是禁止该行为。</li></ul><p><strong>OOM 操作：</strong></p><p>OOM 是 out of memory 的缩写，可以翻译成内存用光。cgroup 可以控制内存用完之后应该怎么处理进程，默认情况下，用光内存的进程会被杀死。</p><p><code>memory.oom_control</code>：是否启动 OOM killer，如果启动（值为 0，是默认情况）超过内存限制的进程会被杀死；如果不启动（值为 1），使用超过限定内存的进程不会被杀死，而是被暂停，直到它释放了内存能够被继续使用。</p><p><strong>统计内存使用情况：</strong></p><ul><li><code>memory.stat</code>：汇报内存的使用情况，里面的数据包括：<ul><li><code>cache</code>：页缓存（page cache）字节数，包括 tmpfs（shmem）</li><li><code>rss</code>：匿名和 swap cache 字节数，不包括 tmpfs</li><li><code>mapped_file</code>：内存映射（memory-mapped）的文件大小，包括 tmpfs，单位是字节</li><li><code>pgpgin</code>: paged into 内存的页数</li><li><code>pgpgout</code>：paged out 内存的页数</li><li><code>swap</code>：使用的 swap 字节数</li><li><code>active_anon</code>：活跃的 LRU 列表中匿名和 swap 缓存的字节数，包括 tmpfs</li><li><code>inactive_anon</code>：不活跃的 LRU 列表中匿名和 swap 缓存的字节数，包括 tmpfs</li><li><code>active_file</code>：活跃 LRU 列表中文件支持的（file-backed）的内存字节数</li><li><code>inactive_file</code>：不活跃列表中文件支持的（file-backed）的内存字节数</li><li><code>unevictable</code>：不可以回收的内存字节数</li></ul></li><li><code>memory.usage_in_bytes</code>：cgroup 中进程当前使用的总内存字节数</li><li><code>memory.memsw.usage_in_bytes</code>：cgroup 中进程当前使用的总内存加上总 swap 字节数</li><li><code>memory.max_usage_in_bytes</code>：cgroup 中进程使用的最大内存字节数</li><li><code>memory.memsw.max_usage_in_bytes</code>：cgroup 中进程使用的最大内存加 swap 字节数</li></ul><h3 id="net-cls：为网络报文分类"><a href="#net-cls：为网络报文分类" class="headerlink" title="net_cls：为网络报文分类"></a>net_cls：为网络报文分类</h3><p><code>net_cls</code> 子资源能够给网络报文打上一个标记（classid），这样内核的 tc（traffic control）模块就能根据这个标记做流量控制。</p><p><code>net_cls.classid</code>：包含一个整数值。从文件中读取是的十进制，写入的时候需要是十六进制。比如，<code>0x100001</code> 写入到文件中，读取的将是 <code>1048577</code>， <code>ip</code> 命令操作的形式为 <code>10:1</code>。</p><p>这个值的格式为 <code>0xAAAABBBB</code>，一共 32 位，分成前后两个部分，前置的 0 可以忽略，因此 <code>0x10001</code> 和 <code>0x00010001</code> 一样，表示为 <code>1:1</code>。</p><h3 id="net-prio：网络报文优先级"><a href="#net-prio：网络报文优先级" class="headerlink" title="net_prio：网络报文优先级"></a>net_prio：网络报文优先级</h3><p><code>net_prio</code>（Network Priority）子资源能够动态设置 cgroup 中应用在网络接口的优先级。网络优先级是报文的一个属性值，<code>tc</code>可以设置网络的优先级，socket 也可以通过 <code>SO_PRIORITY</code> 选项设置它（但是很少应用会这么做）。</p><ul><li><code>net_prio.prioidx</code>：只读文件，里面包含了一个整数值，内核用来标识这个 cgroup</li><li><code>net_prio.ifpriomap</code>：网络接口的优先级，里面可以包含很多行，用来为从网络接口中发出去的报文设置优先级。每行的格式为 <code>network_interface priority</code>，比如 <code>echo &quot;eth0 5&quot; &gt; /sys/fs/cgroup/net_prio/mycgroup/net_prio.ifpriomap</code></li></ul><h3 id="devices：设备黑白名单"><a href="#devices：设备黑白名单" class="headerlink" title="devices：设备黑白名单"></a>devices：设备黑白名单</h3><p>device 子资源可以允许或者阻止 cgroup 中的任务访问某个设备，也就是黑名单和白名单的作用。</p><ul><li><code>devices.allow</code>：cgroup 中的任务能够访问的设备列表，格式为 <code>type major:minor access</code>，<ul><li><code>type</code> 表示类型,可以为 <code>a</code>(all), <code>c</code>(char), <code>b</code>(block）</li><li><code>major:minor</code> 代表设备编号，两个标号都可以用<code>*</code> 代替表示所有，比如 <code>*:*</code> 代表所有的设备</li><li><code>accss</code> 表示访问方式，可以为 <code>r</code>(read),<code>w</code>(write), <code>m</code>(mknod) 的组合</li></ul></li><li><code>devices.deny</code>：cgroup 中任务不能访问的设备，和上面的格式相同</li><li><code>devices.list</code>：列出 cgroup 中设备的黑名单和白名单</li></ul><h3 id="freezer"><a href="#freezer" class="headerlink" title="freezer"></a>freezer</h3><p><code>freezer</code> 子资源比较特殊，它并不和任何系统资源相关，而是能暂停和恢复 cgroup 中的任务。</p><ul><li><code>freezer.state</code>：这个文件值存在于非根 cgroup 中（因为所有的任务默认都在根 cgroup 中，停止所有的任务显然是错误的行为），里面的值表示 cgroup 中进程的状态：<ul><li><code>FROZEN</code>：cgroup 中任务都被挂起（暂停）</li><li><code>FREEZING</code>：cgroup 中任务正在被挂起的过程中</li><li><code>THAWED</code>：cgroup 中的任务已经正常恢复</li></ul></li></ul><p>要想挂起某个进程，需要先把它移动到某个有 freezer 的 cgroup 中，然后 Freeze 这个 cgroup。</p><p><strong>NOTE:</strong>如果某个 cgroup 处于挂起状态，不能往里面添加任务。用户可以写入 <code>FROZEN</code> 和 <code>THAWED</code> 来控制进程挂起和恢复，<code>FREEZING</code> 不受用户控制。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>cgroup 提供了强大的功能，能够让我们控制应用的资源使用情况，也能统计资源使用数据，是容器技术的基础。但是 cgroup 整个系统也很复杂，甚至显得有些混乱，目前 cgroup 整个在被重写，新的版本被称为 cgroup V2，而之前的版本也就被称为了 V1。</p><p>cgroup 本身并不提供对网络资源的使用控制，只能添加简单的标记和优先级，具体的控制需要借助 linux 的 TC 模块来实现。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://events.linuxfoundation.org/sites/events/files/slides/cgroups_0.pdf" target="_blank" rel="noopener">An introduction to cgroups and cgroupspy</a></li><li><a href="http://www.novell.com/feeds/nih/wp-content/uploads/2012/05/SUS15_lec.pdf" target="_blank" rel="noopener">LXC, Cgroups and Advanced Linux Container Technology Lecture</a></li><li><a href="https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Resource_Management_Guide/ch-Subsystems_and_Tunable_Parameters.html" target="_blank" rel="noopener">redhat doc:Subsystems and Tunable Parameters</a></li><li><a href="http://www.infoq.com/cn/articles/docker-kernel-knowledge-cgroups-resource-isolation" target="_blank" rel="noopener">Docker背后的内核知识——cgroups资源限制</a></li><li><a href="http://www.infoq.com/cn/articles/docker-resource-management-cgroups" target="_blank" rel="noopener">Docker资源管理探秘：Docker背后的内核Cgroups机制</a></li><li><a href="https://www.kernel.org/doc/Documentation/cgroup-v1/cgroups.txt" target="_blank" rel="noopener">Linux 内核 cgroups 简介</a></li><li><a href="http://files.cnblogs.com/files/lisperl/cgroups%E4%BB%8B%E7%BB%8D.pdf" target="_blank" rel="noopener">王喆锋： Linux Cgroups 详解</a></li><li><a href="http://events.linuxfoundation.org/sites/events/files/slides/2014-KLF.pdf" target="_blank" rel="noopener">Linux Cgroups V2 设计</a></li><li><a href="https://lwn.net/Articles/679786/" target="_blank" rel="noopener">Understanding the new control groups API</a></li><li><a href="http://www.haifux.org/lectures/299/netLec7.pdf" target="_blank" rel="noopener">Resource Management: Linux Kernel Namespaces and cgroups – Rami Rosen</a></li><li><a href="https://en.wikipedia.org/wiki/Cgroups" target="_blank" rel="noopener">wikipedia cgroups page</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;Linux cgroups 的全称是 Linux Control Groups，它是 Linux 内核的特性，主要作用是&lt;strong&gt;限制、记录和隔离进程组（process groups）使用的物理资源（cpu、memory、IO
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="linux" scheme="http://cizixs.com/tags/linux/"/>
    
      <category term="docker" scheme="http://cizixs.com/tags/docker/"/>
    
      <category term="container" scheme="http://cizixs.com/tags/container/"/>
    
      <category term="kernel" scheme="http://cizixs.com/tags/kernel/"/>
    
      <category term="cgroup" scheme="http://cizixs.com/tags/cgroup/"/>
    
  </entry>
  
  <entry>
    <title>docker 容器网络下 UDP 协议的一个问题</title>
    <link href="http://cizixs.com/2017/08/21/docker-udp-issue/"/>
    <id>http://cizixs.com/2017/08/21/docker-udp-issue/</id>
    <published>2017-08-20T16:00:00.000Z</published>
    <updated>2018-09-17T13:18:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近在工作中遇到一个 docker 容器下 UDP 协议网络不通的问题，困扰了很久，也比较有意思，所以想写下来和大家分享。</p><p>我们有个应用是 UDP 协议的，部署上去发现无法工作，但是换成 TCP 协议是可以的（应用同时支持 UDP、TCP 协议，切换成 TCP 模式发现一切正常）。虽然换成 TCP 能解决问题，但是我们还是想知道到底 UDP 协议在网络模式下为什么会出现这个问题，以防止后面其他 UDP 应用会有异常。</p><p>这个问题抽象出来是这样的：如果有 UDP 服务运行在主机上（或者运行在网络模型为 Host 的容器里），并且监听在 <code>0.0.0.0</code> 地址（也就是所有的 ip 地址），从运行在 docker bridge 网络的容器运行客户端访问服务，两者通信有问题。</p><p>注意以上的的限制条件，通过测试，我们发现下来几种情况都是正常的：</p><ul><li>使用 TCP 协议没有这个问题，这个已经说过了</li><li>如果 UDP 服务器监听在 eth0 IP 地址上也不会出现这个问题</li><li>并不是所有的应用都有这个问题，我们的 DNS（dnsmasq + kubeDNS） 也是同样的部署方式，但是功能都正常</li></ul><p>这个问题在 docker 上也有 issue 记录：<a href="https://github.com/moby/moby/issues/15127，但是目前并没有合理的解决方案。" target="_blank" rel="noopener">https://github.com/moby/moby/issues/15127，但是目前并没有合理的解决方案。</a></p><p>这篇文章就分析一下出现这个问题的原因，希望给同样遇到这个问题的读者提供些帮助。</p><h2 id="问题重现"><a href="#问题重现" class="headerlink" title="问题重现"></a>问题重现</h2><p>这个问题很容易重现，我的实验是在 ubuntu16.04 下用 <code>netcat</code> 命令完成的，其他系统应该类似。在主机上通过 nc 监听 56789 端口，然后在容器里使用 <code>nc</code> 发数据。第一个报文是能发送出去的，但是以后的报文虽然在网络上能看到，但是对方无法接收。</p><p>在主机上运行 nc UDP 服务器（<code>-u</code> 表示 UDP 协议，<code>-l</code> 表示监听的端口）</p><pre><code>$ nc -ul 56789</code></pre><p>然后启动一个容器，运行客户端：</p><pre><code>$ docker run -it apline sh/ # nc -u 172.16.13.13 56789</code></pre><p>nc 的通信是双方的，不管对方输入什么字符，回车后对方就能立即收到。但是在这个模式下，客户端第一次输入对方能够收到，后续的报文对方都收不到。</p><p>在这个实验中，容器使用的是 docker 的默认网络，容器的 ip 是 172.17.0.3，通过 veth pair（图中没有显示）连接到虚拟网桥 docker0（ip 地址为 172.17.0.1），主机本身的网络为 eth0，其 ip 地址为 172.16.13.13。</p><pre><code> 172.17.0.3+----------+|   eth0   |+----+-----+     |     |     |     |+----+-----+          +----------+| docker0  |          |  eth0    |+----------+          +----------+172.17.0.1            172.16.13.13</code></pre><h2 id="tcpdump-抓包"><a href="#tcpdump-抓包" class="headerlink" title="tcpdump 抓包"></a>tcpdump 抓包</h2><p>遇到这种疑难杂症，第一个想到的抓包，我们需要在 docker0 上抓包，因为这是报文必经过的地方。通过过滤容器的 ip 地址，很容器找到感兴趣的报文：</p><pre><code>$ tcpdump -i docker0 -nn host 172.17.0.3</code></pre><p>为了模拟多数应用一问一答的通信方式，我们一共发送三个报文，并用 tcpdump 抓取 docker0 接口上的报文：</p><ol><li>客户端先向服务器端发送 <code>hello</code> 字符串</li><li>服务器端回复 <code>world</code> </li><li>客户端继续发送 <code>hi</code> 消息</li></ol><p>抓包的结果如下，可以发现第一个报文发送出去没有任何问题（因为 UDP 是没有 ACK 报文的，所以客户端无法知道对方有没有收到，这里说的没有问题是值没有对应的 ICMP 报文），但是第二个报文从服务端发送的报文，对方会返回一个 <code>ICMP</code> 告诉端口 38908 不可达；第三个报文从客户端发送的报文也是如此。以后的报文情况类似，双方再也无法进行通信了。</p><pre><code>11:20:43.973286 IP 172.17.0.3.38908 &gt; 172.16.13.13.56789: UDP, length 611:20:50.102018 IP 172.17.0.1.56789 &gt; 172.17.0.3.38908: UDP, length 611:20:50.102129 IP 172.17.0.3 &gt; 172.17.0.1: ICMP 172.17.0.3 udp port 38908 unreachable, length 4211:20:54.503198 IP 172.17.0.3.38908 &gt; 172.16.13.13.56789: UDP, length 311:20:54.503242 IP 172.16.13.13 &gt; 172.17.0.3: ICMP 172.16.13.13 udp port 56789 unreachable, length 39</code></pre><p>而此时主机上 UDP nc 服务器并没有退出，使用 <code>lsof -i :56789</code> 可能看到它仍然在监听着该端口。</p><h2 id="问题原因"><a href="#问题原因" class="headerlink" title="问题原因"></a>问题原因</h2><p>从网络报文的分析中可以看到服务端返回的报文源地址不是我们预想的 eth0 地址，而是 docker0 的地址，而客户端直接认为该报文是非法的，返回了 ICMP 的报文给对方。</p><p>那么问题的原因也可以分为两个部分：</p><ol><li>为什么应答报文源地址是<strong>错误的</strong>？</li><li>既然 UDP 是无状态的，内核怎么判断源地址不正确呢？</li></ol><h3 id="主机多网络接口-UDP-源地址选择问题"><a href="#主机多网络接口-UDP-源地址选择问题" class="headerlink" title="主机多网络接口 UDP 源地址选择问题"></a>主机多网络接口 UDP 源地址选择问题</h3><p>第一个问题的关键词是：UDP 和多网络接口。因为如果主机上只有一个网络接口，发出去的报文源地址一定不会有错；而我们也测试过 TCP 协议是能够处理这个问题的。</p><p>通过搜索，发现这确实是个已知的问题。在 UNP（） 这本书中，已经描述过这个问题，下面是对应的内容：</p><p><img src="https://ws3.sinaimg.cn/large/006tKfTcgy1fiqmdohed0j31kw1je1kl.jpg" alt=""></p><p>这个问题可以归结为一句话：UDP 在多网卡的情况下，可能会发生服务器端源地址不对的情况，这是内核选路的结果。<br>为什么 UDP 和 TCP 有不同的选路逻辑呢？因为 UDP 是无状态的协议，内核不会保存连接双方的信息，因此每次发送的报文都认为是独立的，socket 层每次发送报文默认情况不会指明要使用的源地址，只是说明对方地址。因此，内核会为要发出去的报文选择一个 ip，这通常都是报文路由要经过的设备 ip 地址。</p><p>有了这个原因，还要解释一下问题：<strong>为什么 dnsmasq 服务没有这个问题呢</strong>？因此我使用 <code>strace</code> 工具抓取了 dnsmasq 和出问题应用的网络 socket 系统调用，来查看它们两个到底有什么区别。</p><p>dnsmasq 在启动阶段监听了 UDP 和 TCP 的 54 端口（因为是在本地机器上测试的，为了防止和本地 DNS 监听的<br>DNS端口冲突，我选择了 54 而不是标准的 53 端口）：</p><pre><code>socket(PF_INET, SOCK_DGRAM, IPPROTO_IP) = 4setsockopt(4, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0bind(4, {sa_family=AF_INET, sin_port=htons(54), sin_addr=inet_addr(&quot;0.0.0.0&quot;)}, 16) = 0setsockopt(4, SOL_IP, IP_PKTINFO, [1], 4) = 0socket(PF_INET, SOCK_STREAM, IPPROTO_IP) = 5setsockopt(5, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0bind(5, {sa_family=AF_INET, sin_port=htons(54), sin_addr=inet_addr(&quot;0.0.0.0&quot;)}, 16) = 0listen(5, 5)                            = 0</code></pre><p>比起 TCP，UDP 部分少了 <code>listen</code>，但是多个 <code>setsockopt(4, SOL_IP, IP_PKTINFO, [1], 4)</code> 这句。到底这两点和我们的问题是否有关，先暂时放着，继续看传输报文的部分。</p><p>dnsmasq 收包和发包的系统调用，直接使用 <code>recvmsg</code> 和 <code>sendmsg</code> 系统调用：</p><pre><code>recvmsg(4, {msg_name(16)={sa_family=AF_INET, sin_port=htons(52072), sin_addr=inet_addr(&quot;10.111.59.4&quot;)}, msg_iov(1)=[{&quot;\315\n\1 \0\1\0\0\0\0\0\1\fterminal19-0\5u5016\3&quot;..., 4096}], msg_controllen=32, {cmsg_len=28, cmsg_level=SOL_IP, cmsg_type=, ...}, msg_flags=0}, 0) = 67sendmsg(4, {msg_name(16)={sa_family=AF_INET, sin_port=htons(52072), sin_addr=inet_addr(&quot;10.111.59.4&quot;)}, msg_iov(1)=[{&quot;\315\n\201\200\0\1\0\1\0\0\0\1\fterminal19-0\5u5016\3&quot;..., 83}], msg_controllen=28, {cmsg_len=28, cmsg_level=SOL_IP, cmsg_type=, ...}, msg_flags=0}, 0) = 83</code></pre><p>而出问题的应用 <code>strace</code> 结果如下：</p><pre><code>[pid   477] socket(PF_INET6, SOCK_DGRAM, IPPROTO_IP) = 124[pid   477] setsockopt(124, SOL_IPV6, IPV6_V6ONLY, [0], 4) = 0[pid   477] setsockopt(124, SOL_IPV6, IPV6_MULTICAST_HOPS, [1], 4) = 0[pid   477] bind(124, {sa_family=AF_INET6, sin6_port=htons(6088), inet_pton(AF_INET6, &quot;::&quot;, &amp;sin6_addr), sin6_flowinfo=0, sin6_scope_id=0}, 28) = 0[pid   477] getsockname(124, {sa_family=AF_INET6, sin6_port=htons(6088), inet_pton(AF_INET6, &quot;::&quot;, &amp;sin6_addr), sin6_flowinfo=0, sin6_scope_id=0}, [28]) = 0[pid   477] getsockname(124, {sa_family=AF_INET6, sin6_port=htons(6088), inet_pton(AF_INET6, &quot;::&quot;, &amp;sin6_addr), sin6_flowinfo=0, sin6_scope_id=0}, [28]) = 0[pid   477] recvfrom(124, &quot;j\201\2450\201\242\241\3\2\1\5\242\3\2\1\n\243\0160\f0\n\241\4\2\2\0\225\242\2\4\0&quot;..., 2048, 0, {sa_family=AF_INET6, sin6_port=htons(38790), inet_pton(AF_INET6, &quot;::ffff:172.17.0.3&quot;, &amp;sin6_addr), sin6_flowinfo=0, sin6_scope_id=0}, [28]) = 168[pid   477] sendto(124, &quot;k\202\2\0210\202\2\r\240\3\2\1\5\241\3\2\1\v\243\5\33\3TDH\244\0220\20\240\3\2&quot;..., 533, 0, {sa_family=AF_INET6, sin6_port=htons(38790), inet_pton(AF_INET6, &quot;::ffff:172.17.0.3&quot;, &amp;sin6_addr), sin6_flowinfo=0, sin6_scope_id=0}, 28) = 533</code></pre><p>其对应的逻辑是这样的：使用 ipv6 绑定在 <code>0.0.0.0</code> 和 6088 端口，调用 <code>getsockname</code> 获取当前 socket 绑定的端口信息，数据传输过程使用的是 <code>recvfrom</code> 和 <code>sendto</code>。</p><p>对比下来，两者的不同有几点：</p><ul><li>后者使用的是 ipv6，而前者是 ipv4</li><li>后者使用 <code>recvfrom</code> 和 <code>sendto</code> 传输数据，而前者是 <code>sendmsg</code> 和 <code>recvmsg</code></li><li>前者有调用 <code>setsockopt</code> 设置 <code>IP_PKTINFO</code> 的值，而后者没有</li></ul><p>因为是在传输数据的时候出错的，因此第一个疑点是 <code>sendmsg</code>  和 <code>sendto</code> 的某些区别导致选择源地址有不同，通过 <code>man sendto</code> 可以知道 <code>sendmsg</code> 包含了更多的控制信息在 <code>msghdr</code>。一个合理的猜测是 <code>msghdr</code> 中包含了内核选择源地址的信息！</p><p>通过查找，发现 <code>IP_PKTINFO</code> 这个选项就是让内核在 socket 中保存 IP 报文的信息，当然也包括了报文的源地址和目的地址。<code>IP_PKTINFO</code> 和 <code>msghdr</code> 的关系可以在这个 stackoverflow 中找到：<a href="https://stackoverflow.com/questions/3062205/setting-the-source-ip-for-a-udp-socket。" target="_blank" rel="noopener">https://stackoverflow.com/questions/3062205/setting-the-source-ip-for-a-udp-socket。</a></p><p>而 <code>man 7 ip</code> 文档中也说明了 <code>IP_PKTINFO</code> 是怎么控制源地址选择的：</p><pre><code>IP_PKTINFO (since Linux 2.2)              Pass  an  IP_PKTINFO  ancillary message that contains a pktinfo structure that supplies some information about the incoming packet.  This only works for datagram ori‐              ented sockets.  The argument is a flag that tells the socket whether the IP_PKTINFO message should be passed or not.  The message itself can only be sent/retrieved as              control message with a packet using recvmsg(2) or sendmsg(2).                  struct in_pktinfo {                      unsigned int   ipi_ifindex;  /* Interface index */                      struct in_addr ipi_spec_dst; /* Local address */                      struct in_addr ipi_addr;     /* Header Destination                                                      address */                  };              ipi_ifindex  is the unique index of the interface the packet was received on.  ipi_spec_dst is the local address of the packet and ipi_addr is the destination address              in the packet header.  If IP_PKTINFO is passed to sendmsg(2) and ipi_spec_dst is not zero, then it is used as the local source address for the  routing  table  lookup              and  for  setting up IP source route options.  When ipi_ifindex is not zero, the primary local address of the interface specified by the index overwrites ipi_spec_dst              for the routing table lookup.</code></pre><p>如果 <code>ipi_spec_dst</code> 和 <code>ipi_ifindex</code> 不为空，它们都能作为源地址选择的依据，而不是让内核通过路由决定。</p><p>也就是说，通过设置 <code>IP_PKTINFO</code> socket 选项为 1，然后使用 <code>recvmsg</code> 和 <code>sendmsg</code> 传输数据就能保证源地址选择符合我们的期望。这也是 dnsmasq 使用的方案，而出问题的应用是因为使用了默认的 <code>recvfrom</code> 和 <code>sendto</code>。</p><h3 id="关于-UDP-连接的疑惑"><a href="#关于-UDP-连接的疑惑" class="headerlink" title="关于 UDP 连接的疑惑"></a>关于 UDP 连接的疑惑</h3><p>另外一个疑惑是：为什么内核会把源地址和之前不同的报文丢弃？认为它是非法的？因为我们前面已经说过，UDP 协议是无连接的，默认情况下 socket 也不会保存双方连接的信息。即使服务端发送报文的源地址有误，只要对方能正常接收并处理，也不会导致网络不通。</p><p>因为 conntrack，内核的 netfilter 模块会保存连接的状态，并作为防火墙设置的依据。它保存的 UDP 连接，只是简单记录了主机上本地 ip 和端口，和对端 ip 和端口，并不会保存更多的内容。</p><p>可以参考 intables info 网站的文章：<a href="http://www.iptables.info/en/connection-state.html#UDPCONNECTIONS。" target="_blank" rel="noopener">http://www.iptables.info/en/connection-state.html#UDPCONNECTIONS。</a></p><p>在找到根源之前，我们曾经尝试过用 SNAT 来修改服务端应答报文的源地址，期望能够修复该问题。但是却发现这种方法行不通，为什么呢？</p><p>因为 SNAT 是在 netfilter 最后做的，在之前 netfilter 的 conntrack 因为不认识该 connection，直接丢弃了，所以即使添加了 SNAT 也是无法工作的。</p><p>那能不能把 conntrack 功能去掉呢？比如解决方案：</p><pre><code>iptables -I OUTPUT -t raw -p udp --sport 5060 -j CT --notrackiptables -I PREROUTING -t raw -p udp --dport 5060 -j CT --notrack</code></pre><p>答案也是否定的，因为 NAT 需要 conntrack 来做翻译工作，如果去掉 conntrack 等于 SNAT 完全没用。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>知道了问题的原因，解决方案也就很容易找到。</p><h3 id="使用-TCP-协议"><a href="#使用-TCP-协议" class="headerlink" title="使用 TCP 协议"></a>使用 TCP 协议</h3><p>如果服务端和客户端使用 TCP 协议进行通信，它们之间的网络是正常的。</p><pre><code>$ nc -l 56789</code></pre><h3 id="监听在特定端口"><a href="#监听在特定端口" class="headerlink" title="监听在特定端口"></a>监听在特定端口</h3><p>使用 nc 启动一个 udp 服务器，监听在 eth0 上：</p><pre><code>➜  ~ nc -ul 172.16.13.13 56789</code></pre><p><code>nc</code> 可以跟两个参数，分别代表 ip 和 端口，表示服务端监听在某个特定 ip 上。如果接收到的报文目的地址不是 172.16.13.13，也会被内核直接丢弃。</p><p>这种情况下，服务端和客户端也能正常通信。</p><h3 id="改动应用程序实现"><a href="#改动应用程序实现" class="headerlink" title="改动应用程序实现"></a>改动应用程序实现</h3><p>修改应用程序的逻辑，在 UDP socket 上设置 <code>IP_PKTIFO</code>，并通过 <code>recvmsg</code> 和 <code>sendmsg</code> 函数传输数据。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://etherealmind.com/ipv6-which-address-multiple-ipv6-address-default-address-selection/" target="_blank" rel="noopener">IPv6:Which Source Address is used when you have many IPv6 addresses ? Default Address Selection</a></li><li><a href="https://blog.powerdns.com/2012/10/08/on-binding-datagram-udp-sockets-to-the-any-addresses/" target="_blank" rel="noopener">powerDNS blog: on binding datagram udp sockets to the any address</a></li><li><a href="https://www.ietf.org/rfc/rfc3542.txt" target="_blank" rel="noopener">RFC3542: IPV6 source address selection</a></li><li><a href="https://stackoverflow.com/questions/23859164/linux-udp-socket-sendto-operation-not-permitted" target="_blank" rel="noopener">linux udp socket sendto operation not permitted</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;最近在工作中遇到一个 docker 容器下 UDP 协议网络不通的问题，困扰了很久，也比较有意思，所以想写下来和大家分享。&lt;/p&gt;
&lt;p&gt;我们有个应用是 UDP 协议的，部署上去发现无法工作，但是换成 TCP 协议是可以的（应用同时支持 UDP、TCP 协议，切换成
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="linux" scheme="http://cizixs.com/tags/linux/"/>
    
      <category term="socket" scheme="http://cizixs.com/tags/socket/"/>
    
      <category term="docker" scheme="http://cizixs.com/tags/docker/"/>
    
      <category term="container" scheme="http://cizixs.com/tags/container/"/>
    
      <category term="network" scheme="http://cizixs.com/tags/network/"/>
    
      <category term="udp" scheme="http://cizixs.com/tags/udp/"/>
    
  </entry>
  
  <entry>
    <title>使用 docker 对容器资源进行限制</title>
    <link href="http://cizixs.com/2017/08/04/docker-resources-limit/"/>
    <id>http://cizixs.com/2017/08/04/docker-resources-limit/</id>
    <published>2017-08-03T16:00:00.000Z</published>
    <updated>2018-09-17T13:18:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>在使用 docker 运行容器时，一台主机上可能会运行几百个容器，这些容器虽然互相隔离，但是底层却使用着相同的 CPU、内存和磁盘资源。如果不对容器使用的资源进行限制，那么容器之间会互相影响，小的来说会导致容器资源使用不公平；大的来说，可能会导致主机和集群资源耗尽，服务完全不可用。</p><p>docker 作为容器的管理者，自然提供了控制容器资源的功能。正如使用内核的 namespace 来做容器之间的隔离，docker 也是通过内核的 cgroups 来做容器的资源限制。这篇文章就介绍如何使用 docker 来限制 CPU、内存和 IO，以及对应的 cgroups 文件。</p><p><strong>NOTE：</strong>如果想要了解 cgroups 的更多信息，可以参考 <a href="https://www.kernel.org/doc/Documentation/cgroup-v1/" target="_blank" rel="noopener">kernel 文档</a> 或者其他资源。</p><p>我本地测试的 docker 版本是 <code>17.03.0</code> 社区版：</p><pre><code>➜  stress docker versionClient: Version:      17.03.0-ce API version:  1.26 Go version:   go1.7.5 Git commit:   60ccb22 Built:        Thu Feb 23 11:02:43 2017 OS/Arch:      linux/amd64Server: Version:      17.03.0-ce API version:  1.26 (minimum version 1.12) Go version:   go1.7.5 Git commit:   60ccb22 Built:        Thu Feb 23 11:02:43 2017 OS/Arch:      linux/amd64 Experimental: false</code></pre><p>使用的是 ubuntu 16.04 系统，内核版本是 <code>4.10.0</code>：</p><pre><code>➜  ~ uname -aLinux cizixs-ThinkPad-T450 4.10.0-28-generic #32~16.04.2-Ubuntu SMP Thu Jul 20 10:19:48 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux</code></pre><p><strong>NOTE:</strong> 不同版本和系统的功能会有差异，具体的使用方法和功能解释请以具体版本的 docker 官方文档为准。</p><p>我们使用 <a href="https://github.com/progrium/docker-stress" target="_blank" rel="noopener">stress</a> 容器来产生 CPU、内存和 IO 的压力，具体的使用请参考它的帮助文档。</p><h2 id="1-CPU-资源"><a href="#1-CPU-资源" class="headerlink" title="1. CPU 资源"></a>1. CPU 资源</h2><p>主机上的进程会通过时间分片机制使用 CPU，CPU 的量化单位是频率，也就是每秒钟能执行的运算次数。为容器限制 CPU 资源并不能改变 CPU 的运行频率，而是改变每个容器能使用的 CPU 时间片。理想状态下，CPU 应该一直处于运算状态（并且进程需要的计算量不会超过 CPU 的处理能力）。</p><h3 id="docker-限制-CPU-Share"><a href="#docker-限制-CPU-Share" class="headerlink" title="docker 限制 CPU Share"></a>docker 限制 CPU Share</h3><p>docker 允许用户为每个容器设置一个数字，代表容器的 CPU share，默认情况下每个容器的 share 是 1024。要注意，这个 share 是相对的，本身并不能代表任何确定的意义。当主机上有多个容器运行时，每个容器占用的 CPU 时间比例为它的 share 在总额中的比例。举个例子，如果主机上有两个一直使用 CPU 的容器（为了简化理解，不考虑主机上其他进程），其 CPU share 都是 1024，那么两个容器 CPU 使用率都是 50%；如果把其中一个容器的 share 设置为 512，那么两者 CPU 的使用率分别为 67% 和 33%；如果删除 share 为 1024 的容器，剩下来容器的 CPU 使用率将会是 100%。</p><p>总结下来，这种情况下，docker 会根据主机上运行的容器和进程动态调整每个容器使用 CPU 的时间比例。这样的好处是能保证 CPU 尽可能处于运行状态，充分利用 CPU 资源，而且保证所有容器的相对公平；缺点是无法指定容器使用 CPU 的确定值。</p><p>docker 为容器设置 CPU share 的参数是 <code>-c --cpu-shares</code>，它的值是一个整数。</p><p>我的机器是 4 核 CPU，因此使用 <code>stress</code> 启动 4 个进程来产生计算压力：</p><pre><code>➜  stress docker run --rm -it stress --cpu 4stress: info: [1] dispatching hogs: 4 cpu, 0 io, 0 vm, 0 hddstress: dbug: [1] using backoff sleep of 12000usstress: dbug: [1] --&gt; hogcpu worker 4 [7] forkedstress: dbug: [1] using backoff sleep of 9000usstress: dbug: [1] --&gt; hogcpu worker 3 [8] forkedstress: dbug: [1] using backoff sleep of 6000usstress: dbug: [1] --&gt; hogcpu worker 2 [9] forkedstress: dbug: [1] using backoff sleep of 3000usstress: dbug: [1] --&gt; hogcpu worker 1 [10] forked</code></pre><p>在另外一个 terminal 使用 <code>htop</code> 查看资源的使用情况：</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fi6z1alsu4j30yz073myh.jpg" alt=""></p><p>从上图中可以看到，CPU 四个核资源都达到了 100%。四个 stress 进程 CPU 使用率没有达到 100% 是因为系统中还有其他机器在运行。</p><p>为了比较，我另外启动一个 share 为 512 的容器：</p><pre><code>➜  stress docker run --rm -it -c 512 stress --cpu 4 stress: info: [1] dispatching hogs: 4 cpu, 0 io, 0 vm, 0 hddstress: dbug: [1] using backoff sleep of 12000usstress: dbug: [1] --&gt; hogcpu worker 4 [6] forkedstress: dbug: [1] using backoff sleep of 9000usstress: dbug: [1] --&gt; hogcpu worker 3 [7] forkedstress: dbug: [1] using backoff sleep of 6000usstress: dbug: [1] --&gt; hogcpu worker 2 [8] forkedstress: dbug: [1] using backoff sleep of 3000usstress: dbug: [1] --&gt; hogcpu worker 1 [9] forked</code></pre><p>因为默认情况下，容器的 CPU share 为 1024，所以这两个容器的 CPU 使用率应该大致为 2：1，下面是启动第二个容器之后的监控截图：</p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fi6z6elptfj310309mmz9.jpg" alt=""></p><p>两个容器分别启动了四个 <code>stress</code> 进程，第一个容器 <code>stress</code> 进程 CPU 使用率都在 54% 左右，第二个容器 <code>stress</code> 进程 CPU 使用率在 25% 左右，比例关系大致为 2：1，符合之前的预期。</p><h3 id="限制容器能使用的-CPU-核数"><a href="#限制容器能使用的-CPU-核数" class="headerlink" title="限制容器能使用的 CPU 核数"></a>限制容器能使用的 CPU 核数</h3><p>上面讲述的 <code>-c --cpu-shares</code> 参数只能限制容器使用 CPU 的比例，或者说优先级，无法确定地限制容器使用 CPU 的具体核数；从 1.13 版本之后，docker 提供了 <code>--cpus</code> 参数可以限定容器能使用的 CPU 核数。这个功能可以让我们更精确地设置容器 CPU 使用量，是一种更容易理解也因此更常用的手段。</p><p><code>--cpus</code> 后面跟着一个浮点数，代表容器最多使用的核数，可以精确到小数点二位，也就是说容器最小可以使用 <code>0.01</code> 核 CPU。比如，我们可以限制容器只能使用 <code>1.5</code> 核数 CPU：</p><pre><code>➜  ~ docker run --rm -it --cpus 1.5 stress --cpu 3stress: info: [1] dispatching hogs: 3 cpu, 0 io, 0 vm, 0 hddstress: dbug: [1] using backoff sleep of 9000usstress: dbug: [1] --&gt; hogcpu worker 3 [7] forkedstress: dbug: [1] using backoff sleep of 6000usstress: dbug: [1] --&gt; hogcpu worker 2 [8] forkedstress: dbug: [1] using backoff sleep of 3000usstress: dbug: [1] --&gt; hogcpu worker 1 [9] forked</code></pre><p>在容器里启动三个 stress 来跑 CPU 压力，如果不加限制，这个容器会导致 CPU 的使用率为 300% 左右（也就是说会占用三个核的计算能力）。实际的监控如下图：</p><p><img src="https://ws1.sinaimg.cn/large/006tKfTcgy1fi6zckqjtlj310306w0tu.jpg" alt=""></p><p>可以看到，每个 <code>stress</code> 进程 CPU 使用率大约在 50%，总共的使用率为 150%，符合 1.5 核的设置。</p><p>如果设置的 <code>--cpus</code> 值大于主机的 CPU 核数，docker 会直接报错：</p><pre><code>➜  ~ docker run --rm -it --cpus 8 stress --cpu 3docker: Error response from daemon: Range of CPUs is from 0.01 to 4.00, as there are only 4 CPUs available.See &#39;docker run --help&#39;.</code></pre><p>如果多个容器都设置了 <code>--cpus</code> ，并且它们之和超过主机的 CPU 核数，并不会导致容器失败或者退出，这些容器之间会竞争使用 CPU，具体分配的 CPU 数量取决于主机运行情况和容器的 CPU share 值。也就是说 <code>--cpus</code> 只能保证在 CPU 资源充足的情况下容器最多能使用的 CPU 数，docker 并不能保证在任何情况下容器都能使用这么多的 CPU（因为这根本是不可能的）。</p><h3 id="限制容器运行在某些-CPU-核"><a href="#限制容器运行在某些-CPU-核" class="headerlink" title="限制容器运行在某些 CPU 核"></a>限制容器运行在某些 CPU 核</h3><p>现在的笔记本和服务器都会有多个 CPU，docker 也允许调度的时候限定容器运行在哪个 CPU 上。比如，我的主机上有 4 个核，可以通过 <code>--cpuset</code> 参数让容器只运行在前两个核上：</p><pre><code>➜  ~ docker run --rm -it --cpuset-cpus=0,1 stress --cpu 2stress: info: [1] dispatching hogs: 2 cpu, 0 io, 0 vm, 0 hddstress: dbug: [1] using backoff sleep of 6000usstress: dbug: [1] --&gt; hogcpu worker 2 [7] forkedstress: dbug: [1] using backoff sleep of 3000usstress: dbug: [1] --&gt; hogcpu worker 1 [8] forked</code></pre><p>这样，监控中可以看到只有前面两个核 CPU 达到了 100% 使用率。</p><p><img src="https://ws4.sinaimg.cn/large/006tKfTcgy1fi6zk7gwt1j30z706cjsb.jpg" alt=""></p><p><code>--cpuset-cpus</code> 参数可以和 <code>-c --cpu-shares</code> 一起使用，限制容器只能运行在某些 CPU 核上，并且配置了使用率。</p><p>限制容器运行在哪些核上并不是一个很好的做法，因为它需要实现知道主机上有多少 CPU 核，而且非常不灵活。除非有特别的需求，一般并不推荐在生产中这样使用。</p><h3 id="CPU-信息的-cgroup-文件"><a href="#CPU-信息的-cgroup-文件" class="headerlink" title="CPU 信息的 cgroup 文件"></a>CPU 信息的 cgroup 文件</h3><p>所有和容器 CPU share 有关的配置都在 <code>/sys/fs/cgroup/cpu/docker/&lt;docker_id&gt;/</code> 目录下面，其中 <code>cpu.shares</code> 保存了 CPU share 的值（其他文件的意义可以查看 cgroups 的官方文档）：</p><pre><code>➜  ~ ls /sys/fs/cgroup/cpu/docker/d93c9a660f4a13789d995d56024f160e2267f2dc26ce676daa66ea6435473f6f/   cgroup.clone_children  cpuacct.stat   cpuacct.usage_all     cpuacct.usage_percpu_sys   cpuacct.usage_sys   cpu.cfs_period_us  cpu.shares  notify_on_releasecgroup.procs           cpuacct.usage  cpuacct.usage_percpu  cpuacct.usage_percpu_user  cpuacct.usage_user  cpu.cfs_quota_us   cpu.stat    tasks➜  ~ cat /sys/fs/cgroup/cpu/docker/d93c9a660f4a13789d995d56024f160e2267f2dc26ce676daa66ea6435473f6f/cpu.shares 1024</code></pre><p>和 cpuset（限制 CPU 核）有关的文件在 <code>/sys/fs/cgroup/cpuset/docker/&lt;docker_id&gt;</code> 目录下，其中 <code>cpuset.cpus</code> 保存了当前容器能使用的 CPU 核：</p><pre><code>➜  ~ ls /sys/fs/cgroup/cpuset/docker/d93c9a660f4a13789d995d56024f160e2267f2dc26ce676daa66ea6435473f6f/cgroup.clone_children  cpuset.cpus            cpuset.mem_exclusive   cpuset.memory_pressure     cpuset.mems                      notify_on_releasecgroup.procs           cpuset.effective_cpus  cpuset.mem_hardwall    cpuset.memory_spread_page  cpuset.sched_load_balance        taskscpuset.cpu_exclusive   cpuset.effective_mems  cpuset.memory_migrate  cpuset.memory_spread_slab  cpuset.sched_relax_domain_level➜  ~ cat /sys/fs/cgroup/cpuset/docker/d93c9a660f4a13789d995d56024f160e2267f2dc26ce676daa66ea6435473f6f/cpuset.cpus0-1</code></pre><p><code>--cpus</code> 限制 CPU 核数并不像上面两个参数一样有对应的文件对应，它是由 <code>cpu.cfs_period_us</code> 和 <code>cpu.cfs_quota_us</code> 两个文件控制的。如果容器的 <code>--cpus</code> 设置为 3，其对应的这两个文件值为：</p><pre><code>➜  ~ cat /sys/fs/cgroup/cpu/docker/233a38cc641f2e4a1bec3434d88744517a2214aff9d8297e908fa13b9aa12e02/cpu.cfs_period_us 100000➜  ~ cat /sys/fs/cgroup/cpu/docker/233a38cc641f2e4a1bec3434d88744517a2214aff9d8297e908fa13b9aa12e02/cpu.cfs_quota_us 300000</code></pre><p>其实在 1.12 以及之前的版本，都是通过 <code>--cpu-period</code> 和 <code>--cpu-quota</code> 这两个参数控制容器能使用的 CPU 核数的。前者表示 CPU 的周期数，默认是 <code>100000</code>，单位是微秒，也就是 1s，一般不需要修改；后者表示容器的在上述 CPU 周期里能使用的 quota，真正能使用的 CPU 核数就是 <code>cpu-quota / cpu-period</code>，因此对于 3 核的容器，对应的 <code>cpu-quota</code> 值为 <code>300000</code>。</p><h2 id="2-内存资源"><a href="#2-内存资源" class="headerlink" title="2. 内存资源"></a>2. 内存资源</h2><p><strong>默认情况下，docker 并没有对容器内存进行限制</strong>，也就是说容器可以使用主机提供的所有内存。这当然是非常危险的事情，如果某个容器运行了恶意的内存消耗软件，或者代码有内存泄露，很可能会导致主机内存耗尽，因此导致服务不可用。对于这种情况，docker 会设置 docker daemon 的 OOM（out of memory） 值，使其在内存不足的时候被杀死的优先级降低。另外，就是你可以为每个容器设置内存使用的上限，一旦超过这个上限，容器会被杀死，而不是耗尽主机的内存。</p><p>限制内存上限虽然能保护主机，但是也可能会伤害到容器里的服务。如果为服务设置的内存上限太小，会导致服务还在正常工作的时候就被 OOM 杀死；如果设置的过大，会因为调度器算法浪费内存。因此，合理的做法包括：</p><ul><li>为应用做内存压力测试，理解正常业务需求下使用的内存情况，然后才能进入生产环境使用</li><li>一定要限制容器的内存使用上限</li><li>尽量保证主机的资源充足，一旦通过监控发现资源不足，就进行扩容或者对容器进行迁移</li><li>如果可以（内存资源充足的情况），尽量不要使用 swap，swap 的使用会导致内存计算复杂，对调度器非常不友好</li></ul><h3 id="docker-限制容器内存使用量"><a href="#docker-限制容器内存使用量" class="headerlink" title="docker 限制容器内存使用量"></a>docker 限制容器内存使用量</h3><p>在 docker 启动参数中，和内存限制有关的包括（参数的值一般是内存大小，也就是一个正数，后面跟着内存单位 <code>b</code>、<code>k</code>、<code>m</code>、<code>g</code>，分别对应 bytes、KB、MB、和 GB）：</p><ul><li><code>-m --memory</code>：容器能使用的最大内存大小，最小值为 4m</li><li><code>--memory-swap</code>：容器能够使用的 swap 大小</li><li><code>--memory-swappiness</code>：默认情况下，主机可以把容器使用的匿名页（anonymous page）swap 出来，你可以设置一个 0-100 之间的值，代表允许 swap 出来的比例</li><li><code>--memory-reservation</code>：设置一个内存使用的 soft limit，如果 docker 发现主机内存不足，会执行 OOM 操作。这个值必须小于 <code>--memory</code> 设置的值</li><li><code>--kernel-memory</code>：容器能够使用的 kernel memory 大小，最小值为 4m。</li><li><code>--oom-kill-disable</code>：是否运行 OOM 的时候杀死容器。只有设置了 <code>-m</code>，才可以把这个选项设置为 false，否则容器会耗尽主机内存，而且导致主机应用被杀死</li></ul><p>关于 <code>--memory-swap</code> 的设置必须解释一下，<code>--memory-swap</code> 必须在 <code>--memory</code> 也配置的情况下才能有用。</p><ul><li>如果 <code>--memory-swap</code> 的值大于 <code>--memory</code>，那么容器能使用的总内存（内存 + swap）为 <code>--memory-swap</code> 的值，能使用的 swap 值为 <code>--memory-swap</code> 减去 <code>--memory</code> 的值</li><li>如果 <code>--memory-swap</code> 为 0，或者和 <code>--memory</code> 的值相同，那么容器能使用两倍于内存的 swap 大小，如果 <code>--memory</code> 对应的值是 <code>200M</code>，那么容器可以使用 <code>400M</code> swap</li><li>如果 <code>--memory-swap</code> 的值为 -1，那么不限制 swap 的使用，也就是说主机有多少 swap，容器都可以使用</li></ul><p>如果限制容器的内存使用为 64M，在申请 64M 资源的情况下，容器运行正常（如果主机上内存非常紧张，并不一定能保证这一点）：</p><pre class=" language-bash"><code class="language-bash">➜  docker run --rm -it -m 64m stress --vm 1 --vm-bytes 64M --vm-hang 0WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.stress: info: <span class="token punctuation">[</span>1<span class="token punctuation">]</span> dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hddstress: dbug: <span class="token punctuation">[</span>1<span class="token punctuation">]</span> using backoff <span class="token function">sleep</span> of 3000usstress: dbug: <span class="token punctuation">[</span>1<span class="token punctuation">]</span> --<span class="token operator">></span> hogvm worker 1 <span class="token punctuation">[</span>7<span class="token punctuation">]</span> forkedstress: dbug: <span class="token punctuation">[</span>7<span class="token punctuation">]</span> allocating 67108864 bytes <span class="token punctuation">..</span>.stress: dbug: <span class="token punctuation">[</span>7<span class="token punctuation">]</span> touching bytes <span class="token keyword">in</span> strides of 4096 bytes <span class="token punctuation">..</span>.stress: dbug: <span class="token punctuation">[</span>7<span class="token punctuation">]</span> sleeping forever with allocated memory<span class="token punctuation">..</span><span class="token punctuation">..</span>.</code></pre><p>而如果申请 100M 内存，会发现容器里的进程被 kill 掉了（<strong>worker 7 got signal 9</strong>，signal 9 就是 kill 信号）</p><pre><code>➜  docker run --rm -it -m 64m stress --vm 1 --vm-bytes 100M --vm-hang 0WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.stress: info: [1] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hddstress: dbug: [1] using backoff sleep of 3000usstress: dbug: [1] --&gt; hogvm worker 1 [7] forkedstress: dbug: [7] allocating 104857600 bytes ...stress: dbug: [7] touching bytes in strides of 4096 bytes ...stress: FAIL: [1] (415) &lt;-- worker 7 got signal 9stress: WARN: [1] (417) now reaping child worker processesstress: FAIL: [1] (421) kill error: No such processstress: FAIL: [1] (451) failed run completed in 0s</code></pre><p>关于 swap 和 kernel memory 的限制就不在这里过多解释了，感兴趣的可以查看官方的文档。</p><h3 id="内存信息的-cgroups-文件"><a href="#内存信息的-cgroups-文件" class="headerlink" title="内存信息的 cgroups 文件"></a>内存信息的 cgroups 文件</h3><p>对于 docker 来说，它的内存限制也是存放在 cgroups 文件系统的。对于某个容器，你可以在 <code>sys/fs/cgroup/memory/docker/&lt;container_id&gt;</code> 目录下看到容器内存相关的文件：</p><pre><code>➜  ls /sys/fs/cgroup/memory/docker/b067fa0c58dcdd4fa856177fac0112655b605fcc9a0fe07e36950f0086f62f46 cgroup.clone_children  memory.kmem.failcnt             memory.kmem.tcp.limit_in_bytes      memory.max_usage_in_bytes        memory.soft_limit_in_bytes  notify_on_releasecgroup.event_control   memory.kmem.limit_in_bytes      memory.kmem.tcp.max_usage_in_bytes  memory.move_charge_at_immigrate  memory.stat                 taskscgroup.procs           memory.kmem.max_usage_in_bytes  memory.kmem.tcp.usage_in_bytes      memory.numa_stat                 memory.swappinessmemory.failcnt         memory.kmem.slabinfo            memory.kmem.usage_in_bytes          memory.oom_control               memory.usage_in_bytesmemory.force_empty     memory.kmem.tcp.failcnt         memory.limit_in_bytes               memory.pressure_level            memory.use_hierarchy</code></pre><p>而上面的内存限制对应的文件是 <code>memory.limit_in_bytes</code>：</p><pre><code>➜  cat /sys/fs/cgroup/memory/docker/b067fa0c58dcdd4fa856177fac0112655b605fcc9a0fe07e36950f0086f62f46/memory.limit_in_bytes67108864</code></pre><h2 id="3-IO-资源（磁盘）"><a href="#3-IO-资源（磁盘）" class="headerlink" title="3. IO 资源（磁盘）"></a>3. IO 资源（磁盘）</h2><p>对于磁盘来说，考量的参数是容量和读写速度，因此对容器的磁盘限制也应该从这两个维度出发。目前 docker 支持对磁盘的读写速度进行限制，但是并没有方法能限制容器能使用的磁盘容量（一旦磁盘 mount 到容器里，容器就能够使用磁盘的所有容量）。</p><pre><code>➜  ~ docker run -it --rm ubuntu:16.04 bashroot@5229f756523c:/# time $(dd if=/dev/zero of=/tmp/test.data bs=10M count=100 &amp;&amp; sync)100+0 records in100+0 records out1048576000 bytes (1.0 GB) copied, 3.82859 s, 274 MB/sreal    0m4.124suser    0m0.000ssys    0m1.812s</code></pre><h3 id="限制磁盘的权重"><a href="#限制磁盘的权重" class="headerlink" title="限制磁盘的权重"></a>限制磁盘的权重</h3><p>通过 <code>--blkio-weight</code> 参数可以设置 block 的权重，这个权重和 <code>--cpu-shares</code> 类似，它是一个相对值，取值范围是 10-1000，当多个 block 去屑磁盘的时候，其读写速度和权重成反比。</p><p>不过在我的环境中，<code>--blkio-weight</code> 参数虽然设置了对应的 cgroups 值，但是并没有作用，不同 weight 容器的读写速度还是一样的。github 上有一个对应的 <a href="https://github.com/moby/moby/issues/16173" target="_blank" rel="noopener">issue</a>，但是没有详细的解答。</p><p><code>--blkio-weight-device</code> 可以设置某个设备的权重值，测试下来虽然两个容器同时读的速度不同，但是并没有按照对应的比例来限制。</p><h3 id="限制磁盘的读写速率"><a href="#限制磁盘的读写速率" class="headerlink" title="限制磁盘的读写速率"></a>限制磁盘的读写速率</h3><p>除了权重之外，docker 还允许你直接限制磁盘的读写速率，对应的参数有：</p><ul><li><code>--device-read-bps</code>：磁盘每秒最多可以读多少比特（bytes）</li><li><code>--device-write-bps</code>：磁盘每秒最多可以写多少比特（bytes）</li></ul><p>上面两个参数的值都是磁盘以及对应的速率，格式为 <code>&lt;device-path&gt;:&lt;limit&gt;[unit]</code>，<code>device-path</code> 表示磁盘所在的位置，限制 <code>limit</code> 为正整数，单位可以是 <code>kb</code>、<code>mb</code> 和 <code>gb</code>。</p><p>比如可以把设备的度速率限制在 1mb：</p><pre><code>$ docker run -it --device /dev/sda:/dev/sda --device-read-bps /dev/sda:1mb ubuntu:16.04 bashroot@6c048edef769:/# cat /sys/fs/cgroup/blkio/blkio.throttle.read_bps_device 8:0 1048576root@6c048edef769:/# dd iflag=direct,nonblock if=/dev/sda of=/dev/null bs=5M count=1010+0 records in10+0 records out52428800 bytes (52 MB) copied, 50.0154 s, 1.0 MB/s</code></pre><p>从磁盘中读取 50m 花费了 50s 左右，说明磁盘速率限制起了作用。</p><p>另外两个参数可以限制磁盘读写频率（每秒能执行多少次读写操作）：</p><ul><li><code>--device-read-iops</code>：磁盘每秒最多可以执行多少 IO 读操作</li><li><code>--device-write-iops</code>：磁盘每秒最多可以执行多少 IO 写操作</li></ul><p>上面两个参数的值都是磁盘以及对应的 IO 上限，格式为 <code>&lt;device-path&gt;:&lt;limit&gt;</code>，limit 为正整数，表示磁盘 IO 上限数。</p><p>比如，我们可以让磁盘每秒最多读 100 次：</p><pre><code>➜  ~ docker run -it --device /dev/sda:/dev/sda --device-read-iops /dev/sda:100 ubuntu:16.04 bashroot@2e3026e9ccd2:/# dd iflag=direct,nonblock if=/dev/sda of=/dev/null bs=1k count=10001000+0 records in1000+0 records out1024000 bytes (1.0 MB) copied, 9.9159 s, 103 kB/s</code></pre><p>从测试中可以看出，容器设置了读操作的 iops 为 100，在容器内部从 block 中读取 1m 数据（每次 1k，一共要读 1000 次），共计耗时约 10s，换算起来就是 100 iops/s，符合预期结果。</p><p>写操作 bps 和 iops 与读类似，这里就不再重复了，感兴趣的可以自己实验。</p><h3 id="磁盘信息的-cgroups-文件"><a href="#磁盘信息的-cgroups-文件" class="headerlink" title="磁盘信息的 cgroups 文件"></a>磁盘信息的 cgroups 文件</h3><p>容器中磁盘限制的 cgroups 文件位于 <code>/sys/fs/cgroup/blkio/docker/&lt;docker_id&gt;</code> 目录：</p><pre><code>➜  ~ ls /sys/fs/cgroup/blkio/docker/1402c1682cba743b4d80f638da3d4272b2ebdb6dc6c2111acfe9c7f7aeb72917/                               blkio.io_merged                   blkio.io_serviced                blkio.leaf_weight                blkio.throttle.io_serviced        blkio.time_recursive   tasksblkio.io_merged_recursive         blkio.io_serviced_recursive      blkio.leaf_weight_device         blkio.throttle.read_bps_device    blkio.weightblkio.io_queued                   blkio.io_service_time            blkio.reset_stats                blkio.throttle.read_iops_device   blkio.weight_deviceblkio.io_queued_recursive         blkio.io_service_time_recursive  blkio.sectors                    blkio.throttle.write_bps_device   cgroup.clone_childrenblkio.io_service_bytes            blkio.io_wait_time               blkio.sectors_recursive          blkio.throttle.write_iops_device  cgroup.procsblkio.io_service_bytes_recursive  blkio.io_wait_time_recursive     blkio.throttle.io_service_bytes  blkio.time                        notify_on_release</code></pre><p>其中 <code>blkio.throttle.read_iops_device</code> 对应了设备的读 IOPS，前面一列是<a href="http://www.makelinux.net/ldd3/chp-3-sect-2" target="_blank" rel="noopener">设备的编号</a>，可以通过 <code>cat /proc/partitions</code> 查看设备和分区的设备号；后面是 IOPS 上限值：</p><pre><code>➜  ~ cat /sys/fs/cgroup/blkio/docker/1402c1682cba743b4d80f638da3d4272b2ebdb6dc6c2111acfe9c7f7aeb72917/blkio.throttle.read_iops_device 8:0 100</code></pre><p><code>blkio.throttle.read_bps_device</code> 对应了设备的读速率，格式和 IOPS 类似，只是第二列的值为 bps：</p><pre><code>➜  ~ cat /sys/fs/cgroup/blkio/docker/9de94493f1ab4437d9c2c42fab818f12c7e82dddc576f356c555a2db7bc61e21/blkio.throttle.read_bps_device 8:0 1048576</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>从上面的实验可以看出来，CPU 和内存的资源限制已经是比较成熟和易用，能够满足大部分用户的需求。磁盘限制也是不错的，虽然现在无法动态地限制容量，但是限制磁盘读写速度也能应对很多场景。</p><p>至于网络，docker 现在并没有给出网络限制的方案，也不会在可见的未来做这件事情，因为目前网络是通过插件来实现的，和容器本身的功能相对独立，不是很容易实现，扩展性也很差。docker 社区已经有很多呼声，也有 issue 是关于网络流量限制的: <a href="https://github.com/moby/moby/issues/26767" target="_blank" rel="noopener">issue 26767</a>、<a href="https://github.com/moby/moby/issues/37" target="_blank" rel="noopener">issue 37</a>、<a href="https://github.com/moby/moby/issues/4763" target="_blank" rel="noopener">issue 4763</a>。</p><p>资源限制一方面可以让我们为容器（应用）设置合理的 CPU、内存等资源，方便管理；另外一方面也能有效地预防恶意的攻击和异常，对容器来说是非常重要的功能。如果你需要在生产环境使用容器，请务必要花时间去做这件事情。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://docs.docker.com/engine/admin/resource_constraints/" target="_blank" rel="noopener">docker docs: Limit a container’s resources</a></li><li><a href="https://goldmann.pl/blog/2014/09/11/resource-management-in-docker/" target="_blank" rel="noopener">Resource management in Docker</a></li><li><a href="http://www.infoq.com/cn/articles/docker-resource-management-cgroups" target="_blank" rel="noopener">Docker资源管理探秘：Docker背后的内核Cgroups机制</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;在使用 docker 运行容器时，一台主机上可能会运行几百个容器，这些容器虽然互相隔离，但是底层却使用着相同的
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="linux" scheme="http://cizixs.com/tags/linux/"/>
    
      <category term="docker" scheme="http://cizixs.com/tags/docker/"/>
    
      <category term="kernel" scheme="http://cizixs.com/tags/kernel/"/>
    
      <category term="cgroups" scheme="http://cizixs.com/tags/cgroups/"/>
    
  </entry>
  
  <entry>
    <title>ARP 协议解析</title>
    <link href="http://cizixs.com/2017/07/31/arp-protocol/"/>
    <id>http://cizixs.com/2017/07/31/arp-protocol/</id>
    <published>2017-07-30T16:00:00.000Z</published>
    <updated>2018-09-17T13:18:45.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ARP-协议简介"><a href="#ARP-协议简介" class="headerlink" title="ARP 协议简介"></a>ARP 协议简介</h2><p>ARP 的全称是  Address Resolution Protocol，直译过来是 <strong>地址解析协议</strong>。对应的 RFC 文档是 <a href="https://tools.ietf.org/html/rfc826" target="_blank" rel="noopener">RFC826</a>。它的作用是把 IP 地址转换为 MAC 地址。为什么需要做这件事呢？</p><p>这是因为 TCP/IP 网络协议栈是分层的，每层负责不同的功能。IP 层（layer 3）负责路由寻路，换句话说，如果目的机器和客户端不在同一个网络，IP 层会穿过错综复杂的中间网络（互联网）找到目的机器所在的网络。</p><p>当报文在某一个网络中传播时（可能源机器和目的机器本来就在同一个网络，也可能报文在路由过程中执行下一跳步骤），IP 层的功能就没有用了，这时候起作用的是 2 层网络（链路层），大多数情况下就是以太网。以太网负责把多个机器连到一起，组成一个最小单位的局域网。在以太网中，不同机器的标识是 MAC 地址，MAC 地址是机器在生产的时候厂商为机器设定的。可以使用 <code>ip link</code> 命令查看网卡的 MAC 地址，比如我的机器上这个命令的输出是：</p><pre><code>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: enp0s25: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000    link/ether 50:7b:9d:ca:08:f0 brd ff:ff:ff:ff:ff:ff</code></pre><p>我机器的网卡对应的 MAC 地址就是 <code>50:7b:9d:ca:08:f0</code>，这是一个 6 字节的数字，表示的时候每个字节用 <code>:</code> 分隔开，长度是 48 比特。</p><p>有了 MAC 地址，同一个以太网络上的两台机器才能够通信。机器 A 需要知道机器 B 的 MAC 地址，才能发送以太网帧；交换机收到报文之后，根据目的 MAC 地址决定应该从哪个端口发送出去；目的机器读取报文的 MAC 地址才能知道报文是不是要发给自己的。</p><p>最开始的时候，机器 A 只知道目的地址的 IP（用户用某种方式输入 IP 地址，或者通过 DNS 解析出来 IP 地址），不知道对方的 MAC 地址。这时候，机器 A 会发送 ARP 报文，去查询机器 B 的 MAC 地址，拿到 MAC 地址，就能完成通信的过程。</p><p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fi242uryyqj30g90e374i.jpg" alt=""></p><p>ARP 协议的内容，以及怎么拿到 MAC 地址就是这篇文章接下来要讲解的。</p><h2 id="Linux-ARP-缓存"><a href="#Linux-ARP-缓存" class="headerlink" title="Linux ARP 缓存"></a>Linux ARP 缓存</h2><p>如果每次主机通信都要发送 ARP 协议去查询 MAC 地址无疑是低效的，为了提供性能最常见的做法是在系统层面保存 ARP 的结果。因为 IP 地址和 MAC 地址并不会经常变化，而且主机间第一次通信之后有很大的可能性会在短时间内再次通信， 所以 ARP 缓存能够大大提高网络效率。</p><p>在 Linux 系统中，可以通过 <code>ip neighbour</code>（可以简写为 <code>ip neigh</code>） 命令管理 ARP 缓存。为了说明 Linux 系统中 ARP 的工作原理，我会在自己的机器上进行试验。试验环境如下图所示：</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fi28tjdwdmj30qh0fjmyk.jpg" alt=""></p><p>我的工作机器是 A，IP 地址是 <code>172.16.13.16</code>，我会 <code>ping</code> 另外一台和 A 在同一个以太网的机器 B（IP 地址是 <code>172.16.13.18</code>），并查看 A 上 ARP 缓存的情况。</p><p>两台机器在同一个子网中（连到同一台交换机上），这个可以用路由表确认：</p><pre><code>➜  ~ ip route172.16.13.0/24 dev enp0s25  proto kernel  scope link  src 172.16.13.16  metric 100 </code></pre><p>在执行 <code>ping</code> 命令之前，机器 A 上并没有对方的 ARP 缓存，使用 <code>ip neigh</code> 可以列出（实际上我的机器上是有 ARP 规则的，但是这些规则都和 <code>172.16.13.18</code> 无关，因此没有打印在输出中）：</p><pre><code>➜  ~ ip neigh</code></pre><p>执行 <code>ping</code> 命令，呼叫对方主机。<code>-c 3</code> 表示发送多少次请求，可以看到发送 3 次请求并接收到应答后 <code>ping</code> 程序就直接退出了（如果不添加 <code>-c 3</code>，ping 会一直发送请求，除非用户使用 <code>ctl + C</code> 强制退出应用）。</p><pre><code>➜  ~ ping -c 3 172.16.13.18PING 172.16.13.18 (172.16.13.18) 56(84) bytes of data.64 bytes from 172.16.13.18: icmp_seq=1 ttl=64 time=0.282 ms64 bytes from 172.16.13.18: icmp_seq=2 ttl=64 time=0.238 ms64 bytes from 172.16.13.18: icmp_seq=3 ttl=64 time=0.235 ms--- 172.16.13.18 ping statistics ---3 packets transmitted, 3 received, 0% packet loss, time 2028ms</code></pre><p>此时再次查看 ARP 缓存，可以看到 <code>172.16.13.18</code> 对应的表项：</p><pre><code>➜  ~ sudo ip neigh172.16.13.18 dev enp0s25 lladdr 50:7b:9d:e0:8b:a8 REACHABLE</code></pre><p>这个表项表明 <code>172.16.13.18</code> 对应的 MAC 地址是 <code>50:7b:9d:e0:8b:a8</code>，<code>dev enp0s25</code> 是说发送给 <code>172.16.13.18</code> 的报文需要通过这个 interface，<code>REACHABLE</code> 表明目标地址是可达的，状态正常，其他状态还包括：</p><ul><li><code>permanent</code>：这个 ARP 缓存项没有过期时间，会一直生效，直到管理员把它删除</li><li><code>noarp</code>：这个 ARP 表项是有效的，不需要验证它的真实性，但是它有过期时间，过期之后会被自动删除</li><li><code>stale</code>：ARP 表项虽然有效，但是可疑，需要发送验证 ARP 报文</li><li><code>failed</code>：该表项不可用，ARP 请求报文没有应答</li></ul><p>ARP 缓存状态的详细解释可以参考<a href="https://people.cs.clemson.edu/~westall/853/notes/arpstate.pdf" target="_blank" rel="noopener">这个文档</a>。</p><h2 id="ARP-协议解析"><a href="#ARP-协议解析" class="headerlink" title="ARP 协议解析"></a>ARP 协议解析</h2><p>ARP 报文格式如下图所示，对于 IP 地址转换为 MAC 地址来说，ARP 报文长度为 28 字节。</p><p><img src="http://www.tcpipguide.com/free/diagrams/arpformat.png" alt=""></p><p>各个字段的含义为：</p><ul><li><code>Hardware Type</code>：传输 ARP 报文的物理网络类型，最常见的是以太网类型，对应的值是 1。这个字段的长度是 2 字节</li><li><code>Protocol Type</code>：网络报文类型，字段长度是 2 字节。最常用的是 IPv4 报文，对应的值是 2048（十六进制为 0x0800，这和以太网帧中帧类型字段使用的 IP 报文类型相同，这是有意设计的）</li><li><code>Hardware Address Length</code>：物理地址长度，字段长度是 1 比特。ARP 协议报文中物理地址（MAC 地址）有多少比特，对于大部分网络来说，这个值是 6（因为 MAC 地址是 6 个字节，48 比特长）</li><li><code>Protocol Address Length</code>：网络地址长度，字段长度是 1 比特。表示 ARP 协议报文中网络地址（IP 地址）有多少比特，对于大部分网络来说，这个值是 4（因为 IPv4 地址是 4 个字节，32 比特）</li><li><code>Opcode</code>：ARP 报文的类型，接下来我们会看到几种不同的 ARP 报文。这个字段占用 2 个比特，值为 1 代表 ARP 请求报文，值为 2 代表 ARP 应答报文，3 代表 RARP 请求报文，4 代表 RARP 应答报文</li><li><code>Sender Hardware Address</code>：当前 ARP 报文的发送方的物理地址（MAC 地址）</li><li><code>Send Protocol Address</code>：当前 ARP 报文发送发的网络地址（IPv4 地址）</li><li><code>Target Hardware Address</code>：当前 ARP 报文接收方的物理地址（MAC 地址），如果是 ARP 情况请，这个字段为空（因为发送方就是不知道对方的 MAC 地址从会使用 ARP 来解析）</li><li><code>Target Protocol Address</code>：当前 ARP 报文接收方的网络地址（IPv4 地址）</li></ul><p>需要注意的是，虽然 ARP 协议目前最常用的场景是把 IP 地址转换为 MAC 地址，但是它设计之初却是为了更一般的场景。它的硬件类型、协议类型就是为了指明要转换地址的双方；而硬件地址长度和协议地址长度指定双方的地址长度（每种协议的地址长度可以会发生变化），其对应的就是头部最后面四个地址长度。</p><p>也就是说，ARP 本身可以转换其他硬件地址和网络地址，而且允许它们的地址长度是可变的。这导致 ARP 协议现在看来是有点冗余的，毕竟 IPv4 和 MAC 地址长度都是固定的，没有必要在协议中指定。</p><p>ARP 发送出去会被封装在以太网帧里，ARP 报文中有发送端的 MAC 地址，而以太网帧的报文头部也包含了发送端的 MAC 地址，也就是说报文中有完全重复的信息。</p><h2 id="ARP-工作过程"><a href="#ARP-工作过程" class="headerlink" title="ARP 工作过程"></a>ARP 工作过程</h2><p><strong>第一步</strong>：机器 A 想和同一个以太网络的机器 B 通信，A 会现在自己的 ARP 表中查找 B 的 MAC 地址，如果能找到就直接发送以太网帧；如果没有找到，就跳到第二步<br><strong>第二步</strong>：机器 A 发送 ARP 请求报文去查询机器 B 的 MAC 地址，这是个以太网广播报文，因此交换机会广播到网络中所有的机器<br><strong>第三步</strong>：各个主机接收到 ARP 请求报文，如果发现 ARP 报文中询问的 IP 地址和自己不同，则直接丢弃；机器 B 发现 ARP 报文中询问的 IP 地址是自己的主机地址，则生成一个 ARP 应答报文，把自己的 MAC 地址填到报文中，发送给机器 A，这个报文是单播报文，不会发送给其他主机；同时机器 B 也会把机器 A 的 ARP 记录缓存起来<br><strong>第四步</strong>：机器 A 接收到 B 发来的 ARP 应答，读取报文中 B 的 MAC 地址，使用这个 MAC 地址和机器 B 进行后续的通信，同时把它缓存到系统中</p><p>从机器 A <code>ping</code> 机器 B 时，用 <code>wireshark</code> 抓包，过滤出其中的 ARP，显示的结果如图：<br><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fi23aa7xbbj30xa03nmxo.jpg" alt="arp 协议流程"></p><p>可以看到一共有两对 ARP 请求应答的过程，我们来逐个分析。</p><h3 id="ARP-请求报文"><a href="#ARP-请求报文" class="headerlink" title="ARP 请求报文"></a>ARP 请求报文</h3><p>首先是机器 A 发送的 ARP 请求，详细的报文内容如下：<br><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fi23ccvypmj30ws0e6wgn.jpg" alt="ARP 请求报文"></p><p>报文列表的 <code>Info</code> 字段，对应的内容是：</p><blockquote><p>Who has 172.16.13.18? Tell 172.16.13.16</p></blockquote><p>这是 wireshark 帮我们解析 ARP 报文，并用英语表达出来。这句话生动地概括了 ARP 请求的意思：<strong>谁知道 172.16.13.18 的物理地址？告诉 172.16.13.16。</strong></p><p>这个以太网帧的源地址是 <code>50:7b:9d:ca:08:f0</code>，也就是机器 A 的 MAC 地址；目的地址是 <code>ff:ff:ff:ff:ff:ff</code>，这是一个以太网广播地址，<strong>交换机</strong>会把报文发送给网络中所有的主机。</p><p>以太网帧类型（Type）字段的值是 <code>0x0806</code>，表示该数据帧是个 ARP 请求或者应答。</p><p>帧的长度是 42，其中包括 14 字节以太网帧头部，以及 28 字节 ARP 请求数据。</p><p>以太网帧内部是 ARP 请求的具体内容，<code>Opcode</code> 为 1，表示这是 ARP 请求，发送端（也就是机器 A）的 IP 地址是 <code>172.16.13.16</code>，目的端（也就是机器 B）的 IP 地址是 <code>172.16.13.18</code>。发送端的 MAC 地址是填写的，而目的端 MAC 地址为空（全部为 0）。</p><h3 id="ARP-应答报文"><a href="#ARP-应答报文" class="headerlink" title="ARP 应答报文"></a>ARP 应答报文</h3><p>第二个报文是 ARP 应答，详细报文内容如下图：<br><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fi23cw2798j30xl0en76n.jpg" alt="ARP 应答报文"></p><p>这个报文的 <code>info</code> 字段的信息是:</p><blockquote><p>172.16.13.18 is at 50:7b:9d:e0:8b:a8</p></blockquote><p>这也概括了 ARP 应答的意思：<code>172.16.13.18</code> 的 MAC 地址是 <code>50:7b:9d:e0:8b:a8</code>。</p><p>和上个报文不同，这是一个单播报文，直接发送到机器 A，帧的目的 MAC 地址是 <code>50:7b:9d:ca:08:f0</code>。因为机器 B 能够从接收到的 ARP 请求报文中获取机器 A 的 IP 地址和 MAC 地址，可以直接发送单播。</p><p><code>Opcode</code> 字段的值为 2，表示这是个 ARP 应答报文，而且 ARP 报文中四个地址都填上了对应的值（因为此时机器已经知道通信双方的所有地址）。</p><p>另外一点需要注意的是，这个以太网帧的长度是 60 字节，因为它的以太网帧后面加了 18 字节的 padding（填充字符）。这是以太网帧的最小长度值，那为什么 ARP 请求报文的长度可以低于 60 呢？这和 wireshark 抓包的原理有关，wireshark 捕获的包并不是真正发送到线路上的帧，而是发送给网卡驱动的数据。因此，如果从机器 B 上抓包，会发现机器 B 接收到的这个 ARP 请求长度也是 60 字节。</p><p>通过两个报文的时间可以发现，ARP 地址解析的时间在 0.2ms 左右，说明这个网络并不是非常繁忙，速度还是挺快的。</p><h3 id="ARP-cache-validation-报文"><a href="#ARP-cache-validation-报文" class="headerlink" title="ARP cache validation 报文"></a>ARP cache validation 报文</h3><p>后两个 ARP 报文也是一对：请求和应答，它们是从机器 B 发来查询机器 A MAC 地址的。</p><p>但是比较奇怪的是，ARP 请求报文以太网帧的目的地址居然不是广播，而是机器 A 的 MAC 地址？这和我们上面介绍的矛盾啊，为什么已经知道对方的 MAC 地址还要发送 ARP 报文去查询呢？</p><p>注意到，第三个报文距离上一个的时间间隔是 5s 左右，真正的 ICMP 报文（ping 应用传输的报文）已经在这个时间间隙中发送，也就是说机器 B 已经通过 A 发送的 ARP 报文把 ARP 保存到自己的缓存中了。第三个奇怪的 ARP 报文是为了<strong>验证缓存的有效性</strong>！</p><p>ARP 缓存都会有有效期，在 Linux 实现中，它会验证 ARP 缓存的有效性，并更新缓存记录的状态。因为已经知道对方的 ARP 记录，所以就没有必要再通过广播机制造成额外的网络资源浪费，这个 ARP 请求可以理解为： <strong>请问 172.16.13.16，你的 MAC 地址还是 50:7b:9d:ca:08:f0吗？</strong>。如果收到应答，说明该缓存记录有效；如果一直没有收到应答，则需要把缓存记录设置为失效或者删除，并在需要通信的时候使用正常的 ARP 请求获取对方的 MAC 地址。</p><p>我们可以在 <code>RFC1122</code> 的 <code>2.3.2.1</code> 小节（ARP Cache Validation）找到对应的文档说明：</p><blockquote><p>IMPLEMENTATION: Four mechanisms have been used, sometimes in<br>combination, to flush out-of-date cache entries.</p></blockquote><blockquote><p>……</p></blockquote><blockquote><p>(2) Unicast Poll – Actively poll the remote host by periodically sending a point-to-point ARP Request to it, and delete the entry if no ARP Reply is received from N successive polls. Again, the<br>timeout should be on the order of a minute, and typically N is 2.</p></blockquote><p><strong>NOTE：</strong>不同系统实现 ARP 缓存的机制不同，管理缓存有效期的方法也会有差异，并不能假设所有的系统都会使用上面的方法来验证缓存的有效性。</p><h3 id="如果目的-IP-对应的机器不存在？"><a href="#如果目的-IP-对应的机器不存在？" class="headerlink" title="如果目的 IP 对应的机器不存在？"></a>如果目的 IP 对应的机器不存在？</h3><p>上面试验了正常通信情况下的 ARP 报文过程，如果目标地址不存在，ARP 协议又是怎么工作的呢？</p><p>我在自己的机器中做了实验，<code>ping</code> 一台不存在的主机，可以看到 <code>ping</code> 程序每隔一秒发送一个 <code>icmp</code> 报文，对应的结果是 <code>Destination Host Unreachable</code>:</p><pre><code>➜  ~ ping 172.16.13.20PING 172.16.13.20 (172.16.13.20) 56(84) bytes of data.From 172.16.13.16 icmp_seq=1 Destination Host UnreachableFrom 172.16.13.16 icmp_seq=2 Destination Host UnreachableFrom 172.16.13.16 icmp_seq=3 Destination Host UnreachableFrom 172.16.13.16 icmp_seq=4 Destination Host UnreachableFrom 172.16.13.16 icmp_seq=5 Destination Host UnreachableFrom 172.16.13.16 icmp_seq=6 Destination Host Unreachable......</code></pre><p>此时，使用 wireshark 抓包，发现网络上的 ARP 报文如下所示：</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fi23dacq3qj30xi09htbb.jpg" alt="向不存在的主机发送 ping 请求"></p><p>和 ICMP 报文类似，ARP 请求也会每秒都会发送，但是一直接收不到应答。</p><h2 id="Gratuitous-ARP"><a href="#Gratuitous-ARP" class="headerlink" title="Gratuitous ARP"></a>Gratuitous ARP</h2><p>除了标准的 ARP 之外，还有一种特殊的 ARP 报文，称为 Gratuitous ARP（免费 ARP）。这个报文也是广播报文，它的特殊性在于，它的报文中发送端 IP 地址和接收端 IP 地址都被设置为发送该报文的主机 IP。为什么要有这样一个特殊的报文呢？因为它有用，比如：</p><ul><li>检测 IP 冲突。如果免费 ARP 请求接收到应答，说明当前网络上有另外一个和发送机器有相同 IP 的主机</li><li>可以用来更新网络中当前机器的 ARP 缓存。如果机器重新配置了 IP 地址，那么免费 ARP 报文能够把新的 IP-MAC 匹配关系广播到网络中，接收到报文的机器更新自己的 ARP 缓存记录，这样就不会有因为 ARP 缓存失效导致的网络问题</li></ul><p>如果机器 A 重新配置了 IP 地址，那么 <ip-mac> 的对应关系就发生了变化，网络中保存的旧 ARP 表项都失效，无法继续使用，会导致 ping 错误。Linux 系统中可以使用 <code>arping</code> 命令行来发送 Gratuitous ARP，让网络中所有主机更新当前机器的 ARP 记录：</ip-mac></p><pre><code>➜  ~  arping -A -I eth0 172.16.42.161</code></pre><p>这个命令就是把机器上 <code>eth0</code> 绑定的 MAC 地址和 <code>172.16.42.161</code> 作为 ARP 记录发送出去。</p><h2 id="ARP-的缺陷"><a href="#ARP-的缺陷" class="headerlink" title="ARP 的缺陷"></a>ARP 的缺陷</h2><p>ARP 协议很简单，通过缓存机制和 Gratuitous ARP 能够提供便利和高效的地址解析功能。尽管如此，和所有的网络协议一样，它并不是完美的，根据上面的解析，我们知道能发现它的两个不足之处：</p><ol><li>ARP 报文没有任何认证，假设所有的机器都可靠而且诚信，所以 ARP 报文（尤其是应答）可以伪造。（窃听报文，或者报文转发）-&gt; ARP spoofing</li><li>ARP 报文没有状态，机器可以在没有收到请求的时候直接发送应答。虽然特性能够有效地来更新 ARP 记录，也可能被恶意利用</li></ol><p>ARP 报文另外一个让人迷惑的地方在于它在网络协议栈的位置：它既不属于二层（数据链路层），因为它不能把用户数据发送到目的机器，而且它其实是包在以太网帧里面；但它也不是三层（网络层），因为它没有在网络中寻路的功能。<strong>它是介于二层和三层之间，更像是润滑剂的功能，帮助二层和三层正常工作。</strong></p><p>这是网络协议栈非常重要的一个特性，<strong>网络协议是非常实用性的</strong>。每个协议的产生为为了解决某个现实的问题，因为历史局限和现实设计问题，它可能并不完美，但是不妨碍它为我们提供服务。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.tummy.com/articles/networking-basics-how-arp-works/" target="_blank" rel="noopener">Networking Basics: How ARP Works</a></li><li><a href="http://www.omnisecu.com/tcpip/address-resolution-protocol-arp.php" target="_blank" rel="noopener">Address Resolution Protocol Tutorial, How ARP work, ARP Message Format</a></li><li><a href="http://www.tcpipguide.com/free/t_TCPIPAddressResolutionProtocolARP.htm" target="_blank" rel="noopener">The TCP/IP Guide: Address Resolution Protocol (ARP)</a></li><li><a href="https://wiki.wireshark.org/AddressResolutionProtocol" target="_blank" rel="noopener">wireshark wiki: Address Resolution Protocol (ARP)</a></li><li><a href="https://wiki.wireshark.org/Gratuitous_ARP" target="_blank" rel="noopener">wireshark wiki: Gratuitous ARP</a></li><li><a href="https://serverfault.com/questions/409865/why-arp-request-is-unicast" target="_blank" rel="noopener">ServerFault question: Why ARP request is unicast?</a></li><li><a href="http://linux-ip.net/html/ether-arp.html" target="_blank" rel="noopener">Guide to IP Layer Network Administration with Linux: Address Resolution Protocol (ARP)</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;ARP-协议简介&quot;&gt;&lt;a href=&quot;#ARP-协议简介&quot; class=&quot;headerlink&quot; title=&quot;ARP 协议简介&quot;&gt;&lt;/a&gt;ARP 协议简介&lt;/h2&gt;&lt;p&gt;ARP 的全称是  Address Resolution Protocol，直译过来是
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="linux" scheme="http://cizixs.com/tags/linux/"/>
    
      <category term="network" scheme="http://cizixs.com/tags/network/"/>
    
      <category term="arp" scheme="http://cizixs.com/tags/arp/"/>
    
      <category term="wireshark" scheme="http://cizixs.com/tags/wireshark/"/>
    
      <category term="TCP/IP" scheme="http://cizixs.com/tags/TCP-IP/"/>
    
  </entry>
  
  <entry>
    <title>【翻译】理解 TCP/IP 网络栈</title>
    <link href="http://cizixs.com/2017/07/27/understand-tcp-ip-network-stack/"/>
    <id>http://cizixs.com/2017/07/27/understand-tcp-ip-network-stack/</id>
    <published>2017-07-26T16:00:00.000Z</published>
    <updated>2018-09-17T13:18:45.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>TL;DR</strong></p><p>[TOC]</p><p><strong>译者注</strong>：很久没有翻译文章了，最近在网络看到这篇介绍网络栈的文章非常详细，正好最近在看这方面的内容，索性翻译过来。因为很多文章比较长，而且很多内容比较专业，翻译过程中难免会有错误，如果读者发现错误，还望不吝指出。文章中 Linux 内核源码摘自哪个版本原文并没有表明，我也没有找到对应的版本，代码的缩进可能会有问题。</p><p>原文地址： cubrid.org/blog/understanding-tcp-ip-network-stack，有删减。</p><p>没有 TCP/IP 的网络服务是无法想象的，理解数据是怎么在网络中传递的能够让你通过调优、排错来提高网络性能。<br>这篇文章会介绍 Linux OS 和硬件层的数据流和控制流的网络操作。</p><h2 id="一-TCP-IP-特性"><a href="#一-TCP-IP-特性" class="headerlink" title="一. TCP/IP 特性"></a>一. TCP/IP 特性</h2><p><strong>怎么设计一种网络协议，才能保证数据传输速度很快、能够保证数据的顺序而且没有数据丢失呢？</strong> TCP/IP 的设计目标就是如此，下面这些 TCP/IP 的主要特性是理解网络栈的关键。</p><blockquote><p>TCP and IP<br>技术上说，TCP 和 IP 在不同的网络层，应该分开来表述。方便起见，我们这里把它们作为一个概念。</p></blockquote><h3 id="1-面向连接"><a href="#1-面向连接" class="headerlink" title="1. 面向连接"></a>1. 面向连接</h3><p>通信双方先建立连接，才能发送数据。TCP 连接是由四元组唯一确定的：</p><pre><code>&lt;本地 IP，本地端口，远端 IP，远端端口&gt;</code></pre><h3 id="2-双向字节流"><a href="#2-双向字节流" class="headerlink" title="2. 双向字节流"></a>2. 双向字节流</h3><p>使用字节流来进行双向数据传输</p><h3 id="3-有序传输"><a href="#3-有序传输" class="headerlink" title="3. 有序传输"></a>3. 有序传输</h3><p>接收方接收到的数据顺序和发送方的发送顺序一致，要做到这点，数据要有顺序的概念，每个数据段用一个 32 位的整数来标志它的顺序。</p><h3 id="4-通过确认（ACK）来实现可靠性"><a href="#4-通过确认（ACK）来实现可靠性" class="headerlink" title="4. 通过确认（ACK）来实现可靠性"></a>4. 通过确认（ACK）来实现可靠性</h3><p>如果发送方发送报文之后，没有收到接收方返回的 ACK 确认，发送方会重新发送数据。因此，发送方的 TCP 缓存中保存着接收方还没有确认的数据。</p><h3 id="5-流量控制"><a href="#5-流量控制" class="headerlink" title="5. 流量控制"></a>5. 流量控制</h3><p>发送方最多能发送的数据由接收方能接受的数据量决定。接收方会发送它能接收的最大数据量（可用的 buffer 大小，接收窗口大小）给发送方，发送方也只能发送接收方<strong>接收窗口</strong>能够允许的字节大小。</p><h3 id="6-拥塞控制"><a href="#6-拥塞控制" class="headerlink" title="6. 拥塞控制"></a>6. 拥塞控制</h3><p>拥塞窗口独立于接收窗口，通过限制网络中数据流来阻止网络拥塞。和接收窗口类似，发送方根据一定的算法（比如 TCP Vegas、Westwood、BIC、和 CUBIC）发送接收方拥塞窗口允许的最大数据。和流控不同，拥塞控制只在发送方实现。</p><h2 id="二-数据发送流程"><a href="#二-数据发送流程" class="headerlink" title="二. 数据发送流程"></a>二. 数据发送流程</h2><p>网络栈有多个层，下图展示了网络不同的层：</p><p><img src="http://www.cubrid.org/files/attach/images/1943/944/001/4f230194dd6d52ed4566ef365eb3ff1a.png" alt=""></p><p>这些层大致可以分为三类：</p><ol><li>用户域</li><li>内核域</li><li>设备域</li></ol><p>用户域和内核域的任务是 CPU 执行的，它们两个也和成为主机，用以和设备域进行区别。设备指的是发送和接受报文的网卡（Network Interface Card/NIC）。</p><p>我们来看用户域。首先应用构造出需要发送的数据（上图中的 <strong>User Data</strong>部分），然后调用 <code>write()</code> 系统调用发送数据。假设 socket（图中的 <strong>fd</strong>） 已经创建，当系统调用执行的时候，就进入到内核域。</p><p>Linux 和 Unix 这种 POSIX 系列的操作系统暴露文件操作符给应用程序，供它们操作 socket。对于 POSIX 系列操作系统来说，socket 就是一种文件。文件层进行简单的检查，然后通过和文件结构体关联的 socket 结构体调用 socket 对应的函数。</p><p>内核 socket 有两个缓存：</p><ol><li>用来发送数据的 <strong>socket 发送缓存</strong></li><li>用来接收数据的 <strong>socket 接收缓存</strong></li></ol><p>当调用 <code>write</code> 系统调用时，用户域的数据被拷贝到内核内存中，然后添加到 socket 发送缓存的尾部，这是为了按照顺序发送数据。在上图中，浅灰色矩形框代表着 socket 缓存中的数据。接着，TCP 层被调用了。</p><p>socket 和 TCB（TCP Control Block） 相关联，TCB 保存着处理 TCP 连接需要的信息，比如连接状态（<strong>LISTEN</strong>、<strong>ESTABLISHED</strong>、<strong>TIME_WAIT</strong>）、接收窗口、拥塞窗口、序列号、重发计时器等。</p><p>如果当前的 TCP 状态允许数据传输，就会生成一个新的 TCP segment（或者说报文）。如若因为流控等原因无法进行数据传输，系统调用到此结束，重新回到用户模式（或者说，控制权又重新交给应用）。</p><p>如下图所示。TCP 段有两部分：</p><ol><li>TCP 头部</li><li>payload</li></ol><p><img src="http://www.cubrid.org/files/attach/images/1943/944/001/461258caebd0ea3011eaaeeb9cd4a968.png" alt=""></p><p>payload 包括了 socket 发送缓存的数据，payload 的最大值是接收窗口、拥塞窗口和最大段（Maximum Segment Size/MSS） 的三者的最大值。</p><p>接着，计算出 TCP checksum。计算 checksum 的时候，会考虑到 IP 地址、segment 长度、和协议号等信息。根据 TCP 状态不同，可以传输的报文从 1 个到多个不等。</p><p><strong>NOTE：</strong>事实上，TCP checksum 是网卡计算的，不是内核。但是为了简单起见，我们假定是内核做了这件事。</p><p>创建的 TCP 段往下走到 IP 层。IP 层给 TCP 段加上 IP 头部，并执行路由的逻辑。路由是查找下一跳的 IP 地址的过程，目的是更接近目的 IP。</p><p>IP 层计算并添加上 checksum 之后，报文被发送到以太网层。以太网层通过 ARP（Address Resolution Protocol） 协议查找下一跳的 MAC 地址，然后把以太网层的头部添加到报文上，这样主机上的报文就是最终的完整状态。</p><p>IP 层经过路由，就知道了要传输报文的网络接口（NIC），报文就从这个网口发送到下一跳 IP 所在机器。因此，下一步就是调用网口的驱动。</p><p><strong>NOTE：</strong>如果有网络抓包工具（比如 wireshark 或者 tcpdump）在运行，内核会把报文数据拷贝到应用使用的内存区。</p><p>网卡驱动根据网卡制造商编写的通信协议向网卡发送传输数据的请求，收到请求之后，网卡（NIC）把数据从主内存拷贝到自己的内存区，然后发送到网络线路上。这个过程中，为了遵循以太网协议，网卡还会为报文添加IFG（Inter-Frame Gap）、preamble、CRC。其中 IFG 和 preamble 是为了区分报文/帧的开始，CRC 是为了保护报文的内容（和 TCP IP 中的 checksum 功能相同）。数据传输的速度决定于以太网的物理速度以及流量控制的现状。</p><p>网卡发送数据的时候，会在主机 CPU 产生中断，每个中断都有编号，操作系统根据编号找到对应的驱动处理这个中断。驱动程序会在启动的时候注册它的处理函数到系统，操作系统调用驱动注册的处理函数，然后处理函数把传输的报文返回给操作系统。</p><p>至此，我们讨论了应用执行写操作时数据在内核和设备中的发送流程。需要注意的是，即使没有应用层显式的写操作，内核也会调用 TCP 层来发送数据。比如，当收到 ACK 报文，接收窗口扩大，内核会把 socket 发送缓存中的数据组装成 TCP 数据段，发送给接收方。</p><h2 id="三-数据接收流程"><a href="#三-数据接收流程" class="headerlink" title="三. 数据接收流程"></a>三. 数据接收流程</h2><p>这部分，我们来看看数据的接收流程，数据接收流程是网络栈是怎么处理接收到的数据的。下图主要展示了这个过程：</p><p><img src="http://www.cubrid.org/files/attach/images/1943/944/001/5d7322505c1ea20bb741d7b3904ef8f9.png" alt=""></p><p>首先，NIC 把报文拷贝到自己的内存中，检查 CRC 判断报文是否有效。如果有效，则发送到报文到主机的内存缓存区中。这部分内存缓存区是驱动提前申请的，专门用来保存接收到的数据。当缓存被分配的时候，驱动会告诉网卡这块内存的地址和大小。如果网卡接收到某个报文的时候，这部分缓存空间不足了，那么网卡可能直接丢掉报文。</p><p>把报文发送到主机的内存后，网卡会向主机发送一个中断。驱动这时候会检查它是否能处理这个报文，如果可以，它会把报文发送给上层的网络协议。往上层发送数据时，报文必须是操作系统能够理解的形式。比如 linux 的 <code>sk_buff</code>，BSD 系统的 <code>mbuf</code>，windows 系统的 <code>NET_BUFFER_LIST</code>，都是操作系统能理解的报文结构体。驱动需要把结构化的报文发送给上层。</p><p>以太网层检查报文是否合法，然后把上层协议的类型从报文中抽取出来。以太网层在 <code>ethertype</code> 字段中保存着上层使用的协议类型。IPv4 协议对应的值是 <code>0x8000</code>，报文中以太网层的头部会被去掉，剩下的内容发送到上层的 IP 去处理。</p><p>IP 层也会检查报文是否合法，不过它检查的是 IP 协议头部的 checksum。根据 IP 协议头部的地址，这一层会判断报文应该交给上层处理，还是执行路由抉择，或者直接发送给其他系统。如果报文应该有当前主机处理，那么上层协议（传输层）类型会从 IP 头部的 <code>proto</code> 字段读取，比如 TCP 协议对应的值是 6。然后报文的 IP 层头部被去掉，剩下的内容继续发送到上层的 TCP 层处理。</p><p>和其他层一样，TCP 层也会先检查报文是否合法，它的判断依据是 TCP checksum。然后它找到和报文关联的 TCB（TCP Control Block），报文是由 <code>&lt;source IP, source Port, target IP, target Port&gt;</code> 四元组作为连接标识的。系统找到对应的连接就能继续协议层的处理。如果这是收到的新数据，它会把数据拷贝到 socket 接收缓存中。根据 TCP 连接的状态，可能还会发送一个新的 TCP 报文（比如 ACK 报文通知对方报文已经收到）。至此，TCP/IP 报文接收流程就完成了。</p><p>socket 接收缓存的大小就是 TCP 接受窗口，在一定条件下，TCP 的吞吐量会随着接收窗口增加而增加。过去接收窗口是应用或者操作系统进行配置的，现在的网络栈能够自动调整接收窗口。</p><p>当应用调用 <code>read</code> 系统调用时，控制权就到了内核，内核会把数据从 socket 缓存拷贝到用户域的内存中，拷贝之后缓存中的数据就被删除。接着 TCP 相关的函数被触发，因为有了新的缓存空间可用，TCP 会增加接收窗口的大小。如果需要，TCP 还会发送一个报文给对方，如果没有数据要发送，系统调用就到此结束。</p><h2 id="四-网络栈发展"><a href="#四-网络栈发展" class="headerlink" title="四. 网络栈发展"></a>四. 网络栈发展</h2><p>上面只描述了网络栈各层最基本的功能。1990 年代网络栈的功能就已经比上面描述的要多，而最近的网络栈功能更多，复杂度也更高。</p><p>最新的网络栈按照功能可以分成下面几类：</p><h3 id="报文预处理操作"><a href="#报文预处理操作" class="headerlink" title="报文预处理操作"></a>报文预处理操作</h3><p>Netfilter（firewall，NAT）和流量控制允许用户在基本流程中插入控制代码，改变报文的处理逻辑。</p><h3 id="协议性能"><a href="#协议性能" class="headerlink" title="协议性能"></a>协议性能</h3><p>性能是为了提高 TCP 协议在网络环境中的吞吐量，延迟和稳定性，例子包括各样的拥塞控制算法和 SACK 这样的 TCP 功能。这类的协议改进不会在本文讨论，因为它超出了文章的范围。</p><h3 id="报文处理效率"><a href="#报文处理效率" class="headerlink" title="报文处理效率"></a>报文处理效率</h3><p>报文处理效率是为了提高每秒能处理的报文数量，一般是通过减少 CPU 周期，内存使用，和内存读取时间。减少系统延迟要很多方法，比如并行处理、头部预测、zero-copy、single-copy、checksum offload、TSO、LRO、RSS 等。</p><h2 id="五-网络栈流量控制"><a href="#五-网络栈流量控制" class="headerlink" title="五. 网络栈流量控制"></a>五. 网络栈流量控制</h2><p>现在，让我们详细分析网络栈内部的数据流。网络栈基本工作模式是事件驱动的，也就是说事件发生会触发一系列的处理逻辑，因此不需要额外的线程。下图展示了更精细的数据控制流程：</p><p><img src="http://www.cubrid.org/files/attach/images/1943/944/001/bf6bff327d8abd33c8e44258c98ccce6.png" alt=""></p><p>图中 (1) 表示应用程序调用了某个系统调用来执行（或者说使用）TCP，比如调用 <code>read</code> 或者 <code>write</code> 系统调用函数。不过，这一步并没有任何报文传输。</p><p>（2）和 (1) 类似，只是执行 TCP 逻辑之后，还会把报文发送出去。TCP 会生成一个报文，然后往下一直发送到网卡驱动。报文会先到达队列，然后队列的实现决定什么时候把报文发给网卡驱动。这个过程是 linux 中的 queue discipline（qdisc），linux 流量控制就是控制 qdisc 实现的。默认的 qdisc 算法是先进先出（FIFO），通过使用其他的 qdisc 算法，用户可以实现各种效果，比如人为的报文丢失、报文延迟、传输速率控制等。</p><p>流程 (3) 表示 TCP 使用的计时器过期的过程。比如 <strong>TIME_WAIT</strong>计时器过期，TCP 会被调用删除这个连接。</p><p>流程（4）和 流程（3）类似，TCP 计时器过期，但是需要重新发送报文。比如，重传计时器过期，没有接收到 ACK 的报文会重新发送。这两个流程展示了计时器软中断的处理过程。</p><p>当网卡驱动接收到一个中断，它会释放传输的报文。大多数情况下，驱动的任务到此就结束了。流程（5）是报文在传输队列（transmit queue）集聚，网卡驱动请求一个软中断（softirq），中断处理函数把传输队列中的报文发送到网卡驱动中。</p><p>当网卡驱动接受到一个中断，并且收到了一个新的报文，它也会请求一个软中断。这个软中断会处理接收到的报文，调用驱动程序，并把报文传输到上层。在 Linux 系统中，处理接收到报文的过程被称为 New API（NAPI），它和 polling 类似，因为驱动不会直接把报文发送给上层，而是上层直接获取报文。对应的代码成为 NAPI poll 或者简称 poll。</p><p>流程（6）展示了 TCP 执行完成的过程，流程（7）是 TCP 流程需要传输额外的报文。（5）、（6）和（7）都是软中断执行的，而软中断之前也处理了网卡中断。</p><h2 id="六-怎么处理中断和接收到的报文？"><a href="#六-怎么处理中断和接收到的报文？" class="headerlink" title="六. 怎么处理中断和接收到的报文？"></a>六. 怎么处理中断和接收到的报文？</h2><p>中断处理的过程很复杂，但是我们需要了解和报文接收有关的性能问题。下图展示了处理中断的过程：</p><p><img src="http://www.cubrid.org/files/attach/images/1943/944/001/29b36ba3ab2a478bd683d1ab0be694da.png" alt=""></p><p>假设 CPU 0 在执行应用程序，这时网卡收到一个报文，并为 CPU 0 产生一个中断。CPU 会执行内核中断（irq）处理（<code>do_IRQ()</code>），它会找到中断号，调用对应的驱动中断处理函数。驱动释放传送的报文，然后调用 <code>napi_schedule()</code> 函数处理接收的报文。这个函数发起软件中断（softirq）。</p><p>驱动中断处理完成结束后，控制权就回到了内核处理函数,内核处理函数执行软件中断的中断处理（<code>do_softirq()</code>）。</p><p>软件处理函数处理接收报文的是 <code>net_tx_action()</code> 函数。这个函数调用驱动的 <code>poll()</code> 函数，<code>poll()</code> 函数继续调用 <code>netif_receive_skb()</code>函数，然后把接收到的报文逐个发送给上层。软件中断处理结束后，应用就从系统调用之后的地方继续执行。</p><p>CPU 收到中断之后，会从头执行到结束，Linux、 BSD 和 Windows 系统的执行流程大致如此。当检查服务器 CPU 使用率时，有时候会看到多个 CPU 中只有一个 CPU 在执行软中断，就是因为这样。为了解决这个问题，提出了很多方案，比如多队列网卡、RSS、和 RPS。</p><h2 id="七-数据结构"><a href="#七-数据结构" class="headerlink" title="七. 数据结构"></a>七. 数据结构</h2><p>下面介绍网络栈主要的数据结构。</p><h3 id="sk-buff-结构体"><a href="#sk-buff-结构体" class="headerlink" title="sk_buff 结构体"></a>sk_buff 结构体</h3><p><strong>sk_buff</strong> 或者说 <strong>skb</strong> 代表一个报文，下图就展示了 <strong>sk_buff</strong> 的结构。随着网络功能的增加，这个结构体也会越来越复杂，但是基本的功能却保持不变。</p><p><img src="http://www.cubrid.org/files/attach/images/1943/944/001/cfdb2ac9851aa45fdc5dc8fbabf0de37.png" alt=""></p><h4 id="包含报文数据和-metadata"><a href="#包含报文数据和-metadata" class="headerlink" title="包含报文数据和 metadata"></a>包含报文数据和 metadata</h4><p>这个结构体包含了报文数据，或者保存了指向报文数据的指针。上图中，data 指针指向了报文，<code>frags</code> 指向真正的页。</p><p>诸如头部和 payload 长度这些信息保存在 meta data 区域，比如上图中 <code>mac_header</code>、<code>network_header</code> 和 <code>transport_header</code> 分别指向了以太网头部、IP 头部和 TCP 头部，这种方式让 TCP 报文处理更容易。</p><h4 id="如何添加和删除头部"><a href="#如何添加和删除头部" class="headerlink" title="如何添加和删除头部"></a>如何添加和删除头部</h4><p>在网络栈各层向上或者向下移动时，各层会添加或者删除头部。指针是为了操作更有效，比如要删除以太网头部，只需要增加 <code>head</code> 指针偏移量就行。</p><h4 id="如何合并和分解报文"><a href="#如何合并和分解报文" class="headerlink" title="如何合并和分解报文"></a>如何合并和分解报文</h4><p>链表用来高效地执行添加或者删除报文 payload 的任务，<code>next</code> 和 <code>prev</code> 指针就是这个功能。</p><h4 id="快速分配和释放"><a href="#快速分配和释放" class="headerlink" title="快速分配和释放"></a>快速分配和释放</h4><p>因为每次创建报文都要分配一个结构体，因此这里使用了快速分配。比如，如果数据在 10G 的以太网传输，那么每分钟至少要创建和删除一百万报文。</p><h3 id="TCP-Control-Block"><a href="#TCP-Control-Block" class="headerlink" title="TCP Control Block"></a>TCP Control Block</h3><p>其次，还有一个代表 TCP 连接的结构体，被称为 TCP control block，Linux 中对应的是 <code>tcp_sock</code>。在下图中，你可以看到 file、socket、和 <code>tcp_sock</code> 的关系：</p><p><img src="http://www.cubrid.org/files/attach/images/1943/944/001/ca2196ad43ec94fdb25bfb486ed64857.png" alt=""></p><p>系统调用发生时，系统会检查应用使用的文件描述符。对于 Unix 系列的操作系统来说，socket、file、和文件系统的设备都被抽象为文件，因此 <code>file</code> 的结构体中保存的信息最少。对于 socket，有一个额外的 <code>socket</code> 结构体保存着和这个 socket 有关的信息。<code>file</code> 有一个指针指向 <code>socket</code>，而 <code>socket</code> 又指向 <code>tcp_sock</code>。<code>tcp_sock</code> 可以分成 sock、inet_sock 不同的类型来支持出 TCP 之外的各种协议。可以把这理解为多态！</p><p>TCP 协议的所有状态信息都保存在 <code>tcp_sock</code> 中，比如序列号、接受窗口、拥塞控制、和重传计时器都保存在 <code>tcp_sock</code>。</p><p>socket 发送缓存和接收缓存就是 <code>sk_buff</code> 列表，它们也保存了 <code>tcp_sock</code> 信息。<code>dst_entry</code> 和 IP 路由结果是为了避免频繁地进行路由。<code>dst_entry</code> 允许快速搜索 ARP 结果，也就是目的 MAC 地址。<code>dst_entry</code> 是路由表的一部分，路由表的结构非常复杂，这篇文章不会讨论。报文传输要使用的网络设备也能通过 <code>dst_entry</code> 搜索到，网络设备对应的结构体是 <code>net_device</code>。</p><p>因此，通过 <code>file</code> 结构体和各级指针就能找到处理 TCP 报文需要的结构体（从文件一直到网络驱动），各种结构体的大小之和也就是 TCP 连接要占用的内存大小，这个值在几 KB（当然不包括报文的数据）。对着更多的功能加进来，这个内存使用也会逐渐增加。</p><p>最后，我们来看看 TCP 连接查找表（lookup table），这是一个哈希表，用来搜索接收到的报文属于哪个 TCP 连接。哈希值是通过报文的 <code>&lt;source IP, target IP, source port, target port&gt;</code> 四元组和 Jenkins 哈希算法计算的，据说使用这个算法是为了应对对哈希表的攻击。</p><h2 id="八-源码解读：发送数据"><a href="#八-源码解读：发送数据" class="headerlink" title="八. 源码解读：发送数据"></a>八. 源码解读：发送数据</h2><p>我们通过阅读 Linux 内核源码来看看网络栈具体执行的关键任务，我们将会观察经常用到的两条线路。</p><p>首先，第一条是应用程序调用 <code>write</code> 系统调用发送报文的线路。</p><pre class=" language-c"><code class="language-c"><span class="token function">SYSCALL_DEFINE3</span><span class="token punctuation">(</span>write<span class="token punctuation">,</span> <span class="token keyword">unsigned</span> <span class="token keyword">int</span><span class="token punctuation">,</span> fd<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">char</span> __user <span class="token operator">*</span><span class="token punctuation">,</span> buf<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">struct</span> file <span class="token operator">*</span>file<span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    file <span class="token operator">=</span> <span class="token function">fget_light</span><span class="token punctuation">(</span>fd<span class="token punctuation">,</span> <span class="token operator">&amp;</span>fput_needed<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     ret <span class="token operator">=</span> filp<span class="token operator">-></span>f_op<span class="token operator">-></span><span class="token function">aio_write</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>kiocb<span class="token punctuation">,</span> <span class="token operator">&amp;</span>iov<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> kiocb<span class="token punctuation">.</span>ki_pos<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">struct</span> file_operations <span class="token punctuation">{</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token function">ssize_t</span> <span class="token punctuation">(</span><span class="token operator">*</span>aio_read<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token keyword">struct</span> kiocb <span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">struct</span> iovec <span class="token operator">*</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    <span class="token function">ssize_t</span> <span class="token punctuation">(</span><span class="token operator">*</span>aio_write<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token keyword">struct</span> kiocb <span class="token operator">*</span><span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">struct</span> iovec <span class="token operator">*</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">static</span> <span class="token keyword">const</span> <span class="token keyword">struct</span> file_operations socket_file_ops <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token punctuation">.</span>aio_read <span class="token operator">=</span> sock_aio_read<span class="token punctuation">,</span>    <span class="token punctuation">.</span>aio_write <span class="token operator">=</span> sock_aio_write<span class="token punctuation">,</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span class="token punctuation">;</span></code></pre><p>当应用程序调用 <code>write</code> 系统调用，内核执行 <code>write()</code> 函数。首先要根据 fd 找到真正的而繁忙操作符，然后调用 <code>aio_write</code>，这是一个函数指针。在 <code>file</code> 结构体中，你可以看到 <code>file_operations</code> 结构体指针，这个结构体被称作函数表，里面包含了 <code>aio_read</code> 和 <code>aio_write</code> 等函数指针。socket 真正的函数表是 <code>socket_file_ops</code>，socket 使用的 <code>aio_write</code> 函数是 <code>sock_aio_write</code>。这个函数表的功能类似于 Jave 的 interface，可以方便内核进行代码抽象和重构。</p><pre class=" language-c"><code class="language-c"><span class="token keyword">static</span> ssize_t <span class="token function">sock_aio_write</span><span class="token punctuation">(</span><span class="token keyword">struct</span> kiocb <span class="token operator">*</span>iocb<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">struct</span> iovec <span class="token operator">*</span>iov<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">struct</span> socket <span class="token operator">*</span>sock <span class="token operator">=</span> file<span class="token operator">-></span>private_data<span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">return</span> sock<span class="token operator">-></span>ops<span class="token operator">-></span><span class="token function">sendmsg</span><span class="token punctuation">(</span>iocb<span class="token punctuation">,</span> sock<span class="token punctuation">,</span> msg<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token keyword">struct</span> socket <span class="token punctuation">{</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token keyword">struct</span> file <span class="token operator">*</span>file<span class="token punctuation">;</span>    <span class="token keyword">struct</span> sock <span class="token operator">*</span>sk<span class="token punctuation">;</span>    <span class="token keyword">const</span> <span class="token keyword">struct</span> proto_ops <span class="token operator">*</span>ops<span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">const</span> <span class="token keyword">struct</span> proto_ops inet_stream_ops <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token punctuation">.</span>family <span class="token operator">=</span> PF_INET<span class="token punctuation">,</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token punctuation">.</span>connect <span class="token operator">=</span> inet_stream_connect<span class="token punctuation">,</span>    <span class="token punctuation">.</span>accept <span class="token operator">=</span> inet_accept<span class="token punctuation">,</span>    <span class="token punctuation">.</span>listen <span class="token operator">=</span> inet_listen<span class="token punctuation">,</span>     <span class="token punctuation">.</span>sendmsg <span class="token operator">=</span> tcp_sendmsg<span class="token punctuation">,</span>    <span class="token punctuation">.</span>recvmsg <span class="token operator">=</span> inet_recvmsg<span class="token punctuation">,</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token keyword">struct</span> proto_ops <span class="token punctuation">{</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">int</span> <span class="token punctuation">(</span><span class="token operator">*</span>connect<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token keyword">struct</span> socket <span class="token operator">*</span>sock<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    <span class="token keyword">int</span> <span class="token punctuation">(</span><span class="token operator">*</span>accept<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token keyword">struct</span> socket <span class="token operator">*</span>sock<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    <span class="token keyword">int</span> <span class="token punctuation">(</span><span class="token operator">*</span>listen<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token keyword">struct</span> socket <span class="token operator">*</span>sock<span class="token punctuation">,</span> <span class="token keyword">int</span> len<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">int</span> <span class="token punctuation">(</span><span class="token operator">*</span>sendmsg<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token keyword">struct</span> kiocb <span class="token operator">*</span>iocb<span class="token punctuation">,</span> <span class="token keyword">struct</span> socket <span class="token operator">*</span>sock<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    <span class="token keyword">int</span> <span class="token punctuation">(</span><span class="token operator">*</span>recvmsg<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token keyword">struct</span> kiocb <span class="token operator">*</span>iocb<span class="token punctuation">,</span> <span class="token keyword">struct</span> socket <span class="token operator">*</span>sock<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span class="token punctuation">;</span></code></pre><p><code>sock_aio_write</code> 函数从 <code>file</code> 结构体中获取 <code>socket</code> 结构，然后调用 <code>sendmsg</code>，这也是一个函数指针。<code>socket</code> 结构体包括了 <code>proto_ops</code> 的函数表，IPv4 对应的实现是 <code>inet_stream_ops</code>， 其中 <code>sendmsg</code> 对应的实现是 <code>tcp_sendmsg</code>。</p><pre class=" language-c"><code class="language-c"><span class="token keyword">int</span> <span class="token function">tcp_sendmsg</span><span class="token punctuation">(</span><span class="token keyword">struct</span> kiocb <span class="token operator">*</span>iocb<span class="token punctuation">,</span> <span class="token keyword">struct</span> socket <span class="token operator">*</span>sock<span class="token punctuation">,</span><span class="token keyword">struct</span> msghdr <span class="token operator">*</span>msg<span class="token punctuation">,</span> size_t size<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">struct</span> sock <span class="token operator">*</span>sk <span class="token operator">=</span> sock<span class="token operator">-></span>sk<span class="token punctuation">;</span>    <span class="token keyword">struct</span> iovec <span class="token operator">*</span>iov<span class="token punctuation">;</span>    <span class="token keyword">struct</span> tcp_sock <span class="token operator">*</span>tp <span class="token operator">=</span> <span class="token function">tcp_sk</span><span class="token punctuation">(</span>sk<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">struct</span> sk_buff <span class="token operator">*</span>skb<span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    mss_now <span class="token operator">=</span> <span class="token function">tcp_send_mss</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> <span class="token operator">&amp;</span>size_goal<span class="token punctuation">,</span> flags<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/* Ok commence sending. */</span>    iovlen <span class="token operator">=</span> msg<span class="token operator">-></span>msg_iovlen<span class="token punctuation">;</span>    iov <span class="token operator">=</span> msg<span class="token operator">-></span>msg_iov<span class="token punctuation">;</span>    copied <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token operator">--</span>iovlen <span class="token operator">>=</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">int</span> seglen <span class="token operator">=</span> iov<span class="token operator">-></span>iov_len<span class="token punctuation">;</span>        <span class="token keyword">unsigned</span> <span class="token keyword">char</span> __user <span class="token operator">*</span>from <span class="token operator">=</span> iov<span class="token operator">-></span>iov_base<span class="token punctuation">;</span>        iov<span class="token operator">++</span><span class="token punctuation">;</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>seglen <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">int</span> copy <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>            <span class="token keyword">int</span> max <span class="token operator">=</span> size_goal<span class="token punctuation">;</span>            <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>            skb <span class="token operator">=</span> <span class="token function">sk_stream_alloc_skb</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span>                <span class="token function">select_size</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> sg<span class="token punctuation">)</span><span class="token punctuation">,</span>                sk<span class="token operator">-></span>sk_allocation<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>skb<span class="token punctuation">)</span>                <span class="token keyword">goto</span> wait_for_memory<span class="token punctuation">;</span>            <span class="token comment" spellcheck="true">/*            * Check whether we can use HW checksum.            */</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>sk<span class="token operator">-></span>sk_route_caps <span class="token operator">&amp;</span> NETIF_F_ALL_CSUM<span class="token punctuation">)</span>                skb<span class="token operator">-></span>ip_summed <span class="token operator">=</span> CHECKSUM_PARTIAL<span class="token punctuation">;</span>            <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>            <span class="token function">skb_entail</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> skb<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>            <span class="token comment" spellcheck="true">/* Where to copy to? */</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">skb_tailroom</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>                <span class="token comment" spellcheck="true">/* We have some space in skb head. Superb! */</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span>copy <span class="token operator">></span> <span class="token function">skb_tailroom</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">)</span>                    copy <span class="token operator">=</span> <span class="token function">skb_tailroom</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>err <span class="token operator">=</span> <span class="token function">skb_add_data</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> from<span class="token punctuation">,</span> copy<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span>                    <span class="token keyword">goto</span> do_fault<span class="token punctuation">;</span>                <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span>copied<span class="token punctuation">)</span>                    <span class="token function">tcp_push</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> flags<span class="token punctuation">,</span> mss_now<span class="token punctuation">,</span> tp<span class="token operator">-></span>nonagle<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token punctuation">}</span>            <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p><code>tcp_sendmsg</code> 首先从 <code>socket</code> 中获取 <code>tcp_sock</code>，然后把应用要发送的数据拷贝到 socket 发送缓存。当拷贝数据到 <code>sk_buff</code> 的时候，每个 <code>sk_buff</code> 要保存多少数据呢？每个 <code>sk_buff</code> 只能拷贝并保存 MSS(<code>tcp_send_mss</code>) 字节的内容。Maximum Segment Size（MSS）表示一个 TCP 报文能包含的最大 payload 大小。使用 TSO 和 GSO 能够让每个 <code>sk_buff</code> 保存超过 <code>MSS</code> 的数据。相关的内容不会在这篇文章讨论。</p><p><code>sk_stream_allc_skb</code> 函数创建一个新的 <code>sk_buff</code>，<code>skb_entail</code> 把 <code>sk_buff</code> 加到 <code>send_socket_buffer</code> 的尾部。<code>skb_add_data</code> 函数把应用的真正数据拷贝到 <code>sk_buff</code> 中，拷贝的过程是循环多次这个逻辑（创建一个 <code>sk_buff</code>，然后把它加入到 socket 发送缓存中）。因此位于 MSS 的数据所在的 <code>sk_buff</code> 在列表的第二个。最终 <code>tcp_push</code> 把能发送的数据转换成一个报文，并发送出去。</p><pre class=" language-c"><code class="language-c"><span class="token keyword">static</span> <span class="token keyword">inline</span> <span class="token keyword">void</span> <span class="token function">tcp_push</span><span class="token punctuation">(</span><span class="token keyword">struct</span> sock <span class="token operator">*</span>sk<span class="token punctuation">,</span> <span class="token keyword">int</span> flags<span class="token punctuation">,</span> <span class="token keyword">int</span> mss_now<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">static</span> <span class="token keyword">int</span> <span class="token function">tcp_write_xmit</span><span class="token punctuation">(</span><span class="token keyword">struct</span> sock <span class="token operator">*</span>sk<span class="token punctuation">,</span> <span class="token keyword">unsigned</span> <span class="token keyword">int</span> mss_now<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token keyword">int</span> nonagle<span class="token punctuation">,</span><span class="token punctuation">{</span>    <span class="token keyword">struct</span> tcp_sock <span class="token operator">*</span>tp <span class="token operator">=</span> <span class="token function">tcp_sk</span><span class="token punctuation">(</span>sk<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">struct</span> sk_buff <span class="token operator">*</span>skb<span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>skb <span class="token operator">=</span> <span class="token function">tcp_send_head</span><span class="token punctuation">(</span>sk<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>        cwnd_quota <span class="token operator">=</span> <span class="token function">tcp_cwnd_test</span><span class="token punctuation">(</span>tp<span class="token punctuation">,</span> skb<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>cwnd_quota<span class="token punctuation">)</span>            <span class="token keyword">break</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">unlikely</span><span class="token punctuation">(</span><span class="token operator">!</span><span class="token function">tcp_snd_wnd_test</span><span class="token punctuation">(</span>tp<span class="token punctuation">,</span> skb<span class="token punctuation">,</span> mss_now<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">break</span><span class="token punctuation">;</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">unlikely</span><span class="token punctuation">(</span><span class="token function">tcp_transmit_skb</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> skb<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> gfp<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">break</span><span class="token punctuation">;</span>        <span class="token comment" spellcheck="true">/* Advance the send_head. This one is sent out.        * This call will increment packets_out.        */</span>        <span class="token function">tcp_event_new_data_sent</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> skb<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>只要 TCP 允许，<code>tcp_push</code> 函数会尽可能把 socket 发送缓存中的 <code>sk_buff</code> 都发送出去。首先，<code>tcp_send_head</code> 获取到 socket 缓存中第一个 <code>sk_buff</code>，然后 <code>tcp_cwnd_test</code> 和 <code>tcp_snd_wnd_test</code> 检查用色窗口和接受窗口是否允许报文传输。接着，<code>tcp_transmit_skb</code> 函数创建一个报文：</p><pre class=" language-c"><code class="language-c"><span class="token keyword">static</span> <span class="token keyword">int</span> <span class="token function">tcp_transmit_skb</span><span class="token punctuation">(</span><span class="token keyword">struct</span> sock <span class="token operator">*</span>sk<span class="token punctuation">,</span> <span class="token keyword">struct</span> sk_buff <span class="token operator">*</span>skb<span class="token punctuation">,</span><span class="token keyword">int</span> clone_it<span class="token punctuation">,</span> gfp_t gfp_mask<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">const</span> <span class="token keyword">struct</span> inet_connection_sock <span class="token operator">*</span>icsk <span class="token operator">=</span> <span class="token function">inet_csk</span><span class="token punctuation">(</span>sk<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">struct</span> inet_sock <span class="token operator">*</span>inet<span class="token punctuation">;</span>    <span class="token keyword">struct</span> tcp_sock <span class="token operator">*</span>tp<span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">likely</span><span class="token punctuation">(</span>clone_it<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">unlikely</span><span class="token punctuation">(</span><span class="token function">skb_cloned</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            skb <span class="token operator">=</span> <span class="token function">pskb_copy</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> gfp_mask<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">else</span>            skb <span class="token operator">=</span> <span class="token function">skb_clone</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> gfp_mask<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">unlikely</span><span class="token punctuation">(</span><span class="token operator">!</span>skb<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> <span class="token operator">-</span>ENOBUFS<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token function">skb_push</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> tcp_header_size<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">skb_reset_transport_header</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">skb_set_owner_w</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> sk<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/* Build TCP header and checksum it. */</span>    th <span class="token operator">=</span> <span class="token function">tcp_hdr</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>    th<span class="token operator">-></span>source <span class="token operator">=</span> inet<span class="token operator">-></span>inet_sport<span class="token punctuation">;</span>    th<span class="token operator">-></span>dest <span class="token operator">=</span> inet<span class="token operator">-></span>inet_dport<span class="token punctuation">;</span>    th<span class="token operator">-></span>seq <span class="token operator">=</span> <span class="token function">htonl</span><span class="token punctuation">(</span>tcb<span class="token operator">-></span>seq<span class="token punctuation">)</span><span class="token punctuation">;</span>    th<span class="token operator">-></span>ack_seq <span class="token operator">=</span> <span class="token function">htonl</span><span class="token punctuation">(</span>tp<span class="token operator">-></span>rcv_nxt<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    icsk<span class="token operator">-></span>icsk_af_ops<span class="token operator">-></span><span class="token function">send_check</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> skb<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    err <span class="token operator">=</span> icsk<span class="token operator">-></span>icsk_af_ops<span class="token operator">-></span><span class="token function">queue_xmit</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">likely</span><span class="token punctuation">(</span>err <span class="token operator">&lt;=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> err<span class="token punctuation">;</span>    <span class="token function">tcp_enter_cwr</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token function">net_xmit_eval</span><span class="token punctuation">(</span>err<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><p><code>tcp_transmit_skb</code> 创建一份 <code>sk_buff</code> 的拷贝（<code>pskb_copy</code>），不过它只拷贝了 meta 数据，并不没有拷贝整个应用的数据。接着 <code>skb_push</code> 对头部做安全配置，并记录头部字段的值。<code>send_check</code> 计算 TCP 的 checksum，如果使用 checksum offload，那么 checksum 就不用在此计算。最后 <code>queue_xmit</code> 把报文发送到 IP 层，IPv4 实现的 <code>queu_xmit</code> 函数是 <code>ip_queue_xmit</code>：</p><pre class=" language-c"><code class="language-c"><span class="token keyword">int</span> <span class="token function">ip_queue_xmit</span><span class="token punctuation">(</span><span class="token keyword">struct</span> sk_buff <span class="token operator">*</span>skb<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    rt <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">struct</span> rtable <span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">__sk_dst_check</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token comment" spellcheck="true">/* OK, we know where to send it, allocate and build IP header. */</span>    <span class="token function">skb_push</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">struct</span> iphdr<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>opt <span class="token operator">?</span> opt<span class="token operator">-></span>optlen <span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">skb_reset_network_header</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>    iph <span class="token operator">=</span> <span class="token function">ip_hdr</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">*</span><span class="token punctuation">(</span><span class="token punctuation">(</span>__be16 <span class="token operator">*</span><span class="token punctuation">)</span>iph<span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token function">htons</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">4</span> <span class="token operator">&lt;&lt;</span> <span class="token number">12</span><span class="token punctuation">)</span> <span class="token operator">|</span> <span class="token punctuation">(</span><span class="token number">5</span> <span class="token operator">&lt;&lt;</span> <span class="token number">8</span><span class="token punctuation">)</span> <span class="token operator">|</span> <span class="token punctuation">(</span>inet<span class="token operator">-></span>tos <span class="token operator">&amp;</span> <span class="token number">0xff</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">ip_dont_fragment</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> <span class="token operator">&amp;</span>rt<span class="token operator">-></span>dst<span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span>skb<span class="token operator">-></span>local_df<span class="token punctuation">)</span>        iph<span class="token operator">-></span>frag_off <span class="token operator">=</span> <span class="token function">htons</span><span class="token punctuation">(</span>IP_DF<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">else</span>        iph<span class="token operator">-></span>frag_off <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>    iph<span class="token operator">-></span>ttl <span class="token operator">=</span> <span class="token function">ip_select_ttl</span><span class="token punctuation">(</span>inet<span class="token punctuation">,</span> <span class="token operator">&amp;</span>rt<span class="token operator">-></span>dst<span class="token punctuation">)</span><span class="token punctuation">;</span>    iph<span class="token operator">-></span>protocol <span class="token operator">=</span> sk<span class="token operator">-></span>sk_protocol<span class="token punctuation">;</span>    iph<span class="token operator">-></span>saddr <span class="token operator">=</span> rt<span class="token operator">-></span>rt_src<span class="token punctuation">;</span>    iph<span class="token operator">-></span>daddr <span class="token operator">=</span> rt<span class="token operator">-></span>rt_dst<span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    res <span class="token operator">=</span> <span class="token function">ip_local_out</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token operator">==</span><span class="token operator">=</span><span class="token operator">></span>    <span class="token keyword">int</span> <span class="token function">__ip_local_out</span><span class="token punctuation">(</span><span class="token keyword">struct</span> sk_buff <span class="token operator">*</span>skb<span class="token punctuation">)</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token function">ip_send_check</span><span class="token punctuation">(</span>iph<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token function">nf_hook</span><span class="token punctuation">(</span>NFPROTO_IPV4<span class="token punctuation">,</span> NF_INET_LOCAL_OUT<span class="token punctuation">,</span> skb<span class="token punctuation">,</span> <span class="token constant">NULL</span><span class="token punctuation">,</span>                   <span class="token function">skb_dst</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-></span>dev<span class="token punctuation">,</span> dst_output<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token operator">==</span><span class="token operator">=</span><span class="token operator">></span><span class="token punctuation">}</span><span class="token keyword">int</span> <span class="token function">ip_output</span><span class="token punctuation">(</span><span class="token keyword">struct</span> sk_buff <span class="token operator">*</span>skb<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">struct</span> net_device <span class="token operator">*</span>dev <span class="token operator">=</span> <span class="token function">skb_dst</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-></span>dev<span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    skb<span class="token operator">-></span>dev <span class="token operator">=</span> dev<span class="token punctuation">;</span>    skb<span class="token operator">-></span>protocol <span class="token operator">=</span> <span class="token function">htons</span><span class="token punctuation">(</span>ETH_P_IP<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token function">NF_HOOK_COND</span><span class="token punctuation">(</span>NFPROTO_IPV4<span class="token punctuation">,</span> NF_INET_POST_ROUTING<span class="token punctuation">,</span> skb<span class="token punctuation">,</span> <span class="token constant">NULL</span><span class="token punctuation">,</span> dev<span class="token punctuation">,</span>    ip_finish_output<span class="token punctuation">,</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token operator">==</span><span class="token operator">=</span><span class="token operator">></span>    <span class="token keyword">static</span> <span class="token keyword">int</span> <span class="token function">ip_finish_output</span><span class="token punctuation">(</span><span class="token keyword">struct</span> sk_buff <span class="token operator">*</span>skb<span class="token punctuation">)</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>skb<span class="token operator">-></span>len <span class="token operator">></span> <span class="token function">ip_skb_dst_mtu</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span><span class="token function">skb_is_gso</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token function">ip_fragment</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> ip_finish_output2<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">else</span>        <span class="token keyword">return</span> <span class="token function">ip_finish_output2</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><p><code>ip_queue_xmit</code> 执行 IP 层需要的逻辑，<code>__sk_dst_check</code> 检查缓存的路由是否有效。如果没有缓存的路由，或者缓存的路由已经失效，就要执行 IP 路由逻辑。接着 <code>skb_push</code> 用来对 IP 头部进行安全设置，并记录 IP 头部字段值。接着，<code>ip_send_check</code> 计算 IP 头部的 checksum，并调用 <code>netfilter</code> 函数。如果需要 IP 分片，<code>ip_finish_ouput</code> 也会对 IP 进行分片，如果上层是 TCP 的话，就不需要进行分片。因此 <code>ip_finish_output2</code> 就被调用添加以太网头部。最后，一个完整的报文就产生了。</p><pre class=" language-c"><code class="language-c"><span class="token keyword">int</span> <span class="token function">dev_queue_xmit</span><span class="token punctuation">(</span><span class="token keyword">struct</span> sk_buff <span class="token operator">*</span>skb<span class="token punctuation">)</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token operator">==</span><span class="token operator">=</span><span class="token operator">></span>    <span class="token keyword">static</span> <span class="token keyword">inline</span> <span class="token keyword">int</span> <span class="token function">__dev_xmit_skb</span><span class="token punctuation">(</span><span class="token keyword">struct</span> sk_buff <span class="token operator">*</span>skb<span class="token punctuation">,</span> <span class="token keyword">struct</span> Qdisc <span class="token operator">*</span>q<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>q<span class="token operator">-></span>flags <span class="token operator">&amp;</span> TCQ_F_CAN_BYPASS<span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span> <span class="token operator">!</span><span class="token function">qdisc_qlen</span><span class="token punctuation">(</span>q<span class="token punctuation">)</span> <span class="token operator">&amp;&amp;</span>    <span class="token function">qdisc_run_begin</span><span class="token punctuation">(</span>q<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">sch_direct_xmit</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> q<span class="token punctuation">,</span> dev<span class="token punctuation">,</span> txq<span class="token punctuation">,</span> root_lock<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token operator">==</span><span class="token operator">=</span><span class="token operator">></span>            <span class="token keyword">int</span> <span class="token function">sch_direct_xmit</span><span class="token punctuation">(</span><span class="token keyword">struct</span> sk_buff <span class="token operator">*</span>skb<span class="token punctuation">,</span> <span class="token keyword">struct</span> Qdisc <span class="token operator">*</span>q<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>            <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>            <span class="token function">HARD_TX_LOCK</span><span class="token punctuation">(</span>dev<span class="token punctuation">,</span> txq<span class="token punctuation">,</span> <span class="token function">smp_processor_id</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token function">netif_tx_queue_frozen_or_stopped</span><span class="token punctuation">(</span>txq<span class="token punctuation">)</span><span class="token punctuation">)</span>        ret <span class="token operator">=</span> <span class="token function">dev_hard_start_xmit</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> dev<span class="token punctuation">,</span> txq<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">HARD_TX_UNLOCK</span><span class="token punctuation">(</span>dev<span class="token punctuation">,</span> txq<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span class="token keyword">int</span> <span class="token function">dev_hard_start_xmit</span><span class="token punctuation">(</span><span class="token keyword">struct</span> sk_buff <span class="token operator">*</span>skb<span class="token punctuation">,</span> <span class="token keyword">struct</span> net_device <span class="token operator">*</span>dev<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token function">list_empty</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>ptype_all<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token function">dev_queue_xmit_nit</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> dev<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    rc <span class="token operator">=</span> ops<span class="token operator">-></span><span class="token function">ndo_start_xmit</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> dev<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span></code></pre><p>最终完整的报文通过 <code>dev_queue_xmit</code> 传输。首先，报文通过 <code>qdisc</code>，如果使用的是默认 <code>qdisc</code> 而且队列是空的，<code>sch_direct_xmit</code> 函数会跳过队列过程，直接把报文发送给驱动。<code>dev_hard_start_xmit</code> 函数调用真正的驱动，在调用驱动之前，会先锁上设备的 <code>TX</code>，这是为了防止多个线程同时操作驱动。内核锁住设备 <code>TX</code>，内核的传输代码就不需要再次加锁了。</p><p><code>ndo_start_xmit</code> 函数调用驱动代码，在此之前还有 <code>ptype_all</code> 和 <code>dev_queue_xmit_nit</code>。<code>ptype_all</code> 是一个包含了诸如 packet capture 模块的列表，如果有 capture 应用在运行，那么 <code>ptype_all</code> 会把报文拷贝到应用程序使用的地方，所以 tcpdump 一类的工具看到的报文都是要发送给驱动的。如果使用了 checksum offload 或者 TSO，网卡会对报文进行操作，这将导致最终发到网络上的报文和 tcpdump 捕获的不同。报文传输完成之后，驱动中断处理函数返回 <code>sk_buff</code>。</p><h2 id="九-源码解读：接收数据"><a href="#九-源码解读：接收数据" class="headerlink" title="九. 源码解读：接收数据"></a>九. 源码解读：接收数据</h2><p>接收数据的流程大致就是从网络上接收到报文，然后一路网上送到 socket 接收缓存中。在执行完驱动中断程序，我们先来看看 <code>napi</code> poll handler：</p><pre class=" language-c"><code class="language-c"><span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">net_rx_action</span><span class="token punctuation">(</span><span class="token keyword">struct</span> softirq_action <span class="token operator">*</span>h<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">struct</span> softnet_data <span class="token operator">*</span>sd <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token function">__get_cpu_var</span><span class="token punctuation">(</span>softnet_data<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">unsigned</span> <span class="token keyword">long</span> time_limit <span class="token operator">=</span> jiffies <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">;</span>    <span class="token keyword">int</span> budget <span class="token operator">=</span> netdev_budget<span class="token punctuation">;</span>    <span class="token keyword">void</span> <span class="token operator">*</span>have<span class="token punctuation">;</span>    <span class="token function">local_irq_disable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token function">list_empty</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>sd<span class="token operator">-></span>poll_list<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">struct</span> napi_struct <span class="token operator">*</span>n<span class="token punctuation">;</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>        n <span class="token operator">=</span> <span class="token function">list_first_entry</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>sd<span class="token operator">-></span>poll_list<span class="token punctuation">,</span> <span class="token keyword">struct</span> napi_struct<span class="token punctuation">,</span> poll_list<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">test_bit</span><span class="token punctuation">(</span>NAPI_STATE_SCHED<span class="token punctuation">,</span> <span class="token operator">&amp;</span>n<span class="token operator">-></span>state<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            work <span class="token operator">=</span> n<span class="token operator">-></span><span class="token function">poll</span><span class="token punctuation">(</span>n<span class="token punctuation">,</span> weight<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token function">trace_napi_poll</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span class="token keyword">int</span> <span class="token function">netif_receive_skb</span><span class="token punctuation">(</span><span class="token keyword">struct</span> sk_buff <span class="token operator">*</span>skb<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token operator">==</span><span class="token operator">=</span><span class="token operator">></span><span class="token keyword">static</span> <span class="token keyword">int</span> <span class="token function">__netif_receive_skb</span><span class="token punctuation">(</span><span class="token keyword">struct</span> sk_buff <span class="token operator">*</span>skb<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">struct</span> packet_type <span class="token operator">*</span>ptype<span class="token punctuation">,</span> <span class="token operator">*</span>pt_prev<span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    __be16 type<span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token function">list_for_each_entry_rcu</span><span class="token punctuation">(</span>ptype<span class="token punctuation">,</span> <span class="token operator">&amp;</span>ptype_all<span class="token punctuation">,</span> list<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>ptype<span class="token operator">-></span>dev <span class="token operator">||</span> ptype<span class="token operator">-></span>dev <span class="token operator">==</span> skb<span class="token operator">-></span>dev<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>pt_prev<span class="token punctuation">)</span>                ret <span class="token operator">=</span> <span class="token function">deliver_skb</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> pt_prev<span class="token punctuation">,</span> orig_dev<span class="token punctuation">)</span><span class="token punctuation">;</span>        pt_prev <span class="token operator">=</span> ptype<span class="token punctuation">;</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    type <span class="token operator">=</span> skb<span class="token operator">-></span>protocol<span class="token punctuation">;</span>    <span class="token function">list_for_each_entry_rcu</span><span class="token punctuation">(</span>ptype<span class="token punctuation">,</span>    <span class="token operator">&amp;</span>ptype_base<span class="token punctuation">[</span><span class="token function">ntohs</span><span class="token punctuation">(</span>type<span class="token punctuation">)</span> <span class="token operator">&amp;</span> PTYPE_HASH_MASK<span class="token punctuation">]</span><span class="token punctuation">,</span> list<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>ptype<span class="token operator">-></span>type <span class="token operator">==</span> type <span class="token operator">&amp;&amp;</span>        <span class="token punctuation">(</span>ptype<span class="token operator">-></span>dev <span class="token operator">==</span> null_or_dev <span class="token operator">||</span> ptype<span class="token operator">-></span>dev <span class="token operator">==</span> skb<span class="token operator">-></span>dev <span class="token operator">||</span>        ptype<span class="token operator">-></span>dev <span class="token operator">==</span> orig_dev<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>pt_prev<span class="token punctuation">)</span>            ret <span class="token operator">=</span> <span class="token function">deliver_skb</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> pt_prev<span class="token punctuation">,</span> orig_dev<span class="token punctuation">)</span><span class="token punctuation">;</span>        pt_prev <span class="token operator">=</span> ptype<span class="token punctuation">;</span>    <span class="token punctuation">}</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>pt_prev<span class="token punctuation">)</span> <span class="token punctuation">{</span>        ret <span class="token operator">=</span> pt_prev<span class="token operator">-></span><span class="token function">func</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> skb<span class="token operator">-></span>dev<span class="token punctuation">,</span> pt_prev<span class="token punctuation">,</span> orig_dev<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">static</span> <span class="token keyword">struct</span> packet_type ip_packet_type __read_mostly <span class="token operator">=</span> <span class="token punctuation">{</span>            <span class="token punctuation">.</span>type <span class="token operator">=</span> <span class="token function">cpu_to_be16</span><span class="token punctuation">(</span>ETH_P_IP<span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token punctuation">.</span>func <span class="token operator">=</span> ip_rcv<span class="token punctuation">,</span>            <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">;</span></code></pre><p><code>net_rx_action</code> 是收到报文的软件中断处理函数，首先，请求 <code>napi</code> poll 的驱动被从 <code>poll_list</code> 中拿出来，然后调用驱动的 <code>poll</code> handler。驱动把收到的报文转换成 <code>sk_buff</code>，然后调用 <code>netif_receive_skb</code>.</p><p>如果有模块在请求所有的报文，那么 <code>netif_receive_skb</code> 就把报文发送给这个模块。和报文传输一样，这些报文也要发送到 <code>ptype_all</code> 中注册的所有模块，以便可以被捕获程序读取。</p><p>接着，报文根据类型被传输到上层，类型保存在以太网帧头部的 2 比特 <code>ethertype</code> 字段中，里面的值就代表着报文的类型，驱动会把对应的值保存到 <code>sk_buff</code> 结构体中（<code>skb-&gt;protocol</code>）。每个报文都有自己的 <code>packet_type</code> 结构体，并且会把该结构体的指针注册到 <code>ptype_base</code> 的哈希表中。IPv4 使用 <code>ip_packet_type</code>，对应的 <code>Type</code> 字段的值是 IPv4 的 <code>ethertype</code>(<code>ETH_P_IP</code>)。因此，IPv4 报文会调用 <code>ip_rcv</code> 函数：</p><pre class=" language-c"><code class="language-c"><span class="token keyword">int</span> <span class="token function">ip_rcv</span><span class="token punctuation">(</span><span class="token keyword">struct</span> sk_buff <span class="token operator">*</span>skb<span class="token punctuation">,</span> <span class="token keyword">struct</span> net_device <span class="token operator">*</span>dev<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">struct</span> iphdr <span class="token operator">*</span>iph<span class="token punctuation">;</span>    u32 len<span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    iph <span class="token operator">=</span> <span class="token function">ip_hdr</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>iph<span class="token operator">-></span>ihl <span class="token operator">&lt;</span> <span class="token number">5</span> <span class="token operator">||</span> iph<span class="token operator">-></span>version <span class="token operator">!=</span> <span class="token number">4</span><span class="token punctuation">)</span>        <span class="token keyword">goto</span> inhdr_error<span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token function">pskb_may_pull</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> iph<span class="token operator">-></span>ihl<span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">goto</span> inhdr_error<span class="token punctuation">;</span>    iph <span class="token operator">=</span> <span class="token function">ip_hdr</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">unlikely</span><span class="token punctuation">(</span><span class="token function">ip_fast_csum</span><span class="token punctuation">(</span><span class="token punctuation">(</span>u8 <span class="token operator">*</span><span class="token punctuation">)</span>iph<span class="token punctuation">,</span> iph<span class="token operator">-></span>ihl<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">goto</span> inhdr_error<span class="token punctuation">;</span>    len <span class="token operator">=</span> <span class="token function">ntohs</span><span class="token punctuation">(</span>iph<span class="token operator">-></span>tot_len<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>skb<span class="token operator">-></span>len <span class="token operator">&lt;</span> len<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token function">IP_INC_STATS_BH</span><span class="token punctuation">(</span><span class="token function">dev_net</span><span class="token punctuation">(</span>dev<span class="token punctuation">)</span><span class="token punctuation">,</span> IPSTATS_MIB_INTRUNCATEDPKTS<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">goto</span> drop<span class="token punctuation">;</span>    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>len <span class="token operator">&lt;</span> <span class="token punctuation">(</span>iph<span class="token operator">-></span>ihl<span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">goto</span> inhdr_error<span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">return</span> <span class="token function">NF_HOOK</span><span class="token punctuation">(</span>NFPROTO_IPV4<span class="token punctuation">,</span> NF_INET_PRE_ROUTING<span class="token punctuation">,</span> skb<span class="token punctuation">,</span> dev<span class="token punctuation">,</span> <span class="token constant">NULL</span><span class="token punctuation">,</span>    ip_rcv_finish<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token operator">==</span><span class="token operator">=</span><span class="token operator">></span>    <span class="token keyword">int</span> <span class="token function">ip_local_deliver</span><span class="token punctuation">(</span><span class="token keyword">struct</span> sk_buff <span class="token operator">*</span>skb<span class="token punctuation">)</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">ip_hdr</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-></span>frag_off <span class="token operator">&amp;</span> <span class="token function">htons</span><span class="token punctuation">(</span>IP_MF <span class="token operator">|</span> IP_OFFSET<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">ip_defrag</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> IP_DEFRAG_LOCAL_DELIVER<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token punctuation">}</span><span class="token keyword">return</span> <span class="token function">NF_HOOK</span><span class="token punctuation">(</span>NFPROTO_IPV4<span class="token punctuation">,</span> NF_INET_LOCAL_IN<span class="token punctuation">,</span> skb<span class="token punctuation">,</span> skb<span class="token operator">-></span>dev<span class="token punctuation">,</span> <span class="token constant">NULL</span><span class="token punctuation">,</span>ip_local_deliver_finish<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token operator">==</span><span class="token operator">=</span><span class="token operator">></span><span class="token keyword">static</span> <span class="token keyword">int</span> <span class="token function">ip_local_deliver_finish</span><span class="token punctuation">(</span><span class="token keyword">struct</span> sk_buff <span class="token operator">*</span>skb<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token function">__skb_pull</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> <span class="token function">ip_hdrlen</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">int</span> protocol <span class="token operator">=</span> <span class="token function">ip_hdr</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-></span>protocol<span class="token punctuation">;</span><span class="token keyword">int</span> hash<span class="token punctuation">,</span> raw<span class="token punctuation">;</span><span class="token keyword">const</span> <span class="token keyword">struct</span> net_protocol <span class="token operator">*</span>ipprot<span class="token punctuation">;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>hash <span class="token operator">=</span> protocol <span class="token operator">&amp;</span> <span class="token punctuation">(</span>MAX_INET_PROTOS <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>ipprot <span class="token operator">=</span> <span class="token function">rcu_dereference</span><span class="token punctuation">(</span>inet_protos<span class="token punctuation">[</span>hash<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">if</span> <span class="token punctuation">(</span>ipprot <span class="token operator">!=</span> <span class="token constant">NULL</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    ret <span class="token operator">=</span> ipprot<span class="token operator">-></span><span class="token function">handler</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token operator">==</span><span class="token operator">=</span><span class="token operator">></span><span class="token keyword">static</span> <span class="token keyword">const</span> <span class="token keyword">struct</span> net_protocol tcp_protocol <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token punctuation">.</span>handler <span class="token operator">=</span> tcp_v4_rcv<span class="token punctuation">,</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span class="token punctuation">;</span></code></pre><p><code>ip_rcv</code> 函数执行 IP 层的任务，它会先检查报文的长度和头部的 checksum。在通过 netfilter 代码之后，它还会执行 <code>ip_local_deliver</code>，如果需要还会把 IP 报文进行组装，最后调用 <code>ip_local_deliver_finish</code>。</p><p><code>ip_local_deliver_finish</code> 使用 <code>__skb_pull</code> 移除 IP 头部，然后搜索报文中的上层协议，和 <code>ptype_base</code> 类似，每个传输层都会住在 <code>net_protocol</code> 结构体到  <code>inet_protos</code>。IPv4 TCP 使用的是 <code>tcp_protocol</code>，因此会调用注册的 <code>tcp_v4_rcv</code> 处理函数。</p><p>当报文来到 TCP 层，根据 TCP 的状态和报文类型其处理逻辑也不同。这里，我们假定当前 TCP 是 <code>ESTABLISHED</code> 状态，然后收到了期望的数据报文。当没有报文丢失和乱序时，下面的流程会被频繁执行：</p><pre class=" language-c"><code class="language-c"><span class="token keyword">int</span> <span class="token function">tcp_v4_rcv</span><span class="token punctuation">(</span><span class="token keyword">struct</span> sk_buff <span class="token operator">*</span>skb<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token keyword">const</span> <span class="token keyword">struct</span> iphdr <span class="token operator">*</span>iph<span class="token punctuation">;</span>    <span class="token keyword">struct</span> tcphdr <span class="token operator">*</span>th<span class="token punctuation">;</span>    <span class="token keyword">struct</span> sock <span class="token operator">*</span>sk<span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    th <span class="token operator">=</span> <span class="token function">tcp_hdr</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>th<span class="token operator">-></span>doff <span class="token operator">&lt;</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">struct</span> tcphdr<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">4</span><span class="token punctuation">)</span>        <span class="token keyword">goto</span> bad_packet<span class="token punctuation">;</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span><span class="token function">pskb_may_pull</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> th<span class="token operator">-></span>doff <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">goto</span> discard_it<span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    th <span class="token operator">=</span> <span class="token function">tcp_hdr</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>    iph <span class="token operator">=</span> <span class="token function">ip_hdr</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">TCP_SKB_CB</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-></span>seq <span class="token operator">=</span> <span class="token function">ntohl</span><span class="token punctuation">(</span>th<span class="token operator">-></span>seq<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">TCP_SKB_CB</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-></span>end_seq <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token function">TCP_SKB_CB</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-></span>seq <span class="token operator">+</span> th<span class="token operator">-></span>syn <span class="token operator">+</span> th<span class="token operator">-></span>fin <span class="token operator">+</span>    skb<span class="token operator">-></span>len <span class="token operator">-</span> th<span class="token operator">-></span>doff <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">TCP_SKB_CB</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-></span>ack_seq <span class="token operator">=</span> <span class="token function">ntohl</span><span class="token punctuation">(</span>th<span class="token operator">-></span>ack_seq<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">TCP_SKB_CB</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-></span>when <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token function">TCP_SKB_CB</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-></span>flags <span class="token operator">=</span> iph<span class="token operator">-></span>tos<span class="token punctuation">;</span>    <span class="token function">TCP_SKB_CB</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-></span>sacked <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>    sk <span class="token operator">=</span> <span class="token function">__inet_lookup_skb</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>tcp_hashinfo<span class="token punctuation">,</span> skb<span class="token punctuation">,</span> th<span class="token operator">-></span>source<span class="token punctuation">,</span> th<span class="token operator">-></span>dest<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    ret <span class="token operator">=</span> <span class="token function">tcp_v4_do_rcv</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> skb<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span></code></pre><p>首先， <code>tcp_v4_rcv</code> 函数检查接收到的报文，如果报文头部大于数据偏移量( <code>th-&gt;doff &lt; sizeof(struct tcphdr ) /4</code> )，说明头部错误。然后 <code>__inet_lookup_skb</code> 在 TCP 连接哈希表中查找当前报文所属的连接。从找到的 <code>sock</code> 结构体中，就能找到所有其他相关的结构体，比如 <code>tcp_sock</code> 和 <code>socket</code>。</p><pre class=" language-c"><code class="language-c"><span class="token keyword">int</span> <span class="token function">tcp_v4_do_rcv</span><span class="token punctuation">(</span><span class="token keyword">struct</span> sock <span class="token operator">*</span>sk<span class="token punctuation">,</span> <span class="token keyword">struct</span> sk_buff <span class="token operator">*</span>skb<span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>sk<span class="token operator">-></span>sk_state <span class="token operator">==</span> TCP_ESTABLISHED<span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token comment" spellcheck="true">/* Fast path */</span>        <span class="token function">sock_rps_save_rxhash</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> skb<span class="token operator">-></span>rxhash<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">tcp_rcv_established</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> skb<span class="token punctuation">,</span> <span class="token function">tcp_hdr</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token punctuation">,</span> skb<span class="token operator">-></span>len<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token operator">==</span><span class="token operator">=</span><span class="token operator">></span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">int</span> <span class="token function">tcp_rcv_established</span><span class="token punctuation">(</span><span class="token keyword">struct</span> sock <span class="token operator">*</span>sk<span class="token punctuation">,</span> <span class="token keyword">struct</span> sk_buff <span class="token operator">*</span>skb<span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token comment" spellcheck="true">/** Header prediction.*/</span><span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token function">tcp_flag_word</span><span class="token punctuation">(</span>th<span class="token punctuation">)</span> <span class="token operator">&amp;</span> TCP_HP_BITS<span class="token punctuation">)</span> <span class="token operator">==</span> tp<span class="token operator">-></span>pred_flags <span class="token operator">&amp;&amp;</span><span class="token function">TCP_SKB_CB</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-></span>seq <span class="token operator">==</span> tp<span class="token operator">-></span>rcv_nxt <span class="token operator">&amp;&amp;</span><span class="token operator">!</span><span class="token function">after</span><span class="token punctuation">(</span><span class="token function">TCP_SKB_CB</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-></span>ack_seq<span class="token punctuation">,</span> tp<span class="token operator">-></span>snd_nxt<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span>skb<span class="token operator">-></span>truesize <span class="token operator">></span> sk<span class="token operator">-></span>sk_forward_alloc<span class="token punctuation">)</span>    <span class="token keyword">goto</span> step5<span class="token punctuation">;</span><span class="token function">NET_INC_STATS_BH</span><span class="token punctuation">(</span><span class="token function">sock_net</span><span class="token punctuation">(</span>sk<span class="token punctuation">)</span><span class="token punctuation">,</span> LINUX_MIB_TCPHPHITS<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment" spellcheck="true">/* Bulk data transfer: receiver */</span><span class="token function">__skb_pull</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> tcp_header_len<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">__skb_queue_tail</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>sk<span class="token operator">-></span>sk_receive_queue<span class="token punctuation">,</span> skb<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token function">skb_set_owner_r</span><span class="token punctuation">(</span>skb<span class="token punctuation">,</span> sk<span class="token punctuation">)</span><span class="token punctuation">;</span>tp<span class="token operator">-></span>rcv_nxt <span class="token operator">=</span> <span class="token function">TCP_SKB_CB</span><span class="token punctuation">(</span>skb<span class="token punctuation">)</span><span class="token operator">-></span>end_seq<span class="token punctuation">;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>copied_early <span class="token operator">||</span> tp<span class="token operator">-></span>rcv_nxt <span class="token operator">!=</span> tp<span class="token operator">-></span>rcv_wup<span class="token punctuation">)</span>    <span class="token function">__tcp_ack_snd_check</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>step5<span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>th<span class="token operator">-></span>ack <span class="token operator">&amp;&amp;</span> <span class="token function">tcp_ack</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> skb<span class="token punctuation">,</span> FLAG_SLOWPATH<span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">)</span>    <span class="token keyword">goto</span> discard<span class="token punctuation">;</span>    <span class="token function">tcp_rcv_rtt_measure_ts</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> skb<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/* Process urgent data. */</span>    <span class="token function">tcp_urg</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> skb<span class="token punctuation">,</span> th<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">/* step 7: process the segment text */</span>    <span class="token function">tcp_data_queue</span><span class="token punctuation">(</span>sk<span class="token punctuation">,</span> skb<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">tcp_data_snd_check</span><span class="token punctuation">(</span>sk<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token function">tcp_ack_snd_check</span><span class="token punctuation">(</span>sk<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span></code></pre><p><code>tcp_v4_do_rcv</code> 执行和协议相关的内容。如果 TCP 处于 <code>ESTABLISHED</code> 状态，就会调用 <code>tcp_rcv_established</code>，<code>ESTABLISHED</code> 状态的处理逻辑是独立的并且是单独进行优化的，因为它是最常用的状态。<code>tcp_rcv_established</code> 首先执行头部预测代码，常见的状态是接收到的报文是期望收到的，并且没有要发送的数据了，比如序列号就是接收 TCP 期望的。这种情况下，只要把数据放到 socket 缓存，然后发送一个 ACK 报文就行。</p><p>接下来，你会看到比较 <code>truesize</code> 和 <code>sk_forward_alloc</code> 的代码，这是为了检查 socket 接收缓存中是否有足够的空闲空间能添加新的报文数据。如果有，那么头部预测就是 <code>hit</code>（测试成功），那么 <code>__skb_pull</code> 会删除 TCP 头部，然后 <code>__skb_queue_tail</code> 会把报文加到 socket 接收缓存中。最后 <code>__tcp_ack_snd_check</code> 用来发送 ACK。到此，报文处理过程就结束了。</p><p>如果 sockt 接收缓存中没有足够的空间，那么接下来的执行逻辑会话费比较长的事件。<code>tcp_data_queue</code> 函数先分配额一个新的缓存空间，把报文数据加到 socket 缓存中，同时，socket 缓存大小也要自动进行增加。和前面的执行逻辑不同，<code>tcp_data_snd_check</code> 会执行，如果有可以发送的报文，就先发送。然后从调用 <code>tcp_ack_snd_check</code> 创建和发送 ACK 报文。</p><p>这两种情况执行的代码并不多，这是常用 case 优化的结果。换句话说，不常用的 case 处理会更慢，比如报文乱序就属于不常用的 case。</p><h2 id="十-驱动和网卡之间怎么通信"><a href="#十-驱动和网卡之间怎么通信" class="headerlink" title="十. 驱动和网卡之间怎么通信"></a>十. 驱动和网卡之间怎么通信</h2><p>驱动和网卡之间的通信过程位于网络栈的底层，大多数人对此并不怎么关系。但是，网卡在执行越来越多的任务以解决性能问题。理解两者通信的基础知识能让你理解这些技术。</p><p>驱动和网卡之间的通信是异步的。首先，驱动请求报文传输，CPU 不会等待结果就能执行其他任务。网卡把报文发送出去，然后通知 CPU，驱动把接收到的报文返回。</p><p>和报文传输类似，报文接收也是异步的。首先，驱动请求报文接收，CPU 也在执行其他任务。然后网卡接收到报文，并通过 CPU，驱动处理接收到的报文，并返回结果。</p><p>因为是异步的，所以需要一块空间来存放请求和应答的结果。多数情况下，网卡使用 <code>ring</code> 结构体，<code>ring</code> 类似于常见的 <code>queue</code> 数据结构，它有固定的大小。每个元素保存一个请求或者应答数据。元素是按顺序轮流使用的，这也是名字 <code>ring</code> 的来源。</p><p>下图报文发送流程，你可以看到 <code>ring</code> 的用处：</p><p><img src="http://www.cubrid.org/files/attach/images/1943/944/001/95f3d5135499686bca8ca30f502e5201.png" alt=""></p><p>驱动从上层接收到数据，然后创建一个网卡能够理解的发送描述符（send descriptor），描述符中保存了报文的大小和内存的地址。因为网卡需要内存的物理地址，因此驱动还要把虚拟地址转换为物理地址。然后，驱动把描述符加入到 <code>TX ring</code>（1）（发送描述符的 <code>ring</code>）。</p><p>然后，驱动通知网卡有新的请求（2）。驱动会直接把数据写到网卡的内存地址，CPU 会直接通过 PIO（Programmed I/O） 把数据发送给设备。</p><p>网卡收到请求之后从主机内存中获取描述符（3），因为网卡设备没有经过 CPU 而是直接访问内存，所以这个过程被成为 DMA（Direct Memory Access）。</p><p>拿到发送描述符之后，网卡确定报文的地址和大小，然后从主机内存中拿到真正的报文数据（4）。如果使用 checksum offload，当网卡从内存中获取报文数据的时候就会计算 checksum，因此不会产生额外的开销。</p><p>网卡把报文发送出去（5），然后把发送的报文数写到主机内从中（6）。接着，网卡发起一个中断（7），驱动读取发送的报文数，并返回已经发送的报文。</p><p>在下面的图片中，我们看到接收报文的流程：</p><p><img src="http://www.cubrid.org/files/attach/images/1943/944/001/503efceb4e2486358f390a60252271f5.png" alt=""></p><p>首先，驱动为接收到的报文分配主机内存，并创建接收描述符。接收描述符默认包含了缓存大小和内存地址，和发送描述符一样，接收描述符也保存了 DMA 使用的物理内存地址。然后，把发送描述符加到 RX ring（1）。这是接收请求，而 RX ring 代表这接受请求的 ring。</p><p>通过 PIO，驱动通知网卡有新的描述符（2），网卡从 RX ring 中拿到新的描述符。然后它把描述符中的大小和缓存地址保存在网卡内存中（3）。</p><p>报文接收之后（4），网卡把报文发送到主机内存的缓存中。如果 checksum offload 函数存在，那么网卡也会在此时计算 checksum。接收报文的真正大小、checksum 值、以及其他信息都保存在一个单独的 ring（接收返回 ring）（6）。receive return ring 保存了接收请求处理的结果。接着，让卡发送中断（7），驱动从接收返回 ring 中获取报文信息，对接收到的报文进行处理。如果需要，还会分配新的内存缓存空间重复（1）和 （2）步骤。</p><p>要优化网络栈，很多人觉得 ring 和中断的配置需要调整。如果 TX ring 很大，那么一次可以进行多次发送请求，也可以一次接收到多个报文。比较大的 ring 对大量接收和发送的情况有好处，但是大多数情况下，网卡使用计时器来减少中断的次数，因为 CPU 处理中断开销很大。为了防止产生大多的中断，对主机造成泛洪，接收和发送报文的中断会定期收集和发送。</p><h2 id="十一-缓存和流量控制"><a href="#十一-缓存和流量控制" class="headerlink" title="十一. 缓存和流量控制"></a>十一. 缓存和流量控制</h2><p>流量控制在网络栈的多个阶段都有，下图展示了发送数据要用到的缓存。</p><p><img src="http://www.cubrid.org/files/attach/images/1943/944/001/0459cdba18786920fb7cc32717e383c5.png" alt=""></p><p>首先，应用产生数据并把它加到 socket 发送缓存中，如果缓存中没有空间，系统调用就会失败或者阻塞。因此，应用层发往内核的数据必须要通过 socket 缓存大小进行限制。</p><p>TCP 创建报文，并把报文发送到传输队列中（qdisc），这是一个典型的 FIFO 队列，队列的最大值可以通过 <code>ifocnfig</code> 命令输出的 <code>txqueuelen</code> 来查看。通常情况下，这个值在几千报文大小。</p><p>TX ring 在驱动和网卡之间，之前也说过，这是一个传输请求的队列。如果队列中没有空间，就无法执行传输请求，报文会在传输队列（qdisc）中堆积。如果堆积的报文太多，就会有报文被丢弃。</p><p>网卡把要发送的报文保存到内部的缓存中，这个缓存中的报文传输速率直接收到物理速率的影响（比如，1 Gb/s 的网卡不可能提供 10Gb/s 的性能）。如果网卡缓存中没有空闲的空间，传输报文就必须暂停。</p><p>如果内核中报文发送速率比网卡的报文处理速率高，那么报文就会集聚在网卡的缓存中。如果缓存中没有空闲空间，从　 TX ring 中处理传输报文就必须停止，那么会有更多的报文堆在　TX ring 中，直到最后队列中没有空间。驱动也没有没法执行传输请求，报文会堆在传输队列中。就像这样，底层的问题会通过缓存一层层网上传播。</p><p>下图展示了报文接收的流程：</p><p><img src="http://www.cubrid.org/files/attach/images/1943/944/001/353be9e9e64a78e66eb752301d764ab3.png" alt=""></p><p>报文先保存在网卡的接收缓存中，从流量控制的角度看，驱动和网卡之间的 RX ring 可以看到报文的缓存。驱动从 RX ring 获取报文 ，然后把报文发送到上层。驱动和上层之间没有缓存，因为网卡驱动使用 NAPI 进行数据传输。因此，可以认为上层直接从 RX ring 中读取报文。报文的数据保存在 socket 接收缓存中，应用从 socket 接收缓存中读取数据。</p><p>不支持 NAPI 的驱动会先把报文保存到 backlog 对咯中，然后 NAPI 处理函数去队列中获取报文，因此 backlog 队列可以看到驱动和上层之间的缓存。</p><p>如果内核处理报文的速度小于报文流向网卡的速度，那么 RX ring 就会满，网卡的缓存也会满。如果有使用以太网流量控制，那么网卡会发送请求停止继续向网卡发送数据，或者直接丢包。</p><p>TCP socket 不会因为 socket 接收缓存没有空间就丢包，因为 TCP 提供的是端对端的流控。但是如果应用程序处理报文数据的速度很慢，UDP 会把报文丢弃，因为 UDP 不提供流量控制。</p><p>上面两个图中，驱动使用的 TX ring 和 RX ring 大小就是 <code>ethtool</code> 命令显示的 rings 大小。大多数对吞吐量有要求的情况下，提供 ring 大小和 socket 缓存大小很有用。提高这些大小，能够减少因为空间不够导致的失败率，而且能够提高发送和传输报文的速率。</p><h2 id="十二-总结"><a href="#十二-总结" class="headerlink" title="十二. 总结"></a>十二. 总结</h2><p>最初，我只是计划介绍一些网络知识，帮助读者去开发网络应用、执行性能测试以及调试性能问题。这篇文章的介绍内容很多，希望它能够在开发网络应用和监控网络性能方面对你提供帮助。 TCP/IP 协议本身很复杂，而且有很多特殊情况。幸运的是，你不用理解  TCP/IP 的所有代码才能理解和分析网络性能问题，这篇文章的知识应该就够了。</p><p>随着系统网络栈的不断发展，现在的服务器能毫无压力地提供 10-20 Gb/s 的吞吐率。而且还有很多的技术来提高性能，比如 TSO、LRO、RSS、GSO、GRO、UFO、XPS、IOAT、DDIO 和 TOE 等，这次词汇很让人迷惑。</p><p>在接下来的文章中，我会继续从性能角度解释网络栈，并讲解这些技术的问题和影响。</p>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;译者注&lt;/strong&gt;：很久没有翻译文章了，最近在网络看到这篇介绍网络栈的文章非常详细，正好最近在看这方面的内容，索性翻译过来。因为很多文章比较长，而且很多内容比较专业，
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="linux" scheme="http://cizixs.com/tags/linux/"/>
    
      <category term="network" scheme="http://cizixs.com/tags/network/"/>
    
      <category term="TCP/IP" scheme="http://cizixs.com/tags/TCP-IP/"/>
    
      <category term="kernel" scheme="http://cizixs.com/tags/kernel/"/>
    
  </entry>
  
  <entry>
    <title>kubelet scheduler 源码分析：调度器的工作原理</title>
    <link href="http://cizixs.com/2017/07/19/kubernetes-scheduler-source-code-analysis/"/>
    <id>http://cizixs.com/2017/07/19/kubernetes-scheduler-source-code-analysis/</id>
    <published>2017-07-18T16:00:00.000Z</published>
    <updated>2018-09-17T13:18:45.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>TL;DR</strong></p><h2 id="1-kubernetes-Scheduler-简介"><a href="#1-kubernetes-Scheduler-简介" class="headerlink" title="1. kubernetes Scheduler 简介"></a>1. kubernetes Scheduler 简介</h2><p>kubernetes Scheduler 运行在 master 节点，它的核心功能是监听 apiserver 来获取 <code>PodSpec.NodeName</code> 为空的 pod，然后为每个这样的 pod 创建一个 binding 指示 pod 应该调度到哪个节点上。</p><p>从哪里读取还没有调度的 pod 呢？当然是 apiserver。怎么知道 pod 没有调度呢？我们在 <a href="http://cizixs.com/2016/11/07/kubernetes-intro-api-server">介绍 APIServer </a>的文章讲到，可以通过 <code>spec.nodeName</code> 指定 pod 要部署在特定的节点上。调度器也是一样，它会向 apiserver 请求 <code>spec.nodeName</code> 字段为空的 pod，然后调度得到结果之后，把结果写入 apiserver。</p><p>虽然调度的原理说起来很简单，但是要编写一个优秀的调度器却不容易，因为要考虑的东西很多：</p><ul><li>尽可能地将 workload 平均到不同的节点，减少单个节点宕机造成的损失</li><li>可扩展性。随着集群规模的增加，怎么保证调度器不会成为性能的瓶颈</li><li>高可用。调度器能做组成集群，任何一个调度器出现问题，不会影响整个集群的调度</li><li>灵活性。不同的用户有不同的调度需求，一个优秀的调度器还要允许用户能配置不同的调度算法</li><li>资源合理和高效利用。调度器应该尽可能地提高集群的资源利用率，防止资源的浪费</li></ul><p>文章的最后，我们来分析一下 kubernetes 的调度器是否能做到这几点。</p><p>之前 <a href="http://cizixs.com/2017/03/10/kubernetes-intro-scheduler">kubernetes 调度简介的文章</a>，我们介绍了调度分为两个过程：<code>predicate</code> 和 <code>priority</code>。这篇文章就继续深入到源码层面来解析 kubernetes 调度的过程。</p><p><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1fhcxmspuz7j31260h6my6.jpg" alt=""></p><p>和其他组件不同，scheduler 的代码在 <code>plugin/</code> 目录下：<code>plugin/cmd/kube-scheduler/</code> 是代码的 main 函数入口，<code>plugin/pkg/scheduler/</code> 是具体调度算法。从这个目录结构也可以看出来，kube-scheduler 是作为插件接入到集群中的，它的最终形态一定是用户可以很容易地去定制化和二次开发的。</p><h2 id="2-代码分析"><a href="#2-代码分析" class="headerlink" title="2. 代码分析"></a>2. 代码分析</h2><h3 id="2-1-启动流程"><a href="#2-1-启动流程" class="headerlink" title="2.1 启动流程"></a>2.1 启动流程</h3><p>虽然放到了 <code>plugin/</code> 目录下，<code>kube-scheduler</code> 的启动过程和其他组件还是一样的，它会新建一个  <code>SchedulerServer</code>，这是一个保存了 scheduler 启动所需要配置信息的结构体，然后解析命令行的参数，对结构体中的内容进行赋值，最后运行 <code>app.Run(s)</code> 把 scheduler 跑起来。</p><p><code>plugin/cmd/kube-scheduler/scheduler.go</code>：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    s <span class="token operator">:=</span> options<span class="token punctuation">.</span><span class="token function">NewSchedulerServer</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    s<span class="token punctuation">.</span><span class="token function">AddFlags</span><span class="token punctuation">(</span>pflag<span class="token punctuation">.</span>CommandLine<span class="token punctuation">)</span>    flag<span class="token punctuation">.</span><span class="token function">InitFlags</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    logs<span class="token punctuation">.</span><span class="token function">InitLogs</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">defer</span> logs<span class="token punctuation">.</span><span class="token function">FlushLogs</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    verflag<span class="token punctuation">.</span><span class="token function">PrintAndExitIfRequested</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    app<span class="token punctuation">.</span><span class="token function">Run</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><p><code>app.Runs(s)</code> 根据配置信息构建出来各种实例，然后运行 scheduler 的核心逻辑，这个函数会一直运行，不会退出。</p><p><code>plugin/cmd/kube-scheduler/app/server.go</code>：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">Run</span><span class="token punctuation">(</span>s <span class="token operator">*</span>options<span class="token punctuation">.</span>SchedulerServer<span class="token punctuation">)</span> <span class="token builtin">error</span> <span class="token punctuation">{</span>    <span class="token operator">...</span><span class="token operator">...</span>    configFactory <span class="token operator">:=</span> factory<span class="token punctuation">.</span><span class="token function">NewConfigFactory</span><span class="token punctuation">(</span>leaderElectionClient<span class="token punctuation">,</span> s<span class="token punctuation">.</span>SchedulerName<span class="token punctuation">,</span> s<span class="token punctuation">.</span>HardPodAffinitySymmetricWeight<span class="token punctuation">,</span> s<span class="token punctuation">.</span>FailureDomains<span class="token punctuation">)</span>    config<span class="token punctuation">,</span> err <span class="token operator">:=</span> <span class="token function">createConfig</span><span class="token punctuation">(</span>s<span class="token punctuation">,</span> configFactory<span class="token punctuation">)</span>    <span class="token operator">...</span><span class="token operator">...</span>    sched <span class="token operator">:=</span> scheduler<span class="token punctuation">.</span><span class="token function">New</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span>    run <span class="token operator">:=</span> <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token boolean">_</span> <span class="token operator">&lt;-</span><span class="token keyword">chan</span> <span class="token keyword">struct</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        sched<span class="token punctuation">.</span><span class="token function">Run</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">select</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token comment" spellcheck="true">// 多个 kube-scheduler 部署高可用集群会用到 leader election 功能</span>    <span class="token operator">...</span><span class="token operator">...</span><span class="token punctuation">}</span></code></pre><p><code>Run</code> 方法的主要逻辑是这样的：根据传递过来的参数创建 scheduler 需要的配置（主要是需要的各种结构体），然后调用 scheduler 的接口创建一个新的 scheduler 对象，最后运行这个对象开启调度代码。需要注意的是，<code>config</code> 这个对象也是在 <code>configFactory</code> 的基础上创建出来的。</p><p>了解 <code>config</code> 的创建和内容对后面了解调度器的工作原理非常重要，所以我们先来分下它的代码。</p><h3 id="2-2-Config-的创建"><a href="#2-2-Config-的创建" class="headerlink" title="2.2 Config 的创建"></a>2.2 Config 的创建</h3><p><code>factory.NewConfigFactory</code> 方法会创建一个 <code>ConfigFactory</code> 的对象，这个对象里面主要是一些 <code>ListAndWatch</code>，用来从 apiserver 中同步各种资源的内容，用作调度时候的参考。此外，还有两个特别重要的结构体成员：<code>PodQueue</code> 和 <code>PodLister</code>，<code>PodQueue</code> 队列中保存了<strong>还没有调度</strong>的 pod，<code>PodLister</code> 同步未调度的 Pod 和 Pod 的状态信息。</p><p><code>plugin/pkg/scheduler/factory/factory.go</code>：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">NewConfigFactory</span><span class="token punctuation">(</span>client clientset<span class="token punctuation">.</span>Interface<span class="token punctuation">,</span> schedulerName <span class="token builtin">string</span><span class="token punctuation">,</span> hardPodAffinitySymmetricWeight <span class="token builtin">int</span><span class="token punctuation">,</span> failureDomains <span class="token builtin">string</span><span class="token punctuation">)</span> <span class="token operator">*</span>ConfigFactory <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// schedulerCache 保存了 pod 和 node 的信息，是调度过程中两者信息的 source of truth</span>    schedulerCache <span class="token operator">:=</span> schedulercache<span class="token punctuation">.</span><span class="token function">New</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token operator">*</span>time<span class="token punctuation">.</span>Second<span class="token punctuation">,</span> stopEverything<span class="token punctuation">)</span>    informerFactory <span class="token operator">:=</span> informers<span class="token punctuation">.</span><span class="token function">NewSharedInformerFactory</span><span class="token punctuation">(</span>client<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>    pvcInformer <span class="token operator">:=</span> informerFactory<span class="token punctuation">.</span><span class="token function">PersistentVolumeClaims</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    c <span class="token operator">:=</span> <span class="token operator">&amp;</span>ConfigFactory<span class="token punctuation">{</span>        Client<span class="token punctuation">:</span>             client<span class="token punctuation">,</span>        PodQueue<span class="token punctuation">:</span>           cache<span class="token punctuation">.</span><span class="token function">NewFIFO</span><span class="token punctuation">(</span>cache<span class="token punctuation">.</span>MetaNamespaceKeyFunc<span class="token punctuation">)</span><span class="token punctuation">,</span>        ScheduledPodLister<span class="token punctuation">:</span> <span class="token operator">&amp;</span>cache<span class="token punctuation">.</span>StoreToPodLister<span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span>        informerFactory<span class="token punctuation">:</span>    informerFactory<span class="token punctuation">,</span>        <span class="token comment" spellcheck="true">// ConfigFactory 中非常重要的一部分就是各种 `Lister`，用来从获取各种资源列表，它们会和 apiserver 保持实时同步</span>        NodeLister<span class="token punctuation">:</span>                     <span class="token operator">&amp;</span>cache<span class="token punctuation">.</span>StoreToNodeLister<span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span>        PVLister<span class="token punctuation">:</span>                       <span class="token operator">&amp;</span>cache<span class="token punctuation">.</span>StoreToPVFetcher<span class="token punctuation">{</span>Store<span class="token punctuation">:</span> cache<span class="token punctuation">.</span><span class="token function">NewStore</span><span class="token punctuation">(</span>cache<span class="token punctuation">.</span>MetaNamespaceKeyFunc<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>        PVCLister<span class="token punctuation">:</span>                      pvcInformer<span class="token punctuation">.</span><span class="token function">Lister</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        pvcPopulator<span class="token punctuation">:</span>                   pvcInformer<span class="token punctuation">.</span><span class="token function">Informer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">GetController</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        ServiceLister<span class="token punctuation">:</span>                  <span class="token operator">&amp;</span>cache<span class="token punctuation">.</span>StoreToServiceLister<span class="token punctuation">{</span>Indexer<span class="token punctuation">:</span> cache<span class="token punctuation">.</span><span class="token function">NewIndexer</span><span class="token punctuation">(</span>cache<span class="token punctuation">.</span>MetaNamespaceKeyFunc<span class="token punctuation">,</span> cache<span class="token punctuation">.</span>Indexers<span class="token punctuation">{</span>cache<span class="token punctuation">.</span>NamespaceIndex<span class="token punctuation">:</span> cache<span class="token punctuation">.</span>MetaNamespaceIndexFunc<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>        ControllerLister<span class="token punctuation">:</span>               <span class="token operator">&amp;</span>cache<span class="token punctuation">.</span>StoreToReplicationControllerLister<span class="token punctuation">{</span>Indexer<span class="token punctuation">:</span> cache<span class="token punctuation">.</span><span class="token function">NewIndexer</span><span class="token punctuation">(</span>cache<span class="token punctuation">.</span>MetaNamespaceKeyFunc<span class="token punctuation">,</span> cache<span class="token punctuation">.</span>Indexers<span class="token punctuation">{</span>cache<span class="token punctuation">.</span>NamespaceIndex<span class="token punctuation">:</span> cache<span class="token punctuation">.</span>MetaNamespaceIndexFunc<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>        ReplicaSetLister<span class="token punctuation">:</span>               <span class="token operator">&amp;</span>cache<span class="token punctuation">.</span>StoreToReplicaSetLister<span class="token punctuation">{</span>Indexer<span class="token punctuation">:</span> cache<span class="token punctuation">.</span><span class="token function">NewIndexer</span><span class="token punctuation">(</span>cache<span class="token punctuation">.</span>MetaNamespaceKeyFunc<span class="token punctuation">,</span> cache<span class="token punctuation">.</span>Indexers<span class="token punctuation">{</span>cache<span class="token punctuation">.</span>NamespaceIndex<span class="token punctuation">:</span> cache<span class="token punctuation">.</span>MetaNamespaceIndexFunc<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span>        schedulerCache<span class="token punctuation">:</span>                 schedulerCache<span class="token punctuation">,</span>        StopEverything<span class="token punctuation">:</span>                 stopEverything<span class="token punctuation">,</span>        SchedulerName<span class="token punctuation">:</span>                  schedulerName<span class="token punctuation">,</span>        HardPodAffinitySymmetricWeight<span class="token punctuation">:</span> hardPodAffinitySymmetricWeight<span class="token punctuation">,</span>        FailureDomains<span class="token punctuation">:</span>                 failureDomains<span class="token punctuation">,</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// PodLister 和其他 Lister 创建方式不同，它就是 `schedulerCache`</span>    c<span class="token punctuation">.</span>PodLister <span class="token operator">=</span> schedulerCache    <span class="token comment" spellcheck="true">// ScheduledPodLister 保存了已经调度的 pod， 即 `Spec.NodeName` 不为空且状态不是 Failed 或者 Succeeded 的 pod</span>    <span class="token comment" spellcheck="true">// Informer 是对 reflector 的一层封装，reflect 把 ListWatcher 的结果实时更新到 store 中，而 informer 在每次更新的时候会调用对应的 handler 函数。</span>    <span class="token comment" spellcheck="true">// 这里的 handler 函数把 store 中的 pod 数据更新到 schedulerCache 中</span>    c<span class="token punctuation">.</span>ScheduledPodLister<span class="token punctuation">.</span>Indexer<span class="token punctuation">,</span> c<span class="token punctuation">.</span>scheduledPodPopulator <span class="token operator">=</span> cache<span class="token punctuation">.</span><span class="token function">NewIndexerInformer</span><span class="token punctuation">(</span>        c<span class="token punctuation">.</span><span class="token function">createAssignedNonTerminatedPodLW</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token operator">&amp;</span>api<span class="token punctuation">.</span>Pod<span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token number">0</span><span class="token punctuation">,</span>        cache<span class="token punctuation">.</span>ResourceEventHandlerFuncs<span class="token punctuation">{</span>            AddFunc<span class="token punctuation">:</span>    c<span class="token punctuation">.</span>addPodToCache<span class="token punctuation">,</span>            UpdateFunc<span class="token punctuation">:</span> c<span class="token punctuation">.</span>updatePodInCache<span class="token punctuation">,</span>            DeleteFunc<span class="token punctuation">:</span> c<span class="token punctuation">.</span>deletePodFromCache<span class="token punctuation">,</span>        <span class="token punctuation">}</span><span class="token punctuation">,</span>        cache<span class="token punctuation">.</span>Indexers<span class="token punctuation">{</span>cache<span class="token punctuation">.</span>NamespaceIndex<span class="token punctuation">:</span> cache<span class="token punctuation">.</span>MetaNamespaceIndexFunc<span class="token punctuation">}</span><span class="token punctuation">,</span>    <span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 同上，把 node 的数据实时同步到 schedulerCache</span>    c<span class="token punctuation">.</span>NodeLister<span class="token punctuation">.</span>Store<span class="token punctuation">,</span> c<span class="token punctuation">.</span>nodePopulator <span class="token operator">=</span> cache<span class="token punctuation">.</span><span class="token function">NewInformer</span><span class="token punctuation">(</span>        c<span class="token punctuation">.</span><span class="token function">createNodeLW</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token operator">&amp;</span>api<span class="token punctuation">.</span>Node<span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token number">0</span><span class="token punctuation">,</span>        cache<span class="token punctuation">.</span>ResourceEventHandlerFuncs<span class="token punctuation">{</span>            AddFunc<span class="token punctuation">:</span>    c<span class="token punctuation">.</span>addNodeToCache<span class="token punctuation">,</span>            UpdateFunc<span class="token punctuation">:</span> c<span class="token punctuation">.</span>updateNodeInCache<span class="token punctuation">,</span>            DeleteFunc<span class="token punctuation">:</span> c<span class="token punctuation">.</span>deleteNodeFromCache<span class="token punctuation">,</span>        <span class="token punctuation">}</span><span class="token punctuation">,</span>    <span class="token punctuation">)</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token keyword">return</span> c<span class="token punctuation">}</span></code></pre><p><code>ConfigFactory</code> 里面保存了各种 Lister，它们用来获取 kubernetes 中各种资源的信息，并且 <code>schedulerCache</code> 中保存了调度过程中需要用到的 pods 和 nodes 的最新信息。</p><p>然后，<code>createConfig(s, configFactory)</code> 根据配置参数和 <code>configFactory</code> 创建出真正被 scheduler 使用的 config 对象。</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">createConfig</span><span class="token punctuation">(</span>s <span class="token operator">*</span>options<span class="token punctuation">.</span>SchedulerServer<span class="token punctuation">,</span> configFactory <span class="token operator">*</span>factory<span class="token punctuation">.</span>ConfigFactory<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token operator">*</span>scheduler<span class="token punctuation">.</span>Config<span class="token punctuation">,</span> <span class="token builtin">error</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> <span class="token boolean">_</span><span class="token punctuation">,</span> err <span class="token operator">:=</span> os<span class="token punctuation">.</span><span class="token function">Stat</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>PolicyConfigFile<span class="token punctuation">)</span><span class="token punctuation">;</span> err <span class="token operator">==</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token keyword">var</span> <span class="token punctuation">(</span>            policy     schedulerapi<span class="token punctuation">.</span>Policy            configData <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span>        <span class="token punctuation">)</span>        configData<span class="token punctuation">,</span> err <span class="token operator">:=</span> ioutil<span class="token punctuation">.</span><span class="token function">ReadFile</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>PolicyConfigFile<span class="token punctuation">)</span>        <span class="token operator">...</span><span class="token operator">...</span>        <span class="token keyword">if</span> err <span class="token operator">:=</span> runtime<span class="token punctuation">.</span><span class="token function">DecodeInto</span><span class="token punctuation">(</span>latestschedulerapi<span class="token punctuation">.</span>Codec<span class="token punctuation">,</span> configData<span class="token punctuation">,</span> <span class="token operator">&amp;</span>policy<span class="token punctuation">)</span><span class="token punctuation">;</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> <span class="token boolean">nil</span><span class="token punctuation">,</span> fmt<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"invalid configuration: %v"</span><span class="token punctuation">,</span> err<span class="token punctuation">)</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> configFactory<span class="token punctuation">.</span><span class="token function">CreateFromConfig</span><span class="token punctuation">(</span>policy<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> configFactory<span class="token punctuation">.</span><span class="token function">CreateFromProvider</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>AlgorithmProvider<span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><p><code>createConfig</code> 根据不同的配置有两种方式来创建 <code>scheduler.Config</code>：</p><ol><li>通过 policy 文件：用户编写调度器用到的 policy 文件，控制调度器使用哪些 predicates 和 priorities 函数</li><li>通过 algorithm provider：已经在代码中提前编写好的 provider，也就是 predicates 和 priorities 函数的组合</li></ol><p>这两种方法殊途同归，最终都是获取到 predicates 和 priorities 的名字，然后调用 <code>CreateFromKeys</code> 创建 Config 对象：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>f <span class="token operator">*</span>ConfigFactory<span class="token punctuation">)</span> <span class="token function">CreateFromKeys</span><span class="token punctuation">(</span>predicateKeys<span class="token punctuation">,</span> priorityKeys sets<span class="token punctuation">.</span>String<span class="token punctuation">,</span> extenders <span class="token punctuation">[</span><span class="token punctuation">]</span>algorithm<span class="token punctuation">.</span>SchedulerExtender<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token operator">*</span>scheduler<span class="token punctuation">.</span>Config<span class="token punctuation">,</span> <span class="token builtin">error</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 获取所有的 predicates 函数</span>    predicateFuncs<span class="token punctuation">,</span> err <span class="token operator">:=</span> f<span class="token punctuation">.</span><span class="token function">GetPredicates</span><span class="token punctuation">(</span>predicateKeys<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// priority 返回的不是函数，而是 priorityConfigs。一是因为 priority 还包含了权重，二是因为 priority 的实现在迁移到 map-reduce 的方式</span>    priorityConfigs<span class="token punctuation">,</span> err <span class="token operator">:=</span> f<span class="token punctuation">.</span><span class="token function">GetPriorityFunctionConfigs</span><span class="token punctuation">(</span>priorityKeys<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 两种 MetaProducer 都是用来获取调度中用到的 metadata 信息，比如 affinity、toleration，pod ports（用到的端口）、resource request（请求的资源）等</span>    priorityMetaProducer<span class="token punctuation">,</span> err <span class="token operator">:=</span> f<span class="token punctuation">.</span><span class="token function">GetPriorityMetadataProducer</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    predicateMetaProducer<span class="token punctuation">,</span> err <span class="token operator">:=</span> f<span class="token punctuation">.</span><span class="token function">GetPredicateMetadataProducer</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 运行各种 informer 的内部逻辑，从 apiserver 同步资源数据到 Lister 和 cache 中</span>    f<span class="token punctuation">.</span><span class="token function">Run</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 构造出 schedulerAlgorithm 对象，它最核心的方法是 `Schedule` 方法，我们会在下文说到</span>    algo <span class="token operator">:=</span> scheduler<span class="token punctuation">.</span><span class="token function">NewGenericScheduler</span><span class="token punctuation">(</span>f<span class="token punctuation">.</span>schedulerCache<span class="token punctuation">,</span> predicateFuncs<span class="token punctuation">,</span> predicateMetaProducer<span class="token punctuation">,</span> priorityConfigs<span class="token punctuation">,</span> priorityMetaProducer<span class="token punctuation">,</span> extenders<span class="token punctuation">)</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token comment" spellcheck="true">// 返回最终的 Config 对象</span>    <span class="token keyword">return</span> <span class="token operator">&amp;</span>scheduler<span class="token punctuation">.</span>Config<span class="token punctuation">{</span>        SchedulerCache<span class="token punctuation">:</span> f<span class="token punctuation">.</span>schedulerCache<span class="token punctuation">,</span>        NodeLister<span class="token punctuation">:</span>          f<span class="token punctuation">.</span>NodeLister<span class="token punctuation">.</span><span class="token function">NodeCondition</span><span class="token punctuation">(</span><span class="token function">getNodeConditionPredicate</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        Algorithm<span class="token punctuation">:</span>           algo<span class="token punctuation">,</span>        Binder<span class="token punctuation">:</span>              <span class="token operator">&amp;</span>binder<span class="token punctuation">{</span>f<span class="token punctuation">.</span>Client<span class="token punctuation">}</span><span class="token punctuation">,</span>        PodConditionUpdater<span class="token punctuation">:</span> <span class="token operator">&amp;</span>podConditionUpdater<span class="token punctuation">{</span>f<span class="token punctuation">.</span>Client<span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token comment" spellcheck="true">// NextPod 就是从 PodQueue 中取出 下一个未调度的 pod</span>        NextPod<span class="token punctuation">:</span> <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span>api<span class="token punctuation">.</span>Pod <span class="token punctuation">{</span>            <span class="token keyword">return</span> f<span class="token punctuation">.</span><span class="token function">getNextPod</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token comment" spellcheck="true">// 调度出错时的处理函数，会把 pod 重新加入到 podQueue 中，等待下一次调度</span>        Error<span class="token punctuation">:</span>          f<span class="token punctuation">.</span><span class="token function">makeDefaultErrorFunc</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>podBackoff<span class="token punctuation">,</span> f<span class="token punctuation">.</span>PodQueue<span class="token punctuation">)</span><span class="token punctuation">,</span>        StopEverything<span class="token punctuation">:</span> f<span class="token punctuation">.</span>StopEverything<span class="token punctuation">,</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token boolean">nil</span><span class="token punctuation">}</span></code></pre><p><code>Config</code> 的定义在文件 <code>plugins/pkg/scheduler/scheduler.go</code> 中。它把调度器的逻辑分成几个组件，提供了这些功能：</p><ul><li><code>NextPod()</code> 方法能返回下一个需要调度的 pod</li><li><code>Algorithm.Schedule()</code> 方法能计算出某个 pod 在节点中的结果</li><li><code>Error()</code> 方法能够在出错的时候重新把 pod 放到调度队列中进行重试</li><li><code>schedulerCache</code> 能够暂时保存调度中的 pod 信息，占用着 pod 需要的资源，保证资源不会冲突</li><li><code>Binder.Bind</code> 在调度成功之后把调度结果发送到 apiserver 中保存起来</li></ul><p>后面可以看到 <code>Scheduler</code> 对象就是组合这些逻辑组件来完成最终的调度任务的。</p><p><code>Config</code> 中的逻辑组件中，负责调度 pod 的是 <code>Algorithm.Schedule()</code> 方法。其对应的值是 <code>GenericScheduler</code>，<code>GenericScheduler</code> 是 Scheduler 的一种实现，也是 kube-scheduler 默认使用的调度器，它只负责单个 pod 的调度并返回结果：</p><p><code>plugin/pkg/scheduler/generic_scheduler.go</code></p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">NewGenericScheduler</span><span class="token punctuation">(</span>    cache schedulercache<span class="token punctuation">.</span>Cache<span class="token punctuation">,</span>    predicates <span class="token keyword">map</span><span class="token punctuation">[</span><span class="token builtin">string</span><span class="token punctuation">]</span>algorithm<span class="token punctuation">.</span>FitPredicate<span class="token punctuation">,</span>    predicateMetaProducer algorithm<span class="token punctuation">.</span>MetadataProducer<span class="token punctuation">,</span>    prioritizers <span class="token punctuation">[</span><span class="token punctuation">]</span>algorithm<span class="token punctuation">.</span>PriorityConfig<span class="token punctuation">,</span>    priorityMetaProducer algorithm<span class="token punctuation">.</span>MetadataProducer<span class="token punctuation">,</span>    extenders <span class="token punctuation">[</span><span class="token punctuation">]</span>algorithm<span class="token punctuation">.</span>SchedulerExtender<span class="token punctuation">)</span> algorithm<span class="token punctuation">.</span>ScheduleAlgorithm <span class="token punctuation">{</span>    <span class="token keyword">return</span> <span class="token operator">&amp;</span>genericScheduler<span class="token punctuation">{</span>        cache<span class="token punctuation">:</span>                 cache<span class="token punctuation">,</span>        predicates<span class="token punctuation">:</span>            predicates<span class="token punctuation">,</span>        predicateMetaProducer<span class="token punctuation">:</span> predicateMetaProducer<span class="token punctuation">,</span>        prioritizers<span class="token punctuation">:</span>          prioritizers<span class="token punctuation">,</span>        priorityMetaProducer<span class="token punctuation">:</span>  priorityMetaProducer<span class="token punctuation">,</span>        extenders<span class="token punctuation">:</span>             extenders<span class="token punctuation">,</span>        cachedNodeInfoMap<span class="token punctuation">:</span>     <span class="token function">make</span><span class="token punctuation">(</span><span class="token keyword">map</span><span class="token punctuation">[</span><span class="token builtin">string</span><span class="token punctuation">]</span><span class="token operator">*</span>schedulercache<span class="token punctuation">.</span>NodeInfo<span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>调度算法的接口只有一个方法：<code>Schedule</code>，第一个参数是要调度的 pod，第二个参数是能够获取 node 列表的接口对象。它返回一个节点的名字，表示 pod 将会调度到这台节点上。</p><p><code>plugin/pkg/scheduler/algorithm/scheduler_interface.go</code></p><pre><code>type ScheduleAlgorithm interface {    Schedule(*api.Pod, NodeLister) (selectedMachine string, err error)}</code></pre><p><code>Config</code> 创建出来之后，就是 scheduler 的创建和运行，执行最核心的调度逻辑，不断为所有需要调度的 pod 选择合适的节点：</p><pre><code>sched := scheduler.New(config)run := func(_ &lt;-chan struct{}) {    sched.Run()    select {}}</code></pre><p>总结起来，<code>configFactory</code>、<code>config</code> 和 <code>scheduler</code> 三者的关系如下图所示：</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fhozonecbkj30ov0gbjsn.jpg" alt=""></p><ul><li><code>configFactory</code> 对应工厂模式的工厂模型，根据不同的配置和参数生成 <code>config</code>，当然事先会准备好 <code>config</code> 需要的各种数据</li><li><code>config</code> 是调度器中最重要的组件，里面实现了调度的各个组件逻辑</li><li><code>scheduler</code> 使用 <code>config</code> 提供的功能来完成调度</li></ul><p>如果把调度对比成做菜，那么构建 <code>config</code> 就相当于准备食材和调料、洗菜、对食材进行预处理。做菜就是把准备的食材变成美味佳肴的过程！</p><h3 id="2-3-调度的逻辑"><a href="#2-3-调度的逻辑" class="headerlink" title="2.3 调度的逻辑"></a>2.3 调度的逻辑</h3><p>接着上面分析，看看 <code>scheduler</code> 创建和运行的过程。其对应的代码在 <code>plugin/pkg/scheduler/scheduler.go</code> 文件中：</p><pre class=" language-go"><code class="language-go"><span class="token comment" spellcheck="true">// Scheduler 结构体本身非常简单，它把所有的东西都放到了 `Config` 对象中</span><span class="token keyword">type</span> Scheduler <span class="token keyword">struct</span> <span class="token punctuation">{</span>    config <span class="token operator">*</span>Config<span class="token punctuation">}</span><span class="token comment" spellcheck="true">// 创建 scheduler 就是把 config 放到结构体中</span><span class="token keyword">func</span> <span class="token function">New</span><span class="token punctuation">(</span>c <span class="token operator">*</span>Config<span class="token punctuation">)</span> <span class="token operator">*</span>Scheduler <span class="token punctuation">{</span>    s <span class="token operator">:=</span> <span class="token operator">&amp;</span>Scheduler<span class="token punctuation">{</span>        config<span class="token punctuation">:</span> c<span class="token punctuation">,</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> s<span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>s <span class="token operator">*</span>Scheduler<span class="token punctuation">)</span> <span class="token function">Run</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">go</span> wait<span class="token punctuation">.</span><span class="token function">Until</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>scheduleOne<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> s<span class="token punctuation">.</span>config<span class="token punctuation">.</span>StopEverything<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>s <span class="token operator">*</span>Scheduler<span class="token punctuation">)</span> <span class="token function">scheduleOne</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    pod <span class="token operator">:=</span> s<span class="token punctuation">.</span>config<span class="token punctuation">.</span><span class="token function">NextPod</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    dest<span class="token punctuation">,</span> err <span class="token operator">:=</span> s<span class="token punctuation">.</span>config<span class="token punctuation">.</span>Algorithm<span class="token punctuation">.</span><span class="token function">Schedule</span><span class="token punctuation">(</span>pod<span class="token punctuation">,</span> s<span class="token punctuation">.</span>config<span class="token punctuation">.</span>NodeLister<span class="token punctuation">)</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token comment" spellcheck="true">// assumed 表示已经为 pod 选择了 host，但是还没有在 apiserver 中创建绑定</span>    <span class="token comment" spellcheck="true">// 这个状态的 pod 会单独保存在 schedulerCache 中，并暂时占住了节点上的资源</span>    assumed <span class="token operator">:=</span> <span class="token operator">*</span>pod    assumed<span class="token punctuation">.</span>Spec<span class="token punctuation">.</span>NodeName <span class="token operator">=</span> dest    <span class="token keyword">if</span> err <span class="token operator">:=</span> s<span class="token punctuation">.</span>config<span class="token punctuation">.</span>SchedulerCache<span class="token punctuation">.</span><span class="token function">AssumePod</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>assumed<span class="token punctuation">)</span><span class="token punctuation">;</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 异步对 pod 进行 bind 操作</span>    <span class="token keyword">go</span> <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        b <span class="token operator">:=</span> <span class="token operator">&amp;</span>api<span class="token punctuation">.</span>Binding<span class="token punctuation">{</span>            ObjectMeta<span class="token punctuation">:</span> api<span class="token punctuation">.</span>ObjectMeta<span class="token punctuation">{</span>Namespace<span class="token punctuation">:</span> pod<span class="token punctuation">.</span>Namespace<span class="token punctuation">,</span> Name<span class="token punctuation">:</span> pod<span class="token punctuation">.</span>Name<span class="token punctuation">}</span><span class="token punctuation">,</span>            Target<span class="token punctuation">:</span> api<span class="token punctuation">.</span>ObjectReference<span class="token punctuation">{</span>                Kind<span class="token punctuation">:</span> <span class="token string">"Node"</span><span class="token punctuation">,</span>                Name<span class="token punctuation">:</span> dest<span class="token punctuation">,</span>            <span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token punctuation">}</span>        err <span class="token operator">:=</span> s<span class="token punctuation">.</span>config<span class="token punctuation">.</span>Binder<span class="token punctuation">.</span><span class="token function">Bind</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span>        <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// 绑定失败，删除 pod 的信息，占用的节点资源也被释放，可以让其他 pod 使用</span>            <span class="token keyword">if</span> err <span class="token operator">:=</span> s<span class="token punctuation">.</span>config<span class="token punctuation">.</span>SchedulerCache<span class="token punctuation">.</span><span class="token function">ForgetPod</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>assumed<span class="token punctuation">)</span><span class="token punctuation">;</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>                glog<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"scheduler cache ForgetPod failed: %v"</span><span class="token punctuation">,</span> err<span class="token punctuation">)</span>            <span class="token punctuation">}</span>            s<span class="token punctuation">.</span>config<span class="token punctuation">.</span>PodConditionUpdater<span class="token punctuation">.</span><span class="token function">Update</span><span class="token punctuation">(</span>pod<span class="token punctuation">,</span> <span class="token operator">&amp;</span>api<span class="token punctuation">.</span>PodCondition<span class="token punctuation">{</span>                Type<span class="token punctuation">:</span>   api<span class="token punctuation">.</span>PodScheduled<span class="token punctuation">,</span>                Status<span class="token punctuation">:</span> api<span class="token punctuation">.</span>ConditionFalse<span class="token punctuation">,</span>                Reason<span class="token punctuation">:</span> <span class="token string">"BindingRejected"</span><span class="token punctuation">,</span>            <span class="token punctuation">}</span><span class="token punctuation">)</span>            <span class="token keyword">return</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><p><code>scheduler.Run</code> 就是不断调用 <code>scheduler.scheduleOne()</code> 每次调度一个 pod。</p><p>对应的调度逻辑如下图所示：</p><p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fhozbohy5aj30nt0yp75g.jpg" alt=""></p><p>接下来我们逐步分解和解释。</p><h4 id="2-3-1-下一个需要调度的-pod"><a href="#2-3-1-下一个需要调度的-pod" class="headerlink" title="2.3.1 下一个需要调度的 pod"></a>2.3.1 下一个需要调度的 pod</h4><p><code>NextPod</code> 函数就是 <code>configFactory.getNextPod()</code>，它从未调度的队列中返回下一个应该由当前调度器调度的 pod。</p><p>它从 <code>configFactory.PodQueue</code> 中 pop 出来一个应该由当前调度器调度的 pod。当前 pod 可以通过 <code>scheduler.alpha.kubernetes.io/name</code> annotation 来设置调度器的名字，如果调度器名字发现这个名字和自己一致就认为 pod 应该由自己调度。如果对应的值为空，则默认调度器会进行调度。</p><p><code>PodQueue</code> 是一个先进先出的队列： <code>PodQueue:           cache.NewFIFO(cache.MetaNamespaceKeyFunc)</code>，这个 FIFO 的实现代码在 <code>pkg/client/cache/fifo.go</code> 文件中。<code>PodQueue</code> 的内容是 reflector 从 apiserver 实时同步过来的，里面保存了需要调度的 pod（<code>spec.nodeName</code> 为空，而且状态不是 success 或者 failed）：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>f <span class="token operator">*</span>ConfigFactory<span class="token punctuation">)</span> <span class="token function">Run</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// Watch and queue pods that need scheduling.</span>    cache<span class="token punctuation">.</span><span class="token function">NewReflector</span><span class="token punctuation">(</span>f<span class="token punctuation">.</span><span class="token function">createUnassignedNonTerminatedPodLW</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>api<span class="token punctuation">.</span>Pod<span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> f<span class="token punctuation">.</span>PodQueue<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">RunUntil</span><span class="token punctuation">(</span>f<span class="token punctuation">.</span>StopEverything<span class="token punctuation">)</span>    <span class="token operator">...</span><span class="token operator">...</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>factory <span class="token operator">*</span>ConfigFactory<span class="token punctuation">)</span> <span class="token function">createUnassignedNonTerminatedPodLW</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span>cache<span class="token punctuation">.</span>ListWatch <span class="token punctuation">{</span>    selector <span class="token operator">:=</span> fields<span class="token punctuation">.</span><span class="token function">ParseSelectorOrDie</span><span class="token punctuation">(</span><span class="token string">"spec.nodeName=="</span> <span class="token operator">+</span> <span class="token string">""</span> <span class="token operator">+</span> <span class="token string">",status.phase!="</span> <span class="token operator">+</span> <span class="token function">string</span><span class="token punctuation">(</span>api<span class="token punctuation">.</span>PodSucceeded<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">",status.phase!="</span> <span class="token operator">+</span> <span class="token function">string</span><span class="token punctuation">(</span>api<span class="token punctuation">.</span>PodFailed<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> cache<span class="token punctuation">.</span><span class="token function">NewListWatchFromClient</span><span class="token punctuation">(</span>factory<span class="token punctuation">.</span>Client<span class="token punctuation">.</span><span class="token function">Core</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">RESTClient</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"pods"</span><span class="token punctuation">,</span> api<span class="token punctuation">.</span>NamespaceAll<span class="token punctuation">,</span> selector<span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><h4 id="2-3-2-调度单个-pod"><a href="#2-3-2-调度单个-pod" class="headerlink" title="2.3.2 调度单个 pod"></a>2.3.2 调度单个 pod</h4><p>拿到 pod 之后，就调用具体的调度算法选择一个节点。</p><pre class=" language-go"><code class="language-go">dest<span class="token punctuation">,</span> err <span class="token operator">:=</span> s<span class="token punctuation">.</span>config<span class="token punctuation">.</span>Algorithm<span class="token punctuation">.</span><span class="token function">Schedule</span><span class="token punctuation">(</span>pod<span class="token punctuation">,</span> s<span class="token punctuation">.</span>config<span class="token punctuation">.</span>NodeLister<span class="token punctuation">)</span></code></pre><p>上面已经讲过，默认的调度算法就是 <code>generic_scheduler</code>，它的代码在 <code>plugin/pkg/scheduler/generic_scheduler.go</code> 文件：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>g <span class="token operator">*</span>genericScheduler<span class="token punctuation">)</span> <span class="token function">Schedule</span><span class="token punctuation">(</span>pod <span class="token operator">*</span>api<span class="token punctuation">.</span>Pod<span class="token punctuation">,</span> nodeLister algorithm<span class="token punctuation">.</span>NodeLister<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token builtin">string</span><span class="token punctuation">,</span> <span class="token builtin">error</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 第一步：从 nodeLister 中获取 node 的信息</span>    nodes<span class="token punctuation">,</span> err <span class="token operator">:=</span> nodeLister<span class="token punctuation">.</span><span class="token function">List</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token comment" spellcheck="true">// schedulerCache 中保存了调度用到的 pod 和 node 的最新数据，用里面的数据更新 `cachedNodeInfoMap`，作为调度过程中节点信息的参考</span>    err <span class="token operator">=</span> g<span class="token punctuation">.</span>cache<span class="token punctuation">.</span><span class="token function">UpdateNodeNameToInfoMap</span><span class="token punctuation">(</span>g<span class="token punctuation">.</span>cachedNodeInfoMap<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 第二步：执行 predicate，过滤符合调度条件的节点</span>    filteredNodes<span class="token punctuation">,</span> failedPredicateMap<span class="token punctuation">,</span> err <span class="token operator">:=</span> <span class="token function">findNodesThatFit</span><span class="token punctuation">(</span>pod<span class="token punctuation">,</span> g<span class="token punctuation">.</span>cachedNodeInfoMap<span class="token punctuation">,</span> nodes<span class="token punctuation">,</span> g<span class="token punctuation">.</span>predicates<span class="token punctuation">,</span> g<span class="token punctuation">.</span>extenders<span class="token punctuation">,</span> g<span class="token punctuation">.</span>predicateMetaProducer<span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token function">len</span><span class="token punctuation">(</span>filteredNodes<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token string">""</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>FitError<span class="token punctuation">{</span>            Pod<span class="token punctuation">:</span>              pod<span class="token punctuation">,</span>            FailedPredicates<span class="token punctuation">:</span> failedPredicateMap<span class="token punctuation">,</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 第三步：执行 priority，为符合条件的节点排列优先级</span>    metaPrioritiesInterface <span class="token operator">:=</span> g<span class="token punctuation">.</span><span class="token function">priorityMetaProducer</span><span class="token punctuation">(</span>pod<span class="token punctuation">,</span> g<span class="token punctuation">.</span>cachedNodeInfoMap<span class="token punctuation">)</span>    priorityList<span class="token punctuation">,</span> err <span class="token operator">:=</span> <span class="token function">PrioritizeNodes</span><span class="token punctuation">(</span>pod<span class="token punctuation">,</span> g<span class="token punctuation">.</span>cachedNodeInfoMap<span class="token punctuation">,</span> metaPrioritiesInterface<span class="token punctuation">,</span> g<span class="token punctuation">.</span>prioritizers<span class="token punctuation">,</span> filteredNodes<span class="token punctuation">,</span> g<span class="token punctuation">.</span>extenders<span class="token punctuation">)</span>    <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token string">""</span><span class="token punctuation">,</span> err    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 第四步：从最终的结果中选择一个节点</span>    <span class="token keyword">return</span> g<span class="token punctuation">.</span><span class="token function">selectHost</span><span class="token punctuation">(</span>priorityList<span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><p>调度算法的过程分为四步骤：</p><ol><li>获取必要的数据，这个当然就是 pod 和 nodes 信息。pod 是作为参数传递过来的，nodes 有两类，一个是通过 <code>nodeLister</code> 获取的节点信息，一类是 <code>cachedNodeInfoMap</code>。后一类节点信息中额外保存了资源的使用情况，比如节点上有多少调度的 pod、已经申请的资源、还可以分配的资源等</li><li>执行过滤操作。根据当前 pod 和 nodes 信息，过滤掉不适合运行 pod 的节点</li><li>执行优先级排序操作。对适合 pod 运行的节点进行优先级排序</li><li>选择节点。从最终优先级最高的节点中选择出来一个作为 pod 调度的结果</li></ol><p>下面的几个部分就来讲讲<strong>过滤</strong>和<strong>优先级排序</strong>的过程。</p><h4 id="2-3-3-过滤（Predicate）：移除不合适的节点"><a href="#2-3-3-过滤（Predicate）：移除不合适的节点" class="headerlink" title="2.3.3 过滤（Predicate）：移除不合适的节点"></a>2.3.3 过滤（Predicate）：移除不合适的节点</h4><p>调度器的输入是一个 pod（多个 pod 调度可以通过遍历来实现） 和多个节点，输出是一个节点，表示 pod 将被调度到这个节点上。</p><p>如何找到<strong>最合适</strong> pod 运行的节点呢？第一步就是移除不符合调度条件的节点，这个过程 kubernetes 称为 <code>Predicate</code>，这个单词在这里怎么翻译成中文我也不是很确定，<a href="https://www.merriam-webster.com/dictionary/predicate" target="_blank" rel="noopener">韦氏词典</a>给出了这样的定义：</p><blockquote><p>something that is affirmed or denied of the subject in a proposition in logic.</p><ul><li>merriam webster</li></ul></blockquote><p>这个过程用 <code>filter</code> 对我来说会更直观，容易理解，所以下面我们都将这一过程称作<strong>过滤</strong>。</p><p>过滤调用的函数是 <code>findNodesThatFit</code>，代码在 <code>plugins/pkg/scheduler/generic_scheduler.go</code> 文件中：</p><pre><code>func findNodesThatFit(    pod *api.Pod,    nodeNameToInfo map[string]*schedulercache.NodeInfo,    nodes []*api.Node,    predicateFuncs map[string]algorithm.FitPredicate,    extenders []algorithm.SchedulerExtender,    metadataProducer algorithm.MetadataProducer,) ([]*api.Node, FailedPredicateMap, error) {    // filtered 保存通过过滤的节点    var filtered []*api.Node    // failedPredicateMap 保存过滤失败的节点，即不适合 pod 运行的节点    failedPredicateMap := FailedPredicateMap{}    if len(predicateFuncs) == 0 {        filtered = nodes    } else {        filtered = make([]*api.Node, len(nodes))        errs := []error{}        var predicateResultLock sync.Mutex        var filteredLen int32        // meta 函数可以查询 pod 和 node 的信息        meta := metadataProducer(pod, nodeNameToInfo)        // 检查单个 node 能否运行某个 pod        checkNode := func(i int) {            nodeName := nodes[i].Name            fits, failedPredicates, err := podFitsOnNode(pod, meta, nodeNameToInfo[nodeName], predicateFuncs)            ......            if fits {                filtered[atomic.AddInt32(&amp;filteredLen, 1)-1] = nodes[i]            } else {                predicateResultLock.Lock()                failedPredicateMap[nodeName] = failedPredicates                predicateResultLock.Unlock()            }        }        // 使用 workQueue 来并行运行检查，并发数最大是 16        workqueue.Parallelize(16, len(nodes), checkNode)        filtered = filtered[:filteredLen]        if len(errs) &gt; 0 {            return []*api.Node{}, FailedPredicateMap{}, errors.NewAggregate(errs)        }    }    // 在基本过滤的基础上，继续执行 extender 的过滤逻辑    .....    return filtered, failedPredicateMap, nil}</code></pre><p>上面这段代码主要的工作是对 pod 过滤工作进行并发控制、错误处理和结果保存。没有通过过滤的节点信息保存在 <code>failedPredicateMap</code> 字典中，key 是节点名，value 是失败原因的列表；通过过滤的节点保存在 <code>filtered</code> 数组中。</p><p>对于每个 pod，都要检查能否调度到集群中的所有节点上（只包括可调度的节点），而且多个判断逻辑之间是独立的，也就是说 pod 是否能否调度到某个 node 上和其他 node 无关（至少目前是这样的，如果这个假设不再成立，并发要考虑协调的问题），所以可以使用并发来提高性能。并发是通过 <code>workQueue</code> 来实现的，最大并发数量是 16，这个数字是 hard code。</p><p>pod 和 node 是否匹配是调用是 <code>podFitsOnNode</code> 函数来判断的：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">podFitsOnNode</span><span class="token punctuation">(</span>pod <span class="token operator">*</span>api<span class="token punctuation">.</span>Pod<span class="token punctuation">,</span> meta <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> info <span class="token operator">*</span>schedulercache<span class="token punctuation">.</span>NodeInfo<span class="token punctuation">,</span> predicateFuncs <span class="token keyword">map</span><span class="token punctuation">[</span><span class="token builtin">string</span><span class="token punctuation">]</span>algorithm<span class="token punctuation">.</span>FitPredicate<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token builtin">bool</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>algorithm<span class="token punctuation">.</span>PredicateFailureReason<span class="token punctuation">,</span> <span class="token builtin">error</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">var</span> failedPredicates <span class="token punctuation">[</span><span class="token punctuation">]</span>algorithm<span class="token punctuation">.</span>PredicateFailureReason    <span class="token keyword">for</span> <span class="token boolean">_</span><span class="token punctuation">,</span> predicate <span class="token operator">:=</span> <span class="token keyword">range</span> predicateFuncs <span class="token punctuation">{</span>        fit<span class="token punctuation">,</span> reasons<span class="token punctuation">,</span> err <span class="token operator">:=</span> <span class="token function">predicate</span><span class="token punctuation">(</span>pod<span class="token punctuation">,</span> meta<span class="token punctuation">,</span> info<span class="token punctuation">)</span>        <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            err <span class="token operator">:=</span> fmt<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"SchedulerPredicates failed due to %v, which is unexpected."</span><span class="token punctuation">,</span> err<span class="token punctuation">)</span>            <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>algorithm<span class="token punctuation">.</span>PredicateFailureReason<span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> err        <span class="token punctuation">}</span>        <span class="token keyword">if</span> <span class="token operator">!</span>fit <span class="token punctuation">{</span>            failedPredicates <span class="token operator">=</span> <span class="token function">append</span><span class="token punctuation">(</span>failedPredicates<span class="token punctuation">,</span> reasons<span class="token operator">...</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> <span class="token function">len</span><span class="token punctuation">(</span>failedPredicates<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">,</span> failedPredicates<span class="token punctuation">,</span> <span class="token boolean">nil</span><span class="token punctuation">}</span></code></pre><p>它会循环调用所有的 <code>predicateFuncs</code> 定义的过滤方法，并返回节点是否满足调度条件，以及可能的错误信息。每个 predicate 函数的类型是这样的：</p><p><code>plugin/pkg/scheduler/algorithm/types.go</code></p><pre class=" language-go"><code class="language-go"><span class="token keyword">type</span> FitPredicate <span class="token keyword">func</span><span class="token punctuation">(</span>pod <span class="token operator">*</span>api<span class="token punctuation">.</span>Pod<span class="token punctuation">,</span> meta <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> nodeInfo <span class="token operator">*</span>schedulercache<span class="token punctuation">.</span>NodeInfo<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token builtin">bool</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>PredicateFailureReason<span class="token punctuation">,</span> <span class="token builtin">error</span><span class="token punctuation">)</span></code></pre><p>它接受三个参数：</p><ol><li>pod：要调度的 pod</li><li>meta：获取过滤过程中 pod 以及调度参数的函数</li><li>nodeInfo：要过滤的 node 信息</li></ol><p>具体的 predicate 实现都在 <code>plugin/pkg/scheduler/algorithm/predicates/predicates.go</code>：</p><ol><li><code>NoVolumeZoneConflict</code>：pod 请求的 volume 是否能在节点所在的 Zone 使用。通过匹配 node 和 PV 的 <code>failure-domain.beta.kubernetes.io/zone</code> 和 <code>failure-domain.beta.kubernetes.io/region</code> 来决定</li><li><code>MaxEBSVolumeCount</code>：请求的 volumes 是否超过 EBS（Elastic Block Store） 支持的最大值，默认是 39</li><li><code>MaxGCEPDVolumeCount</code>：请求的 volumes 是否超过 GCE 支持的最大值，默认是 16</li><li><code>MatchInterPodAffinity</code>：根据 inter-pod affinity 来决定 pod 是否能调度到节点上。这个过滤方法会看 pod 是否和当前节点的某个 pod 互斥。关于亲和性和互斥性，可以查看<a href="http://cizixs.com/2017/05/17/kubernetes-scheulder-affinity">之前的文章</a>。</li><li><code>NoDiskConflict</code>：检查 pod 请求的 volume 是否就绪和冲突。如果主机上已经挂载了某个卷，则使用相同卷的 pod 不能调度到这个主机上。kubernetes 使用的 volume 类型不同，过滤逻辑也不同。比如不同云主机的 volume 使用限制不同：GCE 允许多个 pods 使用同时使用 volume，前提是它们是只读的；AWS 不允许 pods 使用同一个 volume；Ceph RBD 不允许 pods 共享同一个 monitor</li><li><code>GeneralPredicates</code>：普通过滤函数，主要考虑 kubernetes 资源是否能够满足，比如 CPU 和 Memory 是否足够，端口是否冲突、selector 是否匹配<ul><li><code>PodFitsResources</code>：检查主机上的资源是否满足 pod 的需求。资源的计算是根据主机上运行 pod 请求的资源作为参考的，而不是以实际运行的资源数量</li><li><code>PodFitsHost</code>：如果 pod 指定了 <code>spec.NodeName</code>，看节点的名字是否何它匹配，只有匹配的节点才能运行 pod</li><li><code>PodFitsHostPorts</code>：检查 pod 申请的主机端口是否已经被其他 pod 占用，如果是，则不能调度</li><li><code>PodSelectorMatches</code>：检查主机的标签是否满足 pod 的 selector。包括 NodeAffinity 和 nodeSelector 中定义的标签。</li></ul></li><li><code>PodToleratesNodeTaints</code>：根据 <a href="http://blog.kubernetes.io/2017/03/advanced-scheduling-in-kubernetes.html" target="_blank" rel="noopener">taints 和 toleration</a> 的关系判断 pod 是否可以调度到节点上</li><li><code>CheckNodeMemoryPressure</code>：检查 pod 能否调度到内存有压力的节点上。如有节点有内存压力， guaranteed pod（request 和 limit 相同） 不能调度到节点上。相关资料请查看 <a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/resource-qos.md" target="_blank" rel="noopener">Resource QoS Design</a></li><li><code>CheckNodeDiskPressure</code>：检查 pod 能否调度到磁盘有压力的节点上，目前所有的 pod 都不能调度到磁盘有压力的节点上</li></ol><p>每个过滤函数的逻辑都不复杂，只需要了解相关的概念就能读懂。这篇文章只讲解 <code>PodFitsResources</code> 的实现，也就是判断节点上的资源是否能满足 pod 的请求。</p><p><code>plugin/pkg/scheduler/algorithm/predicates/predicates.go</code>:</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">PodFitsResources</span><span class="token punctuation">(</span>pod <span class="token operator">*</span>api<span class="token punctuation">.</span>Pod<span class="token punctuation">,</span> meta <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> nodeInfo <span class="token operator">*</span>schedulercache<span class="token punctuation">.</span>NodeInfo<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token builtin">bool</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>algorithm<span class="token punctuation">.</span>PredicateFailureReason<span class="token punctuation">,</span> <span class="token builtin">error</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    node <span class="token operator">:=</span> nodeInfo<span class="token punctuation">.</span><span class="token function">Node</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">var</span> predicateFails <span class="token punctuation">[</span><span class="token punctuation">]</span>algorithm<span class="token punctuation">.</span>PredicateFailureReason    <span class="token comment" spellcheck="true">// 判断节点上 pod 数量是否超过限制</span>    allowedPodNumber <span class="token operator">:=</span> nodeInfo<span class="token punctuation">.</span><span class="token function">AllowedPodNumber</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token function">len</span><span class="token punctuation">(</span>nodeInfo<span class="token punctuation">.</span><span class="token function">Pods</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span> <span class="token operator">></span> allowedPodNumber <span class="token punctuation">{</span>        predicateFails <span class="token operator">=</span> <span class="token function">append</span><span class="token punctuation">(</span>predicateFails<span class="token punctuation">,</span> <span class="token function">NewInsufficientResourceError</span><span class="token punctuation">(</span>api<span class="token punctuation">.</span>ResourcePods<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token function">int64</span><span class="token punctuation">(</span><span class="token function">len</span><span class="token punctuation">(</span>nodeInfo<span class="token punctuation">.</span><span class="token function">Pods</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">int64</span><span class="token punctuation">(</span>allowedPodNumber<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 获取 pod 请求的资源，目前支持 CPU、Memory 和 GPU</span>    <span class="token keyword">var</span> podRequest <span class="token operator">*</span>schedulercache<span class="token punctuation">.</span>Resource    <span class="token keyword">if</span> predicateMeta<span class="token punctuation">,</span> ok <span class="token operator">:=</span> meta<span class="token punctuation">.</span><span class="token punctuation">(</span><span class="token operator">*</span>predicateMetadata<span class="token punctuation">)</span><span class="token punctuation">;</span> ok <span class="token punctuation">{</span>        podRequest <span class="token operator">=</span> predicateMeta<span class="token punctuation">.</span>podRequest    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>        podRequest <span class="token operator">=</span> <span class="token function">GetResourceRequest</span><span class="token punctuation">(</span>pod<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token comment" spellcheck="true">// 判断如果 pod 放到节点上，是否超过节点可分配的资源</span>    allocatable <span class="token operator">:=</span> nodeInfo<span class="token punctuation">.</span><span class="token function">AllocatableResource</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> allocatable<span class="token punctuation">.</span>MilliCPU <span class="token operator">&lt;</span> podRequest<span class="token punctuation">.</span>MilliCPU<span class="token operator">+</span>nodeInfo<span class="token punctuation">.</span><span class="token function">RequestedResource</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>MilliCPU <span class="token punctuation">{</span>        predicateFails <span class="token operator">=</span> <span class="token function">append</span><span class="token punctuation">(</span>predicateFails<span class="token punctuation">,</span> <span class="token function">NewInsufficientResourceError</span><span class="token punctuation">(</span>api<span class="token punctuation">.</span>ResourceCPU<span class="token punctuation">,</span> podRequest<span class="token punctuation">.</span>MilliCPU<span class="token punctuation">,</span> nodeInfo<span class="token punctuation">.</span><span class="token function">RequestedResource</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>MilliCPU<span class="token punctuation">,</span> allocatable<span class="token punctuation">.</span>MilliCPU<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token keyword">if</span> allocatable<span class="token punctuation">.</span>Memory <span class="token operator">&lt;</span> podRequest<span class="token punctuation">.</span>Memory<span class="token operator">+</span>nodeInfo<span class="token punctuation">.</span><span class="token function">RequestedResource</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>Memory <span class="token punctuation">{</span>        predicateFails <span class="token operator">=</span> <span class="token function">append</span><span class="token punctuation">(</span>predicateFails<span class="token punctuation">,</span> <span class="token function">NewInsufficientResourceError</span><span class="token punctuation">(</span>api<span class="token punctuation">.</span>ResourceMemory<span class="token punctuation">,</span> podRequest<span class="token punctuation">.</span>Memory<span class="token punctuation">,</span> nodeInfo<span class="token punctuation">.</span><span class="token function">RequestedResource</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>Memory<span class="token punctuation">,</span> allocatable<span class="token punctuation">.</span>Memory<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token keyword">if</span> allocatable<span class="token punctuation">.</span>NvidiaGPU <span class="token operator">&lt;</span> podRequest<span class="token punctuation">.</span>NvidiaGPU<span class="token operator">+</span>nodeInfo<span class="token punctuation">.</span><span class="token function">RequestedResource</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>NvidiaGPU <span class="token punctuation">{</span>        predicateFails <span class="token operator">=</span> <span class="token function">append</span><span class="token punctuation">(</span>predicateFails<span class="token punctuation">,</span> <span class="token function">NewInsufficientResourceError</span><span class="token punctuation">(</span>api<span class="token punctuation">.</span>ResourceNvidiaGPU<span class="token punctuation">,</span> podRequest<span class="token punctuation">.</span>NvidiaGPU<span class="token punctuation">,</span> nodeInfo<span class="token punctuation">.</span><span class="token function">RequestedResource</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>NvidiaGPU<span class="token punctuation">,</span> allocatable<span class="token punctuation">.</span>NvidiaGPU<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token keyword">for</span> rName<span class="token punctuation">,</span> rQuant <span class="token operator">:=</span> <span class="token keyword">range</span> podRequest<span class="token punctuation">.</span>OpaqueIntResources <span class="token punctuation">{</span>        <span class="token keyword">if</span> allocatable<span class="token punctuation">.</span>OpaqueIntResources<span class="token punctuation">[</span>rName<span class="token punctuation">]</span> <span class="token operator">&lt;</span> rQuant<span class="token operator">+</span>nodeInfo<span class="token punctuation">.</span><span class="token function">RequestedResource</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>OpaqueIntResources<span class="token punctuation">[</span>rName<span class="token punctuation">]</span> <span class="token punctuation">{</span>            predicateFails <span class="token operator">=</span> <span class="token function">append</span><span class="token punctuation">(</span>predicateFails<span class="token punctuation">,</span> <span class="token function">NewInsufficientResourceError</span><span class="token punctuation">(</span>rName<span class="token punctuation">,</span> podRequest<span class="token punctuation">.</span>OpaqueIntResources<span class="token punctuation">[</span>rName<span class="token punctuation">]</span><span class="token punctuation">,</span> nodeInfo<span class="token punctuation">.</span><span class="token function">RequestedResource</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>OpaqueIntResources<span class="token punctuation">[</span>rName<span class="token punctuation">]</span><span class="token punctuation">,</span> allocatable<span class="token punctuation">.</span>OpaqueIntResources<span class="token punctuation">[</span>rName<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token keyword">return</span> <span class="token function">len</span><span class="token punctuation">(</span>predicateFails<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">,</span> predicateFails<span class="token punctuation">,</span> <span class="token boolean">nil</span><span class="token punctuation">}</span></code></pre><p>有了前面准备的所有内容，判断节点资源是否满足就简单。只需要把 pod 请求的各种资源和节点上可用的资源比较大小。需要注意的是，如果 pod 没有添加要申请的资源，那么其对应的值为零，也就是说不会受到资源不足影响，同时也不会受资源限制。</p><p>节点上可分配资源是 kubelet 发送给 apiserver 的，而已经请求的资源数量是上面运行的 pods 资源的总和。主要的逻辑就是判断如果 pod 调度到节点上，那么所有 pods 请求的资源总和是否超过节点可用的资源数量，只要有任何一个资源超标，就认为无法调度到 node 上。</p><h4 id="2-3-4-优先级（Priority）：为合适的节点排序"><a href="#2-3-4-优先级（Priority）：为合适的节点排序" class="headerlink" title="2.3.4 优先级（Priority）：为合适的节点排序"></a>2.3.4 优先级（Priority）：为合适的节点排序</h4><p>过滤结束后，剩下的节点都是 pod 可以调度到上面的。如果过滤阶段就把所有的节点 pass 了，那么久直接返回调度错误；如果剩下多个节点，那么我们还要从这些可用的节点中选择一个。</p><p>虽然随机选择一个节点进行调度理论上也可以（毕竟它们都满足调度条件），但是我们还是希望能找到<strong>最合适的节点</strong>。什么是最合适呢？当然要根据需求来决定，但是有一些比较通用性的要求，比如 workload 在集群中要尽量均衡。不同的节点对 pod 的合适程度是不同的，优先级过程就是负责尽量找出更合适的节点的。</p><p>对每个节点，priority 函数都会计算出来一个 0-10 之间的数字，表示 pod 放到该节点的合适程度，其中 10 表示非常合适，0 表示非常不合适。每个不同的优先级函数都有一个权重值，这个值为正数，最终的值为权重和优先级函数结果的乘积，而一个节点的权重就是所有优先级函数结果的加和。比如有两种优先级函数 <code>priorityFunc1</code> 和 <code>priorityFunc2</code>，对应的权重分别为 <code>weight1</code> 和 <code>weight2</code>，那么节点 A 的最终得分是：</p><pre><code>finalScoreNodeA = (weight1 * priorityFunc1) + (weight2 * priorityFunc2)</code></pre><p>而权重最高的节点自然就是最合适的调度结果，优先级步骤对应函数 <code>PrioritizeNodes</code>：</p><pre><code>func PrioritizeNodes(    pod *api.Pod,    nodeNameToInfo map[string]*schedulercache.NodeInfo,    meta interface{},    priorityConfigs []algorithm.PriorityConfig,    nodes []*api.Node,    extenders []algorithm.SchedulerExtender,) (schedulerapi.HostPriorityList, error) {    // 如果没有配置 priority，那么所有节点权重相同，最后的结果类似于随机选择一个节点    ......    var (        mu   = sync.Mutex{}        wg   = sync.WaitGroup{}        errs []error    )    // results 是个二维表格，保存着每个节点对应每个优先级函数的得分    results := make([]schedulerapi.HostPriorityList, 0, len(priorityConfigs))    // 原来的计算方法，通过 `priorityConfig.Function` 计算分值。    // 每次取出一个优先级函数，计算所有节点的值    for i, priorityConfig := range priorityConfigs {        if priorityConfig.Function != nil {            wg.Add(1)            go func(index int, config algorithm.PriorityConfig) {                defer wg.Done()                results[index], err = config.Function(pod, nodeNameToInfo, nodes)            }(i, priorityConfig)        } else {            results[i] = make(schedulerapi.HostPriorityList, len(nodes))        }    }    // 以后会使用的计算方式，通过 map-reduce 的方式来计算分值    processNode := func(index int) {        nodeInfo := nodeNameToInfo[nodes[index].Name]        var err error        for i := range priorityConfigs {            if priorityConfigs[i].Function != nil {                continue            }            results[i][index], err = priorityConfigs[i].Map(pod, meta, nodeInfo)        }    }    // 并发去计算结果    workqueue.Parallelize(16, len(nodes), processNode)    for i, priorityConfig := range priorityConfigs {        if priorityConfig.Reduce == nil {            continue        }        wg.Add(1)        go func(index int, config algorithm.PriorityConfig) {            defer wg.Done()            if err := config.Reduce(pod, meta, nodeNameToInfo, results[index]); err != nil {                appendError(err)            }        }(i, priorityConfig)    }    // 等待所有计算结束    wg.Wait()    if len(errs) != 0 {        return schedulerapi.HostPriorityList{}, errors.NewAggregate(errs)    }    // 计算分值的总和，得到最终的结果    result := make(schedulerapi.HostPriorityList, 0, len(nodes))    for i := range nodes {        result = append(result, schedulerapi.HostPriority{Host: nodes[i].Name, Score: 0})        for j := range priorityConfigs {            result[i].Score += results[j][i].Score * priorityConfigs[j].Weight        }    }    ......    return result, nil}</code></pre><p>要想获得所有节点最终的权重分值，就要先计算每个优先级函数对应该节点的分值，然后计算总和。因此不管过程如何，如果有 N 个节点，M 个优先级函数，一定会计算 M*N 个中间值，构成一个二维表格：</p><p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fhpajksubhj316a0lo0uc.jpg" alt=""></p><p>最后，会把表格中按照节点把优先级函数的权重列表相加，得到最终节点的分值。上面的代码就是这个过程，当然中间过程可以并发计算，以加快速度。</p><p>目前，kubernetes scheduler 提供了很多实用的优先级函数：</p><ul><li><code>LeastRequestedPriority</code>：最低请求优先级。根据 CPU 和内存的使用率来决定优先级，使用率越低优先级越高，也就是说优先调度到资源利用率低的节点，这个优先级函数能起到把负载尽量平均分到集群的节点上。默认权重为 1</li><li><code>BalancedResourceAllocation</code>：资源平衡分配。这个优先级函数会把 pod 分配到 CPU 和 memory 利用率差不多的节点（计算的时候会考虑当前 pod 一旦分配到节点的情况）。默认权重为 1</li><li><code>SelectorSpreadPriority</code>：尽量把同一个 service、replication controller、replica set 的 pod 分配到不同的节点，这些资源都是通过 selector 来选择 pod 的，所以名字才是这样的。默认权重为 1</li><li><code>CalculateAntiAffinityPriority</code>：尽量把同一个 service 下面某个 label 相同的 pod 分配到不同的节点</li><li><code>ImageLocalityPriority</code>：根据镜像是否已经存在的节点上来决定优先级，节点上存在要使用的镜像，而且镜像越大，优先级越高。这个函数会尽量把 pod 分配到下载镜像花销最少的节点</li><li><code>NodeAffinityPriority</code>：NodeAffinity，默认权重为 1</li><li><code>InterPodAffinityPriority</code>：根据 pod 之间的亲和性决定 node 的优先级，默认权重为 1</li><li><code>NodePreferAvoidPodsPriority</code>：默认权重是 10000，把这个权重设置的那么大，就以为这一旦该函数的结果不为 0，就由它决定排序结果</li><li><code>TaintTolerationPriority</code>：默认权重是 1</li></ul><p>不同的优先级函数计算出来节点的权重值是个 [0-10] 的值，也就是它们本身就要做好规范化。如果认为某个优先级函数非常重要，那就增加它的 weight。</p><p>对于优先级函数，我们只讲解 <code>LeastRequestedPriority</code> 和 <code>BalancedResourceAllocation</code> 的实现，因为它们两个和资源密切相关。</p><p><strong>最小资源请求</strong>优先级函数会计算每个节点的资源利用率，它目前只考虑 CPU 和内存两种资源，而且两者权重相同，具体的资源公式为：</p><pre><code>score = (CPU Usage rate * 10 + Memory Usage Rate * 10 )/2</code></pre><p>利用率的计算一样，都是 <code>(capacity - requested)/capacity</code>，capacity 指节点上资源的容量，比如 CPU 的核数，内存的大小；requested 表示节点当前所有 pod 请求对应资源的总和。</p><p>代码就不放出来了，就是做一个算术运算，对应的文件在：<code>plugin/pkg/scheduler/algorithm/priorities/lease_requested.go</code>。</p><p><strong>平衡资源优先级函数</strong>会计算 CPU 和内存的平衡度，并尽量选择更均衡的节点。它会分别计算 CPU 和内存的，计算公式为：</p><pre><code>10 - abs(cpuFraction - memoryFraction)*10</code></pre><p>对应的 cpuFraction 和 memoryFraction 就是资源利用率，计算公式都是 <code>requested/capacity</code>。这种方法不推荐单独使用，一定要和最小资源请求一起使用。<strong>最小资源请求</strong>能尽量选择资源使用率低的节点，而这个方法会尽量考虑资源使用率比较平衡的节点。它能避免这样的情况：节点上 CPU 已经使用完了，剩下很多内存空间可用，但是因为 CPU 不再满足任何 pod 的请求，因此无法调度任何 pod，导致内存资源白白浪费。</p><p>这种实现主要参考了 <em>an energy efficient virtual machine placement algorithm with balanced resource utilization</em> 论文提出的方法，感兴趣的可以自行搜索阅读。</p><h4 id="2-3-5-选择节点作为调度结果"><a href="#2-3-5-选择节点作为调度结果" class="headerlink" title="2.3.5 选择节点作为调度结果"></a>2.3.5 选择节点作为调度结果</h4><p>优先级阶段不会移除任何的节点，只是对节点添加了一个分值，根据分值排序，分值最高的就是最终的结果。</p><p>如果分值最高的节点有多个，就“随机”选择一个。这个步骤就是 <code>selectHost</code> 的逻辑：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>g <span class="token operator">*</span>genericScheduler<span class="token punctuation">)</span> <span class="token function">selectHost</span><span class="token punctuation">(</span>priorityList schedulerapi<span class="token punctuation">.</span>HostPriorityList<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token builtin">string</span><span class="token punctuation">,</span> <span class="token builtin">error</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 没有节点，直接返回错误</span>    <span class="token keyword">if</span> <span class="token function">len</span><span class="token punctuation">(</span>priorityList<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token string">""</span><span class="token punctuation">,</span> fmt<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"empty priorityList"</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 根据权重分值从高到低排序</span>    sort<span class="token punctuation">.</span><span class="token function">Sort</span><span class="token punctuation">(</span>sort<span class="token punctuation">.</span><span class="token function">Reverse</span><span class="token punctuation">(</span>priorityList<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 找到所有最高分值的节点</span>    maxScore <span class="token operator">:=</span> priorityList<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>Score    firstAfterMaxScore <span class="token operator">:=</span> sort<span class="token punctuation">.</span><span class="token function">Search</span><span class="token punctuation">(</span><span class="token function">len</span><span class="token punctuation">(</span>priorityList<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">func</span><span class="token punctuation">(</span>i <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token builtin">bool</span> <span class="token punctuation">{</span> <span class="token keyword">return</span> priorityList<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>Score <span class="token operator">&lt;</span> maxScore <span class="token punctuation">}</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// “随机”选择一个：其实是类似于 roundrobin 方法，记录一个 lastNodeIndex 不断加一，对可用节点数取模</span>    g<span class="token punctuation">.</span>lastNodeIndexLock<span class="token punctuation">.</span><span class="token function">Lock</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    ix <span class="token operator">:=</span> <span class="token function">int</span><span class="token punctuation">(</span>g<span class="token punctuation">.</span>lastNodeIndex <span class="token operator">%</span> <span class="token function">uint64</span><span class="token punctuation">(</span>firstAfterMaxScore<span class="token punctuation">)</span><span class="token punctuation">)</span>    g<span class="token punctuation">.</span>lastNodeIndex<span class="token operator">++</span>    g<span class="token punctuation">.</span>lastNodeIndexLock<span class="token punctuation">.</span><span class="token function">Unlock</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 返回结果</span>    <span class="token keyword">return</span> priorityList<span class="token punctuation">[</span>ix<span class="token punctuation">]</span><span class="token punctuation">.</span>Host<span class="token punctuation">,</span> <span class="token boolean">nil</span><span class="token punctuation">}</span></code></pre><p>这个过程非常简单，没有需要过多解释的地方，代码关键步骤已经写上了注释。</p><h2 id="3-自定义调度器"><a href="#3-自定义调度器" class="headerlink" title="3. 自定义调度器"></a>3. 自定义调度器</h2><p>如果对调度没有特殊的要求，使用 kube-schduler 的默认调度就能满足大部分的需求。如果默认调度不能满足需求，就要对调度进行自定义。这部分介绍几种用户可以自定义调度逻辑的方法！</p><h3 id="3-1-修改-policy-文件"><a href="#3-1-修改-policy-文件" class="headerlink" title="3.1 修改 policy 文件"></a>3.1 修改 policy 文件</h3><p>kube-scheduler 在启动的时候可以通过 <code>--policy-config-file</code> 参数可以指定调度策略文件，用户可以根据需要组装 predicates 和 priority 函数。选择不同的过滤函数和优先级函数、控制优先级函数的权重、调整过滤函数的顺序都会影响调度过程。</p><p>可以参考官方给出的 policy 文件实例：</p><pre><code>{&quot;kind&quot; : &quot;Policy&quot;,&quot;apiVersion&quot; : &quot;v1&quot;,&quot;predicates&quot; : [    {&quot;name&quot; : &quot;PodFitsHostPorts&quot;},    {&quot;name&quot; : &quot;PodFitsResources&quot;},    {&quot;name&quot; : &quot;NoDiskConflict&quot;},    {&quot;name&quot; : &quot;NoVolumeZoneConflict&quot;},    {&quot;name&quot; : &quot;MatchNodeSelector&quot;},    {&quot;name&quot; : &quot;HostName&quot;}    ],&quot;priorities&quot; : [    {&quot;name&quot; : &quot;LeastRequestedPriority&quot;, &quot;weight&quot; : 1},    {&quot;name&quot; : &quot;BalancedResourceAllocation&quot;, &quot;weight&quot; : 1},    {&quot;name&quot; : &quot;ServiceSpreadingPriority&quot;, &quot;weight&quot; : 1},    {&quot;name&quot; : &quot;EqualPriority&quot;, &quot;weight&quot; : 1}    ],&quot;hardPodAffinitySymmetricWeight&quot; : 10}</code></pre><h3 id="3-2-编写自己的-priority-和-predicate-函数"><a href="#3-2-编写自己的-priority-和-predicate-函数" class="headerlink" title="3.2 编写自己的 priority 和 predicate 函数"></a>3.2 编写自己的 priority 和 predicate 函数</h3><p>前一种方法就是对已有的调度模块（过滤函数和优先级函数）进行组合，如果有特殊的需求这些模块本身无法满足，用户还可以编写自己的过滤函数和优先级函数。</p><p>过滤函数的接口已经说过：</p><p><code>plugin/pkg/scheduler/algorithm/types.go</code></p><pre class=" language-go"><code class="language-go"><span class="token keyword">type</span> FitPredicate <span class="token keyword">func</span><span class="token punctuation">(</span>pod <span class="token operator">*</span>v1<span class="token punctuation">.</span>Pod<span class="token punctuation">,</span> meta <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> nodeInfo <span class="token operator">*</span>schedulercache<span class="token punctuation">.</span>NodeInfo<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token builtin">bool</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>PredicateFailureReason<span class="token punctuation">,</span> <span class="token builtin">error</span><span class="token punctuation">)</span></code></pre><p>用户只需要在 <code>plugin/pkg/scheduler/algorithm/predicates/predicates.go</code> 文件中编写对象实现这个接口就行。</p><p>编写完过滤函数还要把它用起来，下一步就是把它进行注册，让 kube-scheduler 启动的时候知道它的存在，注册部分可以在 <code>plugin/pkg/scheduler/algorithmprovider/defaults/defaults.go</code> 完成，可以参考其他过滤函数的注册代码：</p><pre class=" language-go"><code class="language-go">factory<span class="token punctuation">.</span><span class="token function">RegisterFitPredicate</span><span class="token punctuation">(</span><span class="token string">"PodFitsHostPorts"</span><span class="token punctuation">,</span> predicates<span class="token punctuation">.</span>PodFitsHostPorts<span class="token punctuation">)</span></code></pre><p>最后，可以在 <code>--policy-config-file</code> 把自定义的过滤函数写进去，kube-scheduler 运行的时候就能执行你编写调度器的逻辑了。</p><p>自定义优先级函数的过程和这个过滤函数类似，就不赘述了。</p><h3 id="3-3-编写自己的调度器"><a href="#3-3-编写自己的调度器" class="headerlink" title="3.3 编写自己的调度器"></a>3.3 编写自己的调度器</h3><p>除了在 kube-scheduler 已有的框架中进行定制化外，kubernetes 还允许你重头编写自己的调度器组件，并在创建资源的时候使用它。多个调度器可以同时运行和工作，只要名字不冲突就行。</p><p>使用某个调度器就是在 pod 的 <code>spec.schedulername</code> 字段中填写上调度器的名字。kubernetes 提供的调度器名字是 <code>default</code>，如果自定义的调度器名字是 <code>my-scheduler</code>，那么只有当 <code>spec.schedulername</code> 字段是 <code>my-scheduler</code> 才会被后者调度。</p><p><strong>NOTE</strong>：调取器的名字并没有统一保存在 apiserver 中进行统一管理，而是每个调取器去 apiserver 中获取和自己名字一直的 pod 来调度。也就是说，调度器是自己管理名字的，因此做到不冲突而且逻辑正确是每个调度器的工作。</p><p>虽然 kube-scheduler 的实现看起来很复杂，但是调度器最核心的逻辑是非常简单的。它从 apiserver 获取没有调度的 pod 信息和 node 信息，然后从节点中选择一个作为调度结果，然后向 apiserver 中写入 binding 资源。比如下面就是用 bash 编写的最精简调度器：</p><pre class=" language-go"><code class="language-go">#<span class="token operator">!</span><span class="token operator">/</span>bin<span class="token operator">/</span>bashSERVER<span class="token operator">=</span><span class="token string">'localhost:8001'</span>while <span class="token boolean">true</span><span class="token punctuation">;</span>do    <span class="token keyword">for</span> PODNAME in $<span class="token punctuation">(</span>kubectl <span class="token operator">--</span>server $SERVER get pods <span class="token operator">-</span>o json <span class="token operator">|</span> jq <span class="token string">'.items[] | select(.spec.schedulerName == "my-scheduler") | select(.spec.nodeName == null) | .metadata.name'</span> <span class="token operator">|</span> tr <span class="token operator">-</span>d <span class="token string">'"'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    do        NODES<span class="token operator">=</span><span class="token punctuation">(</span>$<span class="token punctuation">(</span>kubectl <span class="token operator">--</span>server $SERVER get nodes <span class="token operator">-</span>o json <span class="token operator">|</span> jq <span class="token string">'.items[].metadata.name'</span> <span class="token operator">|</span> tr <span class="token operator">-</span>d <span class="token string">'"'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        NUMNODES<span class="token operator">=</span>$<span class="token punctuation">{</span>#NODES<span class="token punctuation">[</span>@<span class="token punctuation">]</span><span class="token punctuation">}</span>        CHOSEN<span class="token operator">=</span>$<span class="token punctuation">{</span>NODES<span class="token punctuation">[</span>$<span class="token punctuation">[</span> $RANDOM <span class="token operator">%</span> $NUMNODES <span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">}</span>        curl <span class="token operator">--</span>header <span class="token string">"Content-Type:application/json"</span> <span class="token operator">--</span>request POST <span class="token operator">--</span>data <span class="token string">'{"apiVersion":"v1", "kind": "Binding", "metadata": {"name": "'</span>$PODNAME<span class="token string">'"}, "target": {"apiVersion": "v1", "kind": "Node", "name": "'</span>$CHOSEN<span class="token string">'"}}'</span> http<span class="token punctuation">:</span><span class="token operator">/</span><span class="token operator">/</span>$SERVER<span class="token operator">/</span>api<span class="token operator">/</span>v1<span class="token operator">/</span>namespaces<span class="token operator">/</span><span class="token keyword">default</span><span class="token operator">/</span>pods<span class="token operator">/</span>$PODNAME<span class="token operator">/</span>binding<span class="token operator">/</span>        echo <span class="token string">"Assigned $PODNAME to $CHOSEN"</span>    done    sleep <span class="token number">1</span>done</code></pre><p>它通过 <code>kubectl</code> 命令从 apiserver 获取未调度的 pod（<code>spec.schedulerName</code> 是 <code>my-scheduler</code>，并且<code>spec.nodeName</code> 为空），同样地，用 <code>kubectl</code> 从 apiserver 获取 nodes 的信息，然后随机选择一个 node 作为调度结果，并写入到 apiserver 中。</p><p>当然要想编写一个生产级别的调度器，要完善的东西还很多，比如：</p><ul><li>调度过程中需要保证 pod 是最新的，这个例子中每次调度 pod 的时候，它在 apiserver 中的内容可能已经发生了变化</li><li>调度过程需要考虑资源等因素（节点的资源利用率，存储和网络的信息等）</li><li>尽量提高调度的性能（使用并发来提高调度的性能）</li></ul><p>虽然工作量很多，但是对于调度器要求非常高的话，编写自己的调度器也是不错的选择。</p><h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h2><p>调度的过程是这样的：</p><ul><li>客户端通过 <code>kuberctl</code> 或者 apiserver 提交资源创建的请求，不管是 deployment、replicaset、job 还是 pod，最终都会产生要调度的 pod</li><li>调度器从 apiserver 读取还没有调度的 pod 列表，循环遍历地为每个 pod 分配节点</li><li>调度器会保存集群节点的信息。对每一个 pod，调度器先过滤掉不满足 pod 运行条件的节点，这个过程是 <code>Predicate</code></li><li>通过过滤的节点，调度器会根据一定的算法給它们打分，确定它们的优先级顺序，并选择分数最高的节点作为结果</li><li>调度器根据最终选择出来的节点，把结果写入到 apiserver（创建一个 binding 资源）</li></ul><p>相信阅读到这里，你对这几个步骤都已经非常清晰了。kube-scheduler 实现还是很赞的，目前已经达到生产级别的要求。但是我们还是能看到很多可以优化的地方，我能想到的一些点：</p><ul><li>如果过滤的结果只有一个，应该可以直接使用这个节点，而不用再经过一遍 priority 的过程</li><li>目前每次只调度一个 pod，虽然中间调度过程利用并发来提高效率，但是如果能同时调度多个 pod，性能也会有提升。当然，如果要这样做，一定要考虑并发带来的共享数据的处理方法，代码的复杂性也会增加</li><li>调度的时候没有考虑节点实际使用情况，只是考虑了所有 pods 请求的资源情况。大部分情况下，pod 请求的资源并不能完全被用到，如果能保证这部分资源也被充分利用就更好了。但是因为实际的资源利用率是动态的，而且会有峰值，最重要的是无法判断 pod 未来实际的资源使用情况，想做到这一点需要有更优的算法</li><li>没有填写请求资源的 pod 会对集群带来影响。当前的实现中，如果 pod 没有在自己的配置中写上需要多少资源，scheduler 会把它申请的资源当做 0，这样会导致误判，导致集群不稳定。除了用户在创建的 pod 中都写上资源请求数量，目前还没有很好的方法来解决这个问题</li></ul><p>没有调度器是<strong>完美的</strong>，但是相信 kubernetes scheduler 会在未来得到不断优化，变得越来越好。</p><h2 id="5-参考资料"><a href="#5-参考资料" class="headerlink" title="5. 参考资料"></a>5. 参考资料</h2><ul><li><a href="https://github.com/kubernetes/community/blob/master/contributors/devel/scheduler.md" target="_blank" rel="noopener">The Kubernetes Scheduler</a></li><li><a href="https://github.com/kelseyhightower/scheduler" target="_blank" rel="noopener">A toy kubernetes scheduler</a></li><li><a href="https://deis.com/blog/2016/scheduling-your-kubernetes-pods-with-elixir/" target="_blank" rel="noopener">Scheduling your kubernetes pod with elixir</a></li><li><a href="https://www.slideshare.net/kubecon/kubecon-eu-2016-a-practical-guide-to-container-scheduling" target="_blank" rel="noopener">KubeCon EU 2016: A Practical Guide to Container Scheduling</a></li><li><a href="http://www.firmament.io/blog/scheduler-architectures.html" target="_blank" rel="noopener">The evolution of cluster scheduler architectures.</a></li><li><a href="https://coreos.com/blog/improving-kubernetes-scheduler-performance.html" target="_blank" rel="noopener">Improving Kubernetes Scheduler Performance：CoreOS 团队如何对 kubernetes 进行性能分析和调优</a></li><li><a href="https://my.oschina.net/jxcdwangtao/blog/826741" target="_blank" rel="noopener">Kubernetes Scheduler 源码分析 - Walton Wang</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;1-kubernetes-Scheduler-简介&quot;&gt;&lt;a href=&quot;#1-kubernetes-Scheduler-简介&quot; class=&quot;headerlink&quot; title=&quot;1.
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="kubernetes" scheme="http://cizixs.com/tags/kubernetes/"/>
    
      <category term="scheduler" scheme="http://cizixs.com/tags/scheduler/"/>
    
      <category term="golang" scheme="http://cizixs.com/tags/golang/"/>
    
  </entry>
  
  <entry>
    <title>kubelet 源码分析： 事件处理</title>
    <link href="http://cizixs.com/2017/06/22/kubelet-source-code-analysis-part4-event/"/>
    <id>http://cizixs.com/2017/06/22/kubelet-source-code-analysis-part4-event/</id>
    <published>2017-06-21T16:00:00.000Z</published>
    <updated>2018-09-17T13:18:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>前几篇源码分析的文章介绍了 kubelet 提供的各种功能，这篇文章继续介绍 kubelet 的源码部分：事件机制。事件并不是 kubelet 对外提供的功能，但是对于 kubernetes 系统却非常重要。</p><h2 id="kubelet-事件机制"><a href="#kubelet-事件机制" class="headerlink" title="kubelet 事件机制"></a>kubelet 事件机制</h2><p>我们知道 kubernetes 是分布式的架构，apiserver 是整个集群的交互中心，客户端主要和它打交道，kubelet 是各个节点上的 worker，负责执行具体的任务。对于用户来说，每次创建资源的时候，除了看到它的最终状态（一般是运行态），希望看到资源执行的过程，中间经过了哪些步骤。这些反馈信息对于调试来说非常重要，有些任务会失败或者卡在某个步骤，有了这些信息，我们就能够准确地定位问题。</p><p>kubelet 需要把关键步骤中的执行事件发送到 apiserver，这样客户端就能通过查询知道整个流程发生了哪些事情，不需要登录到 kubelet 所在的节点查看日志的内容或者容器的运行状态。</p><h2 id="事件机制源码分析"><a href="#事件机制源码分析" class="headerlink" title="事件机制源码分析"></a>事件机制源码分析</h2><p>这部分我们讲直接分析 kubelet 的源码，了解事件机制实现的来龙去脉。</p><h3 id="谁会发送事件？"><a href="#谁会发送事件？" class="headerlink" title="谁会发送事件？"></a>谁会发送事件？</h3><p>kubernetes 是以 pod 为核心概念的，不管是 deployment、statefulSet、replicaSet，最终都会创建出来 pod。因此事件机制也是围绕 pod 进行的，在 pod 生命周期的关键步骤都会产生事件消息。比如 Controller Manager 会记录节点注册和销毁的事件、Deployment 扩容和升级的事件；kubelet 会记录镜像回收事件、volume 无法挂载事件等；Scheduler 会记录调度事件等。这篇文章只关心 kubelet 的情况，其他组件实现原理是一样的。</p><p>查看 <code>pkg/kubelet/kubelet.go</code> 文件的代码，你会看到类似下面的代码：</p><pre class=" language-go"><code class="language-go">kl<span class="token punctuation">.</span>recorder<span class="token punctuation">.</span><span class="token function">Eventf</span><span class="token punctuation">(</span>kl<span class="token punctuation">.</span>nodeRef<span class="token punctuation">,</span> api<span class="token punctuation">.</span>EventTypeWarning<span class="token punctuation">,</span> events<span class="token punctuation">.</span>ContainerGCFailed<span class="token punctuation">,</span> err<span class="token punctuation">.</span><span class="token function">Error</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p>上面这行代码是容器 GC 失败的时候出现的，它发送了一条事件消息，通知 apiserver 容器 GC 失败的原因。除了 kubelet 本身之外，kubelet 的各个组件（比如 imageManager、probeManager 等）也会有这个字段，记录重要的事件，读者可以搜索源码去看 kubelet 哪些地方会发送事件。</p><p><code>recorder</code> 是 kubelet 结构的一个字段：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">type</span> kubelet <span class="token keyword">struct</span> <span class="token punctuation">{</span>    <span class="token operator">...</span>    <span class="token comment" spellcheck="true">// The EventBroader to use</span>    recorder    record<span class="token punctuation">.</span>EventRecorder    <span class="token operator">...</span><span class="token punctuation">}</span></code></pre><p>它的类型是 <code>record.EventRecorder</code>，这是个定义了三个方法的  interface，代码在  <code>pkg/client/record/event.go</code> 文件中：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">type</span> EventRecorder <span class="token keyword">interface</span> <span class="token punctuation">{</span>    <span class="token function">Event</span><span class="token punctuation">(</span>object runtime<span class="token punctuation">.</span>Object<span class="token punctuation">,</span> eventtype<span class="token punctuation">,</span> reason<span class="token punctuation">,</span> message <span class="token builtin">string</span><span class="token punctuation">)</span>    <span class="token function">Eventf</span><span class="token punctuation">(</span>object runtime<span class="token punctuation">.</span>Object<span class="token punctuation">,</span> eventtype<span class="token punctuation">,</span> reason<span class="token punctuation">,</span> messageFmt <span class="token builtin">string</span><span class="token punctuation">,</span> args <span class="token operator">...</span><span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span>    <span class="token function">PastEventf</span><span class="token punctuation">(</span>object runtime<span class="token punctuation">.</span>Object<span class="token punctuation">,</span> timestamp unversioned<span class="token punctuation">.</span>Time<span class="token punctuation">,</span> eventtype<span class="token punctuation">,</span> reason<span class="token punctuation">,</span> messageFmt <span class="token builtin">string</span><span class="token punctuation">,</span> args <span class="token operator">...</span><span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span></code></pre><p>这里的三个方法都是记录事件用的，<code>Eventf</code> 就是封装了类似 <code>Printf</code> 的信息打印机制，内部也会调用 <code>Event</code>，而 <code>PastEventf</code> 允许用户传进来自定义的时间戳，因此可以设置事件产生的时间。我们后面会详解介绍它们参数的意思和内部实现。</p><h3 id="EventRecorder-和-EventBroadcaster"><a href="#EventRecorder-和-EventBroadcaster" class="headerlink" title="EventRecorder 和 EventBroadcaster"></a>EventRecorder 和 EventBroadcaster</h3><p>我们已经知道了 <code>recorder</code> 就是事件的负责人，那么接下来就要了解它是怎么实现事件发送机制的。不过在那之前，先让我们找到 <code>recorder</code> 是什么时候被创建的？</p><p>在 <a href="http://cizixs.com/2017/06/06/kubelet-source-code-analysis-part-1">kubelet 启动流程</a> 这篇文章中，我们讲到 <code>RunKubelet</code> 中会初始化 <code>EventBroadcaster</code> 和 <code>Recorder</code>，对应的代码如下：</p><p><code>cmd/kubelet/app/server.go#RunKubelet</code>：</p><pre class=" language-go"><code class="language-go">eventBroadcaster <span class="token operator">:=</span> record<span class="token punctuation">.</span><span class="token function">NewBroadcaster</span><span class="token punctuation">(</span><span class="token punctuation">)</span>kubeDeps<span class="token punctuation">.</span>Recorder <span class="token operator">=</span> eventBroadcaster<span class="token punctuation">.</span><span class="token function">NewRecorder</span><span class="token punctuation">(</span>api<span class="token punctuation">.</span>EventSource<span class="token punctuation">{</span>Component<span class="token punctuation">:</span> <span class="token string">"kubelet"</span><span class="token punctuation">,</span> Host<span class="token punctuation">:</span> <span class="token function">string</span><span class="token punctuation">(</span>nodeName<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>eventBroadcaster<span class="token punctuation">.</span><span class="token function">StartLogging</span><span class="token punctuation">(</span>glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>Infof<span class="token punctuation">)</span><span class="token keyword">if</span> kubeDeps<span class="token punctuation">.</span>EventClient <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>    eventBroadcaster<span class="token punctuation">.</span><span class="token function">StartRecordingToSink</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>unversionedcore<span class="token punctuation">.</span>EventSinkImpl<span class="token punctuation">{</span>Interface<span class="token punctuation">:</span> kubeDeps<span class="token punctuation">.</span>EventClient<span class="token punctuation">.</span><span class="token function">Events</span><span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>    glog<span class="token punctuation">.</span><span class="token function">Warning</span><span class="token punctuation">(</span><span class="token string">"No api server defined - no events will be sent to API server."</span><span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><p>正如名字所示的那样， <code>eventBroadcaster</code> 是个事件广播器，<code>StartLogging</code> 和 <code>StartRecordingToSink</code> 创建了两个不同的事件处理函数，分别把事件记录到日志和发送给 apiserver。而 <code>NewRecorder</code> 新建了一个 <code>Recoder</code> 对象，通过它的 <code>Event</code>、<code>Eventf</code> 和 <code>PastEventf</code> 方法，用户可以往里面发送事件，<code>eventBroadcaster</code> 会把接收到的事件发送个多个处理函数，比如这里提到的写日志和发送到 apiserver。</p><p>知道了 <code>EventBroadcaster</code> 的功能，我们来看看它的实现：</p><p><code>pkg/client/record/event.go</code></p><pre class=" language-go"><code class="language-go"><span class="token keyword">type</span> EventBroadcaster <span class="token keyword">interface</span> <span class="token punctuation">{</span>    <span class="token function">StartEventWatcher</span><span class="token punctuation">(</span>eventHandler <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token operator">*</span>api<span class="token punctuation">.</span>Event<span class="token punctuation">)</span><span class="token punctuation">)</span> watch<span class="token punctuation">.</span>Interface    <span class="token function">StartRecordingToSink</span><span class="token punctuation">(</span>sink EventSink<span class="token punctuation">)</span> watch<span class="token punctuation">.</span>Interface    <span class="token function">StartLogging</span><span class="token punctuation">(</span>logf <span class="token keyword">func</span><span class="token punctuation">(</span>format <span class="token builtin">string</span><span class="token punctuation">,</span> args <span class="token operator">...</span><span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">)</span> watch<span class="token punctuation">.</span>Interface    <span class="token function">NewRecorder</span><span class="token punctuation">(</span>source api<span class="token punctuation">.</span>EventSource<span class="token punctuation">)</span> EventRecorder<span class="token punctuation">}</span></code></pre><p><code>EventBroadcaster</code> 是个接口类型，<code>NewRecorder</code> 新建一个 <code>EventRecoder</code> 对象，它就像一个事件记录仪，用户可以通过它记录事件，它在内部会把事件发送给 <code>EventBroadcaster</code>。</p><p>此外，<code>EventBroadcaster</code> 定义了三个 <code>Start</code> 开头的方法，它们用来添加事件处理 handler 。其中核心方法是 <code>StartEventWatcher</code>，它会在后台启动一个 goroutine，不断从 EventBroadcaster 提供的管道中接收事件，然后调用 <code>eventHandler</code> 处理函数对事件进行处理。<code>StartRecordingToSink</code> 和 <code>StartLogging</code> 是对 <code>StartEventWatcher</code> 的封装，分别实现了不同的处理函数（发送给 apiserver 和写日志）。</p><p>至此，<code>EventBroadcaster</code> 的工作原理就比较清晰了：它通过 <code>EventRecorder</code> 提供接口供用户写事件，内部把接收到的事件发送给处理函数。处理函数是可以扩展的，用户可以通过 <code>StartEventWatcher</code> 来编写自己的事件处理逻辑，<code>kubelet</code> 默认会使用 <code>StartRecordingToSink</code> 和 <code>StartLogging</code>，也就是说任何一个事件会同时发送给 apiserver，并打印到日志中。</p><p>知道了 <code>EventBroadcaster</code> 做的事情，接下来我们就要分析它是怎么做的。这些内容可以分为三个部分：</p><ol><li><code>EventRecorder</code> 是怎么把事件发送给 <code>EventBroadcaster</code> 的？</li><li><code>EventBroadcaster</code> 是怎么实现事件广播的？</li><li><code>StartRecodingToSink</code> 内部是如何把事件发送到 apiserver 的？</li></ol><p>分析完以上三点，我们就能知道事件的整个流程。</p><h3 id="发送事件的过程"><a href="#发送事件的过程" class="headerlink" title="发送事件的过程"></a>发送事件的过程</h3><p>通过上面的分析，我们知道事件是通过 <code>EventRecorder</code> 对象发送出来的，它的具体实现在 <code>pkg/event/record/event.go</code>：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">type</span> recorderImpl <span class="token keyword">struct</span> <span class="token punctuation">{</span>    source api<span class="token punctuation">.</span>EventSource    <span class="token operator">*</span>watch<span class="token punctuation">.</span>Broadcaster    clock clock<span class="token punctuation">.</span>Clock<span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>eventBroadcaster <span class="token operator">*</span>eventBroadcasterImpl<span class="token punctuation">)</span> <span class="token function">NewRecorder</span><span class="token punctuation">(</span>source api<span class="token punctuation">.</span>EventSource<span class="token punctuation">)</span> EventRecorder <span class="token punctuation">{</span>    <span class="token keyword">return</span> <span class="token operator">&amp;</span>recorderImpl<span class="token punctuation">{</span>source<span class="token punctuation">,</span> eventBroadcaster<span class="token punctuation">.</span>Broadcaster<span class="token punctuation">,</span> clock<span class="token punctuation">.</span>RealClock<span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>recorder <span class="token operator">*</span>recorderImpl<span class="token punctuation">)</span> <span class="token function">Event</span><span class="token punctuation">(</span>object runtime<span class="token punctuation">.</span>Object<span class="token punctuation">,</span> eventtype<span class="token punctuation">,</span> reason<span class="token punctuation">,</span> message <span class="token builtin">string</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    recorder<span class="token punctuation">.</span><span class="token function">generateEvent</span><span class="token punctuation">(</span>object<span class="token punctuation">,</span> unversioned<span class="token punctuation">.</span><span class="token function">Now</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eventtype<span class="token punctuation">,</span> reason<span class="token punctuation">,</span> message<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>recorder <span class="token operator">*</span>recorderImpl<span class="token punctuation">)</span> <span class="token function">Eventf</span><span class="token punctuation">(</span>object runtime<span class="token punctuation">.</span>Object<span class="token punctuation">,</span> eventtype<span class="token punctuation">,</span> reason<span class="token punctuation">,</span> messageFmt <span class="token builtin">string</span><span class="token punctuation">,</span> args <span class="token operator">...</span><span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    recorder<span class="token punctuation">.</span><span class="token function">Event</span><span class="token punctuation">(</span>object<span class="token punctuation">,</span> eventtype<span class="token punctuation">,</span> reason<span class="token punctuation">,</span> fmt<span class="token punctuation">.</span><span class="token function">Sprintf</span><span class="token punctuation">(</span>messageFmt<span class="token punctuation">,</span> args<span class="token operator">...</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>recorder <span class="token operator">*</span>recorderImpl<span class="token punctuation">)</span> <span class="token function">PastEventf</span><span class="token punctuation">(</span>object runtime<span class="token punctuation">.</span>Object<span class="token punctuation">,</span> timestamp unversioned<span class="token punctuation">.</span>Time<span class="token punctuation">,</span> eventtype<span class="token punctuation">,</span> reason<span class="token punctuation">,</span> messageFmt <span class="token builtin">string</span><span class="token punctuation">,</span> args <span class="token operator">...</span><span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    recorder<span class="token punctuation">.</span><span class="token function">generateEvent</span><span class="token punctuation">(</span>object<span class="token punctuation">,</span> timestamp<span class="token punctuation">,</span> eventtype<span class="token punctuation">,</span> reason<span class="token punctuation">,</span> fmt<span class="token punctuation">.</span><span class="token function">Sprintf</span><span class="token punctuation">(</span>messageFmt<span class="token punctuation">,</span> args<span class="token operator">...</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><p><code>recorderImpl</code> 是具体的实现，<code>eventBroadcaster.NewRecorder</code> 会创建一个指定 <code>EventSource</code> 的 <code>EventRecorder</code>，<code>EventSource</code> 指明了哪个节点的哪个组件。</p><p>recorder 对外暴露了三个方法：<code>Event</code>、<code>Eventf</code> 和 <code>PastEventf</code>，它们的内部最终都是调用 <code>generateEvent</code> 方法：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>recorder <span class="token operator">*</span>recorderImpl<span class="token punctuation">)</span> <span class="token function">generateEvent</span><span class="token punctuation">(</span>object runtime<span class="token punctuation">.</span>Object<span class="token punctuation">,</span> timestamp unversioned<span class="token punctuation">.</span>Time<span class="token punctuation">,</span> eventtype<span class="token punctuation">,</span> reason<span class="token punctuation">,</span> message <span class="token builtin">string</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    ref<span class="token punctuation">,</span> err <span class="token operator">:=</span> api<span class="token punctuation">.</span><span class="token function">GetReference</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token keyword">if</span> <span class="token operator">!</span><span class="token function">validateEventType</span><span class="token punctuation">(</span>eventtype<span class="token punctuation">)</span> <span class="token punctuation">{</span>        glog<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"Unsupported event type: '%v'"</span><span class="token punctuation">,</span> eventtype<span class="token punctuation">)</span>        <span class="token keyword">return</span>    <span class="token punctuation">}</span>    event <span class="token operator">:=</span> recorder<span class="token punctuation">.</span><span class="token function">makeEvent</span><span class="token punctuation">(</span>ref<span class="token punctuation">,</span> eventtype<span class="token punctuation">,</span> reason<span class="token punctuation">,</span> message<span class="token punctuation">)</span>    <span class="token keyword">if</span> pod<span class="token punctuation">,</span> ok <span class="token operator">:=</span> object<span class="token punctuation">.</span><span class="token punctuation">(</span><span class="token operator">*</span>api<span class="token punctuation">.</span>Pod<span class="token punctuation">)</span><span class="token punctuation">;</span> ok <span class="token operator">&amp;&amp;</span> pod<span class="token punctuation">.</span>ObjectMeta<span class="token punctuation">.</span>Labels <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// add the labels in pod to event</span>        event<span class="token punctuation">.</span>ObjectMeta<span class="token punctuation">.</span>Labels <span class="token operator">=</span> <span class="token keyword">map</span><span class="token punctuation">[</span><span class="token builtin">string</span><span class="token punctuation">]</span><span class="token builtin">string</span><span class="token punctuation">{</span><span class="token punctuation">}</span>        <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token operator">:=</span> <span class="token keyword">range</span> pod<span class="token punctuation">.</span>ObjectMeta<span class="token punctuation">.</span>Labels <span class="token punctuation">{</span>            event<span class="token punctuation">.</span>ObjectMeta<span class="token punctuation">.</span>Labels<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> v        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    event<span class="token punctuation">.</span>Source <span class="token operator">=</span> recorder<span class="token punctuation">.</span>source    <span class="token keyword">go</span> <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">defer</span> utilruntime<span class="token punctuation">.</span><span class="token function">HandleCrash</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        recorder<span class="token punctuation">.</span><span class="token function">Action</span><span class="token punctuation">(</span>watch<span class="token punctuation">.</span>Added<span class="token punctuation">,</span> event<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><p><code>generateEvent</code> 就是根据传入的参数，生成一个 <code>api.Event</code> 对象，并发送出去。它各个参数的意思是：</p><ul><li>object：哪个组件/对象发出的事件，比如 kubelet 产生的事件会使用 node 对象</li><li>timestamp：事件产生的时间</li><li>eventtype：事件类型，目前有两种：<code>Normal</code> 和 <code>Warning</code>，分别代表正常的事件和可能有问题的事件，定义在 <code>pkg/api/types.go</code> 文件中，未来可能有其他类型的事件扩展</li><li>reason：事件产生的原因，可以在 <code>pkg/kubelet/events/event.go</code> 看到 kubelet 定义的所有事件类型</li><li>message：事件的具体内容，用户可以理解的语句</li></ul><p><code>makeEvent</code> 就是根据参数构建 <code>api.Event</code> 对象，自动填充时间戳和 namespace：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>recorder <span class="token operator">*</span>recorderImpl<span class="token punctuation">)</span> <span class="token function">makeEvent</span><span class="token punctuation">(</span>ref <span class="token operator">*</span>api<span class="token punctuation">.</span>ObjectReference<span class="token punctuation">,</span> eventtype<span class="token punctuation">,</span> reason<span class="token punctuation">,</span> message <span class="token builtin">string</span><span class="token punctuation">)</span> <span class="token operator">*</span>api<span class="token punctuation">.</span>Event <span class="token punctuation">{</span>    t <span class="token operator">:=</span> unversioned<span class="token punctuation">.</span>Time<span class="token punctuation">{</span>Time<span class="token punctuation">:</span> recorder<span class="token punctuation">.</span>clock<span class="token punctuation">.</span><span class="token function">Now</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>    namespace <span class="token operator">:=</span> ref<span class="token punctuation">.</span>Namespace    <span class="token keyword">if</span> namespace <span class="token operator">==</span> <span class="token string">""</span> <span class="token punctuation">{</span>        namespace <span class="token operator">=</span> api<span class="token punctuation">.</span>NamespaceDefault    <span class="token punctuation">}</span>    <span class="token keyword">return</span> <span class="token operator">&amp;</span>api<span class="token punctuation">.</span>Event<span class="token punctuation">{</span>        ObjectMeta<span class="token punctuation">:</span> api<span class="token punctuation">.</span>ObjectMeta<span class="token punctuation">{</span>            Name<span class="token punctuation">:</span>      fmt<span class="token punctuation">.</span><span class="token function">Sprintf</span><span class="token punctuation">(</span><span class="token string">"%v.%x"</span><span class="token punctuation">,</span> ref<span class="token punctuation">.</span>Name<span class="token punctuation">,</span> t<span class="token punctuation">.</span><span class="token function">UnixNano</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            Namespace<span class="token punctuation">:</span> namespace<span class="token punctuation">,</span>        <span class="token punctuation">}</span><span class="token punctuation">,</span>        InvolvedObject<span class="token punctuation">:</span> <span class="token operator">*</span>ref<span class="token punctuation">,</span>        Reason<span class="token punctuation">:</span>         reason<span class="token punctuation">,</span>        Message<span class="token punctuation">:</span>        message<span class="token punctuation">,</span>        FirstTimestamp<span class="token punctuation">:</span> t<span class="token punctuation">,</span>        LastTimestamp<span class="token punctuation">:</span>  t<span class="token punctuation">,</span>        Count<span class="token punctuation">:</span>          <span class="token number">1</span><span class="token punctuation">,</span>        Type<span class="token punctuation">:</span>           eventtype<span class="token punctuation">,</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p><strong>注意 Event 事件的名字的构成</strong>，它有两部分：事件关联对象的名字和当前的时间，中间用点隔开。</p><p><code>api.Event</code> 这个结构体定义在 <code>pkg/api/types.go</code>：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">type</span> Event <span class="token keyword">struct</span> <span class="token punctuation">{</span>    unversioned<span class="token punctuation">.</span>TypeMeta <span class="token string">`json:",inline"`</span>    ObjectMeta <span class="token string">`json:"metadata,omitempty"`</span>    InvolvedObject ObjectReference <span class="token string">`json:"involvedObject,omitempty"`</span>    Reason <span class="token builtin">string</span> <span class="token string">`json:"reason,omitempty"`</span>    Message <span class="token builtin">string</span> <span class="token string">`json:"message,omitempty"`</span>    Source EventSource <span class="token string">`json:"source,omitempty"`</span>    Type <span class="token builtin">string</span> <span class="token string">`json:"type,omitempty"`</span>    FirstTimestamp unversioned<span class="token punctuation">.</span>Time <span class="token string">`json:"firstTimestamp,omitempty"`</span>    LastTimestamp unversioned<span class="token punctuation">.</span>Time <span class="token string">`json:"lastTimestamp,omitempty"`</span>    Count <span class="token builtin">int32</span> <span class="token string">`json:"count,omitempty"`</span><span class="token punctuation">}</span></code></pre><p>除了所有的 kubernetes 资源都有的 <code>unversioned.TypeMeta</code>（资源的类型和版本，对应了 yaml 文件的 <code>Kind</code> 和 <code>apiVersion</code> 字段） 和 <code>ObjectMera</code> 字段（资源的元数据，比如 name、nemspace、labels、uuid、创建时间等）之外，还有和事件本身息息相关的字段，比如事件消息、来源、类型，以及数量（kubernetes 会把多个相同的事件汇聚到一起）和第一个事件的发生的时间等。</p><p>中间有个 <code>InvolvedObject</code> 字段，它其实指向了和事件关联的对象，如果是启动容器的事件，这个对象就是 Pod。</p><p>至此，我们就疏通了事件是怎么创建出来的。下面看看事件是怎么发出去的，发送是通过 <code>recorder.Action()</code> 实现的。找到对应的代码部分，竟然简单得只有一句话，把对象封装一下，发送到 <code>m.incoming</code> 管道。</p><pre class=" language-go"><code class="language-go"><span class="token comment" spellcheck="true">// Action distributes the given event among all watchers.</span><span class="token keyword">func</span> <span class="token punctuation">(</span>m <span class="token operator">*</span>Broadcaster<span class="token punctuation">)</span> <span class="token function">Action</span><span class="token punctuation">(</span>action EventType<span class="token punctuation">,</span> obj runtime<span class="token punctuation">.</span>Object<span class="token punctuation">)</span> <span class="token punctuation">{</span>    m<span class="token punctuation">.</span>incoming <span class="token operator">&lt;-</span> Event<span class="token punctuation">{</span>action<span class="token punctuation">,</span> obj<span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p><code>Broadcaster</code> 是 <code>Recoder</code> 内部的对象，调用 <code>NewRecoder</code> 的时候 <code>EventBroadcaster</code> 传给它的。接下来，我们要分析 <code>EventBroadcaster</code> 的实现。</p><h3 id="EventBroadcaster-实现事件的分发"><a href="#EventBroadcaster-实现事件的分发" class="headerlink" title="EventBroadcaster 实现事件的分发"></a>EventBroadcaster 实现事件的分发</h3><p><code>EventBroadcaster</code> 也在 <code>pkg/event/record/event.go</code> 文件中：</p><pre><code>type eventBroadcasterImpl struct {    *watch.Broadcaster    sleepDuration time.Duration}func NewBroadcaster() EventBroadcaster {    return &amp;eventBroadcasterImpl{watch.NewBroadcaster(maxQueuedEvents, watch.DropIfChannelFull), defaultSleepDuration}}</code></pre><p>它的核心组件是 <code>watch.Broadcaster</code>，<code>Broadcaster</code> 就是广播的意思，主要功能就是把发给它的消息，广播给所有的监听者（watcher）。它的实现代码在 <code>pkg/watch/mux.go</code>，我们不再深入剖析，不过这部分代码如何使用 golang channel 是值得所有读者学习的。</p><p>简单来说，<code>watch.Broadcaster</code> 是一个分发器，内部保存了一个消息队列，可以通过 <code>Watch</code> 创建监听它内部的 worker。当有消息发送到队列中，<code>watch.Broadcaster</code> 后台运行的 goroutine 会接收消息并发送给所有的 watcher。而每个 <code>watcher</code> 都有一个接收消息的 channel，用户可以通过它的 <code>ResultChan()</code> 获取这个 channel 从中读取数据进行处理。</p><p>前面说过 <code>StartLogging</code> 和 <code>StartRecordingToSink</code> 都是启动一个事件处理的函数，我们就以后者为例，看看事件的处理过程：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>eventBroadcaster <span class="token operator">*</span>eventBroadcasterImpl<span class="token punctuation">)</span> <span class="token function">StartRecordingToSink</span><span class="token punctuation">(</span>sink EventSink<span class="token punctuation">)</span> watch<span class="token punctuation">.</span>Interface <span class="token punctuation">{</span>    randGen <span class="token operator">:=</span> rand<span class="token punctuation">.</span><span class="token function">New</span><span class="token punctuation">(</span>rand<span class="token punctuation">.</span><span class="token function">NewSource</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span><span class="token function">Now</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">UnixNano</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    eventCorrelator <span class="token operator">:=</span> <span class="token function">NewEventCorrelator</span><span class="token punctuation">(</span>clock<span class="token punctuation">.</span>RealClock<span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> eventBroadcaster<span class="token punctuation">.</span><span class="token function">StartEventWatcher</span><span class="token punctuation">(</span>        <span class="token keyword">func</span><span class="token punctuation">(</span>event <span class="token operator">*</span>api<span class="token punctuation">.</span>Event<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token function">recordToSink</span><span class="token punctuation">(</span>sink<span class="token punctuation">,</span> event<span class="token punctuation">,</span> eventCorrelator<span class="token punctuation">,</span> randGen<span class="token punctuation">,</span> eventBroadcaster<span class="token punctuation">.</span>sleepDuration<span class="token punctuation">)</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><p><code>StartRecordingToSink</code> 就是对 <code>StartEventWatcher</code> 的封装，将处理函数设置为 <code>recordToSink</code>。我们先看看 <code>StartEventWatcher</code> 的代码：</p><pre><code>func (eventBroadcaster *eventBroadcasterImpl) StartEventWatcher(eventHandler func(*api.Event)) watch.Interface {    watcher := eventBroadcaster.Watch()    go func() {        defer utilruntime.HandleCrash()        for {            watchEvent, open := &lt;-watcher.ResultChan()            if !open {                return            }            event, ok := watchEvent.Object.(*api.Event)            if !ok {                continue            }            eventHandler(event)        }    }()    return watcher}</code></pre><p>它启动一个 goroutine，不断从 <code>watcher.ResultChan()</code> 中读取消息，然后调用 <code>eventHandler(event)</code> 对事件进行处理。</p><p>而我们的处理函数就是 <code>recordToSink</code>，它的代码是下一节的重点。</p><h3 id="事件的处理过程"><a href="#事件的处理过程" class="headerlink" title="事件的处理过程"></a>事件的处理过程</h3><p><code>recordToSink</code> 负责把事件发送到 apiserver，这里的 sink 其实就是和 apiserver 交互的 restclient， event 是要发送的事件，eventCorrelator 在发送事件之前先对事件进行预处理。</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">recordToSink</span><span class="token punctuation">(</span>sink EventSink<span class="token punctuation">,</span> event <span class="token operator">*</span>api<span class="token punctuation">.</span>Event<span class="token punctuation">,</span> eventCorrelator <span class="token operator">*</span>EventCorrelator<span class="token punctuation">,</span> randGen <span class="token operator">*</span>rand<span class="token punctuation">.</span>Rand<span class="token punctuation">,</span> sleepDuration time<span class="token punctuation">.</span>Duration<span class="token punctuation">)</span> <span class="token punctuation">{</span>    eventCopy <span class="token operator">:=</span> <span class="token operator">*</span>event    event <span class="token operator">=</span> <span class="token operator">&amp;</span>eventCopy    result<span class="token punctuation">,</span> err <span class="token operator">:=</span> eventCorrelator<span class="token punctuation">.</span><span class="token function">EventCorrelate</span><span class="token punctuation">(</span>event<span class="token punctuation">)</span>    <span class="token keyword">if</span> result<span class="token punctuation">.</span>Skip <span class="token punctuation">{</span>        <span class="token keyword">return</span>    <span class="token punctuation">}</span>    tries <span class="token operator">:=</span> <span class="token number">0</span>    <span class="token keyword">for</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token function">recordEvent</span><span class="token punctuation">(</span>sink<span class="token punctuation">,</span> result<span class="token punctuation">.</span>Event<span class="token punctuation">,</span> result<span class="token punctuation">.</span>Patch<span class="token punctuation">,</span> result<span class="token punctuation">.</span>Event<span class="token punctuation">.</span>Count <span class="token operator">></span> <span class="token number">1</span><span class="token punctuation">,</span> eventCorrelator<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">break</span>        <span class="token punctuation">}</span>        tries<span class="token operator">++</span>        <span class="token keyword">if</span> tries <span class="token operator">>=</span> maxTriesPerEvent <span class="token punctuation">{</span>            glog<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"Unable to write event '%#v' (retry limit exceeded!)"</span><span class="token punctuation">,</span> event<span class="token punctuation">)</span>            <span class="token keyword">break</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// 第一次重试增加随机性，防止 apiserver 重启的时候所有的事件都在同一时间发送事件</span>        <span class="token keyword">if</span> tries <span class="token operator">==</span> <span class="token number">1</span> <span class="token punctuation">{</span>            time<span class="token punctuation">.</span><span class="token function">Sleep</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span><span class="token function">Duration</span><span class="token punctuation">(</span><span class="token function">float64</span><span class="token punctuation">(</span>sleepDuration<span class="token punctuation">)</span> <span class="token operator">*</span> randGen<span class="token punctuation">.</span><span class="token function">Float64</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            time<span class="token punctuation">.</span><span class="token function">Sleep</span><span class="token punctuation">(</span>sleepDuration<span class="token punctuation">)</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p><code>recordToSink</code> 对事件的处理分为两个步骤：<code>eventCorrelator.EventCorrelate</code> 会对事件做预处理，主要是聚合相同的事件（避免产生的事件过多，增加 etcd 和 apiserver 的压力，也会导致查看 pod 事件很不清晰）；<code>recordEvent</code> 负责最终把事件发送到 apiserver，它会重试很多次（默认是 12 次），并且每次重试都有一定时间间隔（默认是 10 秒钟）。</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">recordEvent</span><span class="token punctuation">(</span>sink EventSink<span class="token punctuation">,</span> event <span class="token operator">*</span>api<span class="token punctuation">.</span>Event<span class="token punctuation">,</span> patch <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">byte</span><span class="token punctuation">,</span> updateExistingEvent <span class="token builtin">bool</span><span class="token punctuation">,</span> eventCorrelator <span class="token operator">*</span>EventCorrelator<span class="token punctuation">)</span> <span class="token builtin">bool</span> <span class="token punctuation">{</span>    <span class="token keyword">var</span> newEvent <span class="token operator">*</span>api<span class="token punctuation">.</span>Event    <span class="token keyword">var</span> err <span class="token builtin">error</span>    <span class="token comment" spellcheck="true">// 更新已经存在的事件</span>    <span class="token keyword">if</span> updateExistingEvent <span class="token punctuation">{</span>        newEvent<span class="token punctuation">,</span> err <span class="token operator">=</span> sink<span class="token punctuation">.</span><span class="token function">Patch</span><span class="token punctuation">(</span>event<span class="token punctuation">,</span> patch<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 创建一个新的事件</span>    <span class="token keyword">if</span> <span class="token operator">!</span>updateExistingEvent <span class="token operator">||</span> <span class="token punctuation">(</span>updateExistingEvent <span class="token operator">&amp;&amp;</span> <span class="token function">isKeyNotFoundError</span><span class="token punctuation">(</span>err<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        event<span class="token punctuation">.</span>ResourceVersion <span class="token operator">=</span> <span class="token string">""</span>        newEvent<span class="token punctuation">,</span> err <span class="token operator">=</span> sink<span class="token punctuation">.</span><span class="token function">Create</span><span class="token punctuation">(</span>event<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token keyword">if</span> err <span class="token operator">==</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// we need to update our event correlator with the server returned state to handle name/resourceversion</span>        eventCorrelator<span class="token punctuation">.</span><span class="token function">UpdateState</span><span class="token punctuation">(</span>newEvent<span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token boolean">true</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 如果是已知错误，就不要再重试了；否则，返回 false，让上层进行重试</span>    <span class="token keyword">switch</span> err<span class="token punctuation">.</span><span class="token punctuation">(</span><span class="token keyword">type</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">case</span> <span class="token operator">*</span>restclient<span class="token punctuation">.</span>RequestConstructionError<span class="token punctuation">:</span>        glog<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"Unable to construct event '%#v': '%v' (will not retry!)"</span><span class="token punctuation">,</span> event<span class="token punctuation">,</span> err<span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token boolean">true</span>    <span class="token keyword">case</span> <span class="token operator">*</span>errors<span class="token punctuation">.</span>StatusError<span class="token punctuation">:</span>        <span class="token keyword">if</span> errors<span class="token punctuation">.</span><span class="token function">IsAlreadyExists</span><span class="token punctuation">(</span>err<span class="token punctuation">)</span> <span class="token punctuation">{</span>            glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"Server rejected event '%#v': '%v' (will not retry!)"</span><span class="token punctuation">,</span> event<span class="token punctuation">,</span> err<span class="token punctuation">)</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            glog<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"Server rejected event '%#v': '%v' (will not retry!)"</span><span class="token punctuation">,</span> event<span class="token punctuation">,</span> err<span class="token punctuation">)</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span> <span class="token boolean">true</span>    <span class="token keyword">case</span> <span class="token operator">*</span>errors<span class="token punctuation">.</span>UnexpectedObjectError<span class="token punctuation">:</span>    <span class="token keyword">default</span><span class="token punctuation">:</span>    <span class="token punctuation">}</span>    glog<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"Unable to write event: '%v' (may retry after sleeping)"</span><span class="token punctuation">,</span> err<span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">}</span></code></pre><p>它根据 <code>eventCorrelator</code> 的结果来决定是新建一个事件还是更新已经存在的事件，并根据请求的结果决定是否需要重试（返回值为 false 说明需要重试，返回值为 true 表明已经操作成功或者忽略请求错误）。<code>sink.Create</code> 和 <code>sink.Patch</code> 是自动生成的 apiserver 的 client，对应的代码在： <code>pkg/client/clientset_generated/internalclientset/typed/core/internalversion/event_expansion.go</code> 。</p><p>到这里，事件总算完成了它的使命，到了目的地。但是我们略过了 <code>EventCorrelator</code> 的部分，它在发送之前对事件做过滤和聚合处理，以免产生大量的事件给 apiserver 和 etcd 带来太大的压力。</p><h3 id="EventCorrelator：事件的预处理"><a href="#EventCorrelator：事件的预处理" class="headerlink" title="EventCorrelator：事件的预处理"></a>EventCorrelator：事件的预处理</h3><p><code>EventCorrelator</code> 的代码在 <code>pkg/client/record/event_cache.go</code> 文件中，从文件名可以猜测出它对事件做了缓存。</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">NewEventCorrelator</span><span class="token punctuation">(</span>clock clock<span class="token punctuation">.</span>Clock<span class="token punctuation">)</span> <span class="token operator">*</span>EventCorrelator <span class="token punctuation">{</span>    cacheSize <span class="token operator">:=</span> maxLruCacheEntries    <span class="token keyword">return</span> <span class="token operator">&amp;</span>EventCorrelator<span class="token punctuation">{</span>        filterFunc<span class="token punctuation">:</span> DefaultEventFilterFunc<span class="token punctuation">,</span>        aggregator<span class="token punctuation">:</span> <span class="token function">NewEventAggregator</span><span class="token punctuation">(</span>            cacheSize<span class="token punctuation">,</span>            EventAggregatorByReasonFunc<span class="token punctuation">,</span>            EventAggregatorByReasonMessageFunc<span class="token punctuation">,</span>            defaultAggregateMaxEvents<span class="token punctuation">,</span>            defaultAggregateIntervalInSeconds<span class="token punctuation">,</span>            clock<span class="token punctuation">)</span><span class="token punctuation">,</span>        logger<span class="token punctuation">:</span> <span class="token function">newEventLogger</span><span class="token punctuation">(</span>cacheSize<span class="token punctuation">,</span> clock<span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// EventCorrelate filters, aggregates, counts, and de-duplicates all incoming events</span><span class="token keyword">func</span> <span class="token punctuation">(</span>c <span class="token operator">*</span>EventCorrelator<span class="token punctuation">)</span> <span class="token function">EventCorrelate</span><span class="token punctuation">(</span>newEvent <span class="token operator">*</span>api<span class="token punctuation">.</span>Event<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token operator">*</span>EventCorrelateResult<span class="token punctuation">,</span> <span class="token builtin">error</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> c<span class="token punctuation">.</span><span class="token function">filterFunc</span><span class="token punctuation">(</span>newEvent<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token operator">&amp;</span>EventCorrelateResult<span class="token punctuation">{</span>Skip<span class="token punctuation">:</span> <span class="token boolean">true</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token boolean">nil</span>    <span class="token punctuation">}</span>    aggregateEvent<span class="token punctuation">,</span> err <span class="token operator">:=</span> c<span class="token punctuation">.</span>aggregator<span class="token punctuation">.</span><span class="token function">EventAggregate</span><span class="token punctuation">(</span>newEvent<span class="token punctuation">)</span>    <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token operator">&amp;</span>EventCorrelateResult<span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> err    <span class="token punctuation">}</span>    observedEvent<span class="token punctuation">,</span> patch<span class="token punctuation">,</span> err <span class="token operator">:=</span> c<span class="token punctuation">.</span>logger<span class="token punctuation">.</span><span class="token function">eventObserve</span><span class="token punctuation">(</span>aggregateEvent<span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token operator">&amp;</span>EventCorrelateResult<span class="token punctuation">{</span>Event<span class="token punctuation">:</span> observedEvent<span class="token punctuation">,</span> Patch<span class="token punctuation">:</span> patch<span class="token punctuation">}</span><span class="token punctuation">,</span> err<span class="token punctuation">}</span></code></pre><p><code>EventCorrelator</code> 内部有三个对象：<code>filterFunc</code>、<code>aggregator</code> 和 <code>logger</code>，它们分别对事件进行过滤、把相似的事件汇聚在一起、把相同的事件记录到一起。使用 <code>NewEventCorrelator</code> 初始化的时候内部会自动创建各个对象的默认值，<code>EventCorrelate</code> 会以此调用三个对象的方法，并返回最终的结果。现在它们的逻辑是这样的：</p><ul><li><code>filterFunc</code>：目前不做过滤，也就是说所有的事件都要经过后续处理，后面可能会做扩展</li><li><code>aggregator</code>：如果在最近 10 分钟出现过 10 个相似的事件（除了 message 和时间戳之外其他关键字段都相同的事件），aggregator 会把它们的 message 设置为 <code>events with common reason combined</code>，这样它们就完全一样了</li><li><code>logger</code>：这个变量的名字有点奇怪，其实它会把相同的事件（除了时间戳之外其他字段都相同）变成同一个事件，通过增加事件的 <code>Count</code> 字段来记录该事件发生了多少次。经过 <code>aggregator</code> 的事件会在这里变成同一个事件</li></ul><p><code>aggregator</code> 和 <code>logger</code> 都会在内部维护一个缓存（默认长度是 4096），事件的相似性和相同性比较是和缓存中的事件进行的，也就是说它并在乎 kubelet 启动之前的事件，而且如果事件超过 4096 的长度，最近没有被访问的事件也会被从缓存中移除。这也是这个文件中带有 <code>cache</code> 的原因。它们的内部实现并不复杂，有兴趣的读者请自行阅读相关源码。</p><h2 id="Event-总结"><a href="#Event-总结" class="headerlink" title="Event 总结"></a>Event 总结</h2><p>通过这篇文章，我们了解到了整个事件机制的来龙去脉。最后，我们再做一个总结，看看事件流动的整个过程：</p><ol><li>kubelet 通过 <code>recorder</code> 对象提供的 <code>Event</code>、<code>Eventf</code> 和 <code>PastEventf</code> 方法产生特性的事件</li><li><code>recorder</code> 根据传递过来的参数新建一个 <code>Event</code> 对象，并把它发送给 <code>EventBroadcaster</code> 的管道</li><li><code>EventBroadcaster</code> 后台运行的 goroutine 从管道中读取事件消息，把它广播给之前注册的 handler 进行处理</li><li>kubelet 有两个 handler，它们分别把事件记录到日志和发送给 apiserver。记录到日志很简单，直接打印就行</li><li>发送给 apiserver 的 handler 叫做 <code>EventSink</code>，它在发送事件给 apiserver 之前会先做预处理</li><li>预处理操作是 <code>EventCorrelator</code> 完成的，它会对事件做过滤、汇聚和去重操作，返回处理后的事件（可能是原来的事件，也可能是新创建的事件）</li><li>最后通过 restclient （eventClient） 调用对应的方法，给 apiserver 发送请求，这个过程如果出错会进行重试</li><li>apiserver 接收到事件的请求把数据更新到 etcd</li></ol><p>事件的产生过程是这样的，那么这些事件都有什么用呢？它一般用于调试，用户可以通过 <code>kubectl</code> 命令获取整个集群或者某个 pod 的事件信息。<code>kubectl get events</code> 可以看到所有的事件，<code>kubectl describe pod PODNAME</code> 能看到关于某个 pod 的事件。对于前者很好理解，kubectl 会直接访问 apiserver 的 event 资源，而对于后者 kubectl 还根据 pod 的名字进行搜索，匹配 InvolvedObject 名称和 pod 名称匹配的事件。</p><p>我们来思考一下事件机制的框架，有哪些我们可以借鉴的设计思想呢？我想最重要的一点是：<strong>需求决定实现</strong>。</p><p>Event 和 kubernetes 中其他的资源不同，它有一个很重要的特性就是它可以丢失。如果某个事件丢了，并不会影响集群的正常工作。事件的重要性远低于集群的稳定性，所以我们看到事件整个流程中如果有错误，会直接忽略这个事件。</p><p>事件的另外一个特性是它的数量很多，相比于 pod 或者 deployment 等资源，事件要比它们多很多，而且每次有事件都要对 etcd 进行写操作。整个集群如果不加管理地往 etcd 中写事件，会对 etcd 造成很大的压力，而 etcd 的可用性是整个集群的基础，所以每个组件在写事件之前，会对事件进行汇聚和去重工作，减少最终的写操作。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.kubernetes.org.cn/1195.html" target="_blank" rel="noopener">Kubernetes Events介绍（下）</a></li><li><a href="https://kubernetes.io/docs/tasks/debug-application-cluster/debug-application-introspection/" target="_blank" rel="noopener">Application Introspection and Debugging</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;前几篇源码分析的文章介绍了 kubelet 提供的各种功能，这篇文章继续介绍 kubelet 的源码部分：事件机制。事件并不是 kubelet 对外提供的功能，但是对于 kubernetes 系统却非常重要。&lt;/p&gt;
&lt;h2 id=&quot;kubelet-事件机制&quot;&gt;&lt;a
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="kubernetes" scheme="http://cizixs.com/tags/kubernetes/"/>
    
      <category term="kubelet" scheme="http://cizixs.com/tags/kubelet/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes 权限管理</title>
    <link href="http://cizixs.com/2017/06/16/kubernetes-authentication-and-authorization/"/>
    <id>http://cizixs.com/2017/06/16/kubernetes-authentication-and-authorization/</id>
    <published>2017-06-15T16:00:00.000Z</published>
    <updated>2018-09-17T13:18:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>kubernetes 主要通过 APIServer 对外提供服务，对于这样的系统集群来说，请求访问的安全性是非常重要的考虑因素。如果不对请求加以限制，那么会导致请求被滥用，甚至被黑客攻击。</p><p>kubernetes 对于访问 API 来说提供了两个步骤的安全措施：认证和授权。认证解决用户是谁的问题，授权解决用户能做什么的问题。通过合理的权限管理，能够保证系统的安全可靠。</p><p>下图是 API 访问要经过的三个步骤，前面两个是认证和授权，第三个是 Admission Control，它也能在一定程度上提高安全性，不过更多是资源管理方面的作用，在这篇文章不会介绍。</p><p><img src="https://kubernetes.io/images/docs/admin/access-control-overview.svg" alt=""></p><p><strong>NOTE</strong>： 只有通过 HTTPS 访问的时候才会通过认证和授权，HTTP 不需要。</p><h2 id="一-认证（Authentication）：我是谁"><a href="#一-认证（Authentication）：我是谁" class="headerlink" title="一. 认证（Authentication）：我是谁"></a>一. 认证（Authentication）：我是谁</h2><p>认证关注的是谁发送的请求，也就是说客户端必须用某种方式揭示自己的身份信息。我们常见的认证手段是用户名和密码的方法，比如几乎所有的社交网站；现在也有很多手机应用采用指纹的方式进行认证。不管怎么说，认证的功能只有一个，提供用户的身份信息。</p><p>kubernetes 并没有完整的用户系统，因此目前认证的方式并不是统一的，而是提供了很多可以配置的认证方式供用户选择。这些认证方式包括：</p><h3 id="客户端证书认证"><a href="#客户端证书认证" class="headerlink" title="客户端证书认证"></a>客户端证书认证</h3><p>我们知道，一般在访问服务端的时候为了安全考虑会采用 HTTPS 的方式。但其实 HTTPS 连接可以是双向的，也就是说客户端也可以提供证书给服务端。kubernetes 可以使用客户端证书来作为认证，X509 HTTPS 的证书中会包含证书所有者的身份信息，就是证书中的 <code>Common Name</code> 字段。apiserver 启动的时候通过参数 <code>--client-ca-file=SOMEFILE</code> 来配置签发客户端证书的 CA，当客户端发送证书过来的时候，apiserver 会使用 CA 进行验证，如果证书合法，就提取其中的 <code>Common Name</code> 字段作为用户名。</p><p>NOTE：关于 HTTPS、CA、证书的内容的解释超过了这篇文章的范围，感兴趣的读者可以自行搜索对应的资料了解。</p><h3 id="静态密码文件认证"><a href="#静态密码文件认证" class="headerlink" title="静态密码文件认证"></a>静态密码文件认证</h3><p>静态密码的方式是提前在某个文件中保存了用户名和密码的信息，然后在 apiserver 启动的时候通过参数 <code>--basic-auth-file=SOMEFILE</code> 指定文件的路径。apiserver 一旦启动，加载的用户名和密码信息就不会发生改变，任何对源文件的修改必须重启 apiserver 才能生效。</p><p>静态密码文件是 CSV 格式的文件，每行对应一个用户的信息，前面三列密码、用户名、用户 ID 是必须的，第四列是可选的组名（如果有多个组，必须用双引号）：</p><pre><code>password,user,uid,&quot;group1,group2,group3&quot;</code></pre><p>客户端在发送请求的时候需要在请求头部添加上 <code>Authorization</code> 字段，对应的值是 <code>Basic BASE64ENCODED(USER:PASSWORD)</code>。apiserver 解析出客户端提供的用户名和密码，如果和文件中的某一行匹配，就认为认证成功。</p><p><strong>NOTE</strong>：这种方式很不灵活，也不安全，可以说名存实亡，不推荐使用。</p><h3 id="静态-Token-文件认证"><a href="#静态-Token-文件认证" class="headerlink" title="静态 Token 文件认证"></a>静态 Token 文件认证</h3><p>静态 Token 文件的方式很简单，事先在一个文件中写上用户的认证信息（用户名、用户 id、token、用户所在的组名），apiserver 启动通过参数 <code>--token-auth-file=SOMEFILE</code> 指定这个文件，apiserver 把这些信息加载起来。token 文件是 CSV 格式的文件，每行代表一个用户的信息，至少包含 token、用户名和用户 ID 三列，最后一列组名列表是可选的（如果有多个组必须用双引号括起来），比如：</p><pre><code>token,user,uid,&quot;group1,group2,group3&quot;</code></pre><p>token 有点像令牌，客户端不需要证明自己和 token 的关系，只要客户端提供了令牌，就认为客户端身份是合法的。这有点像古装剧中拿着皇上颁发的某个令牌行事，不管谁拿着令牌都有对应的权力。</p><p>客户端只要在请求的头部加上 <code>Authorization</code> 字段就能完成认证，对应的值是 <code>Bearer TOKEN</code>。</p><p>这种方式下，apiserver 一旦启动就不会再根据文件的内容调整内存中的数据，想要让修改的文件生效，只能重启 apiserver。<strong>和静态密码一样，这种方法也是名存实亡，不推荐使用。</strong></p><p>如果配置了多个认证方式，kubernetes 会以此遍历它们（并不保证它们的先后顺序），一旦请求能通过某个认证，就算成功。</p><h3 id="Service-Account-Tokens-认证"><a href="#Service-Account-Tokens-认证" class="headerlink" title="Service Account Tokens 认证"></a>Service Account Tokens 认证</h3><p>有些情况下，我们希望在 pod 内部访问 apiserver，获取集群的信息，甚至对集群进行改动。针对这种情况，kubernetes 提供了一种特殊的认证方式：Service Account。</p><p>Service Account 是面向 namespace 的，每个 namespace 创建的时候，kubernetes 会自动在这个 namespace 下面创建一个默认的 Service Account；并且这个 Service Account 只能访问该 namespace 的资源。Service Account 和 pod、service、deployment 一样是 kubernetes 集群中的一种资源，用户也可以创建自己的 serviceaccount。</p><p>ServiceAccount 主要包含了三个内容：namespace、Token 和 CA。namespace 指定了 pod 所在的 namespace，CA 用于验证 apiserver 的证书，token 用作身份验证。它们都通过 mount 的方式保存在 pod 的文件系统中，其中 <code>token</code> 保存的路径是 <code>/var/run/secrets/kubernetes.io/serviceaccount/token</code>，是 apiserver 通过私钥签发 token 的 base64 编码后的结果；<code>CA</code> 保存的路径是 <code>/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</code>，namespace 保存的路径是 <code>/var/run/secrets/kubernetes.io/serviceaccount/namespace</code>，也是用 base64 编码。</p><p>如果 token 能够通过认证，那么请求的用户名将被设置为 <code>system:serviceaccount:(NAMESPACE):(SERVICEACCOUNT)</code>，而请求的组名有两个：<code>system:serviceaccounts</code> 和 <code>system:serviceaccounts:(NAMESPACE)</code>。</p><p>关于 Service Account 的配置可以参考官方的 <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/" target="_blank" rel="noopener">Configure Service Accounts for Pods</a> 文档。</p><h3 id="OpenID-认证"><a href="#OpenID-认证" class="headerlink" title="OpenID 认证"></a>OpenID 认证</h3><p>这种认证方式是通过 OAuth2 协议进行的，也就是第三方登录常用的方式。因为没有使用过，略过不表，感兴趣可以参考 OAuth2 的原理。</p><h3 id="Webhook-Token-认证"><a href="#Webhook-Token-认证" class="headerlink" title="Webhook Token 认证"></a>Webhook Token 认证</h3><p>Webhook Token 认证方式可以让用户使用自己的认证方式，用户只需要按照约定的请求格式和应答格式提供 HTTPS 服务，当用户把 Bearer Token 放到请求的头部，kubernetes 会把 token 发送给事先配置的地址进行认证，如果认证结果成功，则认为请求用户合法。</p><p>这种方式下有两个参数可以配置：</p><ul><li><code>--authentication-token-webhook-config-file</code>：kubeconfig 文件说明如果访问认证服务器</li><li><code>--authentication-token-webhook-cache-ttl</code>：认证结果要缓存多久，默认是两分钟</li></ul><p>这种方式下，自定义认证的请求和应答都有一定的格式，具体的规范请参考<a href="https://kubernetes.io/docs/admin/authentication/#webhook-token-authentication" target="_blank" rel="noopener">官方文档的说明</a>。</p><h3 id="Keystone-认证"><a href="#Keystone-认证" class="headerlink" title="Keystone 认证"></a>Keystone 认证</h3><p><a href="http://docs.openstack.org/developer/keystone/" target="_blank" rel="noopener">Keystone</a> 是 openstack 提供的认证和授权组件，这个方法对于已经使用 openstack 来搭建 Iaas 平台的公司比较适用，直接使用 keystone 可以保证 Iaas 和 Caas 平台保持一致的用户体系。</p><p>kubernetes 目前对 keystone 的支持还是实验阶段，不推荐在生产系统中使用。</p><h3 id="匿名请求"><a href="#匿名请求" class="headerlink" title="匿名请求"></a>匿名请求</h3><p>如果请求没有通过以上任何方式的认证，正常情况下应该是直接返回 401 错误。但是 kubernetes 还提供另外一种选择，给没有通过认证的请求一个特殊的用户名 <code>system:anonymous</code> 和组名 <code>system:unauthenticated</code>。</p><p>这样的话，可以跟下面要讲的授权结合起来，为匿名请求设置一些特殊的权限，比如只能读取当前 namespace 的 pod 信息，方便用户访问。</p><h2 id="二-授权（Authorization）：我能做什么"><a href="#二-授权（Authorization）：我能做什么" class="headerlink" title="二. 授权（Authorization）：我能做什么"></a>二. 授权（Authorization）：我能做什么</h2><p>授权发生在认证之后，通过认证的请求就能知道 username，而授权判断这个用户是否有权限对访问的资源执行特定的动作。</p><p>还是拿社交软件做例子，当用户成功登录之后，他能操作的资源范围是固定的：查看和自己有关系的用户的数据，但是只能修改自己的数据。不难想象，你可以随意地删除或者修改其他用户的信息是一件多么恐怖的事情。</p><p>在系统软件中，用户还分成不同的角色，最常见的比如管理员。如果普通用户只能看到自己视角内的内容，那么管理员的权限则大得多，它一般能查看整个系统的数据，并且能对大部分内容做修改（包括删除）。</p><p><strong>控制不同用户能操作哪些内容就是授权要做的事情</strong>。</p><p>在启动 apiserver 的时候，可以通过 <code>--authorization_mode</code> 参数来指定授权模式，目前支持的模式有：</p><ul><li><code>AlwaysDeny</code>：阻止所有的请求访问，只用于测试环境</li><li><code>AlwaysAllow</code>：允许所有的请求访问，注意这个模式下没有对请求进行限制，只有你能确保没有恶意请求的时候使用</li><li><code>ABAC</code>：基于属性的访问控制</li><li><code>RBAC</code>：基于角色的访问控制，这是 1.6 版本之后开始推荐的授权方式</li><li><code>WebHook</code>：</li></ul><p>kubernetes apiserver 根据事先定义的授权策略 来决定用户是否有权限访问。每个请求都带上了用户和资源的信息：比如发送请求的用户、请求的路径、请求的动作等，授权就是根据这些信息和授权策略进行比较，如果符合策略，则认为授权通过，否则会返回 <code>403 Unauthorized</code> 错误。</p><p>和认证一样，管理员可以配置多个授权方式，一种任何一种方式通过，就认为授权成功。所以如果配置了 <code>AlwaysAllow</code>，不管还配置了什么，请求都能直接通过授权。</p><p>kubernetes 把请求分成了两种：资源请求和非资源请求。资源请求是对 kubernetes 封装的资源实体的请求，比如 pods、nodes、services 等；非资源请求相反，是对诸如 <code>/api</code>、<code>/metrics</code>、<code>healthz</code> 等和资源无关的请求。它们两者的授权也有区别。</p><p><code>AlwaysAllow</code> 和 <code>AlwaysDeny</code> 比较简单，我们就不介绍了，而是看看其他三种方法。</p><h3 id="ABAC（Attribute-Based-Access-Control）"><a href="#ABAC（Attribute-Based-Access-Control）" class="headerlink" title="ABAC（Attribute-Based Access Control）"></a>ABAC（Attribute-Based Access Control）</h3><p>ABAC 根据请求的属性来决定某个请求是否有权限，授权策略是写到文件中的，因此如果配置了该方法，apiserver 在启动的时候还要通过参数 <code>--authorization-policy-file=SOME_FILENAME</code> 告诉策略文件的位置。</p><p>这个文件每行定义了一个策略，每个策略都是 JSON 格式的内容。这个 JSON 可以包含如下的内容：</p><ul><li><code>apiVersion</code>：版本号，目前是 <code>abac.authorization.kubernetes.io/v1beta1</code></li><li><code>kind</code>：资源类型，必须是 <code>Policy</code></li><li><code>spec</code>：具体的策略配置，这是个字典，包括这些字段：<ul><li><code>user</code>：用户名</li><li><code>group</code>：组名。<code>system:authenticated</code> 匹配所有通过认证的请求，<code>system:unauthenticated</code> 匹配所有没有通过认证的请求</li><li><code>apiGroup</code>：资源的 API group，比如 <code>extensions</code>，<code>*</code> 表示匹配所有的 API group</li><li><code>namespace</code>：kubernetes 中的 namespace，比如 <code>kube-system</code>，<code>*</code> 匹配所有的 namespace</li><li><code>resource</code>：资源类型，比如 <code>pods</code>，<code>*</code> 匹配所有的资源类型</li><li><code>nonResourcePath</code>：非资源请求的路径，比如 <code>/version</code>或者 <code>/apis</code> 等，<code>*</code> 匹配所有的非资源路径，<code>/foo/*</code> 匹配所有 <code>/foo</code> 的子路径</li><li><code>readonly</code>：布尔型，是否只读，默认为 false。如果设置为 true，则用户只有 GET、LIST 和 WATCH 权限</li></ul></li></ul><p>每个请求都有对应的属性，授权的时候会一次匹配所有的规则，如果有某个规则匹配，则认为请求有对应的权限（Read/Write）。可以看到，通配符 <code>*</code> 表示匹配任意的值，比如可以让某个用户可以访问任意资源。</p><p>来看几个例子：</p><h4 id="1-Alice-可以做任何事情"><a href="#1-Alice-可以做任何事情" class="headerlink" title="1. Alice 可以做任何事情"></a>1. Alice 可以做任何事情</h4><pre><code>{&quot;apiVersion&quot;: &quot;abac.authorization.kubernetes.io/v1beta1&quot;, &quot;kind&quot;: &quot;Policy&quot;, &quot;spec&quot;: {&quot;user&quot;: &quot;alice&quot;, &quot;namespace&quot;: &quot;*&quot;, &quot;resource&quot;: &quot;*&quot;, &quot;apiGroup&quot;: &quot;*&quot;}}</code></pre><h4 id="2-kubelet-可以读取所有-pods-的信息"><a href="#2-kubelet-可以读取所有-pods-的信息" class="headerlink" title="2. kubelet 可以读取所有 pods 的信息"></a>2. kubelet 可以读取所有 pods 的信息</h4><pre><code>{&quot;apiVersion&quot;: &quot;abac.authorization.kubernetes.io/v1beta1&quot;, &quot;kind&quot;: &quot;Policy&quot;, &quot;spec&quot;: {&quot;user&quot;: &quot;kubelet&quot;, &quot;namespace&quot;: &quot;*&quot;, &quot;resource&quot;: &quot;pods&quot;, &quot;readonly&quot;: true}}</code></pre><h4 id="3-kubelet-可以对-events-进行任何的读写操作"><a href="#3-kubelet-可以对-events-进行任何的读写操作" class="headerlink" title="3. kubelet 可以对 events 进行任何的读写操作"></a>3. kubelet 可以对 events 进行任何的读写操作</h4><pre><code>{&quot;apiVersion&quot;: &quot;abac.authorization.kubernetes.io/v1beta1&quot;, &quot;kind&quot;: &quot;Policy&quot;, &quot;spec&quot;: {&quot;user&quot;: &quot;kubelet&quot;, &quot;namespace&quot;: &quot;*&quot;, &quot;resource&quot;: &quot;events&quot;}}</code></pre><h4 id="4-Bob-可以读取-projectCaribou-namespace-的所有-pods-信息"><a href="#4-Bob-可以读取-projectCaribou-namespace-的所有-pods-信息" class="headerlink" title="4. Bob 可以读取 projectCaribou namespace 的所有 pods 信息"></a>4. Bob 可以读取 <code>projectCaribou</code> namespace 的所有 pods 信息</h4><pre><code>{&quot;apiVersion&quot;: &quot;abac.authorization.kubernetes.io/v1beta1&quot;, &quot;kind&quot;: &quot;Policy&quot;, &quot;spec&quot;: {&quot;user&quot;: &quot;bob&quot;, &quot;namespace&quot;: &quot;projectCaribou&quot;, &quot;resource&quot;: &quot;pods&quot;, &quot;readonly&quot;: true}}</code></pre><h4 id="5-所有人都能对所有路径发送只读请求"><a href="#5-所有人都能对所有路径发送只读请求" class="headerlink" title="5. 所有人都能对所有路径发送只读请求"></a>5. 所有人都能对所有路径发送只读请求</h4><pre><code>{&quot;apiVersion&quot;: &quot;abac.authorization.kubernetes.io/v1beta1&quot;, &quot;kind&quot;: &quot;Policy&quot;, &quot;spec&quot;: {&quot;group&quot;: &quot;system:authenticated&quot;, &quot;readonly&quot;: true, &quot;nonResourcePath&quot;: &quot;*&quot;}}{&quot;apiVersion&quot;: &quot;abac.authorization.kubernetes.io/v1beta1&quot;, &quot;kind&quot;: &quot;Policy&quot;, &quot;spec&quot;: {&quot;group&quot;: &quot;system:unauthenticated&quot;, &quot;readonly&quot;: true, &quot;nonResourcePath&quot;: &quot;*&quot;}}</code></pre><p><strong>NOTE</strong>：ABAC 对权限的定义比较少，只有可读、可读写两种。并且策略修改后只有重启 apiserver 才能生效，因此用起来不是很方便。</p><h3 id="RBAC（Role-Based-Access-Control）"><a href="#RBAC（Role-Based-Access-Control）" class="headerlink" title="RBAC（Role-Based Access Control）"></a>RBAC（Role-Based Access Control）</h3><p>RBAC 是官方才 1.6 版本之后推荐使用的授权方式，因为它比较灵活，而且能够很好地实现资源隔离效果。</p><p>这种方法引入了一个重要的概念：Role，翻译成角色。所有的权限都是围绕角色进行的，也就是说角色本身会包含一系列的权限规则，表明某个角色能做哪些事情。比如管理员可以操作所有的资源，某个 namespace 的用户只能修改该 namespace的内容，或者有些角色只允许读取资源。角色和 pods、services 这些资源一样，可以通过 API 创建和删除，因此用户可以非常灵活地根据需求创建角色。</p><p>RBAC 定义了 <code>Role</code> 和 <code>ClusterRole</code>，分别对应单个 namespace 的权限和整个集群的权限，来对两者进行区分。</p><p>权限就是对某个资源可以执行什么样的操作，操作可以是 <code>get</code>、<code>list</code>、<code>watch</code>、<code>create</code>、<code>update</code>、<code>patch</code> 和 <code>delete</code>，因此粒度要比 ABAC 更细，资源就对应了 kubernetes API 管理的资源概念，比如：</p><pre><code>rules:- apiGroups: [&quot;&quot;]  resources: [&quot;pods&quot;]  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;]- apiGroups: [&quot;batch&quot;, &quot;extensions&quot;]  resources: [&quot;jobs&quot;]  verbs: [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;]</code></pre><p>上面定义了两个权限，分别是读取 pods 和读写 jobs 资源。</p><p>有了权限之后，最终还是要对应到用户上面，用户和角色之间可以进行绑定，绑定后的用户就能拥有对应角色的所有权限。比如我们可以添加一个管理员角色，然后把公司的某几个人设置（绑定）成管理员。一个用户可以和多个角色进行绑定，同时应用这些角色的权限。</p><p>和 Role 一样，RBAC 也有两种资源：<code>RoleBinding</code> 和 <code>ClusterRoleBinding</code>，分别对应单个 namespace 和整个集群范围。</p><p>我们来看个例子：</p><pre><code>kind: RoleBindingapiVersion: rbac.authorization.k8s.io/v1beta1metadata:  name: read-pods  namespace: defaultsubjects:- kind: User  name: jane  apiGroup: rbac.authorization.k8s.ioroleRef:  kind: Role  name: pod-reader  apiGroup: rbac.authorization.k8s.io</code></pre><p>这个 RoleBinding 就是把用户 <code>jane</code> 绑定到 <code>pod-reader</code> 这个角色。</p><p>以上就是 RBAC 最核心的概念，还有什么细节没有讲，比如怎么具体去指定某个资源/子资源、怎么做授权、ClusterRole 的一些边缘特性、kubernetes 预先创建的一些默认角色和绑定等等。RBAC 相对 ABAC 概念更多，也更复杂，想看具体的例子和更多 RBAC 的内容，可以参考<a href="https://kubernetes.io/docs/admin/authorization/rbac/" target="_blank" rel="noopener">官方文档</a>。</p><h3 id="Web-Hook"><a href="#Web-Hook" class="headerlink" title="Web Hook"></a>Web Hook</h3><p>这里的 webhook 和验证差不多，就是用户在外部提供 HTTPS 服务，然后配置 apiserver 调用该服务去进行授权，略过不提。</p><h3 id="自定义"><a href="#自定义" class="headerlink" title="自定义"></a>自定义</h3><p>除了上面两个方式之外，用户也可以自己直接修改 kubernetes 代码，编写授权方式。因为 kubernetes 做了很好的封装，用户只需要实现下面的接口即可：</p><pre><code>type Authorizer interface {  Authorize(a Attributes) error}</code></pre><p>把自己编写的代码放在 <code>pkg/auth/authorizer/$MODULENAME</code> 路径就行。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://kubernetes.io/docs/admin/accessing-the-api/" target="_blank" rel="noopener">Controlling Access to the Kubernetes API：和 kubernetes API 通信的流程</a></li><li><a href="https://kubernetes.io/docs/admin/authentication/" target="_blank" rel="noopener">Authenticating：kubernetes 认证机制</a></li><li><a href="https://kubernetes.io/docs/admin/authorization/" target="_blank" rel="noopener">Authorization：kubernetes 授权机制</a></li><li><a href="https://kubernetes.io/docs/admin/admission-controllers/" target="_blank" rel="noopener">Using Admission Controllers</a></li><li><a href="https://zhuanlan.zhihu.com/p/26220963" target="_blank" rel="noopener">容器编排之Kubernetes认证与授权</a></li><li><a href="http://cloudgeekz.com/1045/kubernetes-authentication-and-authorization.html" target="_blank" rel="noopener">Understanding Kubernetes Authentication and Authorization</a></li><li><a href="https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#accessing-the-api-from-a-pod" target="_blank" rel="noopener">Accessing the API from a Pod</a></li><li><a href="http://tonybai.com/2017/03/03/access-api-server-from-a-pod-through-serviceaccount/" target="_blank" rel="noopener">在Kubernetes Pod中使用Service Account访问API Server</a></li><li><a href="http://tonybai.com/2016/11/25/the-security-settings-for-kubernetes-cluster/" target="_blank" rel="noopener">Kubernetes集群的安全配置</a></li><li><a href="http://www.sel.zju.edu.cn/?p=588" target="_blank" rel="noopener">4S: SERVICES ACCOUNT, SECRET, SECURITY CONTEXT AND SECURITY IN KUBERNETES</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;kubernetes 主要通过 APIServer 对外提供服务，对于这样的系统集群来说，请求访问的安全性是非常重要的考虑因素。如果不对请求加以限制，那么会导致请求被滥用，甚至被黑客攻击。&lt;/p&gt;
&lt;p&gt;kubernetes 对于访问 API
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="kubernetes" scheme="http://cizixs.com/tags/kubernetes/"/>
    
      <category term="container" scheme="http://cizixs.com/tags/container/"/>
    
      <category term="https" scheme="http://cizixs.com/tags/https/"/>
    
      <category term="ABAC" scheme="http://cizixs.com/tags/ABAC/"/>
    
      <category term="RBAC" scheme="http://cizixs.com/tags/RBAC/"/>
    
      <category term="security" scheme="http://cizixs.com/tags/security/"/>
    
  </entry>
  
  <entry>
    <title>kubelet 源码分析：statusManager 和 probeManager</title>
    <link href="http://cizixs.com/2017/06/12/kubelet-source-code-analysis-part4-status-manager/"/>
    <id>http://cizixs.com/2017/06/12/kubelet-source-code-analysis-part4-status-manager/</id>
    <published>2017-06-11T16:00:00.000Z</published>
    <updated>2018-09-17T13:18:45.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>在 kubelet 初始化的时候，会创建 statusManager 和 probeManager，两者都和 pod 的状态有关系，因此我们放到一起来讲解。</p><p>statusManager 负责维护状态信息，并把 pod 状态更新到 apiserver，但是它并不负责监控 pod 状态的变化，而是提供对应的接口供其他组件调用，比如 probeManager。probeManager 会定时去监控 pod 中容器的健康状况，一旦发现状态发生变化，就调用 statusManager 提供的方法更新 pod 的状态。</p><pre class=" language-go"><code class="language-go">klet<span class="token punctuation">.</span>statusManager <span class="token operator">=</span> status<span class="token punctuation">.</span><span class="token function">NewManager</span><span class="token punctuation">(</span>kubeClient<span class="token punctuation">,</span> klet<span class="token punctuation">.</span>podManager<span class="token punctuation">)</span>klet<span class="token punctuation">.</span>probeManager <span class="token operator">=</span> prober<span class="token punctuation">.</span><span class="token function">NewManager</span><span class="token punctuation">(</span>        klet<span class="token punctuation">.</span>statusManager<span class="token punctuation">,</span>        klet<span class="token punctuation">.</span>livenessManager<span class="token punctuation">,</span>        klet<span class="token punctuation">.</span>runner<span class="token punctuation">,</span>        containerRefManager<span class="token punctuation">,</span>        kubeDeps<span class="token punctuation">.</span>Recorder<span class="token punctuation">)</span></code></pre><h2 id="StatusManager"><a href="#StatusManager" class="headerlink" title="StatusManager"></a>StatusManager</h2><p>statusManager 对应的代码在 <code>pkg/kubelet/status/status_manager.go</code> 文件中，</p><pre class=" language-go"><code class="language-go"><span class="token keyword">type</span> PodStatusProvider <span class="token keyword">interface</span> <span class="token punctuation">{</span>    <span class="token function">GetPodStatus</span><span class="token punctuation">(</span>uid types<span class="token punctuation">.</span>UID<span class="token punctuation">)</span> <span class="token punctuation">(</span>api<span class="token punctuation">.</span>PodStatus<span class="token punctuation">,</span> <span class="token builtin">bool</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token keyword">type</span> Manager <span class="token keyword">interface</span> <span class="token punctuation">{</span>    PodStatusProvider    <span class="token function">Start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token function">SetPodStatus</span><span class="token punctuation">(</span>pod <span class="token operator">*</span>api<span class="token punctuation">.</span>Pod<span class="token punctuation">,</span> status api<span class="token punctuation">.</span>PodStatus<span class="token punctuation">)</span>    <span class="token function">SetContainerReadiness</span><span class="token punctuation">(</span>podUID types<span class="token punctuation">.</span>UID<span class="token punctuation">,</span> containerID kubecontainer<span class="token punctuation">.</span>ContainerID<span class="token punctuation">,</span> ready <span class="token builtin">bool</span><span class="token punctuation">)</span>    <span class="token function">TerminatePod</span><span class="token punctuation">(</span>pod <span class="token operator">*</span>api<span class="token punctuation">.</span>Pod<span class="token punctuation">)</span>    <span class="token function">RemoveOrphanedStatuses</span><span class="token punctuation">(</span>podUIDs <span class="token keyword">map</span><span class="token punctuation">[</span>types<span class="token punctuation">.</span>UID<span class="token punctuation">]</span><span class="token builtin">bool</span><span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><p>这个接口的方法可以分成三组：获取某个 pod 的状态、后台运行 goroutine 执行同步工作、修改 pod 的状态。修改状态的方法有多个，每个都有不同的用途：</p><ul><li>SetPodStatus：如果 pod 的状态发生了变化，会调用这个方法，把新状态更新到 apiserver，一般在 kubelet 维护 pod 生命周期的时候会调用</li><li>SetContainerReadiness：如果健康检查发现 pod 中容器的健康状态发生变化，会调用这个方法，修改 pod 的健康状态</li><li>TerminatePod：kubelet 在删除 pod 的时候，会调用这个方法，把 pod 中所有的容器设置为 terminated 状态</li><li>RemoveOrphanedStatuses：删除孤儿 pod，直接把对应的状态数据从缓存中删除即可</li></ul><p><code>Start()</code> 方法是在 kubelet 运行的时候调用的，它会启动一个 goroutine 执行更新操作：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">const</span> syncPeriod <span class="token operator">=</span> <span class="token number">10</span> <span class="token operator">*</span> time<span class="token punctuation">.</span>Second<span class="token keyword">func</span> <span class="token punctuation">(</span>m <span class="token operator">*</span>manager<span class="token punctuation">)</span> <span class="token function">Start</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token operator">...</span><span class="token operator">...</span>    glog<span class="token punctuation">.</span><span class="token function">Info</span><span class="token punctuation">(</span><span class="token string">"Starting to sync pod status with apiserver"</span><span class="token punctuation">)</span>    syncTicker <span class="token operator">:=</span> time<span class="token punctuation">.</span><span class="token function">Tick</span><span class="token punctuation">(</span>syncPeriod<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// syncPod and syncBatch share the same go routine to avoid sync races.</span>    <span class="token keyword">go</span> wait<span class="token punctuation">.</span><span class="token function">Forever</span><span class="token punctuation">(</span><span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">select</span> <span class="token punctuation">{</span>        <span class="token keyword">case</span> syncRequest <span class="token operator">:=</span> <span class="token operator">&lt;-</span>m<span class="token punctuation">.</span>podStatusChannel<span class="token punctuation">:</span>            m<span class="token punctuation">.</span><span class="token function">syncPod</span><span class="token punctuation">(</span>syncRequest<span class="token punctuation">.</span>podUID<span class="token punctuation">,</span> syncRequest<span class="token punctuation">.</span>status<span class="token punctuation">)</span>        <span class="token keyword">case</span> <span class="token operator">&lt;-</span>syncTicker<span class="token punctuation">:</span>            m<span class="token punctuation">.</span><span class="token function">syncBatch</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><p>这个 goroutine 就能不断地从两个 channel 监听数据进行处理：<code>syncTicker</code> 是个定时器，也就是说它会定时保证 apiserver 和自己缓存的最新 pod 状态保持一致；<code>podStatusChannel</code> 是所有 pod 状态更新发送到的地方，调用方不会直接操作这个 channel，而是通过调用上面提到的修改状态的各种方法，这些方法内部会往这个 channel 写数据。</p><p><code>m.syncPod</code> 根据参数中的 pod 和它的状态信息对 apiserver 中的数据进行更新，如果发现 pod 已经被删除也会把它从内部数据结构中删除。</p><h2 id="ProbeManager"><a href="#ProbeManager" class="headerlink" title="ProbeManager"></a>ProbeManager</h2><p>probeManager 检测 <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/" target="_blank" rel="noopener">pod 中容器的健康状态</a>，目前有两种 probe：readiness 和 liveness。<strong>readinessProbe</strong> 检测容器是否可以接受请求，如果检测结果失败，则将其从 service 的 endpoints 中移除，后续的请求也就不会发送给这个容器；livenessProbe 检测容器是否存活，如果检测结果失败，kubelet 会杀死这个容器，并重启一个新的（除非 RestartPolicy 设置成了 Never）。</p><p>并不是所有的 pod 中的容器都有健康检查的探针，如果没有，则不对容器进行检测，默认认为容器是正常的。在每次创建新 pod 的时候，kubelet 都会调用 <code>probeManager.AddPod(pod)</code> 方法，它对应的实现在 <code>pkg/kubelet/prober/prober_manager.go</code> 文件中：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>m <span class="token operator">*</span>manager<span class="token punctuation">)</span> <span class="token function">AddPod</span><span class="token punctuation">(</span>pod <span class="token operator">*</span>api<span class="token punctuation">.</span>Pod<span class="token punctuation">)</span> <span class="token punctuation">{</span>    m<span class="token punctuation">.</span>workerLock<span class="token punctuation">.</span><span class="token function">Lock</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">defer</span> m<span class="token punctuation">.</span>workerLock<span class="token punctuation">.</span><span class="token function">Unlock</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    key <span class="token operator">:=</span> probeKey<span class="token punctuation">{</span>podUID<span class="token punctuation">:</span> pod<span class="token punctuation">.</span>UID<span class="token punctuation">}</span>    <span class="token keyword">for</span> <span class="token boolean">_</span><span class="token punctuation">,</span> c <span class="token operator">:=</span> <span class="token keyword">range</span> pod<span class="token punctuation">.</span>Spec<span class="token punctuation">.</span>Containers <span class="token punctuation">{</span>        key<span class="token punctuation">.</span>containerName <span class="token operator">=</span> c<span class="token punctuation">.</span>Name        <span class="token keyword">if</span> c<span class="token punctuation">.</span>ReadinessProbe <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            key<span class="token punctuation">.</span>probeType <span class="token operator">=</span> readiness            <span class="token keyword">if</span> <span class="token boolean">_</span><span class="token punctuation">,</span> ok <span class="token operator">:=</span> m<span class="token punctuation">.</span>workers<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">;</span> ok <span class="token punctuation">{</span>                glog<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"Readiness probe already exists! %v - %v"</span><span class="token punctuation">,</span>                    format<span class="token punctuation">.</span><span class="token function">Pod</span><span class="token punctuation">(</span>pod<span class="token punctuation">)</span><span class="token punctuation">,</span> c<span class="token punctuation">.</span>Name<span class="token punctuation">)</span>                <span class="token keyword">return</span>            <span class="token punctuation">}</span>            w <span class="token operator">:=</span> <span class="token function">newWorker</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> readiness<span class="token punctuation">,</span> pod<span class="token punctuation">,</span> c<span class="token punctuation">)</span>            m<span class="token punctuation">.</span>workers<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> w            <span class="token keyword">go</span> w<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span>        <span class="token keyword">if</span> c<span class="token punctuation">.</span>LivenessProbe <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            key<span class="token punctuation">.</span>probeType <span class="token operator">=</span> liveness            <span class="token keyword">if</span> <span class="token boolean">_</span><span class="token punctuation">,</span> ok <span class="token operator">:=</span> m<span class="token punctuation">.</span>workers<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">;</span> ok <span class="token punctuation">{</span>                glog<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"Liveness probe already exists! %v - %v"</span><span class="token punctuation">,</span>                    format<span class="token punctuation">.</span><span class="token function">Pod</span><span class="token punctuation">(</span>pod<span class="token punctuation">)</span><span class="token punctuation">,</span> c<span class="token punctuation">.</span>Name<span class="token punctuation">)</span>                <span class="token keyword">return</span>            <span class="token punctuation">}</span>            w <span class="token operator">:=</span> <span class="token function">newWorker</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> liveness<span class="token punctuation">,</span> pod<span class="token punctuation">,</span> c<span class="token punctuation">)</span>            m<span class="token punctuation">.</span>workers<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> w            <span class="token keyword">go</span> w<span class="token punctuation">.</span><span class="token function">run</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>遍历 pod 中的容器，如果其定义了 readiness 或者 liveness，就创建一个 worker，并启动一个 goroutine 在后台运行这个 worker。</p><p><code>pkg/kubelet/prober/worker.go</code>：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>w <span class="token operator">*</span>worker<span class="token punctuation">)</span> <span class="token function">run</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    probeTickerPeriod <span class="token operator">:=</span> time<span class="token punctuation">.</span><span class="token function">Duration</span><span class="token punctuation">(</span>w<span class="token punctuation">.</span>spec<span class="token punctuation">.</span>PeriodSeconds<span class="token punctuation">)</span> <span class="token operator">*</span> time<span class="token punctuation">.</span>Second    probeTicker <span class="token operator">:=</span> time<span class="token punctuation">.</span><span class="token function">NewTicker</span><span class="token punctuation">(</span>probeTickerPeriod<span class="token punctuation">)</span>    <span class="token keyword">defer</span> <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        probeTicker<span class="token punctuation">.</span><span class="token function">Stop</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token operator">!</span>w<span class="token punctuation">.</span>containerID<span class="token punctuation">.</span><span class="token function">IsEmpty</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            w<span class="token punctuation">.</span>resultsManager<span class="token punctuation">.</span><span class="token function">Remove</span><span class="token punctuation">(</span>w<span class="token punctuation">.</span>containerID<span class="token punctuation">)</span>        <span class="token punctuation">}</span>        w<span class="token punctuation">.</span>probeManager<span class="token punctuation">.</span><span class="token function">removeWorker</span><span class="token punctuation">(</span>w<span class="token punctuation">.</span>pod<span class="token punctuation">.</span>UID<span class="token punctuation">,</span> w<span class="token punctuation">.</span>container<span class="token punctuation">.</span>Name<span class="token punctuation">,</span> w<span class="token punctuation">.</span>probeType<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    time<span class="token punctuation">.</span><span class="token function">Sleep</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span><span class="token function">Duration</span><span class="token punctuation">(</span>rand<span class="token punctuation">.</span><span class="token function">Float64</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token function">float64</span><span class="token punctuation">(</span>probeTickerPeriod<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>probeLoop<span class="token punctuation">:</span>    <span class="token keyword">for</span> w<span class="token punctuation">.</span><span class="token function">doProbe</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// Wait for next probe tick.</span>        <span class="token keyword">select</span> <span class="token punctuation">{</span>        <span class="token keyword">case</span> <span class="token operator">&lt;-</span>w<span class="token punctuation">.</span>stopCh<span class="token punctuation">:</span>            <span class="token keyword">break</span> probeLoop        <span class="token keyword">case</span> <span class="token operator">&lt;-</span>probeTicker<span class="token punctuation">.</span>C<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true">// continue</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>w <span class="token operator">*</span>worker<span class="token punctuation">)</span> <span class="token function">doProbe</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>keepGoing <span class="token builtin">bool</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">defer</span> <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> <span class="token function">recover</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">}</span><span class="token punctuation">(</span><span class="token punctuation">)</span>     <span class="token keyword">defer</span> runtime<span class="token punctuation">.</span><span class="token function">HandleCrash</span><span class="token punctuation">(</span><span class="token keyword">func</span><span class="token punctuation">(</span><span class="token boolean">_</span> <span class="token keyword">interface</span><span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> keepGoing <span class="token operator">=</span> <span class="token boolean">true</span> <span class="token punctuation">}</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// pod 没有被创建，或者已经被删除了，直接跳过检测，但是会继续检测</span>    status<span class="token punctuation">,</span> ok <span class="token operator">:=</span> w<span class="token punctuation">.</span>probeManager<span class="token punctuation">.</span>statusManager<span class="token punctuation">.</span><span class="token function">GetPodStatus</span><span class="token punctuation">(</span>w<span class="token punctuation">.</span>pod<span class="token punctuation">.</span>UID<span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token operator">!</span>ok <span class="token punctuation">{</span>        glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"No status for pod: %v"</span><span class="token punctuation">,</span> format<span class="token punctuation">.</span><span class="token function">Pod</span><span class="token punctuation">(</span>w<span class="token punctuation">.</span>pod<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token boolean">true</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// pod 已经退出（不管是成功还是失败），直接返回，并终止 worker</span>    <span class="token keyword">if</span> status<span class="token punctuation">.</span>Phase <span class="token operator">==</span> api<span class="token punctuation">.</span>PodFailed <span class="token operator">||</span> status<span class="token punctuation">.</span>Phase <span class="token operator">==</span> api<span class="token punctuation">.</span>PodSucceeded <span class="token punctuation">{</span>        glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"Pod %v %v, exiting probe worker"</span><span class="token punctuation">,</span>            format<span class="token punctuation">.</span><span class="token function">Pod</span><span class="token punctuation">(</span>w<span class="token punctuation">.</span>pod<span class="token punctuation">)</span><span class="token punctuation">,</span> status<span class="token punctuation">.</span>Phase<span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token boolean">false</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 容器没有创建，或者已经删除了，直接返回，并继续检测，等待更多的信息</span>    c<span class="token punctuation">,</span> ok <span class="token operator">:=</span> api<span class="token punctuation">.</span><span class="token function">GetContainerStatus</span><span class="token punctuation">(</span>status<span class="token punctuation">.</span>ContainerStatuses<span class="token punctuation">,</span> w<span class="token punctuation">.</span>container<span class="token punctuation">.</span>Name<span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token operator">!</span>ok <span class="token operator">||</span> <span class="token function">len</span><span class="token punctuation">(</span>c<span class="token punctuation">.</span>ContainerID<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token punctuation">{</span>        glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"Probe target container not found: %v - %v"</span><span class="token punctuation">,</span>            format<span class="token punctuation">.</span><span class="token function">Pod</span><span class="token punctuation">(</span>w<span class="token punctuation">.</span>pod<span class="token punctuation">)</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>container<span class="token punctuation">.</span>Name<span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token boolean">true</span>     <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// pod 更新了容器，使用最新的容器信息</span>    <span class="token keyword">if</span> w<span class="token punctuation">.</span>containerID<span class="token punctuation">.</span><span class="token function">String</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> c<span class="token punctuation">.</span>ContainerID <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token operator">!</span>w<span class="token punctuation">.</span>containerID<span class="token punctuation">.</span><span class="token function">IsEmpty</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            w<span class="token punctuation">.</span>resultsManager<span class="token punctuation">.</span><span class="token function">Remove</span><span class="token punctuation">(</span>w<span class="token punctuation">.</span>containerID<span class="token punctuation">)</span>        <span class="token punctuation">}</span>        w<span class="token punctuation">.</span>containerID <span class="token operator">=</span> kubecontainer<span class="token punctuation">.</span><span class="token function">ParseContainerID</span><span class="token punctuation">(</span>c<span class="token punctuation">.</span>ContainerID<span class="token punctuation">)</span>        w<span class="token punctuation">.</span>resultsManager<span class="token punctuation">.</span><span class="token function">Set</span><span class="token punctuation">(</span>w<span class="token punctuation">.</span>containerID<span class="token punctuation">,</span> w<span class="token punctuation">.</span>initialValue<span class="token punctuation">,</span> w<span class="token punctuation">.</span>pod<span class="token punctuation">)</span>        w<span class="token punctuation">.</span>onHold <span class="token operator">=</span> <span class="token boolean">false</span>    <span class="token punctuation">}</span>    <span class="token keyword">if</span> w<span class="token punctuation">.</span>onHold <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token boolean">true</span>    <span class="token punctuation">}</span>    <span class="token keyword">if</span> c<span class="token punctuation">.</span>State<span class="token punctuation">.</span>Running <span class="token operator">==</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"Non-running container probed: %v - %v"</span><span class="token punctuation">,</span>            format<span class="token punctuation">.</span><span class="token function">Pod</span><span class="token punctuation">(</span>w<span class="token punctuation">.</span>pod<span class="token punctuation">)</span><span class="token punctuation">,</span> w<span class="token punctuation">.</span>container<span class="token punctuation">.</span>Name<span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token operator">!</span>w<span class="token punctuation">.</span>containerID<span class="token punctuation">.</span><span class="token function">IsEmpty</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            w<span class="token punctuation">.</span>resultsManager<span class="token punctuation">.</span><span class="token function">Set</span><span class="token punctuation">(</span>w<span class="token punctuation">.</span>containerID<span class="token punctuation">,</span> results<span class="token punctuation">.</span>Failure<span class="token punctuation">,</span> w<span class="token punctuation">.</span>pod<span class="token punctuation">)</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// 容器失败退出，并且不会再重启，终止 worker</span>        <span class="token keyword">return</span> c<span class="token punctuation">.</span>State<span class="token punctuation">.</span>Terminated <span class="token operator">==</span> <span class="token boolean">nil</span> <span class="token operator">||</span>            w<span class="token punctuation">.</span>pod<span class="token punctuation">.</span>Spec<span class="token punctuation">.</span>RestartPolicy <span class="token operator">!=</span> api<span class="token punctuation">.</span>RestartPolicyNever    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 容器启动时间太短，没有超过配置的初始化等待时间 InitialDelaySeconds</span>    <span class="token keyword">if</span> <span class="token function">int32</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span><span class="token function">Since</span><span class="token punctuation">(</span>c<span class="token punctuation">.</span>State<span class="token punctuation">.</span>Running<span class="token punctuation">.</span>StartedAt<span class="token punctuation">.</span>Time<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Seconds</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> w<span class="token punctuation">.</span>spec<span class="token punctuation">.</span>InitialDelaySeconds <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token boolean">true</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 调用 prober 进行检测容器的状态</span>    result<span class="token punctuation">,</span> err <span class="token operator">:=</span> w<span class="token punctuation">.</span>probeManager<span class="token punctuation">.</span>prober<span class="token punctuation">.</span><span class="token function">probe</span><span class="token punctuation">(</span>w<span class="token punctuation">.</span>probeType<span class="token punctuation">,</span> w<span class="token punctuation">.</span>pod<span class="token punctuation">,</span> status<span class="token punctuation">,</span> w<span class="token punctuation">.</span>container<span class="token punctuation">,</span> w<span class="token punctuation">.</span>containerID<span class="token punctuation">)</span>    <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token boolean">true</span>    <span class="token punctuation">}</span>    <span class="token keyword">if</span> w<span class="token punctuation">.</span>lastResult <span class="token operator">==</span> result <span class="token punctuation">{</span>        w<span class="token punctuation">.</span>resultRun<span class="token operator">++</span>    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>        w<span class="token punctuation">.</span>lastResult <span class="token operator">=</span> result        w<span class="token punctuation">.</span>resultRun <span class="token operator">=</span> <span class="token number">1</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 如果容器退出，并且没有超过最大的失败次数，则继续检测</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>result <span class="token operator">==</span> results<span class="token punctuation">.</span>Failure <span class="token operator">&amp;&amp;</span> w<span class="token punctuation">.</span>resultRun <span class="token operator">&lt;</span> <span class="token function">int</span><span class="token punctuation">(</span>w<span class="token punctuation">.</span>spec<span class="token punctuation">.</span>FailureThreshold<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">||</span>        <span class="token punctuation">(</span>result <span class="token operator">==</span> results<span class="token punctuation">.</span>Success <span class="token operator">&amp;&amp;</span> w<span class="token punctuation">.</span>resultRun <span class="token operator">&lt;</span> <span class="token function">int</span><span class="token punctuation">(</span>w<span class="token punctuation">.</span>spec<span class="token punctuation">.</span>SuccessThreshold<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token boolean">true</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 保存最新的检测结果</span>    w<span class="token punctuation">.</span>resultsManager<span class="token punctuation">.</span><span class="token function">Set</span><span class="token punctuation">(</span>w<span class="token punctuation">.</span>containerID<span class="token punctuation">,</span> result<span class="token punctuation">,</span> w<span class="token punctuation">.</span>pod<span class="token punctuation">)</span>    <span class="token keyword">if</span> w<span class="token punctuation">.</span>probeType <span class="token operator">==</span> liveness <span class="token operator">&amp;&amp;</span> result <span class="token operator">==</span> results<span class="token punctuation">.</span>Failure <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 容器 liveness 检测失败，需要删除容器并重新创建，在新容器成功创建出来之前，暂停检测</span>        w<span class="token punctuation">.</span>onHold <span class="token operator">=</span> <span class="token boolean">true</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">}</span></code></pre><p>每次检测的时候都会用 <code>w.resultsManager.Set(w.containerID, result, w.pod)</code> 来保存检测结果，<code>resultsManager</code> 的代码在 <code>pkg/kubelet/prober/results/results_manager.go</code>：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>m <span class="token operator">*</span>manager<span class="token punctuation">)</span> <span class="token function">Set</span><span class="token punctuation">(</span>id kubecontainer<span class="token punctuation">.</span>ContainerID<span class="token punctuation">,</span> result Result<span class="token punctuation">,</span> pod <span class="token operator">*</span>api<span class="token punctuation">.</span>Pod<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> m<span class="token punctuation">.</span><span class="token function">setInternal</span><span class="token punctuation">(</span>id<span class="token punctuation">,</span> result<span class="token punctuation">)</span> <span class="token punctuation">{</span>        m<span class="token punctuation">.</span>updates <span class="token operator">&lt;-</span> Update<span class="token punctuation">{</span>id<span class="token punctuation">,</span> result<span class="token punctuation">,</span> pod<span class="token punctuation">.</span>UID<span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>m <span class="token operator">*</span>manager<span class="token punctuation">)</span> <span class="token function">setInternal</span><span class="token punctuation">(</span>id kubecontainer<span class="token punctuation">.</span>ContainerID<span class="token punctuation">,</span> result Result<span class="token punctuation">)</span> <span class="token builtin">bool</span> <span class="token punctuation">{</span>    m<span class="token punctuation">.</span><span class="token function">Lock</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">defer</span> m<span class="token punctuation">.</span><span class="token function">Unlock</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    prev<span class="token punctuation">,</span> exists <span class="token operator">:=</span> m<span class="token punctuation">.</span>cache<span class="token punctuation">[</span>id<span class="token punctuation">]</span>    <span class="token keyword">if</span> <span class="token operator">!</span>exists <span class="token operator">||</span> prev <span class="token operator">!=</span> result <span class="token punctuation">{</span>        m<span class="token punctuation">.</span>cache<span class="token punctuation">[</span>id<span class="token punctuation">]</span> <span class="token operator">=</span> result        <span class="token keyword">return</span> <span class="token boolean">true</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> <span class="token boolean">false</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>m <span class="token operator">*</span>manager<span class="token punctuation">)</span> <span class="token function">Updates</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;-</span><span class="token keyword">chan</span> Update <span class="token punctuation">{</span>    <span class="token keyword">return</span> m<span class="token punctuation">.</span>updates<span class="token punctuation">}</span></code></pre><p>它把结果保存在缓存中，并发送到 <code>m.updates</code> 管道。对于 liveness 来说，它的管道消费者是 kubelet，还记得 <code>syncLoopIteration</code> 中的这段代码逻辑吗？</p><pre class=" language-go"><code class="language-go"><span class="token keyword">case</span> update <span class="token operator">:=</span> <span class="token operator">&lt;-</span>kl<span class="token punctuation">.</span>livenessManager<span class="token punctuation">.</span><span class="token function">Updates</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> update<span class="token punctuation">.</span>Result <span class="token operator">==</span> proberesults<span class="token punctuation">.</span>Failure <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// The liveness manager detected a failure; sync the pod.</span>            pod<span class="token punctuation">,</span> ok <span class="token operator">:=</span> kl<span class="token punctuation">.</span>podManager<span class="token punctuation">.</span><span class="token function">GetPodByUID</span><span class="token punctuation">(</span>update<span class="token punctuation">.</span>PodUID<span class="token punctuation">)</span>            <span class="token keyword">if</span> <span class="token operator">!</span>ok <span class="token punctuation">{</span>                <span class="token comment" spellcheck="true">// If the pod no longer exists, ignore the update.</span>                glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"SyncLoop (container unhealthy): ignore irrelevant update: %#v"</span><span class="token punctuation">,</span> update<span class="token punctuation">)</span>                <span class="token keyword">break</span>            <span class="token punctuation">}</span>            glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"SyncLoop (container unhealthy): %q"</span><span class="token punctuation">,</span> format<span class="token punctuation">.</span><span class="token function">Pod</span><span class="token punctuation">(</span>pod<span class="token punctuation">)</span><span class="token punctuation">)</span>            handler<span class="token punctuation">.</span><span class="token function">HandlePodSyncs</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token operator">*</span>api<span class="token punctuation">.</span>Pod<span class="token punctuation">{</span>pod<span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span></code></pre><p>因为 liveness 关系者 pod 的生死，因此需要 kubelet 的处理逻辑。而 readiness 即使失败也不会重新创建 pod，它的处理逻辑是不同的，它的处理代码同样在 <code>pkg/kubelet/prober/prober_manager.go</code>：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>m <span class="token operator">*</span>manager<span class="token punctuation">)</span> <span class="token function">Start</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">go</span> wait<span class="token punctuation">.</span><span class="token function">Forever</span><span class="token punctuation">(</span>m<span class="token punctuation">.</span>updateReadiness<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>m <span class="token operator">*</span>manager<span class="token punctuation">)</span> <span class="token function">updateReadiness</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    update <span class="token operator">:=</span> <span class="token operator">&lt;-</span>m<span class="token punctuation">.</span>readinessManager<span class="token punctuation">.</span><span class="token function">Updates</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    ready <span class="token operator">:=</span> update<span class="token punctuation">.</span>Result <span class="token operator">==</span> results<span class="token punctuation">.</span>Success    m<span class="token punctuation">.</span>statusManager<span class="token punctuation">.</span><span class="token function">SetContainerReadiness</span><span class="token punctuation">(</span>update<span class="token punctuation">.</span>PodUID<span class="token punctuation">,</span> update<span class="token punctuation">.</span>ContainerID<span class="token punctuation">,</span> ready<span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><p><code>proberManager</code> 启动的时候，会运行一个 goroutine 定时读取 readinessManager 管道中的数据，并根据数据调用 <code>statusManager</code> 去更新 apiserver 中 pod 的状态信息。负责 Service 逻辑的组件获取到了这个状态，就能根据不同的值来决定是否需要更新 endpoints 的内容，也就是 service 的请求是否发送到这个 pod。</p><p>具体执行检测的代码在 <code>pkg/kubelet/prober/prober.go</code> 文件中，它会根据不同的 prober 方法（exec、HTTP、TCP）调用对应的处理逻辑，而这些具体的逻辑代码是在 <code>pkg/probe/</code> 文件夹中，三种方法的实现都不复杂，就不再详细解释了。</p>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;在 kubelet 初始化的时候，会创建 statusManager 和 probeManager，两者都和 pod
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="kubernetes" scheme="http://cizixs.com/tags/kubernetes/"/>
    
      <category term="container" scheme="http://cizixs.com/tags/container/"/>
    
      <category term="golang" scheme="http://cizixs.com/tags/golang/"/>
    
      <category term="kubelet" scheme="http://cizixs.com/tags/kubelet/"/>
    
  </entry>
  
  <entry>
    <title>kubelet 源码分析：Garbage Collect</title>
    <link href="http://cizixs.com/2017/06/09/kubelet-source-code-analysis-part-3/"/>
    <id>http://cizixs.com/2017/06/09/kubelet-source-code-analysis-part-3/</id>
    <published>2017-06-08T16:00:00.000Z</published>
    <updated>2018-09-17T13:18:45.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="kubernetes-GC-简介"><a href="#kubernetes-GC-简介" class="headerlink" title="kubernetes GC 简介"></a>kubernetes GC 简介</h2><p>作为 kubernetes 中重要的组件，kubelet 接管了节点上容器相关的所有工作。除了最核心的任务：根据 apiserver 分配的 pod 创建容器之外，它还有其他很多事情要做，其中之一就是 GC（Garbage Collect）。</p><p>在运行一段时候之后，节点上会下载很多镜像，也会有很多因为各种原因退出的容器。为了保证节点能够正常运行，kubelet 要防止镜像太多占满磁盘空间，也要防止退出的容器太多导致系统运行缓慢或者出现错误。</p><p>GC 的工作不需要手动干预，kubelet 会周期性去执行，不过在启动 kubelet 进程的时候可以通过参数控制 GC 的策略。这篇文章会介绍 GC 的功能，然后跟着代码看一下它的实现。</p><h3 id="容器-Garbage-Collect"><a href="#容器-Garbage-Collect" class="headerlink" title="容器 Garbage Collect"></a>容器 Garbage Collect</h3><p>退出的容器也会继续占用系统资源，比如还会在文件系统存储很多数据、docker 应用也要占用 CPU 和内存去维护这些容器。docker 本身并不会自动删除已经退出的容器，因此 kubelet 就负起了这个责任。kubelet 容器的回收是为了删除已经退出的容器以节省节点的空间，提升性能。</p><p>容器 GC 虽然有利于空间和性能，但是删除容器也会导致错误现场被清理，不利于 debug 和错误定位，因此不建议把所有退出的容器都删除。因此容器的清理需要一定的策略，主要是告诉 kubelet 你要保存多少已经退出的容器。和容器 GC 有关的可以配置的 kubelet 启动参数包括：</p><ul><li><code>minimum-container-ttl-duration</code>：container 结束多长时间之后才能够被回收，默认是一分钟</li><li><code>maximum-dead-containers-per-container</code>：每个 container 最终可以保存多少个已经结束的容器，默认是 1，设置为负数表示不做限制</li><li><code>maximum-dead-containers</code>：节点上最多能保留多少个结束的容器，默认是 -1，表示不做限制</li></ul><p>也就是说默认情况下，kubelet 会自动每分钟去做容器 GC，容器退出一分钟之后就可以被删除，而且每个容器做多只会保留一个已经退出的历史容器。</p><h3 id="镜像-Garbage-Collect"><a href="#镜像-Garbage-Collect" class="headerlink" title="镜像 Garbage Collect"></a>镜像 Garbage Collect</h3><p>镜像主要占用磁盘空间，虽然 docker 使用镜像分层可以让多个镜像共享存储，但是长时间运行的节点如果下载了很多镜像也会导致占用的存储空间过多。如果镜像导致磁盘被占满，会造成应用无法正常工作。docker 默认也不会做镜像清理，镜像一旦下载就会永远留在本地，除非被手动删除。</p><p>其实很多镜像并没有被实际使用，这些不用的镜像继续占用空间是非常大的浪费，也是巨大的隐患，因此 kubelet 也会周期性地去清理镜像。</p><p>镜像的清理和容器不同，是以占用的空间作为标准的，用户可以配置当镜像占据多大比例的存储空间时才进行清理。清理的时候会优先清理最久没有被使用的镜像，镜像被 pull 下来或者被容器使用都会更新它的最近使用时间。</p><p>启动 kubelet 的时候，可以配置这些参数控制镜像清理的策略：</p><ul><li><code>image-gc-high-threshold</code>：磁盘使用率的上限，当达到这一使用率的时候会触发镜像清理。默认值为 90%</li><li><code>image-gc-low-threshold</code>：磁盘使用率的下限，每次清理直到使用率低于这个值或者没有可以清理的镜像了才会停止.默认值为 80%</li><li><code>minimum-image-ttl-duration</code>：镜像最少这么久没有被使用才会被清理，可以使用 <code>h</code>（小时）、<code>m</code>（分钟）、<code>s</code>（秒）和 <code>ms</code>（毫秒）时间单位进行配置，默认是 <code>2m</code>(两分钟)</li></ul><p>也就是说，默认情况下，当镜像占满所在盘 90% 容量的时候，kubelet 就会进行清理，一直到镜像占用率低于 80% 为止。</p><h2 id="容器-GC-的代码分析"><a href="#容器-GC-的代码分析" class="headerlink" title="容器 GC 的代码分析"></a>容器 GC 的代码分析</h2><p>我们在之前<a href="http://cizixs.com/2017/06/06/kubelet-source-code-analysis-part-1">分析 kubelet 启动</a>的时候讲过，kubelet 会调用 <code>StartGarbageCollection</code> 启动 GC：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>kl <span class="token operator">*</span>Kubelet<span class="token punctuation">)</span> <span class="token function">StartGarbageCollection</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    loggedContainerGCFailure <span class="token operator">:=</span> <span class="token boolean">false</span>    <span class="token keyword">go</span> wait<span class="token punctuation">.</span><span class="token function">Until</span><span class="token punctuation">(</span><span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> err <span class="token operator">:=</span> kl<span class="token punctuation">.</span>containerGC<span class="token punctuation">.</span><span class="token function">GarbageCollect</span><span class="token punctuation">(</span>kl<span class="token punctuation">.</span>sourcesReady<span class="token punctuation">.</span><span class="token function">AllReady</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            kl<span class="token punctuation">.</span>recorder<span class="token punctuation">.</span><span class="token function">Eventf</span><span class="token punctuation">(</span>kl<span class="token punctuation">.</span>nodeRef<span class="token punctuation">,</span> api<span class="token punctuation">.</span>EventTypeWarning<span class="token punctuation">,</span> events<span class="token punctuation">.</span>ContainerGCFailed<span class="token punctuation">,</span> err<span class="token punctuation">.</span><span class="token function">Error</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            loggedContainerGCFailure <span class="token operator">=</span> <span class="token boolean">true</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            <span class="token keyword">var</span> vLevel glog<span class="token punctuation">.</span>Level <span class="token operator">=</span> <span class="token number">4</span>            <span class="token keyword">if</span> loggedContainerGCFailure <span class="token punctuation">{</span>                vLevel <span class="token operator">=</span> <span class="token number">1</span>                loggedContainerGCFailure <span class="token operator">=</span> <span class="token boolean">false</span>            <span class="token punctuation">}</span>            glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span>vLevel<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"Container garbage collection succeeded"</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span> ContainerGCPeriod<span class="token punctuation">,</span> wait<span class="token punctuation">.</span>NeverStop<span class="token punctuation">)</span>    loggedImageGCFailure <span class="token operator">:=</span> <span class="token boolean">false</span>    <span class="token keyword">go</span> wait<span class="token punctuation">.</span><span class="token function">Until</span><span class="token punctuation">(</span><span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> err <span class="token operator">:=</span> kl<span class="token punctuation">.</span>imageManager<span class="token punctuation">.</span><span class="token function">GarbageCollect</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            kl<span class="token punctuation">.</span>recorder<span class="token punctuation">.</span><span class="token function">Eventf</span><span class="token punctuation">(</span>kl<span class="token punctuation">.</span>nodeRef<span class="token punctuation">,</span> api<span class="token punctuation">.</span>EventTypeWarning<span class="token punctuation">,</span> events<span class="token punctuation">.</span>ImageGCFailed<span class="token punctuation">,</span> err<span class="token punctuation">.</span><span class="token function">Error</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            loggedImageGCFailure <span class="token operator">=</span> <span class="token boolean">true</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            <span class="token keyword">var</span> vLevel glog<span class="token punctuation">.</span>Level <span class="token operator">=</span> <span class="token number">4</span>            <span class="token keyword">if</span> loggedImageGCFailure <span class="token punctuation">{</span>                vLevel <span class="token operator">=</span> <span class="token number">1</span>                loggedImageGCFailure <span class="token operator">=</span> <span class="token boolean">false</span>            <span class="token punctuation">}</span>            glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span>vLevel<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"Image garbage collection succeeded"</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span> ImageGCPeriod<span class="token punctuation">,</span> wait<span class="token punctuation">.</span>NeverStop<span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><p>容器 GC 和镜像 GC 分别是在独立的 goroutine 中执行的，我们先来分析容器 GC 的过程。containerGC 的创建是在 <code>pkg/kubelet/kubelet.go#NewMainKublet</code> 中完成的，对应的代码有：</p><pre class=" language-go"><code class="language-go">containerGCPolicy <span class="token operator">:=</span> kubecontainer<span class="token punctuation">.</span>ContainerGCPolicy<span class="token punctuation">{</span>    MinAge<span class="token punctuation">:</span>             kubeCfg<span class="token punctuation">.</span>MinimumGCAge<span class="token punctuation">.</span>Duration<span class="token punctuation">,</span>    MaxPerPodContainer<span class="token punctuation">:</span> <span class="token function">int</span><span class="token punctuation">(</span>kubeCfg<span class="token punctuation">.</span>MaxPerPodContainerCount<span class="token punctuation">)</span><span class="token punctuation">,</span>    MaxContainers<span class="token punctuation">:</span>      <span class="token function">int</span><span class="token punctuation">(</span>kubeCfg<span class="token punctuation">.</span>MaxContainerCount<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">}</span>containerGC<span class="token punctuation">,</span> err <span class="token operator">:=</span> kubecontainer<span class="token punctuation">.</span><span class="token function">NewContainerGC</span><span class="token punctuation">(</span>klet<span class="token punctuation">.</span>containerRuntime<span class="token punctuation">,</span> containerGCPolicy<span class="token punctuation">)</span><span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>    <span class="token keyword">return</span> <span class="token boolean">nil</span><span class="token punctuation">,</span> err<span class="token punctuation">}</span>klet<span class="token punctuation">.</span>containerGC <span class="token operator">=</span> containerGCklet<span class="token punctuation">.</span>containerDeletor <span class="token operator">=</span> <span class="token function">newPodContainerDeletor</span><span class="token punctuation">(</span>klet<span class="token punctuation">.</span>containerRuntime<span class="token punctuation">,</span> integer<span class="token punctuation">.</span><span class="token function">IntMax</span><span class="token punctuation">(</span>containerGCPolicy<span class="token punctuation">.</span>MaxPerPodContainer<span class="token punctuation">,</span> minDeadContainerInPod<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><p><code>containerGCPolicy</code> 对应了我们上面提到的容器 GC 的策略，具体的初始化和实现的代码在 <code>pkg/kubelet/container/container_gc.go</code> 文件中：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">type</span> ContainerGCPolicy <span class="token keyword">struct</span> <span class="token punctuation">{</span>    MinAge time<span class="token punctuation">.</span>Duration    MaxPerPodContainer <span class="token builtin">int</span>    MaxContainers <span class="token builtin">int</span><span class="token punctuation">}</span><span class="token keyword">type</span> ContainerGC <span class="token keyword">interface</span> <span class="token punctuation">{</span>    <span class="token function">GarbageCollect</span><span class="token punctuation">(</span>allSourcesReady <span class="token builtin">bool</span><span class="token punctuation">)</span> <span class="token builtin">error</span><span class="token punctuation">}</span><span class="token keyword">type</span> realContainerGC <span class="token keyword">struct</span> <span class="token punctuation">{</span>    runtime Runtime    policy ContainerGCPolicy<span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token function">NewContainerGC</span><span class="token punctuation">(</span>runtime Runtime<span class="token punctuation">,</span> policy ContainerGCPolicy<span class="token punctuation">)</span> <span class="token punctuation">(</span>ContainerGC<span class="token punctuation">,</span> <span class="token builtin">error</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> policy<span class="token punctuation">.</span>MinAge <span class="token operator">&lt;</span> <span class="token number">0</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token boolean">nil</span><span class="token punctuation">,</span> fmt<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"invalid minimum garbage collection age: %v"</span><span class="token punctuation">,</span> policy<span class="token punctuation">.</span>MinAge<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> <span class="token operator">&amp;</span>realContainerGC<span class="token punctuation">{</span>        runtime<span class="token punctuation">:</span> runtime<span class="token punctuation">,</span>        policy<span class="token punctuation">:</span>  policy<span class="token punctuation">,</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token boolean">nil</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>cgc <span class="token operator">*</span>realContainerGC<span class="token punctuation">)</span> <span class="token function">GarbageCollect</span><span class="token punctuation">(</span>allSourcesReady <span class="token builtin">bool</span><span class="token punctuation">)</span> <span class="token builtin">error</span> <span class="token punctuation">{</span>    <span class="token keyword">return</span> cgc<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span><span class="token function">GarbageCollect</span><span class="token punctuation">(</span>cgc<span class="token punctuation">.</span>policy<span class="token punctuation">,</span> allSourcesReady<span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><p>这里的代码只是一层封装，最终会调用 <code>runtime.GarbageCollect</code>，对于 docker 来说，对应的代码是 <code>pkg/kubelet/dockertools/docker_manager.go</code>：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>dm <span class="token operator">*</span>DockerManager<span class="token punctuation">)</span> <span class="token function">GarbageCollect</span><span class="token punctuation">(</span>gcPolicy kubecontainer<span class="token punctuation">.</span>ContainerGCPolicy<span class="token punctuation">,</span> allSourcesReady <span class="token builtin">bool</span><span class="token punctuation">)</span> <span class="token builtin">error</span> <span class="token punctuation">{</span>    <span class="token keyword">return</span> dm<span class="token punctuation">.</span>containerGC<span class="token punctuation">.</span><span class="token function">GarbageCollect</span><span class="token punctuation">(</span>gcPolicy<span class="token punctuation">,</span> allSourcesReady<span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><p>内容又被包装到 <code>dm.containerGC</code>，我们找到创建 dockerManager 的代码，看一下 <code>containerGC</code> 初始化部分：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">NewDockerManager</span><span class="token punctuation">(</span><span class="token operator">...</span><span class="token punctuation">)</span><span class="token punctuation">{</span>    <span class="token operator">...</span>    dm<span class="token punctuation">.</span>containerGC <span class="token operator">=</span> <span class="token function">NewContainerGC</span><span class="token punctuation">(</span>client<span class="token punctuation">,</span> podGetter<span class="token punctuation">,</span> containerLogsDir<span class="token punctuation">)</span>    <span class="token operator">...</span><span class="token punctuation">}</span></code></pre><p>这才是具体的 docker container GC 的实现， 对应的代码在 <code>pkg/kubelet/dockertools/container_gc.go#NewContainerGC</code>：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">type</span> containerGC <span class="token keyword">struct</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// client 用来和 docker API 交互，比如获取容器列表、查看某个容器的详细信息等</span>    client           DockerInterface    podGetter        podGetter    containerLogsDir <span class="token builtin">string</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token function">NewContainerGC</span><span class="token punctuation">(</span>client DockerInterface<span class="token punctuation">,</span> podGetter podGetter<span class="token punctuation">,</span> containerLogsDir <span class="token builtin">string</span><span class="token punctuation">)</span> <span class="token operator">*</span>containerGC <span class="token punctuation">{</span>    <span class="token keyword">return</span> <span class="token operator">&amp;</span>containerGC<span class="token punctuation">{</span>        client<span class="token punctuation">:</span>           client<span class="token punctuation">,</span>        podGetter<span class="token punctuation">:</span>        podGetter<span class="token punctuation">,</span>        containerLogsDir<span class="token punctuation">:</span> containerLogsDir<span class="token punctuation">,</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>cgc <span class="token operator">*</span>containerGC<span class="token punctuation">)</span> <span class="token function">GarbageCollect</span><span class="token punctuation">(</span>gcPolicy kubecontainer<span class="token punctuation">.</span>ContainerGCPolicy<span class="token punctuation">,</span> allSourcesReady <span class="token builtin">bool</span><span class="token punctuation">)</span> <span class="token builtin">error</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 找到可以清理的容器列表，条件是不在运行并且创建时间超过 MinAge。</span>    <span class="token comment" spellcheck="true">// 这个步骤会过滤掉不是 kubelet 管理的容器，并且把容器按照创建时间进行排序（也就是说最早创建的容器会先被删除）</span>    <span class="token comment" spellcheck="true">// evictUnits 返回的是需要被正确回收的，第二个参数是 kubelet 无法识别的容器</span>    evictUnits<span class="token punctuation">,</span> unidentifiedContainers<span class="token punctuation">,</span> err <span class="token operator">:=</span> cgc<span class="token punctuation">.</span><span class="token function">evictableContainers</span><span class="token punctuation">(</span>gcPolicy<span class="token punctuation">.</span>MinAge<span class="token punctuation">)</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token comment" spellcheck="true">// 删除无法识别的容器</span>    <span class="token keyword">for</span> <span class="token boolean">_</span><span class="token punctuation">,</span> container <span class="token operator">:=</span> <span class="token keyword">range</span> unidentifiedContainers <span class="token punctuation">{</span>        glog<span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"Removing unidentified dead container %q with ID %q"</span><span class="token punctuation">,</span> container<span class="token punctuation">.</span>name<span class="token punctuation">,</span> container<span class="token punctuation">.</span>id<span class="token punctuation">)</span>        err <span class="token operator">=</span> cgc<span class="token punctuation">.</span>client<span class="token punctuation">.</span><span class="token function">RemoveContainer</span><span class="token punctuation">(</span>container<span class="token punctuation">.</span>id<span class="token punctuation">,</span> dockertypes<span class="token punctuation">.</span>ContainerRemoveOptions<span class="token punctuation">{</span>RemoveVolumes<span class="token punctuation">:</span> <span class="token boolean">true</span><span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            glog<span class="token punctuation">.</span><span class="token function">Warningf</span><span class="token punctuation">(</span><span class="token string">"Failed to remove unidentified dead container %q: %v"</span><span class="token punctuation">,</span> container<span class="token punctuation">.</span>name<span class="token punctuation">,</span> err<span class="token punctuation">)</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 如果 pod 已经不存在了，就删除其中所有的容器</span>    <span class="token keyword">if</span> allSourcesReady <span class="token punctuation">{</span>        <span class="token keyword">for</span> key<span class="token punctuation">,</span> unit <span class="token operator">:=</span> <span class="token keyword">range</span> evictUnits <span class="token punctuation">{</span>            <span class="token keyword">if</span> cgc<span class="token punctuation">.</span><span class="token function">isPodDeleted</span><span class="token punctuation">(</span>key<span class="token punctuation">.</span>uid<span class="token punctuation">)</span> <span class="token punctuation">{</span>                cgc<span class="token punctuation">.</span><span class="token function">removeOldestN</span><span class="token punctuation">(</span>unit<span class="token punctuation">,</span> <span class="token function">len</span><span class="token punctuation">(</span>unit<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">// Remove all.</span>                <span class="token function">delete</span><span class="token punctuation">(</span>evictUnits<span class="token punctuation">,</span> key<span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 执行 GC 策略，保证每个 POD 最多只能保存 MaxPerPodContainer 个已经退出的容器</span>    <span class="token keyword">if</span> gcPolicy<span class="token punctuation">.</span>MaxPerPodContainer <span class="token operator">>=</span> <span class="token number">0</span> <span class="token punctuation">{</span>        cgc<span class="token punctuation">.</span><span class="token function">enforceMaxContainersPerEvictUnit</span><span class="token punctuation">(</span>evictUnits<span class="token punctuation">,</span> gcPolicy<span class="token punctuation">.</span>MaxPerPodContainer<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 执行 GC 策略，保证节点上最多有 MaxContainers 个已经退出的容器</span>    <span class="token comment" spellcheck="true">// 先把最大容器数量平分到 pod，保证每个 pod 在平均数量以下；如果还不满足要求的数量，就按照时间顺序先删除最旧的容器</span>    <span class="token keyword">if</span> gcPolicy<span class="token punctuation">.</span>MaxContainers <span class="token operator">>=</span> <span class="token number">0</span> <span class="token operator">&amp;&amp;</span> evictUnits<span class="token punctuation">.</span><span class="token function">NumContainers</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> gcPolicy<span class="token punctuation">.</span>MaxContainers <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// 先按照 pod 进行删除，每个 pod 能保留的容器数是总数的平均值</span>        numContainersPerEvictUnit <span class="token operator">:=</span> gcPolicy<span class="token punctuation">.</span>MaxContainers <span class="token operator">/</span> evictUnits<span class="token punctuation">.</span><span class="token function">NumEvictUnits</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> numContainersPerEvictUnit <span class="token operator">&lt;</span> <span class="token number">1</span> <span class="token punctuation">{</span>            numContainersPerEvictUnit <span class="token operator">=</span> <span class="token number">1</span>        <span class="token punctuation">}</span>        cgc<span class="token punctuation">.</span><span class="token function">enforceMaxContainersPerEvictUnit</span><span class="token punctuation">(</span>evictUnits<span class="token punctuation">,</span> numContainersPerEvictUnit<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// 如果还不满足数量要求，按照容器进行删除，先删除最老的</span>        numContainers <span class="token operator">:=</span> evictUnits<span class="token punctuation">.</span><span class="token function">NumContainers</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> numContainers <span class="token operator">></span> gcPolicy<span class="token punctuation">.</span>MaxContainers <span class="token punctuation">{</span>            flattened <span class="token operator">:=</span> <span class="token function">make</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span>containerGCInfo<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> numContainers<span class="token punctuation">)</span>            <span class="token keyword">for</span> uid <span class="token operator">:=</span> <span class="token keyword">range</span> evictUnits <span class="token punctuation">{</span>                flattened <span class="token operator">=</span> <span class="token function">append</span><span class="token punctuation">(</span>flattened<span class="token punctuation">,</span> evictUnits<span class="token punctuation">[</span>uid<span class="token punctuation">]</span><span class="token operator">...</span><span class="token punctuation">)</span>            <span class="token punctuation">}</span>            sort<span class="token punctuation">.</span><span class="token function">Sort</span><span class="token punctuation">(</span><span class="token function">byCreated</span><span class="token punctuation">(</span>flattened<span class="token punctuation">)</span><span class="token punctuation">)</span>            cgc<span class="token punctuation">.</span><span class="token function">removeOldestN</span><span class="token punctuation">(</span>flattened<span class="token punctuation">,</span> numContainers<span class="token operator">-</span>gcPolicy<span class="token punctuation">.</span>MaxContainers<span class="token punctuation">)</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token keyword">return</span> <span class="token boolean">nil</span><span class="token punctuation">}</span></code></pre><p>这段代码才是容器 GC 的核心逻辑，它做的事情是这样的：</p><ul><li>先从正在运行的容器中找到可以被清理的，包括符合清理条件或者不被 kubelet 识别的容器</li><li>直接删除不能识别的容器，以及 pod 信息已经不存在的容器</li><li>根据配置的容器删除策略，对剩下的容器进行删除</li></ul><h2 id="镜像-GC-的代码"><a href="#镜像-GC-的代码" class="headerlink" title="镜像 GC 的代码"></a>镜像 GC 的代码</h2><p>看过了容器 GC 的代码逻辑，我们再来看看镜像 GC 的逻辑。因为两者非常类似，这里略过参数的引用、对象的初始化和调用链分析，直接分析最核心的逻辑代码，这部分内容在 <code>pkg/kubelet/images/image_gc_manager.go</code> 文件中：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">type</span> ImageGCManager <span class="token keyword">interface</span> <span class="token punctuation">{</span>    <span class="token function">GarbageCollect</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token builtin">error</span>    <span class="token comment" spellcheck="true">// Start async garbage collection of images.</span>    <span class="token function">Start</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token builtin">error</span>    <span class="token function">GetImageList</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span>kubecontainer<span class="token punctuation">.</span>Image<span class="token punctuation">,</span> <span class="token builtin">error</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// Delete all unused images and returns the number of bytes freed. The number of bytes freed is always returned.</span>    <span class="token function">DeleteUnusedImages</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token builtin">int64</span><span class="token punctuation">,</span> <span class="token builtin">error</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token comment" spellcheck="true">// 镜像 GC 策略</span><span class="token keyword">type</span> ImageGCPolicy <span class="token keyword">struct</span> <span class="token punctuation">{</span>    HighThresholdPercent <span class="token builtin">int</span>    LowThresholdPercent <span class="token builtin">int</span>    MinAge time<span class="token punctuation">.</span>Duration<span class="token punctuation">}</span><span class="token keyword">type</span> realImageGCManager <span class="token keyword">struct</span> <span class="token punctuation">{</span>    runtime container<span class="token punctuation">.</span>Runtime    <span class="token comment" spellcheck="true">// 记录了当前使用的镜像</span>    imageRecords     <span class="token keyword">map</span><span class="token punctuation">[</span><span class="token builtin">string</span><span class="token punctuation">]</span><span class="token operator">*</span>imageRecord    imageRecordsLock sync<span class="token punctuation">.</span>Mutex    policy ImageGCPolicy    cadvisor cadvisor<span class="token punctuation">.</span>Interface    recorder record<span class="token punctuation">.</span>EventRecorder    nodeRef <span class="token operator">*</span>api<span class="token punctuation">.</span>ObjectReference    initialized <span class="token builtin">bool</span>    <span class="token comment" spellcheck="true">// imageCache is the cache of latest image list.</span>    imageCache imageCache<span class="token punctuation">}</span><span class="token keyword">type</span> imageRecord <span class="token keyword">struct</span> <span class="token punctuation">{</span>    firstDetected time<span class="token punctuation">.</span>Time    lastUsed time<span class="token punctuation">.</span>Time    <span class="token comment" spellcheck="true">// Size of the image in bytes.</span>    size <span class="token builtin">int64</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>im <span class="token operator">*</span>realImageGCManager<span class="token punctuation">)</span> <span class="token function">Start</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token builtin">error</span> <span class="token punctuation">{</span>    <span class="token keyword">go</span> wait<span class="token punctuation">.</span><span class="token function">Until</span><span class="token punctuation">(</span><span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// Initial detection make detected time "unknown" in the past.</span>        <span class="token keyword">var</span> ts time<span class="token punctuation">.</span>Time        <span class="token keyword">if</span> im<span class="token punctuation">.</span>initialized <span class="token punctuation">{</span>            ts <span class="token operator">=</span> time<span class="token punctuation">.</span><span class="token function">Now</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span>        err <span class="token operator">:=</span> im<span class="token punctuation">.</span><span class="token function">detectImages</span><span class="token punctuation">(</span>ts<span class="token punctuation">)</span>        <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            glog<span class="token punctuation">.</span><span class="token function">Warningf</span><span class="token punctuation">(</span><span class="token string">"[imageGCManager] Failed to monitor images: %v"</span><span class="token punctuation">,</span> err<span class="token punctuation">)</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            im<span class="token punctuation">.</span>initialized <span class="token operator">=</span> <span class="token boolean">true</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token operator">*</span>time<span class="token punctuation">.</span>Minute<span class="token punctuation">,</span> wait<span class="token punctuation">.</span>NeverStop<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// Start a goroutine periodically updates image cache.</span>    <span class="token keyword">go</span> wait<span class="token punctuation">.</span><span class="token function">Until</span><span class="token punctuation">(</span><span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        images<span class="token punctuation">,</span> err <span class="token operator">:=</span> im<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span><span class="token function">ListImages</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            glog<span class="token punctuation">.</span><span class="token function">Warningf</span><span class="token punctuation">(</span><span class="token string">"[imageGCManager] Failed to update image list: %v"</span><span class="token punctuation">,</span> err<span class="token punctuation">)</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            im<span class="token punctuation">.</span>imageCache<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>images<span class="token punctuation">)</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token operator">*</span>time<span class="token punctuation">.</span>Second<span class="token punctuation">,</span> wait<span class="token punctuation">.</span>NeverStop<span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token boolean">nil</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>im <span class="token operator">*</span>realImageGCManager<span class="token punctuation">)</span> <span class="token function">GarbageCollect</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token builtin">error</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 从 cadvisor 中获取镜像所在文件系统的信息，包括磁盘的容量和当前的使用量</span>    fsInfo<span class="token punctuation">,</span> err <span class="token operator">:=</span> im<span class="token punctuation">.</span>cadvisor<span class="token punctuation">.</span><span class="token function">ImagesFsInfo</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> err    <span class="token punctuation">}</span>    capacity <span class="token operator">:=</span> <span class="token function">int64</span><span class="token punctuation">(</span>fsInfo<span class="token punctuation">.</span>Capacity<span class="token punctuation">)</span>    available <span class="token operator">:=</span> <span class="token function">int64</span><span class="token punctuation">(</span>fsInfo<span class="token punctuation">.</span>Available<span class="token punctuation">)</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token comment" spellcheck="true">// 如果镜像的磁盘使用率达到了设定的最高阈值，就进行清理工作，直到使用率</span>    usagePercent <span class="token operator">:=</span> <span class="token number">100</span> <span class="token operator">-</span> <span class="token function">int</span><span class="token punctuation">(</span>available<span class="token operator">*</span><span class="token number">100</span><span class="token operator">/</span>capacity<span class="token punctuation">)</span>    <span class="token keyword">if</span> usagePercent <span class="token operator">>=</span> im<span class="token punctuation">.</span>policy<span class="token punctuation">.</span>HighThresholdPercent <span class="token punctuation">{</span>        amountToFree <span class="token operator">:=</span> capacity<span class="token operator">*</span><span class="token function">int64</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token operator">-</span>im<span class="token punctuation">.</span>policy<span class="token punctuation">.</span>LowThresholdPercent<span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">100</span> <span class="token operator">-</span> available        glog<span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"[imageGCManager]: Disk usage on %q (%s) is at %d%% which is over the high threshold (%d%%). Trying to free %d bytes"</span><span class="token punctuation">,</span> fsInfo<span class="token punctuation">.</span>Device<span class="token punctuation">,</span> fsInfo<span class="token punctuation">.</span>Mountpoint<span class="token punctuation">,</span> usagePercent<span class="token punctuation">,</span> im<span class="token punctuation">.</span>policy<span class="token punctuation">.</span>HighThresholdPercent<span class="token punctuation">,</span> amountToFree<span class="token punctuation">)</span>        freed<span class="token punctuation">,</span> err <span class="token operator">:=</span> im<span class="token punctuation">.</span><span class="token function">freeSpace</span><span class="token punctuation">(</span>amountToFree<span class="token punctuation">,</span> time<span class="token punctuation">.</span><span class="token function">Now</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> err        <span class="token punctuation">}</span>        <span class="token keyword">if</span> freed <span class="token operator">&lt;</span> amountToFree <span class="token punctuation">{</span>            err <span class="token operator">:=</span> fmt<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"failed to garbage collect required amount of images. Wanted to free %d, but freed %d"</span><span class="token punctuation">,</span> amountToFree<span class="token punctuation">,</span> freed<span class="token punctuation">)</span>            im<span class="token punctuation">.</span>recorder<span class="token punctuation">.</span><span class="token function">Eventf</span><span class="token punctuation">(</span>im<span class="token punctuation">.</span>nodeRef<span class="token punctuation">,</span> api<span class="token punctuation">.</span>EventTypeWarning<span class="token punctuation">,</span> events<span class="token punctuation">.</span>FreeDiskSpaceFailed<span class="token punctuation">,</span> err<span class="token punctuation">.</span><span class="token function">Error</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> err        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> <span class="token boolean">nil</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>im <span class="token operator">*</span>realImageGCManager<span class="token punctuation">)</span> <span class="token function">DeleteUnusedImages</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token builtin">int64</span><span class="token punctuation">,</span> <span class="token builtin">error</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">return</span> im<span class="token punctuation">.</span><span class="token function">freeSpace</span><span class="token punctuation">(</span>math<span class="token punctuation">.</span>MaxInt64<span class="token punctuation">,</span> time<span class="token punctuation">.</span><span class="token function">Now</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token punctuation">(</span>im <span class="token operator">*</span>realImageGCManager<span class="token punctuation">)</span> <span class="token function">freeSpace</span><span class="token punctuation">(</span>bytesToFree <span class="token builtin">int64</span><span class="token punctuation">,</span> freeTime time<span class="token punctuation">.</span>Time<span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token builtin">int64</span><span class="token punctuation">,</span> <span class="token builtin">error</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 更新镜像记录列表中的数据，添加刚发现的镜像，移除已经不存在的镜像</span>    err <span class="token operator">:=</span> im<span class="token punctuation">.</span><span class="token function">detectImages</span><span class="token punctuation">(</span>freeTime<span class="token punctuation">)</span>    <span class="token operator">...</span><span class="token operator">...</span>    im<span class="token punctuation">.</span>imageRecordsLock<span class="token punctuation">.</span><span class="token function">Lock</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">defer</span> im<span class="token punctuation">.</span>imageRecordsLock<span class="token punctuation">.</span><span class="token function">Unlock</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 根据镜像的最近使用时间和最近发现时间进行排序</span>    images <span class="token operator">:=</span> <span class="token function">make</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span>evictionInfo<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token function">len</span><span class="token punctuation">(</span>im<span class="token punctuation">.</span>imageRecords<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> image<span class="token punctuation">,</span> record <span class="token operator">:=</span> <span class="token keyword">range</span> im<span class="token punctuation">.</span>imageRecords <span class="token punctuation">{</span>        images <span class="token operator">=</span> <span class="token function">append</span><span class="token punctuation">(</span>images<span class="token punctuation">,</span> evictionInfo<span class="token punctuation">{</span>            id<span class="token punctuation">:</span>          image<span class="token punctuation">,</span>            imageRecord<span class="token punctuation">:</span> <span class="token operator">*</span>record<span class="token punctuation">,</span>        <span class="token punctuation">}</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    sort<span class="token punctuation">.</span><span class="token function">Sort</span><span class="token punctuation">(</span><span class="token function">byLastUsedAndDetected</span><span class="token punctuation">(</span>images<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// Delete unused images until we've freed up enough space.</span>    <span class="token keyword">var</span> deletionErrors <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">error</span>    spaceFreed <span class="token operator">:=</span> <span class="token function">int64</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> <span class="token boolean">_</span><span class="token punctuation">,</span> image <span class="token operator">:=</span> <span class="token keyword">range</span> images <span class="token punctuation">{</span>        <span class="token operator">...</span><span class="token operator">...</span>        <span class="token comment" spellcheck="true">// 略过最近使用时间距离现在小于设置的 MinAge 的镜像</span>        <span class="token keyword">if</span> freeTime<span class="token punctuation">.</span><span class="token function">Sub</span><span class="token punctuation">(</span>image<span class="token punctuation">.</span>firstDetected<span class="token punctuation">)</span> <span class="token operator">&lt;</span> im<span class="token punctuation">.</span>policy<span class="token punctuation">.</span>MinAge <span class="token punctuation">{</span>            <span class="token keyword">continue</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// 删除镜像并更新 imageRecords 对象中缓存的镜像信息，记录删除的镜像大小</span>        err <span class="token operator">:=</span> im<span class="token punctuation">.</span>runtime<span class="token punctuation">.</span><span class="token function">RemoveImage</span><span class="token punctuation">(</span>container<span class="token punctuation">.</span>ImageSpec<span class="token punctuation">{</span>Image<span class="token punctuation">:</span> image<span class="token punctuation">.</span>id<span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            deletionErrors <span class="token operator">=</span> <span class="token function">append</span><span class="token punctuation">(</span>deletionErrors<span class="token punctuation">,</span> err<span class="token punctuation">)</span>            <span class="token keyword">continue</span>        <span class="token punctuation">}</span>        <span class="token function">delete</span><span class="token punctuation">(</span>im<span class="token punctuation">.</span>imageRecords<span class="token punctuation">,</span> image<span class="token punctuation">.</span>id<span class="token punctuation">)</span>        spaceFreed <span class="token operator">+=</span> image<span class="token punctuation">.</span>size        <span class="token comment" spellcheck="true">// 如果删除的镜像大小满足需求，停止继续删除</span>        <span class="token keyword">if</span> spaceFreed <span class="token operator">>=</span> bytesToFree <span class="token punctuation">{</span>            <span class="token keyword">break</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token keyword">if</span> <span class="token function">len</span><span class="token punctuation">(</span>deletionErrors<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> spaceFreed<span class="token punctuation">,</span> fmt<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"wanted to free %d, but freed %d space with errors in image deletion: %v"</span><span class="token punctuation">,</span> bytesToFree<span class="token punctuation">,</span> spaceFreed<span class="token punctuation">,</span> errors<span class="token punctuation">.</span><span class="token function">NewAggregate</span><span class="token punctuation">(</span>deletionErrors<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> spaceFreed<span class="token punctuation">,</span> <span class="token boolean">nil</span><span class="token punctuation">}</span></code></pre><p><code>realImageGCManager</code> 缓存了当前节点使用的镜像信息，并在 <code>Start()</code> 方法中启动两个 goroutine 周期性地去更新缓存的内容。<code>GarbageCollect</code> 的逻辑是这样的：</p><ul><li>调用 cAdvisor 接口获取镜像所在磁盘的文件系统信息，根据当前的使用量和配置的 GC 策略确定是否需要进行清理</li><li>如果需要清理，计算需要清理的总大小，调用 <code>freeSpace</code> 进行镜像清理工作</li><li>把所有可以清理的镜像根据使用时间进行排序，进行逐个清理，知道清理的镜像总大小满足需求才停止</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>容器和镜像 GC 的内容相对比较独立，而且逻辑也不是很复杂，源代码也很容易理解。但这部分内容却非常重要，影响到节点的正常工作状况，最后总结几点需要注意的地方：</p><ul><li>默认情况下，container GC 是每分钟进行一次，image GC 是每五分钟一次，如果有不同的需要，可以通过 kubelet 的启动参数进行修改</li><li>不要手动清理镜像和容器，因为 kubelet 运行的时候会保存当前节点上镜像和容器的缓存，并定时更新。手动清理镜像和容器会让 kubelet 做出误判，带来不确定的问题</li><li>不是 kubelet 管理的容器不在 GC 的范围内，也就是说用户手动通过 docker 创建的容器不会被 kubelet 删除</li></ul><p><strong>NOTE</strong>：GC 机制后面会被 eviction 机制替代，可以在官方文档查看 <a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/kubelet-eviction.md" target="_blank" rel="noopener"> eviction 的设计</a>。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://kubernetes.io/docs/concepts/cluster-administration/kubelet-garbage-collection/" target="_blank" rel="noopener">Configuring kubelet Garbage Collection</a></li><li><a href="https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/" target="_blank" rel="noopener">Configuring Out Of Resource Handling</a></li><li><a href="https://blog.kublr.com/learn-how-kubelet-eviction-policies-impact-cluster-rebalancing-2e976ebc53ea" target="_blank" rel="noopener">Learn how kubelet eviction policies impact cluster rebalancing</a></li><li><a href="https://kubernetes.cn/topics/48" target="_blank" rel="noopener">谈 Kubernetes 如何控制 Node 的资源使用</a></li><li><a href="http://www.cnblogs.com/openxxs/p/5275051.html" target="_blank" rel="noopener">Kubernetes中的垃圾回收机制</a></li><li><a href="http://dockone.io/article/2134" target="_blank" rel="noopener">Kubelet源码分析（三）：Garbage Collection</a></li><li><a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/kubelet-eviction.md" target="_blank" rel="noopener">Kubelet - Eviction Policy Proposals Doc</a></li><li><a href="https://github.com/kubernetes/kubernetes/issues/31362" target="_blank" rel="noopener">Kubelet evictions - whats remaining?</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;kubernetes-GC-简介&quot;&gt;&lt;a href=&quot;#kubernetes-GC-简介&quot; class=&quot;headerlink&quot; title=&quot;kubernetes GC 简介&quot;&gt;&lt;/a&gt;kubernetes GC 简介&lt;/h2&gt;&lt;p&gt;作为 kubernetes
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="kubernetes" scheme="http://cizixs.com/tags/kubernetes/"/>
    
      <category term="container" scheme="http://cizixs.com/tags/container/"/>
    
      <category term="golang" scheme="http://cizixs.com/tags/golang/"/>
    
      <category term="kubelet" scheme="http://cizixs.com/tags/kubelet/"/>
    
  </entry>
  
  <entry>
    <title>kubelet 源码分析：pod 新建流程</title>
    <link href="http://cizixs.com/2017/06/07/kubelet-source-code-analysis-part-2/"/>
    <id>http://cizixs.com/2017/06/07/kubelet-source-code-analysis-part-2/</id>
    <published>2017-06-06T16:00:00.000Z</published>
    <updated>2018-09-17T13:18:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>在<a href="http://cizixs.com/2017/06/06/kubelet-source-code-analysis-part-1">上一篇文章</a>中，我们分析了 kubelet 是怎么从命令行进行解析参数、怎么根据配置初始化各种对象、以及最终怎么创建出来 <code>Kubelet</code>并运行的。这篇文章我们就接着分析，当有新的 pod 分配到该节点的时候，kubelet 是怎么处理的。</p><h2 id="syncLoop"><a href="#syncLoop" class="headerlink" title="syncLoop"></a>syncLoop</h2><p><code>syncLoop</code> 是 kubelet 的主循环方法，它从不同的管道（文件、URL 和 apiserver）监听变化，并把它们汇聚起来。当有新的变化发生时，它会调用对应的处理函数，保证 pod 处于期望的状态。如果 pod 没有变化，它也会定期保证所有的容器和最新的期望状态保持一致。这个方法是 for 循环，不会退出。</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>kl <span class="token operator">*</span>Kubelet<span class="token punctuation">)</span> <span class="token function">syncLoop</span><span class="token punctuation">(</span>updates <span class="token operator">&lt;-</span><span class="token keyword">chan</span> kubetypes<span class="token punctuation">.</span>PodUpdate<span class="token punctuation">,</span> handler SyncHandler<span class="token punctuation">)</span> <span class="token punctuation">{</span>    glog<span class="token punctuation">.</span><span class="token function">Info</span><span class="token punctuation">(</span><span class="token string">"Starting kubelet main sync loop."</span><span class="token punctuation">)</span>    syncTicker <span class="token operator">:=</span> time<span class="token punctuation">.</span><span class="token function">NewTicker</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span>Second<span class="token punctuation">)</span>    <span class="token keyword">defer</span> syncTicker<span class="token punctuation">.</span><span class="token function">Stop</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    housekeepingTicker <span class="token operator">:=</span> time<span class="token punctuation">.</span><span class="token function">NewTicker</span><span class="token punctuation">(</span>housekeepingPeriod<span class="token punctuation">)</span>    <span class="token keyword">defer</span> housekeepingTicker<span class="token punctuation">.</span><span class="token function">Stop</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    plegCh <span class="token operator">:=</span> kl<span class="token punctuation">.</span>pleg<span class="token punctuation">.</span><span class="token function">Watch</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> rs <span class="token operator">:=</span> kl<span class="token punctuation">.</span>runtimeState<span class="token punctuation">.</span><span class="token function">runtimeErrors</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">len</span><span class="token punctuation">(</span>rs<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">0</span> <span class="token punctuation">{</span>            glog<span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"skipping pod synchronization - %v"</span><span class="token punctuation">,</span> rs<span class="token punctuation">)</span>            time<span class="token punctuation">.</span><span class="token function">Sleep</span><span class="token punctuation">(</span><span class="token number">5</span> <span class="token operator">*</span> time<span class="token punctuation">.</span>Second<span class="token punctuation">)</span>            <span class="token keyword">continue</span>        <span class="token punctuation">}</span>        <span class="token keyword">if</span> <span class="token operator">!</span>kl<span class="token punctuation">.</span><span class="token function">syncLoopIteration</span><span class="token punctuation">(</span>updates<span class="token punctuation">,</span> handler<span class="token punctuation">,</span> syncTicker<span class="token punctuation">.</span>C<span class="token punctuation">,</span> housekeepingTicker<span class="token punctuation">.</span>C<span class="token punctuation">,</span> plegCh<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">break</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>这里的代码主逻辑是 <code>for</code> 循环，不断调用 <code>syncLoopIteration</code> 方法。在此之前创建了两个定时器： <code>syncTicker</code> 和 <code>housekeepingTicker</code>，即使没有需要更新的 pod 配置，kubelet 也会定时去做同步和清理工作。如果在每次循环过程中出现比较严重的错误，kubelet 会记录到 <code>runtimeState</code> 中，遇到错误就等待 5 秒中继续循环。注意第二个参数变成了 <code>SyncHandler</code> 类型，这是一个 interface，定义了处理不同情况的接口，我们在在后面会看到它的具体方法。</p><p>我们继续看 <code>syncLoopIteration</code>，这个方法就是对多个管道做遍历，发现任何一个管道有消息就交给 handler 去处理。</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>kl <span class="token operator">*</span>Kubelet<span class="token punctuation">)</span> <span class="token function">syncLoopIteration</span><span class="token punctuation">(</span>configCh <span class="token operator">&lt;-</span><span class="token keyword">chan</span> kubetypes<span class="token punctuation">.</span>PodUpdate<span class="token punctuation">,</span> handler SyncHandler<span class="token punctuation">,</span>    syncCh <span class="token operator">&lt;-</span><span class="token keyword">chan</span> time<span class="token punctuation">.</span>Time<span class="token punctuation">,</span> housekeepingCh <span class="token operator">&lt;-</span><span class="token keyword">chan</span> time<span class="token punctuation">.</span>Time<span class="token punctuation">,</span> plegCh <span class="token operator">&lt;-</span><span class="token keyword">chan</span> <span class="token operator">*</span>pleg<span class="token punctuation">.</span>PodLifecycleEvent<span class="token punctuation">)</span> <span class="token builtin">bool</span> <span class="token punctuation">{</span>    kl<span class="token punctuation">.</span>syncLoopMonitor<span class="token punctuation">.</span><span class="token function">Store</span><span class="token punctuation">(</span>kl<span class="token punctuation">.</span>clock<span class="token punctuation">.</span><span class="token function">Now</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">select</span> <span class="token punctuation">{</span>    <span class="token keyword">case</span> u<span class="token punctuation">,</span> open <span class="token operator">:=</span> <span class="token operator">&lt;-</span>configCh<span class="token punctuation">:</span>        <span class="token keyword">switch</span> u<span class="token punctuation">.</span>Op <span class="token punctuation">{</span>        <span class="token keyword">case</span> kubetypes<span class="token punctuation">.</span>ADD<span class="token punctuation">:</span>            glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"SyncLoop (ADD, %q): %q"</span><span class="token punctuation">,</span> u<span class="token punctuation">.</span>Source<span class="token punctuation">,</span> format<span class="token punctuation">.</span><span class="token function">Pods</span><span class="token punctuation">(</span>u<span class="token punctuation">.</span>Pods<span class="token punctuation">)</span><span class="token punctuation">)</span>            handler<span class="token punctuation">.</span><span class="token function">HandlePodAdditions</span><span class="token punctuation">(</span>u<span class="token punctuation">.</span>Pods<span class="token punctuation">)</span>        <span class="token keyword">case</span> kubetypes<span class="token punctuation">.</span>UPDATE<span class="token punctuation">:</span>            glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"SyncLoop (UPDATE, %q): %q"</span><span class="token punctuation">,</span> u<span class="token punctuation">.</span>Source<span class="token punctuation">,</span> format<span class="token punctuation">.</span><span class="token function">PodsWithDeletiontimestamps</span><span class="token punctuation">(</span>u<span class="token punctuation">.</span>Pods<span class="token punctuation">)</span><span class="token punctuation">)</span>            handler<span class="token punctuation">.</span><span class="token function">HandlePodUpdates</span><span class="token punctuation">(</span>u<span class="token punctuation">.</span>Pods<span class="token punctuation">)</span>        <span class="token keyword">case</span> kubetypes<span class="token punctuation">.</span>REMOVE<span class="token punctuation">:</span>            glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"SyncLoop (REMOVE, %q): %q"</span><span class="token punctuation">,</span> u<span class="token punctuation">.</span>Source<span class="token punctuation">,</span> format<span class="token punctuation">.</span><span class="token function">Pods</span><span class="token punctuation">(</span>u<span class="token punctuation">.</span>Pods<span class="token punctuation">)</span><span class="token punctuation">)</span>            handler<span class="token punctuation">.</span><span class="token function">HandlePodRemoves</span><span class="token punctuation">(</span>u<span class="token punctuation">.</span>Pods<span class="token punctuation">)</span>        <span class="token keyword">case</span> kubetypes<span class="token punctuation">.</span>RECONCILE<span class="token punctuation">:</span>            glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"SyncLoop (RECONCILE, %q): %q"</span><span class="token punctuation">,</span> u<span class="token punctuation">.</span>Source<span class="token punctuation">,</span> format<span class="token punctuation">.</span><span class="token function">Pods</span><span class="token punctuation">(</span>u<span class="token punctuation">.</span>Pods<span class="token punctuation">)</span><span class="token punctuation">)</span>            handler<span class="token punctuation">.</span><span class="token function">HandlePodReconcile</span><span class="token punctuation">(</span>u<span class="token punctuation">.</span>Pods<span class="token punctuation">)</span>        <span class="token keyword">case</span> kubetypes<span class="token punctuation">.</span>DELETE<span class="token punctuation">:</span>            glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"SyncLoop (DELETE, %q): %q"</span><span class="token punctuation">,</span> u<span class="token punctuation">.</span>Source<span class="token punctuation">,</span> format<span class="token punctuation">.</span><span class="token function">Pods</span><span class="token punctuation">(</span>u<span class="token punctuation">.</span>Pods<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true">// DELETE is treated as a UPDATE because of graceful deletion.</span>            handler<span class="token punctuation">.</span><span class="token function">HandlePodUpdates</span><span class="token punctuation">(</span>u<span class="token punctuation">.</span>Pods<span class="token punctuation">)</span>        <span class="token keyword">case</span> kubetypes<span class="token punctuation">.</span>SET<span class="token punctuation">:</span>            <span class="token comment" spellcheck="true">// TODO: Do we want to support this?</span>            glog<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"Kubelet does not support snapshot update"</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// 收到消息之后就把对应的来源标记为 ready 状态</span>        kl<span class="token punctuation">.</span>sourcesReady<span class="token punctuation">.</span><span class="token function">AddSource</span><span class="token punctuation">(</span>u<span class="token punctuation">.</span>Source<span class="token punctuation">)</span>    <span class="token keyword">case</span> e <span class="token operator">:=</span> <span class="token operator">&lt;-</span>plegCh<span class="token punctuation">:</span>        <span class="token keyword">if</span> <span class="token function">isSyncPodWorthy</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// PLEG event for a pod; sync it.</span>            <span class="token keyword">if</span> pod<span class="token punctuation">,</span> ok <span class="token operator">:=</span> kl<span class="token punctuation">.</span>podManager<span class="token punctuation">.</span><span class="token function">GetPodByUID</span><span class="token punctuation">(</span>e<span class="token punctuation">.</span>ID<span class="token punctuation">)</span><span class="token punctuation">;</span> ok <span class="token punctuation">{</span>                glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"SyncLoop (PLEG): %q, event: %#v"</span><span class="token punctuation">,</span> format<span class="token punctuation">.</span><span class="token function">Pod</span><span class="token punctuation">(</span>pod<span class="token punctuation">)</span><span class="token punctuation">,</span> e<span class="token punctuation">)</span>                handler<span class="token punctuation">.</span><span class="token function">HandlePodSyncs</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token operator">*</span>api<span class="token punctuation">.</span>Pod<span class="token punctuation">{</span>pod<span class="token punctuation">}</span><span class="token punctuation">)</span>            <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>                glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"SyncLoop (PLEG): ignore irrelevant event: %#v"</span><span class="token punctuation">,</span> e<span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token keyword">if</span> e<span class="token punctuation">.</span>Type <span class="token operator">==</span> pleg<span class="token punctuation">.</span>ContainerDied <span class="token punctuation">{</span>            <span class="token keyword">if</span> containerID<span class="token punctuation">,</span> ok <span class="token operator">:=</span> e<span class="token punctuation">.</span>Data<span class="token punctuation">.</span><span class="token punctuation">(</span><span class="token builtin">string</span><span class="token punctuation">)</span><span class="token punctuation">;</span> ok <span class="token punctuation">{</span>                kl<span class="token punctuation">.</span><span class="token function">cleanUpContainersInPod</span><span class="token punctuation">(</span>e<span class="token punctuation">.</span>ID<span class="token punctuation">,</span> containerID<span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token keyword">case</span> <span class="token operator">&lt;-</span>syncCh<span class="token punctuation">:</span>        podsToSync <span class="token operator">:=</span> kl<span class="token punctuation">.</span><span class="token function">getPodsToSync</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token function">len</span><span class="token punctuation">(</span>podsToSync<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token punctuation">{</span>            <span class="token keyword">break</span>        <span class="token punctuation">}</span>        glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"SyncLoop (SYNC): %d pods; %s"</span><span class="token punctuation">,</span> <span class="token function">len</span><span class="token punctuation">(</span>podsToSync<span class="token punctuation">)</span><span class="token punctuation">,</span> format<span class="token punctuation">.</span><span class="token function">Pods</span><span class="token punctuation">(</span>podsToSync<span class="token punctuation">)</span><span class="token punctuation">)</span>        kl<span class="token punctuation">.</span><span class="token function">HandlePodSyncs</span><span class="token punctuation">(</span>podsToSync<span class="token punctuation">)</span>    <span class="token keyword">case</span> update <span class="token operator">:=</span> <span class="token operator">&lt;-</span>kl<span class="token punctuation">.</span>livenessManager<span class="token punctuation">.</span><span class="token function">Updates</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> update<span class="token punctuation">.</span>Result <span class="token operator">==</span> proberesults<span class="token punctuation">.</span>Failure <span class="token punctuation">{</span>            <span class="token comment" spellcheck="true">// The liveness manager detected a failure; sync the pod.</span>            pod<span class="token punctuation">,</span> ok <span class="token operator">:=</span> kl<span class="token punctuation">.</span>podManager<span class="token punctuation">.</span><span class="token function">GetPodByUID</span><span class="token punctuation">(</span>update<span class="token punctuation">.</span>PodUID<span class="token punctuation">)</span>            <span class="token keyword">if</span> <span class="token operator">!</span>ok <span class="token punctuation">{</span>                glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"SyncLoop (container unhealthy): ignore irrelevant update: %#v"</span><span class="token punctuation">,</span> update<span class="token punctuation">)</span>                <span class="token keyword">break</span>            <span class="token punctuation">}</span>            glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"SyncLoop (container unhealthy): %q"</span><span class="token punctuation">,</span> format<span class="token punctuation">.</span><span class="token function">Pod</span><span class="token punctuation">(</span>pod<span class="token punctuation">)</span><span class="token punctuation">)</span>            handler<span class="token punctuation">.</span><span class="token function">HandlePodSyncs</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token operator">*</span>api<span class="token punctuation">.</span>Pod<span class="token punctuation">{</span>pod<span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span>    <span class="token keyword">case</span> <span class="token operator">&lt;-</span>housekeepingCh<span class="token punctuation">:</span>        <span class="token keyword">if</span> <span class="token operator">!</span>kl<span class="token punctuation">.</span>sourcesReady<span class="token punctuation">.</span><span class="token function">AllReady</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"SyncLoop (housekeeping, skipped): sources aren't ready yet."</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>            glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"SyncLoop (housekeeping)"</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> err <span class="token operator">:=</span> handler<span class="token punctuation">.</span><span class="token function">HandlePodCleanups</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>                glog<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"Failed cleaning pods: %v"</span><span class="token punctuation">,</span> err<span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    kl<span class="token punctuation">.</span>syncLoopMonitor<span class="token punctuation">.</span><span class="token function">Store</span><span class="token punctuation">(</span>kl<span class="token punctuation">.</span>clock<span class="token punctuation">.</span><span class="token function">Now</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token boolean">true</span><span class="token punctuation">}</span></code></pre><p>可以看到，它会从以下管道中获取消息：</p><ul><li>configCh：读取配置事件的管道，就是之前讲过的通过文件、URL 和 apiserver 汇聚起来的事件</li><li>syncCh：定时器管道，每次隔一段事件去同步最新保存的 pod 状态</li><li>houseKeepingCh：housekeeping 事件的管道，做 pod 清理工作</li><li>plegCh：PLEG 状态，如果 pod 的状态发生改变（因为某些情况被杀死，被暂停等），kubelet 也要做处理</li><li>livenessManager.Updates()：健康检查发现某个 pod 不可用，一般也要对它进行重启</li></ul><p>需要注意的是， <code>switch-case</code> 语句从管道中读取数据的时候，不像一般情况下那样会从上到下按照顺序，只要任何管道中有数据，<code>switch</code> 就会选择执行对应的 <code>case</code> 语句。</p><p>每个管道的处理思路大同小异，我们只分析用户通过 apiserver 添加新 pod 的情况，也就是 <code>handler.HandlePodAdditions(u.Pods)</code> 这句话的处理逻辑。</p><h2 id="HandlePodAddtions"><a href="#HandlePodAddtions" class="headerlink" title="HandlePodAddtions"></a>HandlePodAddtions</h2><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>kl <span class="token operator">*</span>Kubelet<span class="token punctuation">)</span> <span class="token function">HandlePodAdditions</span><span class="token punctuation">(</span>pods <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token operator">*</span>api<span class="token punctuation">.</span>Pod<span class="token punctuation">)</span> <span class="token punctuation">{</span>    start <span class="token operator">:=</span> kl<span class="token punctuation">.</span>clock<span class="token punctuation">.</span><span class="token function">Now</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    sort<span class="token punctuation">.</span><span class="token function">Sort</span><span class="token punctuation">(</span>sliceutils<span class="token punctuation">.</span><span class="token function">PodsByCreationTime</span><span class="token punctuation">(</span>pods<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> <span class="token boolean">_</span><span class="token punctuation">,</span> pod <span class="token operator">:=</span> <span class="token keyword">range</span> pods <span class="token punctuation">{</span>        existingPods <span class="token operator">:=</span> kl<span class="token punctuation">.</span>podManager<span class="token punctuation">.</span><span class="token function">GetPods</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        kl<span class="token punctuation">.</span>podManager<span class="token punctuation">.</span><span class="token function">AddPod</span><span class="token punctuation">(</span>pod<span class="token punctuation">)</span>        <span class="token keyword">if</span> kubepod<span class="token punctuation">.</span><span class="token function">IsMirrorPod</span><span class="token punctuation">(</span>pod<span class="token punctuation">)</span> <span class="token punctuation">{</span>            kl<span class="token punctuation">.</span><span class="token function">handleMirrorPod</span><span class="token punctuation">(</span>pod<span class="token punctuation">,</span> start<span class="token punctuation">)</span>            <span class="token keyword">continue</span>        <span class="token punctuation">}</span>        <span class="token operator">...</span><span class="token operator">...</span>        mirrorPod<span class="token punctuation">,</span> <span class="token boolean">_</span> <span class="token operator">:=</span> kl<span class="token punctuation">.</span>podManager<span class="token punctuation">.</span><span class="token function">GetMirrorPodByPod</span><span class="token punctuation">(</span>pod<span class="token punctuation">)</span>        kl<span class="token punctuation">.</span><span class="token function">dispatchWork</span><span class="token punctuation">(</span>pod<span class="token punctuation">,</span> kubetypes<span class="token punctuation">.</span>SyncPodCreate<span class="token punctuation">,</span> mirrorPod<span class="token punctuation">,</span> start<span class="token punctuation">)</span>        kl<span class="token punctuation">.</span>probeManager<span class="token punctuation">.</span><span class="token function">AddPod</span><span class="token punctuation">(</span>pod<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>对于事件中的每个 pod，执行以下操作：</p><ul><li>把所有的 pod 按照创建日期进行排序，保证最先创建的 pod 会最先被处理</li><li>把它加入到 <code>podManager</code> 中，因为 <code>podManager</code> 是 kubelet 的 source of truth，所有被管理的 pod 都要出现在里面。如果 <code>podManager</code> 中找不到某个 pod，就认为这个 pod 被删除了</li><li>如果是 mirror pod调用其单独的方法</li><li>验证 pod 是否能在该节点运行，如果不可以直接拒绝</li><li>把 pod 分配给给 worker 做异步处理</li><li>在 <code>probeManager</code> 中添加 pod，如果 pod 中定义了 readiness 和 liveness 健康检查，启动 goroutine 定期进行检测</li></ul><p>这里可以看到 <code>podManger</code> 和 <code>probeManager</code> 发挥用处了，它们两个的具体实现都不复杂，感兴趣的读者可以自行阅读相关的代码。</p><p>pod 具体会被怎么处理呢？我们再来看 <code>dispatchWorker</code> 方法，它的作用就是根据 pod 把任务发送给特定的执行者 <code>podWorkers</code>：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>kl <span class="token operator">*</span>Kubelet<span class="token punctuation">)</span> <span class="token function">dispatchWork</span><span class="token punctuation">(</span>pod <span class="token operator">*</span>api<span class="token punctuation">.</span>Pod<span class="token punctuation">,</span> syncType kubetypes<span class="token punctuation">.</span>SyncPodType<span class="token punctuation">,</span> mirrorPod <span class="token operator">*</span>api<span class="token punctuation">.</span>Pod<span class="token punctuation">,</span> start time<span class="token punctuation">.</span>Time<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> kl<span class="token punctuation">.</span><span class="token function">podIsTerminated</span><span class="token punctuation">(</span>pod<span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token keyword">if</span> pod<span class="token punctuation">.</span>DeletionTimestamp <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            kl<span class="token punctuation">.</span>statusManager<span class="token punctuation">.</span><span class="token function">TerminatePod</span><span class="token punctuation">(</span>pod<span class="token punctuation">)</span>        <span class="token punctuation">}</span>        <span class="token keyword">return</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// Run the sync in an async worker.</span>    kl<span class="token punctuation">.</span>podWorkers<span class="token punctuation">.</span><span class="token function">UpdatePod</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>UpdatePodOptions<span class="token punctuation">{</span>        Pod<span class="token punctuation">:</span>        pod<span class="token punctuation">,</span>        MirrorPod<span class="token punctuation">:</span>  mirrorPod<span class="token punctuation">,</span>        UpdateType<span class="token punctuation">:</span> syncType<span class="token punctuation">,</span>        OnCompleteFunc<span class="token punctuation">:</span> <span class="token keyword">func</span><span class="token punctuation">(</span>err <span class="token builtin">error</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>                metrics<span class="token punctuation">.</span>PodWorkerLatency<span class="token punctuation">.</span><span class="token function">WithLabelValues</span><span class="token punctuation">(</span>syncType<span class="token punctuation">.</span><span class="token function">String</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Observe</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span><span class="token function">SinceInMicroseconds</span><span class="token punctuation">(</span>start<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">,</span>    <span class="token punctuation">}</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// Note the number of containers for new pods.</span>    <span class="token keyword">if</span> syncType <span class="token operator">==</span> kubetypes<span class="token punctuation">.</span>SyncPodCreate <span class="token punctuation">{</span>        metrics<span class="token punctuation">.</span>ContainersPerPodCount<span class="token punctuation">.</span><span class="token function">Observe</span><span class="token punctuation">(</span><span class="token function">float64</span><span class="token punctuation">(</span><span class="token function">len</span><span class="token punctuation">(</span>pod<span class="token punctuation">.</span>Spec<span class="token punctuation">.</span>Containers<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p><code>dispatchWork</code> 主要工作就是把接收到的参数封装成 <code>UpdatePodOptions</code>，调用 <code>kl.podWorkers.UpdatePod</code> 方法。<code>podWorkers</code> 的代码在 <code>pkg/kubelet/pod_workers.go</code> 文件中，它通过 <code>podUpdates</code> 字典保存了一个字典，每个 pod 的 id 作为 key，而类型为 UpdatePodOptions 的管道作为 value 传递 pod 信息。</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>p <span class="token operator">*</span>podWorkers<span class="token punctuation">)</span> <span class="token function">UpdatePod</span><span class="token punctuation">(</span>options <span class="token operator">*</span>UpdatePodOptions<span class="token punctuation">)</span> <span class="token punctuation">{</span>    pod <span class="token operator">:=</span> options<span class="token punctuation">.</span>Pod    uid <span class="token operator">:=</span> pod<span class="token punctuation">.</span>UID    <span class="token keyword">var</span> podUpdates <span class="token keyword">chan</span> UpdatePodOptions    <span class="token keyword">var</span> exists <span class="token builtin">bool</span>    p<span class="token punctuation">.</span>podLock<span class="token punctuation">.</span><span class="token function">Lock</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">defer</span> p<span class="token punctuation">.</span>podLock<span class="token punctuation">.</span><span class="token function">Unlock</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> podUpdates<span class="token punctuation">,</span> exists <span class="token operator">=</span> p<span class="token punctuation">.</span>podUpdates<span class="token punctuation">[</span>uid<span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token operator">!</span>exists <span class="token punctuation">{</span>        podUpdates <span class="token operator">=</span> <span class="token function">make</span><span class="token punctuation">(</span><span class="token keyword">chan</span> UpdatePodOptions<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        p<span class="token punctuation">.</span>podUpdates<span class="token punctuation">[</span>uid<span class="token punctuation">]</span> <span class="token operator">=</span> podUpdates        <span class="token keyword">go</span> <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            <span class="token keyword">defer</span> runtime<span class="token punctuation">.</span><span class="token function">HandleCrash</span><span class="token punctuation">(</span><span class="token punctuation">)</span>            p<span class="token punctuation">.</span><span class="token function">managePodLoop</span><span class="token punctuation">(</span>podUpdates<span class="token punctuation">)</span>        <span class="token punctuation">}</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token keyword">if</span> <span class="token operator">!</span>p<span class="token punctuation">.</span>isWorking<span class="token punctuation">[</span>pod<span class="token punctuation">.</span>UID<span class="token punctuation">]</span> <span class="token punctuation">{</span>        p<span class="token punctuation">.</span>isWorking<span class="token punctuation">[</span>pod<span class="token punctuation">.</span>UID<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">true</span>        podUpdates <span class="token operator">&lt;-</span> <span class="token operator">*</span>options    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>        update<span class="token punctuation">,</span> found <span class="token operator">:=</span> p<span class="token punctuation">.</span>lastUndeliveredWorkUpdate<span class="token punctuation">[</span>pod<span class="token punctuation">.</span>UID<span class="token punctuation">]</span>        <span class="token keyword">if</span> <span class="token operator">!</span>found <span class="token operator">||</span> update<span class="token punctuation">.</span>UpdateType <span class="token operator">!=</span> kubetypes<span class="token punctuation">.</span>SyncPodKill <span class="token punctuation">{</span>            p<span class="token punctuation">.</span>lastUndeliveredWorkUpdate<span class="token punctuation">[</span>pod<span class="token punctuation">.</span>UID<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">*</span>options        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p><code>UpdatePod</code> 会先去检查 <code>podUpdates</code> 字典是否已经存在对应的 pod，因为这里的新建的 pod，所以会调用 <code>p.managePodLoop()</code> 方法作为 goroutine 运行更新工作。也就是说对于管理的每个 pod，<code>podWorkers</code> 都会启动一个 goroutine 在后台执行，除此之外，它还会更新 <code>podUpdate</code> 和 <code>isWorking</code>，填入新 pod 的信息，并往 <code>podUpdates</code> 管道中发送接收到的 pod 选项信息。</p><p><code>managePodLoop</code> 的代码如下：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>p <span class="token operator">*</span>podWorkers<span class="token punctuation">)</span> <span class="token function">managePodLoop</span><span class="token punctuation">(</span>podUpdates <span class="token operator">&lt;-</span><span class="token keyword">chan</span> UpdatePodOptions<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token keyword">var</span> lastSyncTime time<span class="token punctuation">.</span>Time    <span class="token keyword">for</span> update <span class="token operator">:=</span> <span class="token keyword">range</span> podUpdates <span class="token punctuation">{</span>        err <span class="token operator">:=</span> <span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token builtin">error</span> <span class="token punctuation">{</span>            podUID <span class="token operator">:=</span> update<span class="token punctuation">.</span>Pod<span class="token punctuation">.</span>UID            status<span class="token punctuation">,</span> err <span class="token operator">:=</span> p<span class="token punctuation">.</span>podCache<span class="token punctuation">.</span><span class="token function">GetNewerThan</span><span class="token punctuation">(</span>podUID<span class="token punctuation">,</span> lastSyncTime<span class="token punctuation">)</span>            <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>                <span class="token keyword">return</span> err            <span class="token punctuation">}</span>            err <span class="token operator">=</span> p<span class="token punctuation">.</span><span class="token function">syncPodFn</span><span class="token punctuation">(</span>syncPodOptions<span class="token punctuation">{</span>                mirrorPod<span class="token punctuation">:</span>      update<span class="token punctuation">.</span>MirrorPod<span class="token punctuation">,</span>                pod<span class="token punctuation">:</span>            update<span class="token punctuation">.</span>Pod<span class="token punctuation">,</span>                podStatus<span class="token punctuation">:</span>      status<span class="token punctuation">,</span>                killPodOptions<span class="token punctuation">:</span> update<span class="token punctuation">.</span>KillPodOptions<span class="token punctuation">,</span>                updateType<span class="token punctuation">:</span>     update<span class="token punctuation">.</span>UpdateType<span class="token punctuation">,</span>            <span class="token punctuation">}</span><span class="token punctuation">)</span>            lastSyncTime <span class="token operator">=</span> time<span class="token punctuation">.</span><span class="token function">Now</span><span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>                <span class="token keyword">return</span> err            <span class="token punctuation">}</span>            <span class="token keyword">return</span> <span class="token boolean">nil</span>        <span class="token punctuation">}</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// notify the call-back function if the operation succeeded or not</span>        <span class="token keyword">if</span> update<span class="token punctuation">.</span>OnCompleteFunc <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            update<span class="token punctuation">.</span><span class="token function">OnCompleteFunc</span><span class="token punctuation">(</span>err<span class="token punctuation">)</span>        <span class="token punctuation">}</span>        <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            glog<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"Error syncing pod %s, skipping: %v"</span><span class="token punctuation">,</span> update<span class="token punctuation">.</span>Pod<span class="token punctuation">.</span>UID<span class="token punctuation">,</span> err<span class="token punctuation">)</span>            p<span class="token punctuation">.</span>recorder<span class="token punctuation">.</span><span class="token function">Eventf</span><span class="token punctuation">(</span>update<span class="token punctuation">.</span>Pod<span class="token punctuation">,</span> api<span class="token punctuation">.</span>EventTypeWarning<span class="token punctuation">,</span> events<span class="token punctuation">.</span>FailedSync<span class="token punctuation">,</span> <span class="token string">"Error syncing pod, skipping: %v"</span><span class="token punctuation">,</span> err<span class="token punctuation">)</span>        <span class="token punctuation">}</span>        p<span class="token punctuation">.</span><span class="token function">wrapUp</span><span class="token punctuation">(</span>update<span class="token punctuation">.</span>Pod<span class="token punctuation">.</span>UID<span class="token punctuation">,</span> err<span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p><code>managePodLoop</code> 调用 <code>syncPodFn</code> 方法去同步 pod，<code>syncPodFn</code> 实际上就是 <code>kubelet.SyncPod</code>。</p><h2 id="SyncPod"><a href="#SyncPod" class="headerlink" title="SyncPod"></a>SyncPod</h2><p><code>SyncPod</code> 的内容比较长，我们这里就不贴出它的代码了，它做的事情包括：</p><ul><li>如果是删除 pod，立即执行并返回</li><li>检查 pod 是否能运行在本节点，主要是权限检查（是否能使用主机网络模式，是否可以以 privileged 权限运行等）。如果没有权限，就删除本地旧的 pod 并返回错误信息</li><li>如果是 static Pod，就创建或者更新对应的 mirrorPod</li><li>创建 pod 的数据目录，存放 volume 和 plugin 信息</li><li>如果定义了 PV，等待所有的 volume  mount 完成（volumeManager 会在后台做这些事情）</li><li>如果有 image secrets，去 apiserver 获取对应的 secrets 数据</li><li>调用 container runtime 的 SyncPod 方法，去实现真正的容器创建逻辑</li></ul><p>这里所有的事情都和具体的容器没有关系，可以看做是提前做的准备工作。最重要的事情发生在 <code>kl.containerRuntime.SyncPod()</code> 里，也就是上面过程的最后一个步骤，它调 runtime 执行具体容器的创建，对于 docker 来说，具体的代码位于 <code>pkg/kubelet/dockertools/docker_manager.go</code>：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token punctuation">(</span>dm <span class="token operator">*</span>DockerManager<span class="token punctuation">)</span> <span class="token function">SyncPod</span><span class="token punctuation">(</span>pod <span class="token operator">*</span>api<span class="token punctuation">.</span>Pod<span class="token punctuation">,</span> <span class="token boolean">_</span> api<span class="token punctuation">.</span>PodStatus<span class="token punctuation">,</span> podStatus <span class="token operator">*</span>kubecontainer<span class="token punctuation">.</span>PodStatus<span class="token punctuation">,</span> pullSecrets <span class="token punctuation">[</span><span class="token punctuation">]</span>api<span class="token punctuation">.</span>Secret<span class="token punctuation">,</span> backOff <span class="token operator">*</span>flowcontrol<span class="token punctuation">.</span>Backoff<span class="token punctuation">)</span> <span class="token punctuation">(</span>result kubecontainer<span class="token punctuation">.</span>PodSyncResult<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 计算容器的变化</span>    containerChanges<span class="token punctuation">,</span> err <span class="token operator">:=</span> dm<span class="token punctuation">.</span><span class="token function">computePodContainerChanges</span><span class="token punctuation">(</span>pod<span class="token punctuation">,</span> podStatus<span class="token punctuation">)</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token comment" spellcheck="true">// 如果需要，先删除运行的容器</span>    <span class="token keyword">if</span> containerChanges<span class="token punctuation">.</span>StartInfraContainer <span class="token operator">||</span> <span class="token punctuation">(</span><span class="token function">len</span><span class="token punctuation">(</span>containerChanges<span class="token punctuation">.</span>ContainersToKeep<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">&amp;&amp;</span> <span class="token function">len</span><span class="token punctuation">(</span>containerChanges<span class="token punctuation">.</span>ContainersToStart<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token operator">...</span><span class="token operator">...</span>        killResult <span class="token operator">:=</span> dm<span class="token punctuation">.</span><span class="token function">killPodWithSyncResult</span><span class="token punctuation">(</span>pod<span class="token punctuation">,</span> kubecontainer<span class="token punctuation">.</span><span class="token function">ConvertPodStatusToRunningPod</span><span class="token punctuation">(</span>dm<span class="token punctuation">.</span><span class="token function">Type</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> podStatus<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">nil</span><span class="token punctuation">)</span>        <span class="token operator">...</span><span class="token operator">...</span>    <span class="token punctuation">}</span>    podIP <span class="token operator">:=</span> <span class="token string">""</span>    <span class="token keyword">if</span> podStatus <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        podIP <span class="token operator">=</span> podStatus<span class="token punctuation">.</span>IP    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 先创建 infrastructure 容器</span>    podInfraContainerID <span class="token operator">:=</span> containerChanges<span class="token punctuation">.</span>InfraContainerId    <span class="token keyword">if</span> containerChanges<span class="token punctuation">.</span>StartInfraContainer <span class="token operator">&amp;&amp;</span> <span class="token punctuation">(</span><span class="token function">len</span><span class="token punctuation">(</span>containerChanges<span class="token punctuation">.</span>ContainersToStart<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>        <span class="token operator">...</span><span class="token operator">...</span>        <span class="token comment" spellcheck="true">// 通过 docker 创建出来一个运行的 pause 容器。</span>        <span class="token comment" spellcheck="true">// 如果镜像不存在，kubelet 会先下载 pause 镜像；</span>        <span class="token comment" spellcheck="true">// 如果 pod 是主机模式，容器也是；其他情况下，容器会使用 None 网络模式，让 kubelet 的网络插件自己进行网络配置</span>        podInfraContainerID<span class="token punctuation">,</span> err<span class="token punctuation">,</span> msg <span class="token operator">=</span> dm<span class="token punctuation">.</span><span class="token function">createPodInfraContainer</span><span class="token punctuation">(</span>pod<span class="token punctuation">)</span>        <span class="token operator">...</span><span class="token operator">...</span>        <span class="token comment" spellcheck="true">// 配置 infrastructure 容器的网络</span>        <span class="token keyword">if</span> <span class="token operator">!</span>kubecontainer<span class="token punctuation">.</span><span class="token function">IsHostNetworkPod</span><span class="token punctuation">(</span>pod<span class="token punctuation">)</span> <span class="token punctuation">{</span>            err <span class="token operator">=</span> dm<span class="token punctuation">.</span>networkPlugin<span class="token punctuation">.</span><span class="token function">SetUpPod</span><span class="token punctuation">(</span>pod<span class="token punctuation">.</span>Namespace<span class="token punctuation">,</span> pod<span class="token punctuation">.</span>Name<span class="token punctuation">,</span> podInfraContainerID<span class="token punctuation">.</span><span class="token function">ContainerID</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token operator">...</span><span class="token operator">...</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token comment" spellcheck="true">// 启动正常的容器</span>    <span class="token keyword">for</span> idx <span class="token operator">:=</span> <span class="token keyword">range</span> containerChanges<span class="token punctuation">.</span>ContainersToStart <span class="token punctuation">{</span>        container <span class="token operator">:=</span> <span class="token operator">&amp;</span>pod<span class="token punctuation">.</span>Spec<span class="token punctuation">.</span>Containers<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>        startContainerResult <span class="token operator">:=</span> kubecontainer<span class="token punctuation">.</span><span class="token function">NewSyncResult</span><span class="token punctuation">(</span>kubecontainer<span class="token punctuation">.</span>StartContainer<span class="token punctuation">,</span> container<span class="token punctuation">.</span>Name<span class="token punctuation">)</span>        result<span class="token punctuation">.</span><span class="token function">AddSyncResult</span><span class="token punctuation">(</span>startContainerResult<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true">// containerChanges.StartInfraContainer causes the containers to be restarted for config reasons</span>        <span class="token keyword">if</span> <span class="token operator">!</span>containerChanges<span class="token punctuation">.</span>StartInfraContainer <span class="token punctuation">{</span>            isInBackOff<span class="token punctuation">,</span> err<span class="token punctuation">,</span> msg <span class="token operator">:=</span> dm<span class="token punctuation">.</span><span class="token function">doBackOff</span><span class="token punctuation">(</span>pod<span class="token punctuation">,</span> container<span class="token punctuation">,</span> podStatus<span class="token punctuation">,</span> backOff<span class="token punctuation">)</span>            <span class="token keyword">if</span> isInBackOff <span class="token punctuation">{</span>                startContainerResult<span class="token punctuation">.</span><span class="token function">Fail</span><span class="token punctuation">(</span>err<span class="token punctuation">,</span> msg<span class="token punctuation">)</span>                <span class="token keyword">continue</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        <span class="token keyword">if</span> err<span class="token punctuation">,</span> msg <span class="token operator">:=</span> dm<span class="token punctuation">.</span><span class="token function">tryContainerStart</span><span class="token punctuation">(</span>container<span class="token punctuation">,</span> pod<span class="token punctuation">,</span> podStatus<span class="token punctuation">,</span> pullSecrets<span class="token punctuation">,</span> namespaceMode<span class="token punctuation">,</span> pidMode<span class="token punctuation">,</span> podIP<span class="token punctuation">)</span><span class="token punctuation">;</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            startContainerResult<span class="token punctuation">.</span><span class="token function">Fail</span><span class="token punctuation">(</span>err<span class="token punctuation">,</span> msg<span class="token punctuation">)</span>            utilruntime<span class="token punctuation">.</span><span class="token function">HandleError</span><span class="token punctuation">(</span>fmt<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"container start failed: %v: %s"</span><span class="token punctuation">,</span> err<span class="token punctuation">,</span> msg<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">continue</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span><span class="token punctuation">}</span></code></pre><p>这个方法的内容也非常多，它的主要逻辑是先比较传递过来的 pod 信息和实际运行的 pod（对于新建 pod 来说后者为空），计算出两者的差别，也就是需要更新的地方。然后先创建 infrastructure 容器，配置好网络，然后再逐个创建应用容器。</p><p><code>dm.computePodContainerChanges</code> 根据最新拿到的 pod 配置，和目前实际运行的容器对比，计算出其中的变化，得到需要重新启动的容器信息。不管是创建、更新还是删除 pod，最终都会调用  <code>syncPod</code> 方法，所以这个结果涵盖了所有的可能性。</p><pre class=" language-go"><code class="language-go"><span class="token keyword">type</span> podContainerChangesSpec <span class="token keyword">struct</span> <span class="token punctuation">{</span>    StartInfraContainer  <span class="token builtin">bool</span>    InfraChanged         <span class="token builtin">bool</span>    InfraContainerId     kubecontainer<span class="token punctuation">.</span>DockerID    InitFailed           <span class="token builtin">bool</span>    InitContainersToKeep <span class="token keyword">map</span><span class="token punctuation">[</span>kubecontainer<span class="token punctuation">.</span>DockerID<span class="token punctuation">]</span><span class="token builtin">int</span>    ContainersToStart    <span class="token keyword">map</span><span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token builtin">string</span>    ContainersToKeep     <span class="token keyword">map</span><span class="token punctuation">[</span>kubecontainer<span class="token punctuation">.</span>DockerID<span class="token punctuation">]</span><span class="token builtin">int</span><span class="token punctuation">}</span></code></pre><p>这个结构体中的内容可以分成三部分：infrastructure 变化信息，init containers 变化信息，以及应用 containers 变化信息。检测 infrastructure pod 有没有变化，只需要检查下面这些内容：</p><ul><li>pasue 镜像</li><li>网络模型有没有变化</li><li>暴露的端口号有没有变化</li><li>镜像拉取策略</li><li>环境变量</li></ul><p>根据 infrastructure 容器的状态，其需要执行的操作可以分为三种情况：</p><ul><li>容器还不存在，或者没有在运行状态：启动新的 pause 容器（这就是我们一直分析的 pod 新建的情况）</li><li>容器正在运行，但是新的 pod 配置发生了变化：杀掉 pause 容器，重新启动</li><li>pause 容器已经运行，而且没有变化，不做任何事情</li></ul><p>应用容器要重建的原因包括：</p><ul><li>容器异常退出</li><li>infrastructure 容器要重启（pod 新建也属于这种情况）</li><li>init 容器运行失败</li><li>container 配置的哈希值发生了变化（对 pod 的内容做了更新操作）</li><li>liveness 检测失败</li></ul><p>容器创建就是根据配置得到 docker client 新建容器需要的所有参数，最终发送给 docker API，这里不再赘述。创建应用容器的时候，会把 infrastructure 容器的网络模式和 pidMode 传过去，这也是 pod 中所有容器共享网络和 pid 资源的地方。</p><p>新建 pod 的逻辑就是这样的，更新和这个流程类似，删除的逻辑比这个简单，我们就不再一一解释。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过上一篇文章和这一篇文章，我们分析了 kubelet 的主要流程代码，包括它是怎么启动的，它是怎么处理新建 pod 的。这两篇代码分析已经把 kubelet 代码的骨架描绘出来了，但也有很多细节性的东西没有提及。我们在后面的文章中会继续分析 kubelet 一些组件的功能，让大家更全面地理解 kubelet 。那些我们没有提及的知识点，读者可以自己阅读源码。</p>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;p&gt;在&lt;a href=&quot;http://cizixs.com/2017/06/06/kubelet-source-code-analysis-part-1&quot;&gt;上一篇文章&lt;/a&gt;中，我们分析了 kubelet
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="kubernetes" scheme="http://cizixs.com/tags/kubernetes/"/>
    
      <category term="container" scheme="http://cizixs.com/tags/container/"/>
    
      <category term="golang" scheme="http://cizixs.com/tags/golang/"/>
    
      <category term="kubelet" scheme="http://cizixs.com/tags/kubelet/"/>
    
  </entry>
  
  <entry>
    <title>kubelet 源码分析：启动流程</title>
    <link href="http://cizixs.com/2017/06/06/kubelet-source-code-analysis-part-1/"/>
    <id>http://cizixs.com/2017/06/06/kubelet-source-code-analysis-part-1/</id>
    <published>2017-06-05T16:00:00.000Z</published>
    <updated>2018-09-17T13:18:45.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="kubelet-简介"><a href="#kubelet-简介" class="headerlink" title="kubelet 简介"></a>kubelet 简介</h2><p>我在<a href="http://cizixs.com/2016/10/25/kubernetes-intro-kubelet">之前的文章介绍过 kubelet 的功能</a>，简言之，kubelet 保证它所在节点的 pod 能够正常工作。它的核心工作是监听 apiserver，一旦发现当前节点的 pod 配置发生变化，就根据最新的配置执行响应的动作，保证运行的 pod 状态和期望的一致。</p><p>kubelet 除了这个最核心的功能之外，还有很多其他特性：</p><ul><li>定时汇报当前节点的状态给 apiserver，以供调度的时候使用</li><li>镜像和容器的清理工作，保证节点上镜像不会占满磁盘空间，退出的容器不会占用太多资源</li><li>运行 HTTP Server，对外提供节点和 pod 信息，如果在 debug 模式下，还包括调试信息</li><li>……</li></ul><p>从这篇文章开始，我们深入到 kubelet 的源码中，看它具体的实现原理。</p><p><strong>NOTE</strong>：文章采用的 kubernetes 的版本是 <code>v1.5.0</code>，其他版本会有出入，请注意。因为 kubernetes 代码很繁杂，文章会适当删减，保证可读性。删除的内容包括但是不限于：</p><ul><li>注释、TODO 等信息</li><li>alpha 或者实验性特性代码</li><li>日志相关代码</li><li>参数验证、错误处理</li><li>和当前函数或者方法相关性很低的代码</li></ul><h2 id="KubeletServer-配置对象"><a href="#KubeletServer-配置对象" class="headerlink" title="KubeletServer 配置对象"></a>KubeletServer 配置对象</h2><p>和其他 kubernetes 组件源代码一样，<code>kubelet</code> 的 <code>main</code> 函数入口放在 <code>cmd/</code> 文件夹下：</p><pre><code>➜  kubernetes git:(v1.5.0) tree cmd/kubelet cmd/kubelet├── app│   ├── auth.go│   ├── bootstrap.go│   ├── bootstrap_test.go│   ├── options│   │   └── options.go│   ├── plugins.go│   ├── server.go│   ├── server_linux.go│   ├── server_test.go│   └── server_unsupported.go└── kubelet.go</code></pre><p><code>cmd</code> 是所有 kubernetes 组件的入口，主要负责二进制文件的命令行解析，和配置初始化工作，最终还是会调用 <code>pkg/</code> 下面各个组件的内容。对于 <code>kubelet</code> 来说，上面 <code>cmd/kubelet/kubelet.go</code> 就是 <code>main</code> 函数所在的文件，因为它的内容比较简单，所以就全部贴在这里了：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    runtime<span class="token punctuation">.</span><span class="token function">GOMAXPROCS</span><span class="token punctuation">(</span>runtime<span class="token punctuation">.</span><span class="token function">NumCPU</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 注意这里，定义了 KubeletServer，主要用于一些参数的初始化和参数的定义</span>    s <span class="token operator">:=</span> options<span class="token punctuation">.</span><span class="token function">NewKubeletServer</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    s<span class="token punctuation">.</span><span class="token function">AddFlags</span><span class="token punctuation">(</span>pflag<span class="token punctuation">.</span>CommandLine<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 解析命令行参数</span>    flag<span class="token punctuation">.</span><span class="token function">InitFlags</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    util<span class="token punctuation">.</span><span class="token function">InitLogs</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">defer</span> util<span class="token punctuation">.</span><span class="token function">FlushLogs</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    verflag<span class="token punctuation">.</span><span class="token function">PrintAndExitIfRequested</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 执行 `app.Run`，运行</span>    <span class="token keyword">if</span> err <span class="token operator">:=</span> app<span class="token punctuation">.</span><span class="token function">Run</span><span class="token punctuation">(</span>s<span class="token punctuation">,</span> <span class="token boolean">nil</span><span class="token punctuation">)</span><span class="token punctuation">;</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        fmt<span class="token punctuation">.</span><span class="token function">Fprintf</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>Stderr<span class="token punctuation">,</span> <span class="token string">"%v\n"</span><span class="token punctuation">,</span> err<span class="token punctuation">)</span>        os<span class="token punctuation">.</span><span class="token function">Exit</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span><span class="token punctuation">}</span></code></pre><p>这段代码主要分成三个部分，按照顺序运行的：</p><ol><li>创建一个 <code>KubeletServer</code> 对象，这个对象保存着 kubelet 运行需要的所有配置信息</li><li>解析命令行，根据命令行的参数更新 <code>KubeletServer</code></li><li>根据 <code>KubeletServer</code> 的配置运行真正的 kubelet 程序</li></ol><p>NOTE：第二部分是 <code>flag</code> 这个库自动完成的，因此我们只分析其他两个部分。</p><p><code>options.NewKubeletServer()</code> 定义在 <code>app/options/options.go</code> 文件中，就是创建一个管理配置的结构体 <code>KubeletServer</code>，初始化一些配置信息。不要被 <code>KubeletServer</code> 这个名字迷惑，它只是一个包含了所有 kubelet 配置参数的结构体，并不是真正运行的 kubelet 实例。<code>KubeletServer</code> 对象结构是这样的：</p><pre class=" language-go"><code class="language-go"><span class="token comment" spellcheck="true">// KubeletServer 封装了运行 kubelet 需要的所有参数</span><span class="token keyword">type</span> KubeletServer <span class="token keyword">struct</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 主要的配置结构体，定义在 `apis/componentconfig/types.go` 文件中，包含了命令行所有可以配置的参数。</span>    <span class="token comment" spellcheck="true">// 因为这个字段是直接引用，所以用户可以通过 `KubeletServer` 直接访问它的字段</span>    componentconfig<span class="token punctuation">.</span>KubeletConfiguration    <span class="token comment" spellcheck="true">// kubeconfig 文件的路径，用于访问 apiserver，在后面的版本中这将成为访问 apiserver 的标准方式</span>    KubeConfig          flag<span class="token punctuation">.</span>StringFlag    BootstrapKubeconfig <span class="token builtin">string</span>    <span class="token comment" spellcheck="true">// 如果设置为 true，那么错误的 kubeConfig 配置会直接导致 kubelet 退出</span>    RequireKubeConfig <span class="token builtin">bool</span>    <span class="token comment" spellcheck="true">// 之前访问 apiserver 的方式，以后会被上面提到的 kubeConfig 配置取代</span>    AuthPath          flag<span class="token punctuation">.</span>StringFlag <span class="token comment" spellcheck="true">// Deprecated -- use KubeConfig instead</span>    APIServerList     <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token builtin">string</span>        <span class="token comment" spellcheck="true">// Deprecated -- use KubeConfig instead</span>    <span class="token operator">...</span><span class="token punctuation">}</span></code></pre><p><code>KubeletServer</code> 有一个 <code>AddFlags</code> 的方法，它的唯一作用就是把命令行参数和它的字段一一对应起来。这样解析命令行参数的时候，就更新对应的字段。这里是所有命令行参数定义的地方，如果要查询某个版本提供了哪些命令行，我会阅读这部分内容。</p><p>后面所有的事情都是在 <code>app.Run()</code> 中做的，看名字也能猜出来，它会运行实际的 kubelet。这个方法定义在 <code>cmd/kubelet/app/server.go</code>：</p><pre class=" language-go"><code class="language-go"><span class="token comment" spellcheck="true">// 根据传进来的 kubeDeps 和 KubeletServer，运行 kubelet 的服务，这个方法会一直运行，正常情况下不会返回</span><span class="token keyword">func</span> <span class="token function">Run</span><span class="token punctuation">(</span>s <span class="token operator">*</span>options<span class="token punctuation">.</span>KubeletServer<span class="token punctuation">,</span> kubeDeps <span class="token operator">*</span>kubelet<span class="token punctuation">.</span>KubeletDeps<span class="token punctuation">)</span> <span class="token builtin">error</span> <span class="token punctuation">{</span>    <span class="token keyword">if</span> err <span class="token operator">:=</span> <span class="token function">run</span><span class="token punctuation">(</span>s<span class="token punctuation">,</span> kubeDeps<span class="token punctuation">)</span><span class="token punctuation">;</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> fmt<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"failed to run Kubelet: %v"</span><span class="token punctuation">,</span> err<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> <span class="token boolean">nil</span><span class="token punctuation">}</span><span class="token keyword">func</span> <span class="token function">run</span><span class="token punctuation">(</span>s <span class="token operator">*</span>options<span class="token punctuation">.</span>KubeletServer<span class="token punctuation">,</span> kubeDeps <span class="token operator">*</span>kubelet<span class="token punctuation">.</span>KubeletDeps<span class="token punctuation">)</span> <span class="token punctuation">(</span>err <span class="token builtin">error</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token keyword">if</span> kubeDeps <span class="token operator">==</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token keyword">var</span> kubeClient<span class="token punctuation">,</span> eventClient <span class="token operator">*</span>clientset<span class="token punctuation">.</span>Clientset        <span class="token keyword">var</span> cloud cloudprovider<span class="token punctuation">.</span>Interface        <span class="token operator">...</span><span class="token operator">...</span>        <span class="token comment" spellcheck="true">// 创建出来两个 client：kubeClient 和 eventClient，用来和 apiserver 通信</span>        clientConfig<span class="token punctuation">,</span> err <span class="token operator">:=</span> <span class="token function">CreateAPIServerClientConfig</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span>        <span class="token keyword">if</span> err <span class="token operator">==</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            kubeClient<span class="token punctuation">,</span> err <span class="token operator">=</span> clientset<span class="token punctuation">.</span><span class="token function">NewForConfig</span><span class="token punctuation">(</span>clientConfig<span class="token punctuation">)</span>            <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>                glog<span class="token punctuation">.</span><span class="token function">Warningf</span><span class="token punctuation">(</span><span class="token string">"New kubeClient from clientConfig error: %v"</span><span class="token punctuation">,</span> err<span class="token punctuation">)</span>            <span class="token punctuation">}</span>            <span class="token comment" spellcheck="true">// make a separate client for events</span>            eventClientConfig <span class="token operator">:=</span> <span class="token operator">*</span>clientConfig            eventClientConfig<span class="token punctuation">.</span>QPS <span class="token operator">=</span> <span class="token function">float32</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>EventRecordQPS<span class="token punctuation">)</span>            eventClientConfig<span class="token punctuation">.</span>Burst <span class="token operator">=</span> <span class="token function">int</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>EventBurst<span class="token punctuation">)</span>            eventClient<span class="token punctuation">,</span> err <span class="token operator">=</span> clientset<span class="token punctuation">.</span><span class="token function">NewForConfig</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>eventClientConfig<span class="token punctuation">)</span>        <span class="token punctuation">}</span>        <span class="token operator">...</span><span class="token operator">...</span>        <span class="token comment" spellcheck="true">// 创建出来一个默认的 kubeDeps，里面包含了 dockerClient、Network Plugins 对象、Volume Plugins 对象</span>        kubeDeps<span class="token punctuation">,</span> err <span class="token operator">=</span> <span class="token function">UnsecuredKubeletDeps</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span>        <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> err        <span class="token punctuation">}</span>        <span class="token comment" spellcheck="true">// 把之前创建的对象赋给 kubeDeps</span>        kubeDeps<span class="token punctuation">.</span>Cloud <span class="token operator">=</span> cloud        kubeDeps<span class="token punctuation">.</span>KubeClient <span class="token operator">=</span> kubeClient        kubeDeps<span class="token punctuation">.</span>EventClient <span class="token operator">=</span> eventClient    <span class="token punctuation">}</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token comment" spellcheck="true">// 创建 cAdvisor 对象，负责收集容器的监控信息</span>    <span class="token keyword">if</span> kubeDeps<span class="token punctuation">.</span>CAdvisorInterface <span class="token operator">==</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        kubeDeps<span class="token punctuation">.</span>CAdvisorInterface<span class="token punctuation">,</span> err <span class="token operator">=</span> cadvisor<span class="token punctuation">.</span><span class="token function">New</span><span class="token punctuation">(</span><span class="token function">uint</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>CAdvisorPort<span class="token punctuation">)</span><span class="token punctuation">,</span> s<span class="token punctuation">.</span>ContainerRuntime<span class="token punctuation">,</span> s<span class="token punctuation">.</span>RootDirectory<span class="token punctuation">)</span>        <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> err        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 创建 ContainerManager 对象</span>    <span class="token keyword">if</span> kubeDeps<span class="token punctuation">.</span>ContainerManager <span class="token operator">==</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token operator">...</span><span class="token operator">...</span>        kubeDeps<span class="token punctuation">.</span>ContainerManager<span class="token punctuation">,</span> err <span class="token operator">=</span> cm<span class="token punctuation">.</span><span class="token function">NewContainerManager</span><span class="token punctuation">(</span>            kubeDeps<span class="token punctuation">.</span>Mounter<span class="token punctuation">,</span>            kubeDeps<span class="token punctuation">.</span>CAdvisorInterface<span class="token punctuation">,</span>            cm<span class="token punctuation">.</span>NodeConfig<span class="token punctuation">{</span>                RuntimeCgroupsName<span class="token punctuation">:</span>    s<span class="token punctuation">.</span>RuntimeCgroups<span class="token punctuation">,</span>                SystemCgroupsName<span class="token punctuation">:</span>     s<span class="token punctuation">.</span>SystemCgroups<span class="token punctuation">,</span>                KubeletCgroupsName<span class="token punctuation">:</span>    s<span class="token punctuation">.</span>KubeletCgroups<span class="token punctuation">,</span>                ContainerRuntime<span class="token punctuation">:</span>      s<span class="token punctuation">.</span>ContainerRuntime<span class="token punctuation">,</span>                CgroupsPerQOS<span class="token punctuation">:</span>         s<span class="token punctuation">.</span>ExperimentalCgroupsPerQOS<span class="token punctuation">,</span>                CgroupRoot<span class="token punctuation">:</span>            s<span class="token punctuation">.</span>CgroupRoot<span class="token punctuation">,</span>                CgroupDriver<span class="token punctuation">:</span>          s<span class="token punctuation">.</span>CgroupDriver<span class="token punctuation">,</span>                ProtectKernelDefaults<span class="token punctuation">:</span> s<span class="token punctuation">.</span>ProtectKernelDefaults<span class="token punctuation">,</span>                EnableCRI<span class="token punctuation">:</span>             s<span class="token punctuation">.</span>EnableCRI<span class="token punctuation">,</span>            <span class="token punctuation">}</span><span class="token punctuation">,</span>            s<span class="token punctuation">.</span>ExperimentalFailSwapOn<span class="token punctuation">)</span>        <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> err        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token comment" spellcheck="true">// 运行 kubelet，这个函数会启动 goroutine 一直运行，是 kubelet 核心功能执行的地方</span>    <span class="token keyword">if</span> err <span class="token operator">:=</span> <span class="token function">RunKubelet</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>s<span class="token punctuation">.</span>KubeletConfiguration<span class="token punctuation">,</span> kubeDeps<span class="token punctuation">,</span> s<span class="token punctuation">.</span>RunOnce<span class="token punctuation">,</span> standaloneMode<span class="token punctuation">)</span><span class="token punctuation">;</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> err    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 运行 healthz HTTP 服务</span>    <span class="token keyword">if</span> s<span class="token punctuation">.</span>HealthzPort <span class="token operator">></span> <span class="token number">0</span> <span class="token punctuation">{</span>        healthz<span class="token punctuation">.</span><span class="token function">DefaultHealthz</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">go</span> wait<span class="token punctuation">.</span><span class="token function">Until</span><span class="token punctuation">(</span><span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            err <span class="token operator">:=</span> http<span class="token punctuation">.</span><span class="token function">ListenAndServe</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span><span class="token function">JoinHostPort</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>HealthzBindAddress<span class="token punctuation">,</span> strconv<span class="token punctuation">.</span><span class="token function">Itoa</span><span class="token punctuation">(</span><span class="token function">int</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>HealthzPort<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">nil</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>                glog<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"Starting health server failed: %v"</span><span class="token punctuation">,</span> err<span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token operator">*</span>time<span class="token punctuation">.</span>Second<span class="token punctuation">,</span> wait<span class="token punctuation">.</span>NeverStop<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token operator">&lt;-</span>done    <span class="token keyword">return</span> <span class="token boolean">nil</span><span class="token punctuation">}</span></code></pre><p>这段代码的最后，是真正运行的东西。前面大部分的内容都是是在创建和初始化 <code>kubeDeps</code> 这个对象，它最终会传递到 <code>RunKubelet</code> 函数中。</p><p><code>kubeDeps</code> 的名字听起来很奇怪，其实它内部保存了 kubelet 各个重要组件的对象，之所以要把它作为参数传递，是为了实现 dependency injection。简单地说，就是把 kubelet 依赖的组件对象作为参数传进来，这样可以控制 kubelet 的行为。比如在测试的时候，只要构建 fake 的组件实现，就能很轻松进行测试。<code>KubeDeps</code> 包含的组件很多，下面列出一些：</p><ul><li>CAdvisorInterface：提供 cAdvisor 接口功能的组件，用来获取监控信息</li><li>DockerClient：docker 客户端，用来和 docker 交互</li><li>KubeClient：apiserver 客户端，用来和 api server 通信</li><li>Mounter：执行 mount 相关操作</li><li>NetworkPlugins：网络插件，执行网络设置工作</li><li>VolumePlugins：volume 插件，执行 volume 设置工作</li></ul><p>可以看到，这些组件要么需要和第三方交互（kubeClient、DockerClient），要么有副作用（ <code>Mounter</code>、<code>NetworkPlugins</code>、<code>VolumePlugins</code>），在进行单元测试的时候一般都会编写对应的 Fake 对象，只要满足响应的接口，就能正常工作。</p><p><code>run</code> 方法允许传进来的 <code>kubeDeps</code> 为空，这个时候它会自动生成默认的 <code>kubeDeps</code> 对象，这也就是我们上面代码的逻辑。运行 HTTP Server 的代码我们暂时略过，留作以后再讲，继续来看 <code>RunKubelet</code>，它的代码是这样的：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">RunKubelet</span><span class="token punctuation">(</span>kubeCfg <span class="token operator">*</span>componentconfig<span class="token punctuation">.</span>KubeletConfiguration<span class="token punctuation">,</span> kubeDeps <span class="token operator">*</span>kubelet<span class="token punctuation">.</span>KubeletDeps<span class="token punctuation">,</span> runOnce <span class="token builtin">bool</span><span class="token punctuation">,</span> standaloneMode <span class="token builtin">bool</span><span class="token punctuation">)</span> <span class="token builtin">error</span> <span class="token punctuation">{</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token comment" spellcheck="true">// 一些初始化的工作，配置 eventBroadcaster，这样就能发送事件了</span>    eventBroadcaster <span class="token operator">:=</span> record<span class="token punctuation">.</span><span class="token function">NewBroadcaster</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    kubeDeps<span class="token punctuation">.</span>Recorder <span class="token operator">=</span> eventBroadcaster<span class="token punctuation">.</span><span class="token function">NewRecorder</span><span class="token punctuation">(</span>api<span class="token punctuation">.</span>EventSource<span class="token punctuation">{</span>Component<span class="token punctuation">:</span> <span class="token string">"kubelet"</span><span class="token punctuation">,</span> Host<span class="token punctuation">:</span> <span class="token function">string</span><span class="token punctuation">(</span>nodeName<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>    eventBroadcaster<span class="token punctuation">.</span><span class="token function">StartLogging</span><span class="token punctuation">(</span>glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>Infof<span class="token punctuation">)</span>    <span class="token keyword">if</span> kubeDeps<span class="token punctuation">.</span>EventClient <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        glog<span class="token punctuation">.</span><span class="token function">V</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"Sending events to api server."</span><span class="token punctuation">)</span>        eventBroadcaster<span class="token punctuation">.</span><span class="token function">StartRecordingToSink</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>unversionedcore<span class="token punctuation">.</span>EventSinkImpl<span class="token punctuation">{</span>Interface<span class="token punctuation">:</span> kubeDeps<span class="token punctuation">.</span>EventClient<span class="token punctuation">.</span><span class="token function">Events</span><span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>        glog<span class="token punctuation">.</span><span class="token function">Warning</span><span class="token punctuation">(</span><span class="token string">"No api server defined - no events will be sent to API server."</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token operator">...</span><span class="token operator">...</span>    privilegedSources <span class="token operator">:=</span> capabilities<span class="token punctuation">.</span>PrivilegedSources<span class="token punctuation">{</span>        HostNetworkSources<span class="token punctuation">:</span> hostNetworkSources<span class="token punctuation">,</span>        HostPIDSources<span class="token punctuation">:</span>     hostPIDSources<span class="token punctuation">,</span>        HostIPCSources<span class="token punctuation">:</span>     hostIPCSources<span class="token punctuation">,</span>    <span class="token punctuation">}</span>    capabilities<span class="token punctuation">.</span><span class="token function">Setup</span><span class="token punctuation">(</span>kubeCfg<span class="token punctuation">.</span>AllowPrivileged<span class="token punctuation">,</span> privilegedSources<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token comment" spellcheck="true">// 使用 Builder 创建 mainKubelet，默认使用 `CreateAndInitKubelet`</span>    builder <span class="token operator">:=</span> kubeDeps<span class="token punctuation">.</span>Builder    <span class="token keyword">if</span> builder <span class="token operator">==</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        builder <span class="token operator">=</span> CreateAndInitKubelet    <span class="token punctuation">}</span>    <span class="token keyword">if</span> kubeDeps<span class="token punctuation">.</span>OSInterface <span class="token operator">==</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        kubeDeps<span class="token punctuation">.</span>OSInterface <span class="token operator">=</span> kubecontainer<span class="token punctuation">.</span>RealOS<span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token punctuation">}</span>    k<span class="token punctuation">,</span> err <span class="token operator">:=</span> <span class="token function">builder</span><span class="token punctuation">(</span>kubeCfg<span class="token punctuation">,</span> kubeDeps<span class="token punctuation">,</span> standaloneMode<span class="token punctuation">)</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token comment" spellcheck="true">// 运行 kubelet</span>    <span class="token keyword">if</span> runOnce <span class="token punctuation">{</span>        <span class="token keyword">if</span> <span class="token boolean">_</span><span class="token punctuation">,</span> err <span class="token operator">:=</span> k<span class="token punctuation">.</span><span class="token function">RunOnce</span><span class="token punctuation">(</span>podCfg<span class="token punctuation">.</span><span class="token function">Updates</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> fmt<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"runonce failed: %v"</span><span class="token punctuation">,</span> err<span class="token punctuation">)</span>        <span class="token punctuation">}</span>        glog<span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"Started kubelet %s as runonce"</span><span class="token punctuation">,</span> version<span class="token punctuation">.</span><span class="token function">Get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">String</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>        err <span class="token operator">:=</span> <span class="token function">startKubelet</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> podCfg<span class="token punctuation">,</span> kubeCfg<span class="token punctuation">,</span> kubeDeps<span class="token punctuation">)</span>        <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>            <span class="token keyword">return</span> err        <span class="token punctuation">}</span>        glog<span class="token punctuation">.</span><span class="token function">Infof</span><span class="token punctuation">(</span><span class="token string">"Started kubelet %s"</span><span class="token punctuation">,</span> version<span class="token punctuation">.</span><span class="token function">Get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">String</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> <span class="token boolean">nil</span><span class="token punctuation">}</span></code></pre><p><code>RunKubelet()</code> 和 <code>runKubelet()</code> 完成了真正意义上的 <code>kubelet</code> 对象的创建和运行。<code>RunKubelet</code> 用来创建 kubelet、验证参数、以及做一些初始化（事件处理和配置 capabilities 等），<code>runKubelet</code> 负责运行。</p><p><code>RunKubelet</code> 的内容可以分成三个部分：</p><ol><li>初始化各个对象，比如 eventBroadcaster，这样就能给 apiserver 发送 kubelet 的事件</li><li>通过 builder 创建出来 <code>Kubelet</code> </li><li>根据运行模式，运行 <code>Kubelet</code></li></ol><p>创建工作是在 <code>k, err := builder(kubeCfg, kubeDeps, standaloneMode)</code> 这句完成的，默认的 <code>builder</code> 是 <code>CreateAndInitKubelet</code>：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">CreateAndInitKubelet</span><span class="token punctuation">(</span>kubeCfg <span class="token operator">*</span>componentconfig<span class="token punctuation">.</span>KubeletConfiguration<span class="token punctuation">,</span> kubeDeps <span class="token operator">*</span>kubelet<span class="token punctuation">.</span>KubeletDeps<span class="token punctuation">,</span> standaloneMode <span class="token builtin">bool</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>k kubelet<span class="token punctuation">.</span>KubeletBootstrap<span class="token punctuation">,</span> err <span class="token builtin">error</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 调用 pkg/kubelet/kubelet.go 文件创建 MainKubelet 的代码</span>    k<span class="token punctuation">,</span> err <span class="token operator">=</span> kubelet<span class="token punctuation">.</span><span class="token function">NewMainKubelet</span><span class="token punctuation">(</span>kubeCfg<span class="token punctuation">,</span> kubeDeps<span class="token punctuation">,</span> standaloneMode<span class="token punctuation">)</span>    <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token boolean">nil</span><span class="token punctuation">,</span> err    <span class="token punctuation">}</span>    k<span class="token punctuation">.</span><span class="token function">BirthCry</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 启动 GC</span>    k<span class="token punctuation">.</span><span class="token function">StartGarbageCollection</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> k<span class="token punctuation">,</span> <span class="token boolean">nil</span><span class="token punctuation">}</span></code></pre><p><code>BirthCry()</code> 只是发送一个事件，宣告 kubelet 已经成功启动；<code>StartGarbageCollection()</code> 正如名字所示，启动 kubelet GC 流程，我们后面会详细解释它的内部实现。接下来，我们先看一下 <code>NewMainKubelet()</code> 的代码，毕竟它是创建出 kubelet 的地方。</p><h2 id="kubelet-的创建"><a href="#kubelet-的创建" class="headerlink" title="kubelet 的创建"></a>kubelet 的创建</h2><p><code>MainKubelet</code> 函数定义在 <code>pkg/kubelet/kubelet.go#NewMainKubelet</code>，我们终于从 <code>cmd/kubelet/</code> 分析到 <code>pkg/kubelet/</code> 了。</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">NewMainKubelet</span><span class="token punctuation">(</span>kubeCfg <span class="token operator">*</span>componentconfig<span class="token punctuation">.</span>KubeletConfiguration<span class="token punctuation">,</span> kubeDeps <span class="token operator">*</span>KubeletDeps<span class="token punctuation">,</span> standaloneMode <span class="token builtin">bool</span><span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token operator">*</span>Kubelet<span class="token punctuation">,</span> <span class="token builtin">error</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token comment" spellcheck="true">// PodConfig 非常重要，它是 pod 信息的来源，kubelet 支持文件、URL 和 apiserver 三种渠道，PodConfig 将它们汇聚到一起，通过管道来传递</span>    <span class="token keyword">if</span> kubeDeps<span class="token punctuation">.</span>PodConfig <span class="token operator">==</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        kubeDeps<span class="token punctuation">.</span>PodConfig<span class="token punctuation">,</span> err <span class="token operator">=</span> <span class="token function">makePodSourceConfig</span><span class="token punctuation">(</span>kubeCfg<span class="token punctuation">,</span> kubeDeps<span class="token punctuation">,</span> nodeName<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token comment" spellcheck="true">// exec 处理函数，进入到容器中执行命令的方式。之前使用的是 nsenter 命令行的方式，后来 docker 提供了 `docker exec` 命令，默认是后者</span>    <span class="token keyword">var</span> dockerExecHandler dockertools<span class="token punctuation">.</span>ExecHandler    <span class="token keyword">switch</span> kubeCfg<span class="token punctuation">.</span>DockerExecHandlerName <span class="token punctuation">{</span>    <span class="token keyword">case</span> <span class="token string">"native"</span><span class="token punctuation">:</span>        dockerExecHandler <span class="token operator">=</span> <span class="token operator">&amp;</span>dockertools<span class="token punctuation">.</span>NativeExecHandler<span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token keyword">case</span> <span class="token string">"nsenter"</span><span class="token punctuation">:</span>        dockerExecHandler <span class="token operator">=</span> <span class="token operator">&amp;</span>dockertools<span class="token punctuation">.</span>NsenterExecHandler<span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token keyword">default</span><span class="token punctuation">:</span>        glog<span class="token punctuation">.</span><span class="token function">Warningf</span><span class="token punctuation">(</span><span class="token string">"Unknown Docker exec handler %q; defaulting to native"</span><span class="token punctuation">,</span> kubeCfg<span class="token punctuation">.</span>DockerExecHandlerName<span class="token punctuation">)</span>        dockerExecHandler <span class="token operator">=</span> <span class="token operator">&amp;</span>dockertools<span class="token punctuation">.</span>NativeExecHandler<span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 使用 reflector 把 ListWatch 得到的服务信息实时同步到 serviceStore 对象中</span>    serviceStore <span class="token operator">:=</span> cache<span class="token punctuation">.</span><span class="token function">NewIndexer</span><span class="token punctuation">(</span>cache<span class="token punctuation">.</span>MetaNamespaceKeyFunc<span class="token punctuation">,</span> cache<span class="token punctuation">.</span>Indexers<span class="token punctuation">{</span>cache<span class="token punctuation">.</span>NamespaceIndex<span class="token punctuation">:</span> cache<span class="token punctuation">.</span>MetaNamespaceIndexFunc<span class="token punctuation">}</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> kubeClient <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        serviceLW <span class="token operator">:=</span> cache<span class="token punctuation">.</span><span class="token function">NewListWatchFromClient</span><span class="token punctuation">(</span>kubeClient<span class="token punctuation">.</span><span class="token function">Core</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">RESTClient</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"services"</span><span class="token punctuation">,</span> api<span class="token punctuation">.</span>NamespaceAll<span class="token punctuation">,</span> fields<span class="token punctuation">.</span><span class="token function">Everything</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        cache<span class="token punctuation">.</span><span class="token function">NewReflector</span><span class="token punctuation">(</span>serviceLW<span class="token punctuation">,</span> <span class="token operator">&amp;</span>api<span class="token punctuation">.</span>Service<span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> serviceStore<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Run</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    serviceLister <span class="token operator">:=</span> <span class="token operator">&amp;</span>cache<span class="token punctuation">.</span>StoreToServiceLister<span class="token punctuation">{</span>Indexer<span class="token punctuation">:</span> serviceStore<span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 使用 reflector 把 ListWatch 得到的节点信息实时同步到  nodeStore 对象中</span>    nodeStore <span class="token operator">:=</span> cache<span class="token punctuation">.</span><span class="token function">NewStore</span><span class="token punctuation">(</span>cache<span class="token punctuation">.</span>MetaNamespaceKeyFunc<span class="token punctuation">)</span>    <span class="token keyword">if</span> kubeClient <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        fieldSelector <span class="token operator">:=</span> fields<span class="token punctuation">.</span>Set<span class="token punctuation">{</span>api<span class="token punctuation">.</span>ObjectNameField<span class="token punctuation">:</span> <span class="token function">string</span><span class="token punctuation">(</span>nodeName<span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">.</span><span class="token function">AsSelector</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        nodeLW <span class="token operator">:=</span> cache<span class="token punctuation">.</span><span class="token function">NewListWatchFromClient</span><span class="token punctuation">(</span>kubeClient<span class="token punctuation">.</span><span class="token function">Core</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">RESTClient</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"nodes"</span><span class="token punctuation">,</span> api<span class="token punctuation">.</span>NamespaceAll<span class="token punctuation">,</span> fieldSelector<span class="token punctuation">)</span>        cache<span class="token punctuation">.</span><span class="token function">NewReflector</span><span class="token punctuation">(</span>nodeLW<span class="token punctuation">,</span> <span class="token operator">&amp;</span>api<span class="token punctuation">.</span>Node<span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> nodeStore<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">Run</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">}</span>    nodeLister <span class="token operator">:=</span> <span class="token operator">&amp;</span>cache<span class="token punctuation">.</span>StoreToNodeLister<span class="token punctuation">{</span>Store<span class="token punctuation">:</span> nodeStore<span class="token punctuation">}</span>    nodeInfo <span class="token operator">:=</span> <span class="token operator">&amp;</span>predicates<span class="token punctuation">.</span>CachedNodeInfo<span class="token punctuation">{</span>StoreToNodeLister<span class="token punctuation">:</span> nodeLister<span class="token punctuation">}</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token comment" spellcheck="true">// 根据配置信息和各种对象创建 Kubelet 实例</span>    klet <span class="token operator">:=</span> <span class="token operator">&amp;</span>Kubelet<span class="token punctuation">{</span>        hostname<span class="token punctuation">:</span>                       hostname<span class="token punctuation">,</span>        nodeName<span class="token punctuation">:</span>                       nodeName<span class="token punctuation">,</span>        dockerClient<span class="token punctuation">:</span>                   kubeDeps<span class="token punctuation">.</span>DockerClient<span class="token punctuation">,</span>        kubeClient<span class="token punctuation">:</span>                     kubeClient<span class="token punctuation">,</span>        <span class="token operator">...</span><span class="token operator">...</span>        clusterDomain<span class="token punctuation">:</span>                  kubeCfg<span class="token punctuation">.</span>ClusterDomain<span class="token punctuation">,</span>        clusterDNS<span class="token punctuation">:</span>                     net<span class="token punctuation">.</span><span class="token function">ParseIP</span><span class="token punctuation">(</span>kubeCfg<span class="token punctuation">.</span>ClusterDNS<span class="token punctuation">)</span><span class="token punctuation">,</span>        serviceLister<span class="token punctuation">:</span>                  serviceLister<span class="token punctuation">,</span>        nodeLister<span class="token punctuation">:</span>                     nodeLister<span class="token punctuation">,</span>        nodeInfo<span class="token punctuation">:</span>                       nodeInfo<span class="token punctuation">,</span>        masterServiceNamespace<span class="token punctuation">:</span>         kubeCfg<span class="token punctuation">.</span>MasterServiceNamespace<span class="token punctuation">,</span>        streamingConnectionIdleTimeout<span class="token punctuation">:</span> kubeCfg<span class="token punctuation">.</span>StreamingConnectionIdleTimeout<span class="token punctuation">.</span>Duration<span class="token punctuation">,</span>        recorder<span class="token punctuation">:</span>                       kubeDeps<span class="token punctuation">.</span>Recorder<span class="token punctuation">,</span>        cadvisor<span class="token punctuation">:</span>                       kubeDeps<span class="token punctuation">.</span>CAdvisorInterface<span class="token punctuation">,</span>        diskSpaceManager<span class="token punctuation">:</span>               diskSpaceManager<span class="token punctuation">,</span>        <span class="token operator">...</span><span class="token operator">...</span>    <span class="token punctuation">}</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token comment" spellcheck="true">// 网络插件的初始化工作</span>    <span class="token keyword">if</span> plug<span class="token punctuation">,</span> err <span class="token operator">:=</span> network<span class="token punctuation">.</span><span class="token function">InitNetworkPlugin</span><span class="token punctuation">(</span>kubeDeps<span class="token punctuation">.</span>NetworkPlugins<span class="token punctuation">,</span> kubeCfg<span class="token punctuation">.</span>NetworkPluginName<span class="token punctuation">,</span> <span class="token operator">&amp;</span>criNetworkHost<span class="token punctuation">{</span><span class="token operator">&amp;</span>networkHost<span class="token punctuation">{</span>klet<span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">,</span> klet<span class="token punctuation">.</span>hairpinMode<span class="token punctuation">,</span> klet<span class="token punctuation">.</span>nonMasqueradeCIDR<span class="token punctuation">,</span> <span class="token function">int</span><span class="token punctuation">(</span>kubeCfg<span class="token punctuation">.</span>NetworkPluginMTU<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token boolean">nil</span><span class="token punctuation">,</span> err    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>        klet<span class="token punctuation">.</span>networkPlugin <span class="token operator">=</span> plug    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 从 cAdvisor 获取当前机器的信息</span>    machineInfo<span class="token punctuation">,</span> err <span class="token operator">:=</span> klet<span class="token punctuation">.</span><span class="token function">GetCachedMachineInfo</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token operator">...</span><span class="token operator">...</span>    procFs <span class="token operator">:=</span> procfs<span class="token punctuation">.</span><span class="token function">NewProcFS</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    imageBackOff <span class="token operator">:=</span> flowcontrol<span class="token punctuation">.</span><span class="token function">NewBackOff</span><span class="token punctuation">(</span>backOffPeriod<span class="token punctuation">,</span> MaxContainerBackOff<span class="token punctuation">)</span>    klet<span class="token punctuation">.</span>livenessManager <span class="token operator">=</span> proberesults<span class="token punctuation">.</span><span class="token function">NewManager</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// podManager 负责管理当前节点上的 pod 信息，它保存了所有 pod 的内容，包括 static pod。</span>    <span class="token comment" spellcheck="true">// kubelet 从本地文件、网络地址和 apiserver 三个地方获取 pod 的内容，</span>    klet<span class="token punctuation">.</span>podCache <span class="token operator">=</span> kubecontainer<span class="token punctuation">.</span><span class="token function">NewCache</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    klet<span class="token punctuation">.</span>podManager <span class="token operator">=</span> kubepod<span class="token punctuation">.</span><span class="token function">NewBasicPodManager</span><span class="token punctuation">(</span>kubepod<span class="token punctuation">.</span><span class="token function">NewBasicMirrorClient</span><span class="token punctuation">(</span>klet<span class="token punctuation">.</span>kubeClient<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token comment" spellcheck="true">// 创建 runtime 对象，以后会改用 CRI 接口和 runtime 交互，目前使用 DockerManager</span>    <span class="token keyword">if</span> kubeCfg<span class="token punctuation">.</span>EnableCRI <span class="token punctuation">{</span>        <span class="token operator">...</span><span class="token operator">...</span>    <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span>        <span class="token keyword">switch</span> kubeCfg<span class="token punctuation">.</span>ContainerRuntime <span class="token punctuation">{</span>        <span class="token keyword">case</span> <span class="token string">"docker"</span><span class="token punctuation">:</span>            runtime <span class="token operator">:=</span> dockertools<span class="token punctuation">.</span><span class="token function">NewDockerManager</span><span class="token punctuation">(</span>                kubeDeps<span class="token punctuation">.</span>DockerClient<span class="token punctuation">,</span>                kubecontainer<span class="token punctuation">.</span><span class="token function">FilterEventRecorder</span><span class="token punctuation">(</span>kubeDeps<span class="token punctuation">.</span>Recorder<span class="token punctuation">)</span><span class="token punctuation">,</span>                klet<span class="token punctuation">.</span>livenessManager<span class="token punctuation">,</span>                containerRefManager<span class="token punctuation">,</span>                klet<span class="token punctuation">.</span>podManager<span class="token punctuation">,</span>                machineInfo<span class="token punctuation">,</span>                kubeCfg<span class="token punctuation">.</span>PodInfraContainerImage<span class="token punctuation">,</span>                <span class="token function">float32</span><span class="token punctuation">(</span>kubeCfg<span class="token punctuation">.</span>RegistryPullQPS<span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token function">int</span><span class="token punctuation">(</span>kubeCfg<span class="token punctuation">.</span>RegistryBurst<span class="token punctuation">)</span><span class="token punctuation">,</span>                ContainerLogsDir<span class="token punctuation">,</span>                kubeDeps<span class="token punctuation">.</span>OSInterface<span class="token punctuation">,</span>                klet<span class="token punctuation">.</span>networkPlugin<span class="token punctuation">,</span>                klet<span class="token punctuation">,</span>                klet<span class="token punctuation">.</span>httpClient<span class="token punctuation">,</span>                dockerExecHandler<span class="token punctuation">,</span>                kubeDeps<span class="token punctuation">.</span>OOMAdjuster<span class="token punctuation">,</span>                procFs<span class="token punctuation">,</span>                klet<span class="token punctuation">.</span>cpuCFSQuota<span class="token punctuation">,</span>                imageBackOff<span class="token punctuation">,</span>                kubeCfg<span class="token punctuation">.</span>SerializeImagePulls<span class="token punctuation">,</span>                kubeCfg<span class="token punctuation">.</span>EnableCustomMetrics<span class="token punctuation">,</span>                klet<span class="token punctuation">.</span>hairpinMode <span class="token operator">==</span> componentconfig<span class="token punctuation">.</span>HairpinVeth <span class="token operator">&amp;&amp;</span> kubeCfg<span class="token punctuation">.</span>NetworkPluginName <span class="token operator">!=</span> <span class="token string">"kubenet"</span><span class="token punctuation">,</span>                kubeCfg<span class="token punctuation">.</span>SeccompProfileRoot<span class="token punctuation">,</span>                kubeDeps<span class="token punctuation">.</span>ContainerRuntimeOptions<span class="token operator">...</span><span class="token punctuation">,</span>            <span class="token punctuation">)</span>            klet<span class="token punctuation">.</span>containerRuntime <span class="token operator">=</span> runtime            klet<span class="token punctuation">.</span>runner <span class="token operator">=</span> kubecontainer<span class="token punctuation">.</span><span class="token function">DirectStreamingRunner</span><span class="token punctuation">(</span>runtime<span class="token punctuation">)</span>        <span class="token keyword">case</span> <span class="token string">"rkt"</span><span class="token punctuation">:</span>            <span class="token operator">...</span><span class="token operator">...</span>        <span class="token keyword">default</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">nil</span><span class="token punctuation">,</span> fmt<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"unsupported container runtime %q specified"</span><span class="token punctuation">,</span> kubeCfg<span class="token punctuation">.</span>ContainerRuntime<span class="token punctuation">)</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span>    <span class="token operator">...</span><span class="token operator">...</span>    klet<span class="token punctuation">.</span>pleg <span class="token operator">=</span> pleg<span class="token punctuation">.</span><span class="token function">NewGenericPLEG</span><span class="token punctuation">(</span>klet<span class="token punctuation">.</span>containerRuntime<span class="token punctuation">,</span> plegChannelCapacity<span class="token punctuation">,</span> plegRelistPeriod<span class="token punctuation">,</span> klet<span class="token punctuation">.</span>podCache<span class="token punctuation">,</span> clock<span class="token punctuation">.</span>RealClock<span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span>    klet<span class="token punctuation">.</span>runtimeState <span class="token operator">=</span> <span class="token function">newRuntimeState</span><span class="token punctuation">(</span>maxWaitForContainerRuntime<span class="token punctuation">)</span>    klet<span class="token punctuation">.</span><span class="token function">updatePodCIDR</span><span class="token punctuation">(</span>kubeCfg<span class="token punctuation">.</span>PodCIDR<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 创建 containerGC 对象，进行周期性的容器清理工作</span>    containerGC<span class="token punctuation">,</span> err <span class="token operator">:=</span> kubecontainer<span class="token punctuation">.</span><span class="token function">NewContainerGC</span><span class="token punctuation">(</span>klet<span class="token punctuation">.</span>containerRuntime<span class="token punctuation">,</span> containerGCPolicy<span class="token punctuation">)</span>    <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token boolean">nil</span><span class="token punctuation">,</span> err    <span class="token punctuation">}</span>    klet<span class="token punctuation">.</span>containerGC <span class="token operator">=</span> containerGC    klet<span class="token punctuation">.</span>containerDeletor <span class="token operator">=</span> <span class="token function">newPodContainerDeletor</span><span class="token punctuation">(</span>klet<span class="token punctuation">.</span>containerRuntime<span class="token punctuation">,</span> integer<span class="token punctuation">.</span><span class="token function">IntMax</span><span class="token punctuation">(</span>containerGCPolicy<span class="token punctuation">.</span>MaxPerPodContainer<span class="token punctuation">,</span> minDeadContainerInPod<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 创建 imageManager 对象，管理镜像</span>    imageManager<span class="token punctuation">,</span> err <span class="token operator">:=</span> images<span class="token punctuation">.</span><span class="token function">NewImageGCManager</span><span class="token punctuation">(</span>klet<span class="token punctuation">.</span>containerRuntime<span class="token punctuation">,</span> kubeDeps<span class="token punctuation">.</span>CAdvisorInterface<span class="token punctuation">,</span> kubeDeps<span class="token punctuation">.</span>Recorder<span class="token punctuation">,</span> nodeRef<span class="token punctuation">,</span> imageGCPolicy<span class="token punctuation">)</span>    <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token boolean">nil</span><span class="token punctuation">,</span> fmt<span class="token punctuation">.</span><span class="token function">Errorf</span><span class="token punctuation">(</span><span class="token string">"failed to initialize image manager: %v"</span><span class="token punctuation">,</span> err<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    klet<span class="token punctuation">.</span>imageManager <span class="token operator">=</span> imageManager    <span class="token comment" spellcheck="true">// statusManager 实时检测节点上 pod 的状态，并更新到 apiserver 对应的 pod </span>    klet<span class="token punctuation">.</span>statusManager <span class="token operator">=</span> status<span class="token punctuation">.</span><span class="token function">NewManager</span><span class="token punctuation">(</span>kubeClient<span class="token punctuation">,</span> klet<span class="token punctuation">.</span>podManager<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// probeManager 检测 pod 的状态，并通过 statusManager 进行更新</span>    klet<span class="token punctuation">.</span>probeManager <span class="token operator">=</span> prober<span class="token punctuation">.</span><span class="token function">NewManager</span><span class="token punctuation">(</span>        klet<span class="token punctuation">.</span>statusManager<span class="token punctuation">,</span>        klet<span class="token punctuation">.</span>livenessManager<span class="token punctuation">,</span>        klet<span class="token punctuation">.</span>runner<span class="token punctuation">,</span>        containerRefManager<span class="token punctuation">,</span>        kubeDeps<span class="token punctuation">.</span>Recorder<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// volumeManager 管理节点上 volume</span>    klet<span class="token punctuation">.</span>volumePluginMgr<span class="token punctuation">,</span> err <span class="token operator">=</span>        <span class="token function">NewInitializedVolumePluginMgr</span><span class="token punctuation">(</span>klet<span class="token punctuation">,</span> kubeDeps<span class="token punctuation">.</span>VolumePlugins<span class="token punctuation">)</span>    <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token boolean">nil</span><span class="token punctuation">,</span> err    <span class="token punctuation">}</span>    <span class="token operator">...</span><span class="token operator">...</span>    <span class="token comment" spellcheck="true">// setup volumeManager</span>    klet<span class="token punctuation">.</span>volumeManager<span class="token punctuation">,</span> err <span class="token operator">=</span> volumemanager<span class="token punctuation">.</span><span class="token function">NewVolumeManager</span><span class="token punctuation">(</span>        kubeCfg<span class="token punctuation">.</span>EnableControllerAttachDetach<span class="token punctuation">,</span>        nodeName<span class="token punctuation">,</span>        klet<span class="token punctuation">.</span>podManager<span class="token punctuation">,</span>        klet<span class="token punctuation">.</span>kubeClient<span class="token punctuation">,</span>        klet<span class="token punctuation">.</span>volumePluginMgr<span class="token punctuation">,</span>        klet<span class="token punctuation">.</span>containerRuntime<span class="token punctuation">,</span>        kubeDeps<span class="token punctuation">.</span>Mounter<span class="token punctuation">,</span>        klet<span class="token punctuation">.</span><span class="token function">getPodsDir</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        kubeDeps<span class="token punctuation">.</span>Recorder<span class="token punctuation">,</span>        kubeCfg<span class="token punctuation">.</span>ExperimentalCheckNodeCapabilitiesBeforeMount<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 保存了节点上正在运行的 pod 信息</span>    runtimeCache<span class="token punctuation">,</span> err <span class="token operator">:=</span> kubecontainer<span class="token punctuation">.</span><span class="token function">NewRuntimeCache</span><span class="token punctuation">(</span>klet<span class="token punctuation">.</span>containerRuntime<span class="token punctuation">)</span>    <span class="token keyword">if</span> err <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token keyword">return</span> <span class="token boolean">nil</span><span class="token punctuation">,</span> err    <span class="token punctuation">}</span>    klet<span class="token punctuation">.</span>runtimeCache <span class="token operator">=</span> runtimeCache    klet<span class="token punctuation">.</span>reasonCache <span class="token operator">=</span> <span class="token function">NewReasonCache</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    klet<span class="token punctuation">.</span>workQueue <span class="token operator">=</span> queue<span class="token punctuation">.</span><span class="token function">NewBasicWorkQueue</span><span class="token punctuation">(</span>klet<span class="token punctuation">.</span>clock<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// podWorkers 是具体的执行者</span>    klet<span class="token punctuation">.</span>podWorkers <span class="token operator">=</span> <span class="token function">newPodWorkers</span><span class="token punctuation">(</span>klet<span class="token punctuation">.</span>syncPod<span class="token punctuation">,</span> kubeDeps<span class="token punctuation">.</span>Recorder<span class="token punctuation">,</span> klet<span class="token punctuation">.</span>workQueue<span class="token punctuation">,</span> klet<span class="token punctuation">.</span>resyncInterval<span class="token punctuation">,</span> backOffPeriod<span class="token punctuation">,</span> klet<span class="token punctuation">.</span>podCache<span class="token punctuation">)</span>    <span class="token operator">...</span><span class="token operator">...</span>    klet<span class="token punctuation">.</span>kubeletConfiguration <span class="token operator">=</span> <span class="token operator">*</span>kubeCfg    <span class="token keyword">return</span> klet<span class="token punctuation">,</span> <span class="token boolean">nil</span><span class="token punctuation">}</span></code></pre><p><code>NewMainKubelet</code> 正如名字所示，主要的工作就是创建 <code>Kubelet</code> 这个对象，它包含了 kubelet 运行需要的所有对象，上面的代码就是各种对象的初始化和赋值的过程，这里只介绍几个非常重要的对象来说：</p><ul><li>podConfig：这个对象里面会从文件、网络和 apiserver 三个来源中汇聚节点要运行的 pod 信息，并通过管道发送出来，读取这个管道就能获取实时的 pod 最新配置</li><li>ServiceLister：能够读取 kubernetes 中服务信息</li><li>nodeLister：能够读取 apiserver 中节点的信息</li><li>diskSpaceManager：返回容器存储空间的信息</li><li>podManager：缓存了 pod 的信息，是所有需要该信息都会去访问的地方</li><li>runtime：容器运行时，对容器引擎（docker 或者 rkt）的一层封装，负责调用容器引擎接口管理容器的状态，比如启动、暂停、杀死容器等</li><li>probeManager：如果 pod 配置了状态监测，那么 probeManager 会定时检查 pod 是否正常工作，并通过 statusManager 向 apiserver 更新 pod 的状态</li><li>volumeManager：负责容器需要的 volume 管理。检测某个 volume 是否已经 mount、获取 pod 使用的 volume 等</li><li>podWorkers：具体的执行者，每次有 pod 需要更新的时候都会发送给它</li></ul><p>这里并不一一展开所有对象的实现和具体功能，以后的文章会对其中一些继续分析。</p><h2 id="kubelet-的运行"><a href="#kubelet-的运行" class="headerlink" title="kubelet 的运行"></a>kubelet 的运行</h2><p>接着回到 kubelet 的分析，通过 <code>NewMainKubelet</code> 创建完 <code>Kubelet</code> 对象，下一步就是看看如果运行它。在 <code>RunKubelet</code> 内部，我们看到它最终会调用 <code>startKublet</code> 函数：</p><pre class=" language-go"><code class="language-go"><span class="token keyword">func</span> <span class="token function">startKubelet</span><span class="token punctuation">(</span>k kubelet<span class="token punctuation">.</span>KubeletBootstrap<span class="token punctuation">,</span> podCfg <span class="token operator">*</span>config<span class="token punctuation">.</span>PodConfig<span class="token punctuation">,</span> kubeCfg <span class="token operator">*</span>componentconfig<span class="token punctuation">.</span>KubeletConfiguration<span class="token punctuation">,</span> kubeDeps <span class="token operator">*</span>kubelet<span class="token punctuation">.</span>KubeletDeps<span class="token punctuation">)</span> <span class="token builtin">error</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">// 启动 kubelet</span>    <span class="token keyword">go</span> wait<span class="token punctuation">.</span><span class="token function">Until</span><span class="token punctuation">(</span><span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span> k<span class="token punctuation">.</span><span class="token function">Run</span><span class="token punctuation">(</span>podCfg<span class="token punctuation">.</span><span class="token function">Updates</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> wait<span class="token punctuation">.</span>NeverStop<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 启动 kubelet server</span>    <span class="token keyword">if</span> kubeCfg<span class="token punctuation">.</span>EnableServer <span class="token punctuation">{</span>        <span class="token keyword">go</span> wait<span class="token punctuation">.</span><span class="token function">Until</span><span class="token punctuation">(</span><span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            k<span class="token punctuation">.</span><span class="token function">ListenAndServe</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span><span class="token function">ParseIP</span><span class="token punctuation">(</span>kubeCfg<span class="token punctuation">.</span>Address<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">uint</span><span class="token punctuation">(</span>kubeCfg<span class="token punctuation">.</span>Port<span class="token punctuation">)</span><span class="token punctuation">,</span> kubeDeps<span class="token punctuation">.</span>TLSOptions<span class="token punctuation">,</span> kubeDeps<span class="token punctuation">.</span>Auth<span class="token punctuation">,</span> kubeCfg<span class="token punctuation">.</span>EnableDebuggingHandlers<span class="token punctuation">)</span>        <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> wait<span class="token punctuation">.</span>NeverStop<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token keyword">if</span> kubeCfg<span class="token punctuation">.</span>ReadOnlyPort <span class="token operator">></span> <span class="token number">0</span> <span class="token punctuation">{</span>        <span class="token keyword">go</span> wait<span class="token punctuation">.</span><span class="token function">Until</span><span class="token punctuation">(</span><span class="token keyword">func</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>            k<span class="token punctuation">.</span><span class="token function">ListenAndServeReadOnly</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span><span class="token function">ParseIP</span><span class="token punctuation">(</span>kubeCfg<span class="token punctuation">.</span>Address<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">uint</span><span class="token punctuation">(</span>kubeCfg<span class="token punctuation">.</span>ReadOnlyPort<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> wait<span class="token punctuation">.</span>NeverStop<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token keyword">return</span> <span class="token boolean">nil</span><span class="token punctuation">}</span></code></pre><p>运行 kubelet 主要启动两个功能，<code>k.Run()</code> 来进入主循环，<code>k.ListenAndServe()</code> 启动 kubelet 的 API 服务，后者并不是这篇文章的重点，我们来看看前者，它的执行入口是 <code>k.Run(podCfg.Updates())</code>，<code>podCfg.Updates()</code> 我们前面已经说过，它是一个管道，会实时地发送过来 pod 最新的配置信息，至于是怎么实现的，我们以后再说，这里知道它的作用就行。<code>Run</code> 方法的代码如下：</p><pre class=" language-go"><code class="language-go"><span class="token operator">/</span> Run starts the kubelet reacting to config updates<span class="token keyword">func</span> <span class="token punctuation">(</span>kl <span class="token operator">*</span>Kubelet<span class="token punctuation">)</span> <span class="token function">Run</span><span class="token punctuation">(</span>updates <span class="token operator">&lt;-</span><span class="token keyword">chan</span> kubetypes<span class="token punctuation">.</span>PodUpdate<span class="token punctuation">)</span> <span class="token punctuation">{</span>    <span class="token operator">...</span><span class="token punctuation">.</span><span class="token punctuation">.</span>    <span class="token comment" spellcheck="true">// Start volume manager</span>    <span class="token keyword">go</span> kl<span class="token punctuation">.</span>volumeManager<span class="token punctuation">.</span><span class="token function">Run</span><span class="token punctuation">(</span>kl<span class="token punctuation">.</span>sourcesReady<span class="token punctuation">,</span> wait<span class="token punctuation">.</span>NeverStop<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 定时向 apiserver 更新 node 信息，用作调度时的重要参考</span>    <span class="token keyword">if</span> kl<span class="token punctuation">.</span>kubeClient <span class="token operator">!=</span> <span class="token boolean">nil</span> <span class="token punctuation">{</span>        <span class="token comment" spellcheck="true">// Start syncing node status immediately, this may set up things the runtime needs to run.</span>        <span class="token keyword">go</span> wait<span class="token punctuation">.</span><span class="token function">Until</span><span class="token punctuation">(</span>kl<span class="token punctuation">.</span>syncNodeStatus<span class="token punctuation">,</span> kl<span class="token punctuation">.</span>nodeStatusUpdateFrequency<span class="token punctuation">,</span> wait<span class="token punctuation">.</span>NeverStop<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token keyword">go</span> wait<span class="token punctuation">.</span><span class="token function">Until</span><span class="token punctuation">(</span>kl<span class="token punctuation">.</span>syncNetworkStatus<span class="token punctuation">,</span> <span class="token number">30</span><span class="token operator">*</span>time<span class="token punctuation">.</span>Second<span class="token punctuation">,</span> wait<span class="token punctuation">.</span>NeverStop<span class="token punctuation">)</span>    <span class="token keyword">go</span> wait<span class="token punctuation">.</span><span class="token function">Until</span><span class="token punctuation">(</span>kl<span class="token punctuation">.</span>updateRuntimeUp<span class="token punctuation">,</span> <span class="token number">5</span><span class="token operator">*</span>time<span class="token punctuation">.</span>Second<span class="token punctuation">,</span> wait<span class="token punctuation">.</span>NeverStop<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// Start loop to sync iptables util rules</span>    <span class="token keyword">if</span> kl<span class="token punctuation">.</span>makeIPTablesUtilChains <span class="token punctuation">{</span>        <span class="token keyword">go</span> wait<span class="token punctuation">.</span><span class="token function">Until</span><span class="token punctuation">(</span>kl<span class="token punctuation">.</span>syncNetworkUtil<span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">*</span>time<span class="token punctuation">.</span>Minute<span class="token punctuation">,</span> wait<span class="token punctuation">.</span>NeverStop<span class="token punctuation">)</span>    <span class="token punctuation">}</span>    <span class="token comment" spellcheck="true">// 删除 podWorker 没有正常处理的 pod </span>    <span class="token keyword">go</span> wait<span class="token punctuation">.</span><span class="token function">Until</span><span class="token punctuation">(</span>kl<span class="token punctuation">.</span>podKiller<span class="token punctuation">,</span> <span class="token number">1</span><span class="token operator">*</span>time<span class="token punctuation">.</span>Second<span class="token punctuation">,</span> wait<span class="token punctuation">.</span>NeverStop<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// Start component sync loops.</span>    <span class="token comment" spellcheck="true">// 管理 pod 和容器的状态</span>    kl<span class="token punctuation">.</span>statusManager<span class="token punctuation">.</span><span class="token function">Start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// readiness 和 liveness 管理</span>    kl<span class="token punctuation">.</span>probeManager<span class="token punctuation">.</span><span class="token function">Start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// pleg  的全称是 Pod Lifecycle Event Generator</span>    kl<span class="token punctuation">.</span>pleg<span class="token punctuation">.</span><span class="token function">Start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">// 宫殿的入口</span>    kl<span class="token punctuation">.</span><span class="token function">syncLoop</span><span class="token punctuation">(</span>updates<span class="token punctuation">,</span> kl<span class="token punctuation">)</span><span class="token punctuation">}</span></code></pre><p>基本上就是 <code>kubelet</code> 各种组件的启动，每个组件都是以 goroutine 运行的，这里不做赘述。最后一句 <code>kl.syncLoop(updates, kl)</code> 是处理所有 pod 更新的主循环，获取 pod 的变化（新建、修改和删除），调用对应的处理函数保证节点上的容器符合 pod 的配置。</p><p>如果 kubelet 是做宫殿，那么 <code>syncLoop</code> 就是这座宫殿的入口。我们从很远的地方出发，穿过丛林、越过高山，一路上到处问路，经过一座座的城镇，终于抵达都城。穿行过眼花缭乱的商铺、士兵、民宅，站在金碧辉煌巍峨高大的宫殿门口，心中一定激情澎湃。</p><p>在下一篇文章，我们就要打开宫殿大门，一探其中究竟。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://www.webpaas.com/index.php/archives/120/" target="_blank" rel="noopener">k8s kubelet源码剖析</a></li><li><a href="http://licyhust.com/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/2016/10/20/kubelet-1/" target="_blank" rel="noopener">kubelet源码解析(1)</a></li><li><a href="http://www.sel.zju.edu.cn/?p=595" target="_blank" rel="noopener">KUBERNETES NODE COMPONENTS – KUBELET</a></li><li><a href="http://blog.csdn.net/zhaoguoguang/article/details/51225553" target="_blank" rel="noopener">kubernetes源码分析 – kubelet组件</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;kubelet-简介&quot;&gt;&lt;a href=&quot;#kubelet-简介&quot; class=&quot;headerlink&quot; title=&quot;kubelet 简介&quot;&gt;&lt;/a&gt;kubelet 简介&lt;/h2&gt;&lt;p&gt;我在&lt;a
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="kubernetes" scheme="http://cizixs.com/tags/kubernetes/"/>
    
      <category term="container" scheme="http://cizixs.com/tags/container/"/>
    
      <category term="golang" scheme="http://cizixs.com/tags/golang/"/>
    
      <category term="kubelet" scheme="http://cizixs.com/tags/kubelet/"/>
    
  </entry>
  
  <entry>
    <title>CNI：容器网络接口</title>
    <link href="http://cizixs.com/2017/05/23/container-network-cni/"/>
    <id>http://cizixs.com/2017/05/23/container-network-cni/</id>
    <published>2017-05-22T16:00:00.000Z</published>
    <updated>2018-09-17T13:18:45.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="CNI-简介"><a href="#CNI-简介" class="headerlink" title="CNI 简介"></a>CNI 简介</h2><p>不管是 docker 还是 kubernetes，在网络方面目前都没有一个完美的、终极的、普适性的解决方案，不同的用户和企业因为各种原因会使用不同的网络方案。目前存在网络方案 flannel、calico、openvswitch、weave、ipvlan等，而且以后一定会有其他的网络方案，这些方案接口和使用方法都不相同，而不同的容器平台都需要网络功能，它们之间的适配如果没有统一的标准，会有很大的工作量和重复劳动。</p><p>CNI 就是这样一个标准，它旨在为容器平台提供网络的标准化。不同的容器平台（比如目前的 kubernetes、mesos 和 rkt）能够通过相同的接口调用不同的网络组件。</p><p>CNI(Conteinre Network Interface) 是 google 和 CoreOS 主导制定的容器网络标准，它 本身并不是实现或者代码，可以理解成一个协议。这个标准是在 <a href="https://docs.google.com/a/coreos.com/document/d/1PUeV68q9muEmkHmRuW10HQ6cHgd4819_67pIxDRVNlM/edit#heading=h.ievko3xsjwxd" target="_blank" rel="noopener">rkt 网络提议</a> 的基础上发展起来的，综合考虑了灵活性、扩展性、ip 分配、多网卡等因素。</p><p>这个协议连接了两个组件：容器管理系统和网络插件。它们之间通过 JSON 格式的文件进行通信，实现容器的网络功能。具体的事情都是插件来实现的，包括：创建容器网络空间（network namespace）、把网络接口（interface）放到对应的网络空间、给网络接口分配 IP 等等。</p><p><img src="https://cdn.thenewstack.io/media/2016/09/Chart_Container-Network-Interface-Drivers.png" alt=""></p><p>关于网络，docker 也提出了 CNM 标准，它要解决的问题和 CNI 是重合的，也就是说目前两者是竞争关系。目前 CNM 只能使用在 docker 中，而 CNI 可以使用在任何容器运行时。CNM 主要用来实现 docker 自身的网络问题，也就是 <code>docker network</code> 子命令提供的功能。</p><h2 id="官方网络插件"><a href="#官方网络插件" class="headerlink" title="官方网络插件"></a>官方网络插件</h2><p>所有的标准和协议都要有具体的实现，才能够被大家使用。CNI 也不例外，目前官方在 github 上维护了同名的 <a href="https://github.com/containernetworking/cni" target="_blank" rel="noopener">CNI</a> 代码库，里面已经有很多可以直接拿来使用的 CNI 插件。</p><p>官方提供的插件目前分成三类：main、meta 和 ipam。main 是主要的实现了某种特定网络功能的插件；meta 本身并不会提供具体的网络功能，它会调用其他插件，或者单纯是为了测试；ipam 是分配 IP 地址的插件。</p><p>ipam 并不提供某种网络功能，只是为了灵活性把它单独抽象出来，这样不同的网络插件可以根据需求选择 ipam，或者实现自己的 ipam。</p><p>这些插件的功能说明如下：</p><ul><li>main<ul><li>loopback：这个插件很简单，负责生成 <code>lo</code> 网卡，并配置上 <code>127.0.0.1/8</code> 地址</li><li>bridge：和 docker 默认的网络模型很像，把所有的容器连接到虚拟交换机上</li><li>macvlan：使用 macvlan 技术，从某个物理网卡虚拟出多个虚拟网卡，它们有独立的 ip 和 mac 地址</li><li>ipvlan：和 macvlan 类似，区别是虚拟网卡有着相同的 mac 地址</li><li>ptp：通过 veth pair 在容器和主机之间建立通道</li></ul></li><li>meta<ul><li>flannel：结合 bridge 插件使用，根据 flannel 分配的网段信息，调用 bridge 插件，保证多主机情况下容器</li></ul></li><li>ipam<ul><li>host-local：基于本地文件的 ip 分配和管理，把分配的 IP 地址保存在文件中</li><li>dhcp：从已经运行的 DHCP 服务器中获取 ip 地址</li></ul></li></ul><h2 id="接口参数"><a href="#接口参数" class="headerlink" title="接口参数"></a>接口参数</h2><p>网络插件是独立的可执行文件，被上层的容器管理平台调用。网络插件只有两件事情要做：把容器加入到网络以及把容器从网络中删除。调用插件的数据通过两种方式传递：环境变量和标准输入。一般插件需要三种类型的数据：容器相关的信息，比如 ns 的文件、容器 id 等；网络配置的信息，包括网段、网关、DNS 以及插件额外的信息等；还有就是 CNI 本身的信息，比如 CNI 插件的位置、添加网络还是删除网络。</p><p>我们来看一下为容器添加网络是怎么工作的，删除网络和它过程一样。</p><p><strong>把容器加入到网络</strong></p><p>调用插件的时候，这些参数会通过环境变量进行传递：</p><ul><li><code>CNI_COMMAND</code>：要执行的操作，可以是 <code>ADD</code>（把容器加入到某个网络）、<code>DEL</code>（把容器从某个网络中删除）</li><li><code>CNI_CONTAINERID</code>：容器的 ID，比如 ipam 会把容器 ID 和分配的 IP 地址保存下来。可选的参数，但是推荐传递过去。需要保证在管理平台上是唯一的，如果容器被删除后可以循环使用</li><li><code>CNI_NETNS</code>：容器的 network namespace 文件，访问这个文件可以在容器的网络 namespace 中操作</li><li><code>CNI_IFNAME</code>：要配置的 interface 名字，比如 <code>eth0</code></li><li><code>CNI_ARGS</code>：额外的参数，是由分号<code>;</code>分割的键值对，比如 “FOO=BAR;hello=world”</li><li><code>CNI_PATH</code>：CNI 二进制查找的路径列表，多个路径用分隔符 <code>:</code> 分隔</li></ul><p>网络信息主要通过标准输入，作为 JSON 字符串传递给插件，必须的参数包括：</p><ul><li><code>cniVersion</code>：CNI 标准的版本号。因为 CNI 在演化过程中，不同的版本有不同的要求</li><li><code>name</code>：网络的名字，在集群中应该保持唯一</li><li><code>type</code>：网络插件的类型，也就是 CNI 可执行文件的名称</li><li><code>args</code>：额外的信息，类型为字典</li><li><code>ipMasq</code>：是否在主机上为该网络配置 IP masquerade</li><li><code>ipam</code>：IP 分配相关的信息，类型为字典</li><li><code>dns</code>：DNS 相关的信息，类型为字典</li></ul><p>插件接到这些数据，从输入和环境变量解析到需要的信息，根据这些信息执行程序逻辑，然后把结果返回给调用者，返回的结果中一般包括这些参数：</p><ul><li>IPs assigned to the interface：网络接口被分配的 ip，可以是 IPv4、IPv6 或者都有</li><li>DNS 信息：包含 nameservers、domain、search domains 和其他选项的字典</li></ul><p>CNI 协议的内容还在不断更新，请到<a href="https://github.com/containernetworking/cni/blob/master/SPEC.md" target="_blank" rel="noopener">官方文档</a>获取当前的信息。</p><h2 id="CNI-的特性"><a href="#CNI-的特性" class="headerlink" title="CNI 的特性"></a>CNI 的特性</h2><p>CNI 作为一个协议/标准，它有很强的扩展性和灵活性。如果用户对某个插件有额外的需求，可以通过输入中的 <code>args</code> 和环境变量 <code>CNI_ARGS</code> 传输，然后在插件中实现自定义的功能，这大大增加了它的扩展性；CNI 插件把 main 和 ipam 分开，用户可以自由组合它们，而且一个 CNI 插件也可以直接调用另外一个 CNI 插件，使用起来非常灵活。</p><p>如果要实现一个继承性的 CNI 插件也不复杂，可以编写自己的 CNI 插件，根据传入的配置调用 main 中已经有的插件，就能让用户自由选择容器的网络。</p><h2 id="在-kubernetes-中的使用"><a href="#在-kubernetes-中的使用" class="headerlink" title="在 kubernetes 中的使用"></a>在 kubernetes 中的使用</h2><p>CNI 目前已经在 kubernetes 中开始使用，也是目前官方推荐的网络方案，具体的配置方法可以参考<a href="https://kubernetes.io/docs/concepts/cluster-administration/network-plugins/#cni" target="_blank" rel="noopener">kubernetes 官方文档</a>。</p><p>kubernetes 使用了 CNI 网络插件之后，工作过程是这样的：</p><ul><li>kubernetes 先创建 pause 容器生成对应的 network namespace</li><li>调用网络 driver（因为配置的是 CNI，所以会调用 CNI 相关代码）</li><li>CNI driver 根据配置调用具体的 cni 插件</li><li>cni 插件给 pause 容器配置正确的网络</li><li>pod 中其他的容器都是用 pause 的网络</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://github.com/containernetworking/cni/blob/master/SPEC.md" target="_blank" rel="noopener">CNI spec 文档</a></li><li><a href="http://murat1985.github.io/kubernetes/cni/2016/05/14/netns-and-cni.html" target="_blank" rel="noopener">Linux Network namespaces and CNI</a></li><li><a href="https://thenewstack.io/container-networking-landscape-cni-coreos-cnm-docker/" target="_blank" rel="noopener">The container networking landscape: cni from coreos and cnm from docker</a></li><li><a href="http://linuxplumbersconf.org/2015/ocw/system/presentations/3357/original/LPC_-_CNI_and_OCI.pdf" target="_blank" rel="noopener">CNI and OCI</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;CNI-简介&quot;&gt;&lt;a href=&quot;#CNI-简介&quot; class=&quot;headerlink&quot; title=&quot;CNI 简介&quot;&gt;&lt;/a&gt;CNI 简介&lt;/h2&gt;&lt;p&gt;不管是 docker 还是
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="kubernetes" scheme="http://cizixs.com/tags/kubernetes/"/>
    
      <category term="container" scheme="http://cizixs.com/tags/container/"/>
    
      <category term="network" scheme="http://cizixs.com/tags/network/"/>
    
      <category term="cni" scheme="http://cizixs.com/tags/cni/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes 亲和性调度</title>
    <link href="http://cizixs.com/2017/05/17/kubernetes-scheulder-affinity/"/>
    <id>http://cizixs.com/2017/05/17/kubernetes-scheulder-affinity/</id>
    <published>2017-05-16T16:00:00.000Z</published>
    <updated>2018-09-17T13:18:45.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="kubernetes-pod-调度简介"><a href="#kubernetes-pod-调度简介" class="headerlink" title="kubernetes pod 调度简介"></a>kubernetes pod 调度简介</h2><p>除了让 <a href="http://cizixs.com/2017/03/10/kubernetes-intro-scheduler">kubernetes 集群调度器</a>自动为 pod 资源选择某个节点（默认调度考虑的是资源足够，并且 load 尽量平均），有些情况我们希望能更多地控制 pod 应该如何调度。比如，集群中有些机器的配置更好（ SSD，更好的内存等），我们希望比较核心的服务（比如说数据库）运行在上面；或者某两个服务的网络传输很频繁，我们希望它们最好在同一台机器上，或者同一个机房。</p><p>这种调度在 kubernetes 中分为两类：node affinity 和 pod affinity。</p><h2 id="选择-node"><a href="#选择-node" class="headerlink" title="选择 node"></a>选择 node</h2><p>kubernetes 中有很多对 label 的使用，node 就是其中一例。label 可以让用户非常灵活地管理集群中的资源，service 选择 pod 就用到了 label。这篇文章介绍到的调度也是如此，可以根据节点的各种不同的特性添加 label，然后在调度的时候选择特定 label 的节点。</p><p>在使用这种方法之前，需要先给 node 加上 label，通过 <code>kubectl</code> 非常容易做：</p><pre><code>kubectl label nodes &lt;node-name&gt; &lt;label-key&gt;=&lt;label-value&gt;</code></pre><p>列出 node 的时候指定 <code>--show-labels</code> 参数就能查看 node 都添加了哪些 label：</p><pre><code>kubectl get nodes --show-labels</code></pre><p>node 有了 label ，在调度的时候就可以用到这些信息，用法也很简单，在 pod 的 spec 字段下面加上 <code>nodeSelector</code>，它里面保存的是多个键值对，表示节点上有对应的 label，并且值也匹配。还是举个例子看得明白，比如原来简单的 nginx pod：</p><pre><code>apiVersion: v1kind: Podmetadata:  name: nginx  labels:    env: testspec:  containers:  - name: nginx    image: nginx</code></pre><p>添加上 node 选择信息，就变成了下面这样：</p><pre><code>apiVersion: v1kind: Podmetadata:  name: nginx  labels:    env: testspec:  containers:  - name: nginx    image: nginx    imagePullPolicy: IfNotPresent  nodeSelector:    disktype: ssd</code></pre><p>这个例子就是告诉 kubernetes 调度的时候把 pod 放到有 SSD 磁盘的机器上。</p><p>除了自己定义的 label 之外，kubernetes 还会自动给集群中的节点添加一些 label，比如：</p><ul><li><code>kubernetes.io/hostname</code>：节点的 hostname 名称</li><li><code>beta.kubernetes.io/os</code>： 节点安装的操作系统</li><li><code>beta.kubernetes.io/arch</code>：节点的架构类型</li><li>……</li></ul><p>不同版本添加的 label 会有不同，这些 label 和手动添加的没有区别，可以通过 <code>--show-labels</code> 查看，也能够用在 <code>nodeSelector</code> 中。</p><p><strong>NOTE</strong>：nodeSelector 的方式比较简单直观，但是不够灵活。以后，它会被我们下面讲到的 <code>Node Affinity</code> 替代，请关注每个版本的 release note。</p><h2 id="Node-Affinity"><a href="#Node-Affinity" class="headerlink" title="Node Affinity"></a>Node Affinity</h2><p><code>Affinity</code> 翻译成中文是“亲和性”，它对应的是 <code>Anti-Affinity</code>，我们翻译成“互斥”。这两个词比较形象，可以把 pod 选择 node 的过程类比成磁铁的吸引和互斥，不同的是除了简单的正负极之外，pod 和 node 的吸引和互斥是可以灵活配置的。</p><p>kubernetes 1.2 版本开始引入这个概念，目前（1.6版本）处于 beta 阶段，相信后面会变成核心的功能。这种方法比 nodeSelector 复杂，但是也更灵活，提供了更精细的调度控制。它的优点包括：</p><ul><li>匹配有更多的逻辑组合，不只是字符的完全相等</li><li>调度分成软策略（soft）和硬策略（hard），在软策略的情况下，如果没有满足调度条件的节点，pod 会忽略这条规则，继续完成调度过程</li></ul><p>目前有两种主要的 node affinity： <code>requiredDuringSchedulingIgnoredDuringExecution</code> 和 <code>preferredDuringSchedulingIgnoredDuringExecution</code>。前者表示 pod 必须部署到满足条件的节点上，如果没有满足条件的节点，就不断重试；后者表示优先部署在满足条件的节点上，如果没有满足条件的节点，就忽略这些条件，按照正常逻辑部署。</p><p><code>IgnoredDuringExecution</code> 正如名字所说，pod 部署之后运行的时候，如果节点标签发生了变化，不再满足 pod 指定的条件，pod 也会继续运行。与之对应的是 <code>requiredDuringSchedulingRequiredDuringExecution</code>，如果运行的 pod 所在节点不再满足条件，kubernetes 会把 pod 从节点中删除，重新选择符合要求的节点。</p><p><strong>吐槽</strong>：命名果然是软件技术的难点之一，kubernetes 开发者命名采取的技巧是——简单粗暴：直接把需求用语言表达出来，这也导致这个名字看起来非常奇怪。</p><p>软策略和硬策略的区分是有用处的，硬策略适用于 pod 必须运行在某种节点，否则会出现问题的情况，比如集群中节点的架构不同，而运行的服务必须依赖某种架构提供的功能；软策略不同，它适用于满不满足条件都能工作，但是满足条件更好的情况，比如服务最好运行在某个区域，减少网络传输等。这种区分是用户的具体需求决定的，并没有绝对的技术依赖。</p><p>拿官方文档的例子来说明：</p><pre><code>apiVersion: v1kind: Podmetadata:  name: with-node-affinityspec:  affinity:    nodeAffinity:      requiredDuringSchedulingIgnoredDuringExecution:        nodeSelectorTerms:        - matchExpressions:          - key: kubernetes.io/e2e-az-name            operator: In            values:            - e2e-az1            - e2e-az2      preferredDuringSchedulingIgnoredDuringExecution:      - weight: 1        preference:          matchExpressions:          - key: another-node-label-key            operator: In            values:            - another-node-label-value  containers:  - name: with-node-affinity    image: gcr.io/google_containers/pause:2.0</code></pre><p>这个 pod 同时定义了 <code>requiredDuringSchedulingIgnoredDuringExecution</code> 和 <code>preferredDuringSchedulingIgnoredDuringExecution</code> 两种 nodeAffinity。第一个<strong>要求</strong> pod 运行在特定 AZ 的节点上，第二个<strong>希望</strong>节点最好有对应的 <code>another-node-label-key:another-node-label-value</code> 标签。</p><p>这里的匹配逻辑是 label 的值在某个列表中，可选的操作符有：</p><ul><li><code>In</code>：label 的值在某个列表中</li><li><code>NotIn</code>：label 的值不在某个列表中</li><li><code>Exists</code>：某个 label 存在</li><li><code>DoesNotExist</code>: 某个 label 不存在</li><li><code>Gt</code>：label 的值大于某个值（字符串比较）</li><li><code>Lt</code>：label 的值小于某个值（字符串比较）</li></ul><p>并没有 node anti-affinity 这种东西，因为 <code>Notin</code> 和 <code>DoesNotExist</code> 能提供类似的功能。</p><p>如果<code>nodeAffinity</code> 中 <code>nodeSelectorTerms</code> 有多个选项，如果节点满足任何一个条件就可以；如果 <code>matchExpressions</code> 有多个选项，则只有同时满足这些逻辑选项的节点才能运行 pod。</p><h3 id="Pod-Affinity"><a href="#Pod-Affinity" class="headerlink" title="Pod Affinity"></a>Pod Affinity</h3><p>通过上一部分内容的介绍，我们知道怎么在调度的时候让 pod 灵活地选择 node；但有些时候我们希望调度能够考虑 pod 之间的关系，而不只是 pod-node 的关系。pod affinity 是在 kubernetes1.4 版本引入的，目前在 1.6 版本也是 beta 功能。</p><p>为什么有这样的需求呢？举个例子，我们系统服务 A 和服务 B 尽量部署在同个主机、机房、城市，因为它们网络沟通比较多；再比如，我们系统数据服务 C 和数据服务 D 尽量分开，因为如果它们分配到一起，然后主机或者机房出了问题，会导致应用完全不可用，如果它们是分开的，应用虽然有影响，但还是可用的。</p><p>pod affinity 可以这样理解：调度的时候选择（或者不选择）这样的节点 N ，这些节点上已经运行了满足条件 X。条件 X 是一组 label 选择器，它必须指明作用的 namespace（也可以作用于所有的 namespace），因为 pod 是运行在某个 namespace 中的。</p><p>和 node affinity 相似，pod affinity 也有 <code>requiredDuringSchedulingIgnoredDuringExecution</code> 和 <code>preferredDuringSchedulingIgnoredDuringExecution</code>，意义也和之前一样。如果有使用亲和性，在 <code>affinity</code> 下面添加 <code>podAffinity</code> 字段，如果要使用互斥性，在 <code>affinity</code> 下面添加 <code>podAntiAffinity</code> 字段。</p><p>下面是一个例子：</p><pre><code>apiVersion: v1kind: Podmetadata:  name: with-pod-affinityspec:  affinity:    podAffinity:      requiredDuringSchedulingIgnoredDuringExecution:      - labelSelector:          matchExpressions:          - key: security            operator: In            values:            - S1        topologyKey: failure-domain.beta.kubernetes.io/zone    podAntiAffinity:      preferredDuringSchedulingIgnoredDuringExecution:      - weight: 100        podAffinityTerm:          labelSelector:            matchExpressions:            - key: security              operator: In              values:              - S2          topologyKey: kubernetes.io/hostname  containers:  - name: with-pod-affinity    image: gcr.io/google_containers/pause:2.0</code></pre><p>这个例子中，pod 需要调度到某个 zone（通过 <code>failure-domain.beta.kubernetes.io/zone</code> 指定），这个 zone 至少有一个节点上运行了这样的 pod：这个 pod 有 <code>security:S1</code> label。互斥性保证节点最好不要调度到这样的节点，这个节点上运行了某个 pod，而且这个 pod 有 <code>security:S2</code> label。</p><p>在 <code>labelSelector</code> 和 <code>topologyKey</code> 同级，还可以定义 <code>namespaces</code> 列表，表示匹配哪些 namespace 里面的 pod，默认情况下，会匹配定义的 pod 所在的 namespace；如果定义了这个字段，但是它的值为空，则匹配所有的 namespaces。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/" target="_blank" rel="noopener">Kubernetes Doc: Assigning Pods to Nodes</a></li><li><a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/nodeaffinity.md" target="_blank" rel="noopener">Node affinity and NodeSelector 设计文档</a></li><li><a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/podaffinity.md" target="_blank" rel="noopener">pod affinity and anti-affinity 设计文档</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        
        
          &lt;h2 id=&quot;kubernetes-pod-调度简介&quot;&gt;&lt;a href=&quot;#kubernetes-pod-调度简介&quot; class=&quot;headerlink&quot; title=&quot;kubernetes pod 调度简介&quot;&gt;&lt;/a&gt;kubernetes pod
        
      
    
    </summary>
    
      <category term="blog" scheme="http://cizixs.com/categories/blog/"/>
    
    
      <category term="kubernetes" scheme="http://cizixs.com/tags/kubernetes/"/>
    
      <category term="scheduler" scheme="http://cizixs.com/tags/scheduler/"/>
    
  </entry>
  
</feed>
